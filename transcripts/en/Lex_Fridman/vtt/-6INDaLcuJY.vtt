WEBVTT

1
00:00:01.070 --> 00:00:06.070
<v Speaker 1>Thank you everyone for braving the cold </v>
<v Speaker 1>and the snow to be here.</v>

2
00:00:08.030 --> 00:00:13.030
<v Speaker 1>This is six zero,</v>
<v Speaker 1>nine for deep learning for self driving </v>

3
00:00:13.030 --> 00:00:16.751
<v Speaker 1>cars and it's a course where we cover </v>
<v Speaker 1>the topic of deep learning,</v>

4
00:00:19.700 --> 00:00:24.700
<v Speaker 1>which is a set of techniques that have </v>
<v Speaker 1>taken a leap in the last decade for our </v>

5
00:00:26.240 --> 00:00:31.240
<v Speaker 1>understanding of what artificial </v>
<v Speaker 1>intelligence systems are capable of </v>

6
00:00:31.240 --> 00:00:34.481
<v Speaker 1>doing and self driving cars,</v>
<v Speaker 1>which is systems that can take these </v>

7
00:00:35.991 --> 00:00:39.680
<v Speaker 1>techniques and integrate them in a </v>
<v Speaker 1>meaningful,</v>

8
00:00:39.681 --> 00:00:44.681
<v Speaker 1>profound way into our daily lives in a </v>
<v Speaker 1>way that transforms society.</v>

9
00:00:45.890 --> 00:00:50.890
<v Speaker 1>So that's why both of these topics are </v>
<v Speaker 1>extremely important and extremely </v>

10
00:00:50.890 --> 00:00:55.511
<v Speaker 1>exciting.</v>
<v Speaker 1>My name is Lex Friedman and I'm joined </v>

11
00:00:55.511 --> 00:00:59.120
<v Speaker 1>by an amazing team of engineers and Jack</v>
<v Speaker 1>Terwilliger,</v>

12
00:00:59.760 --> 00:01:02.630
<v Speaker 1>Julia Kendall's Burger,</v>
<v Speaker 1>Dan Brown,</v>

13
00:01:02.840 --> 00:01:04.910
<v Speaker 1>Michael Glaser,</v>
<v Speaker 1>lead Ding,</v>

14
00:01:05.180 --> 00:01:06.190
<v Speaker 1>Spencer,</v>
<v Speaker 1>dod,</v>

15
00:01:06.470 --> 00:01:11.470
<v Speaker 1>and Ben antigenic among many others.</v>
<v Speaker 1>We build autonomous vehicles here at </v>

16
00:01:13.221 --> 00:01:18.221
<v Speaker 1>Mit,</v>
<v Speaker 1>not just ones that perceive and move </v>

17
00:01:18.221 --> 00:01:21.650
<v Speaker 1>about the environment,</v>
<v Speaker 1>but ones that interact,</v>

18
00:01:21.651 --> 00:01:26.651
<v Speaker 1>communicate and earn the trust and </v>
<v Speaker 1>understanding of human beings inside the</v>

19
00:01:27.501 --> 00:01:32.501
<v Speaker 1>car,</v>
<v Speaker 1>the drivers and the passengers and the </v>

20
00:01:32.501 --> 00:01:34.991
<v Speaker 1>human beings outside the car,</v>
<v Speaker 1>the pedestrians and other drivers and </v>

21
00:01:35.361 --> 00:01:36.080
<v Speaker 1>cyclists.</v>

22
00:01:39.310 --> 00:01:43.330
<v Speaker 1>The website for this course,</v>
<v Speaker 1>self driving cars that mit did to you,</v>

23
00:01:43.750 --> 00:01:47.320
<v Speaker 1>if you have questions,</v>
<v Speaker 1>email deep cars at Mit Dot Edu,</v>

24
00:01:48.100 --> 00:01:53.100
<v Speaker 1>slack,</v>
<v Speaker 1>deep dash mit for registered mit </v>

25
00:01:53.100 --> 00:01:57.810
<v Speaker 1>students.</v>
<v Speaker 1>You have to register on the website and </v>

26
00:01:58.390 --> 00:02:00.100
<v Speaker 1>by midnight,</v>
<v Speaker 1>Friday,</v>

27
00:02:00.160 --> 00:02:05.160
<v Speaker 1>January 19th,</v>
<v Speaker 1>building your own network and submitted </v>

28
00:02:05.160 --> 00:02:09.330
<v Speaker 1>to the competition that achieves the </v>
<v Speaker 1>speed of 65 miles per hour on the new </v>

29
00:02:09.431 --> 00:02:10.540
<v Speaker 1>deep traffic.</v>
<v Speaker 1>Two point.</v>

30
00:02:10.541 --> 00:02:15.541
<v Speaker 1>Oh,</v>
<v Speaker 1>it's much harder and much more </v>

31
00:02:15.541 --> 00:02:16.570
<v Speaker 1>interesting than last years.</v>
<v Speaker 1>For those of you who participated,</v>

32
00:02:18.010 --> 00:02:19.930
<v Speaker 1>there's three competitions in this </v>
<v Speaker 1>class.</v>

33
00:02:20.200 --> 00:02:22.630
<v Speaker 1>Deep traffic segued,</v>
<v Speaker 1>fuse,</v>

34
00:02:22.950 --> 00:02:27.950
<v Speaker 1>deep crash.</v>
<v Speaker 1>There's guest speakers that come from </v>

35
00:02:27.950 --> 00:02:28.540
<v Speaker 1>Waymo,</v>
<v Speaker 1>Google,</v>

36
00:02:29.680 --> 00:02:34.680
<v Speaker 1>Tesla,</v>
<v Speaker 1>and those are starting new autonomous </v>

37
00:02:34.691 --> 00:02:39.691
<v Speaker 1>vehicle startups in voyage.</v>
<v Speaker 1>You autonomy and Aurora and the news a </v>

38
00:02:44.301 --> 00:02:49.301
<v Speaker 1>lot today from cs and we have shirts for</v>
<v Speaker 1>those of you who brave the snow and </v>

39
00:02:52.731 --> 00:02:57.500
<v Speaker 1>continue to do so towards the end of the</v>
<v Speaker 1>class there'll be free shirts.</v>

40
00:02:57.830 --> 00:03:00.700
<v Speaker 1>Yes.</v>
<v Speaker 1>I said free and in the same sentence you</v>

41
00:03:00.701 --> 00:03:03.820
<v Speaker 1>should be here.</v>
<v Speaker 1>Okay.</v>

42
00:03:03.940 --> 00:03:06.280
<v Speaker 1>First,</v>
<v Speaker 1>the deep traffic competition.</v>

43
00:03:07.910 --> 00:03:10.790
<v Speaker 1>There's a lot of updates and we'll cover</v>
<v Speaker 1>those on Wednesday.</v>

44
00:03:11.270 --> 00:03:13.340
<v Speaker 1>It's a deeper enforcement learning </v>
<v Speaker 1>competition.</v>

45
00:03:13.820 --> 00:03:17.270
<v Speaker 1>Last year we received over 18,000</v>
<v Speaker 1>submissions.</v>

46
00:03:18.350 --> 00:03:20.840
<v Speaker 1>This year we're going to go bigger.</v>

47
00:03:23.150 --> 00:03:26.000
<v Speaker 1>Not only can you control one car,</v>
<v Speaker 1>well then you will now work.</v>

48
00:03:26.030 --> 00:03:28.990
<v Speaker 1>You can control up to 10.</v>
<v Speaker 1>This is multiagent,</v>

49
00:03:29.030 --> 00:03:31.910
<v Speaker 1>deeper enforcement learning.</v>
<v Speaker 1>This is super cool.</v>

50
00:03:34.190 --> 00:03:35.990
<v Speaker 1>Second,</v>
<v Speaker 1>psych fuse,</v>

51
00:03:36.080 --> 00:03:41.080
<v Speaker 1>dynamic driving scene segmentation </v>
<v Speaker 1>competition where you're given the raw </v>

52
00:03:42.651 --> 00:03:43.400
<v Speaker 1>video,</v>

53
00:03:44.900 --> 00:03:49.160
<v Speaker 1>the the kinematics of the vehicles and </v>
<v Speaker 1>the movement of the vehicle,</v>

54
00:03:49.790 --> 00:03:54.790
<v Speaker 1>the state of the art segmentation for </v>
<v Speaker 1>the training set you're given ground </v>

55
00:03:54.981 --> 00:03:56.870
<v Speaker 1>truth labels,</v>
<v Speaker 1>pixel level labels,</v>

56
00:03:56.871 --> 00:04:01.871
<v Speaker 1>scene segmentation and optical flow and </v>
<v Speaker 1>would those pieces of data your task to </v>

57
00:04:03.411 --> 00:04:08.411
<v Speaker 1>try to perform better than the state of </v>
<v Speaker 1>the art in image based segmentation.</v>

58
00:04:10.460 --> 00:04:15.460
<v Speaker 1>Why is this critical and fascinating and</v>
<v Speaker 1>open research problem?</v>

59
00:04:17.030 --> 00:04:22.030
<v Speaker 1>Because robots that act in this world </v>
<v Speaker 1>and the physical space not only must </v>

60
00:04:23.901 --> 00:04:28.901
<v Speaker 1>interpret,</v>
<v Speaker 1>use these deep learning methods to </v>

61
00:04:28.901 --> 00:04:28.901
<v Speaker 1>interpret the spacial visual </v>
<v Speaker 1>characteristics of a scene,</v>

62
00:04:29.210 --> 00:04:34.210
<v Speaker 1>they must also interpret,</v>
<v Speaker 1>understand and track the temporal </v>

63
00:04:34.210 --> 00:04:37.811
<v Speaker 1>dynamics of the scene.</v>
<v Speaker 1>This competition is about temporal </v>

64
00:04:37.811 --> 00:04:39.680
<v Speaker 1>propagation of information,</v>
<v Speaker 1>not just seen as segmentation.</v>

65
00:04:40.460 --> 00:04:45.460
<v Speaker 1>You must understand the space and time </v>
<v Speaker 1>and finally,</v>

66
00:04:47.470 --> 00:04:50.500
<v Speaker 1>deep crash where we use deeper </v>
<v Speaker 1>enforcement learning.</v>

67
00:04:50.800 --> 00:04:54.490
<v Speaker 1>The Slam cars thousands of times at uh,</v>
<v Speaker 1>at,</v>

68
00:04:54.491 --> 00:04:55.540
<v Speaker 1>uh,</v>
<v Speaker 1>here at Mit,</v>

69
00:04:55.541 --> 00:05:00.541
<v Speaker 1>at the gym,</v>
<v Speaker 1>you're given data on a thousand runs or </v>

70
00:05:01.570 --> 00:05:06.100
<v Speaker 1>car or a car knowing nothing is using a </v>
<v Speaker 1>monocular camera as a single input,</v>

71
00:05:06.310 --> 00:05:11.310
<v Speaker 1>driving over 30 miles an hour through a </v>
<v Speaker 1>scene that has very little control </v>

72
00:05:11.310 --> 00:05:13.330
<v Speaker 1>through very little capability to </v>
<v Speaker 1>localize itself.</v>

73
00:05:13.390 --> 00:05:18.390
<v Speaker 1>It must act very quickly in that scene.</v>
<v Speaker 1>You're given a thousand runs to learn </v>

74
00:05:18.390 --> 00:05:18.640
<v Speaker 1>anything.</v>

75
00:05:21.470 --> 00:05:26.470
<v Speaker 1>We'll discuss this in the coming weeks.</v>
<v Speaker 1>This competition will result in for </v>

76
00:05:27.811 --> 00:05:32.290
<v Speaker 1>submissions that we evaluate everyone's </v>
<v Speaker 1>in simulation,</v>

77
00:05:32.710 --> 00:05:37.710
<v Speaker 1>but the taskforce submissions we put </v>
<v Speaker 1>head to head at the gym and until there </v>

78
00:05:37.871 --> 00:05:42.871
<v Speaker 1>is a winner declared what keep slamming </v>
<v Speaker 1>cars at 30 miles an hour deep crash and </v>

79
00:05:45.551 --> 00:05:49.180
<v Speaker 1>also on the website is from last year.</v>
<v Speaker 1>And on get hub,</v>

80
00:05:49.181 --> 00:05:54.181
<v Speaker 1>there's deep tesla,</v>
<v Speaker 1>which is using the large scale </v>

81
00:05:54.181 --> 00:05:57.601
<v Speaker 1>naturalistic driving data set.</v>
<v Speaker 1>We have to train a neural network to do </v>

82
00:05:57.601 --> 00:06:01.471
<v Speaker 1>end to end steering.</v>
<v Speaker 1>It takes in monocular video from the </v>

83
00:06:01.471 --> 00:06:04.811
<v Speaker 1>forward roadway and produce the steering</v>
<v Speaker 1>commands that steering commands for the </v>

84
00:06:04.821 --> 00:06:05.120
<v Speaker 1>car</v>

85
00:06:07.140 --> 00:06:12.140
<v Speaker 1>lectures.</v>
<v Speaker 1>Today we'll talk about deep learning </v>

86
00:06:12.140 --> 00:06:15.170
<v Speaker 1>tomorrow.</v>
<v Speaker 1>We'll talk about autonomous vehicles </v>

87
00:06:15.170 --> 00:06:16.260
<v Speaker 1>drls on Wednesday,</v>
<v Speaker 1>driving,</v>

88
00:06:16.261 --> 00:06:17.670
<v Speaker 1>seeing,</v>
<v Speaker 1>understanding,</v>

89
00:06:17.671 --> 00:06:20.970
<v Speaker 1>so segmentation,</v>
<v Speaker 1>that's Thursday.</v>

90
00:06:21.930 --> 00:06:26.930
<v Speaker 1>On Friday we have Sasha or knew the </v>
<v Speaker 1>director of engineering at Waymo.</v>

91
00:06:27.570 --> 00:06:32.570
<v Speaker 1>Waymo is one of the companies that's </v>
<v Speaker 1>truly taking huge strides and fully </v>

92
00:06:32.570 --> 00:06:37.341
<v Speaker 1>autonomous vehicles.</v>
<v Speaker 1>They're taking the fully l four l five </v>

93
00:06:37.341 --> 00:06:38.850
<v Speaker 1>autonomous vehicle approach and it's </v>
<v Speaker 1>fascinating to learn.</v>

94
00:06:39.240 --> 00:06:44.240
<v Speaker 1>He's also the head of perception for </v>
<v Speaker 1>them to learn from him what kind of </v>

95
00:06:44.611 --> 00:06:47.310
<v Speaker 1>problems they're facing,</v>
<v Speaker 1>what kind of approach they're taking on.</v>

96
00:06:47.770 --> 00:06:49.320
<v Speaker 1>We have a meal.</v>
<v Speaker 1>If Rizzoli,</v>

97
00:06:49.590 --> 00:06:52.020
<v Speaker 1>who won to last year,</v>
<v Speaker 1>speakers start to ask.</v>

98
00:06:52.021 --> 00:06:55.110
<v Speaker 1>Carmen said,</v>
<v Speaker 1>Amelia is the smartest person who knows,</v>

99
00:06:55.770 --> 00:06:59.490
<v Speaker 1>so Amelia for is the cto of autonomy and</v>
<v Speaker 1>autonomous vehicle,</v>

100
00:07:00.190 --> 00:07:05.190
<v Speaker 1>a company that was just acquired by </v>
<v Speaker 1>Delphi for a large sum of money and </v>

101
00:07:05.221 --> 00:07:08.490
<v Speaker 1>they're doing a lot of incredible work </v>
<v Speaker 1>in Singapore and here in Boston.</v>

102
00:07:10.320 --> 00:07:15.320
<v Speaker 1>Next Wednesday we are going to talk </v>
<v Speaker 1>about the topic of our research or my </v>

103
00:07:16.201 --> 00:07:19.820
<v Speaker 1>personal fascination is deep learning </v>
<v Speaker 1>for drivers,</v>

104
00:07:19.821 --> 00:07:22.290
<v Speaker 1>states sensing,</v>
<v Speaker 1>understanding the human perceiving,</v>

105
00:07:22.291 --> 00:07:24.380
<v Speaker 1>everything about the human being inside </v>
<v Speaker 1>the car,</v>

106
00:07:24.460 --> 00:07:29.460
<v Speaker 1>outside the car.</v>
<v Speaker 1>One Talk I'm really excited about is </v>

107
00:07:29.950 --> 00:07:31.500
<v Speaker 1>Oliver Cameron.</v>
<v Speaker 1>On Thursday,</v>

108
00:07:32.640 --> 00:07:36.990
<v Speaker 1>he is now the CEO of of autonomous </v>
<v Speaker 1>vehicle startup voyage.</v>

109
00:07:37.160 --> 00:07:41.400
<v Speaker 1>He was previously the director of the </v>
<v Speaker 1>self driving car program free udacity.</v>

110
00:07:41.790 --> 00:07:45.990
<v Speaker 1>He will talk about how to start a self </v>
<v Speaker 1>driving car company.</v>

111
00:07:46.440 --> 00:07:50.550
<v Speaker 1>For those it said that Mit folks and </v>
<v Speaker 1>entrepreneurs,</v>

112
00:07:50.690 --> 00:07:55.690
<v Speaker 1>if you want to start one yourself,</v>
<v Speaker 1>they'll tell you exactly how it's super </v>

113
00:07:55.690 --> 00:07:59.631
<v Speaker 1>cool and then sterling Anderson who was </v>
<v Speaker 1>the director previously,</v>

114
00:08:01.360 --> 00:08:05.880
<v Speaker 1>a tesla autopilot team and now is the </v>
<v Speaker 1>cofounder of Aurora,</v>

115
00:08:06.650 --> 00:08:11.650
<v Speaker 1>the car,</v>
<v Speaker 1>the self driving car startup that I </v>

116
00:08:11.650 --> 00:08:13.680
<v Speaker 1>mentioned that has now partnered with </v>
<v Speaker 1>Nvidia and many others,</v>

117
00:08:13.890 --> 00:08:18.890
<v Speaker 1>so why self driving cars?</v>
<v Speaker 1>Those classes about applying data driven</v>

118
00:08:19.710 --> 00:08:22.620
<v Speaker 1>learning methods to the problem of </v>
<v Speaker 1>autonomous vehicles.</v>

119
00:08:23.280 --> 00:08:28.280
<v Speaker 1>Why self driving cars are fascinating </v>
<v Speaker 1>and interesting problem space quite </v>

120
00:08:30.571 --> 00:08:35.571
<v Speaker 1>possibly in my opinion,</v>
<v Speaker 1>this is the first wide reaching and </v>

121
00:08:35.851 --> 00:08:40.851
<v Speaker 1>profound integration of personal robots </v>
<v Speaker 1>in society wide reaching because there's</v>

122
00:08:41.551 --> 00:08:45.810
<v Speaker 1>1 billion cars on the road.</v>
<v Speaker 1>Even a fraction of that will change</v>

123
00:08:47.110 --> 00:08:52.110
<v Speaker 1>the face of transportation and how we </v>
<v Speaker 1>move about the world profound,</v>

124
00:08:53.050 --> 00:08:56.160
<v Speaker 1>and this is an important point that's </v>
<v Speaker 1>always understood,</v>

125
00:08:57.570 --> 00:09:02.570
<v Speaker 1>is there's an intimate connection </v>
<v Speaker 1>between a human and a vehicle.</v>

126
00:09:04.290 --> 00:09:07.110
<v Speaker 1>When there's a direct transfer of </v>
<v Speaker 1>control,</v>

127
00:09:07.620 --> 00:09:12.620
<v Speaker 1>it's a direct transfer of control that </v>
<v Speaker 1>takes that his or her life into the </v>

128
00:09:13.381 --> 00:09:15.180
<v Speaker 1>hands of an artificial intelligence </v>
<v Speaker 1>system.</v>

129
00:09:16.110 --> 00:09:17.260
<v Speaker 1>I showed a few quick,</v>
<v Speaker 1>quick,</v>

130
00:09:17.960 --> 00:09:22.960
<v Speaker 1>quick,</v>
<v Speaker 1>quick clips here you can google first </v>

131
00:09:22.960 --> 00:09:24.090
<v Speaker 1>time with Tesla,</v>
<v Speaker 1>autopilot on Youtube,</v>

132
00:09:24.270 --> 00:09:27.240
<v Speaker 1>and watch people perform that transfer </v>
<v Speaker 1>of control.</v>

133
00:09:27.720 --> 00:09:32.720
<v Speaker 1>There's something magical about a human </v>
<v Speaker 1>and a robot working together that will </v>

134
00:09:34.230 --> 00:09:39.230
<v Speaker 1>transform what artificial intelligence </v>
<v Speaker 1>is in the 21st century and this </v>

135
00:09:39.601 --> 00:09:42.720
<v Speaker 1>particular autonomous system,</v>
<v Speaker 1>ai system,</v>

136
00:09:42.750 --> 00:09:47.750
<v Speaker 1>self driving cars,</v>
<v Speaker 1>is on the scale and the profound,</v>

137
00:09:47.880 --> 00:09:52.880
<v Speaker 1>the life critical nature of it is </v>
<v Speaker 1>profound in a way that will truly test </v>

138
00:09:52.880 --> 00:09:57.560
<v Speaker 1>the capabilities of Ai.</v>
<v Speaker 1>There is a personal connection that will</v>

139
00:09:58.350 --> 00:10:01.680
<v Speaker 1>argue throughout these lectures that we </v>
<v Speaker 1>cannot escape.</v>

140
00:10:01.681 --> 00:10:06.681
<v Speaker 1>Considering the human being,</v>
<v Speaker 1>that autonomous vehicle must not only </v>

141
00:10:06.681 --> 00:10:08.490
<v Speaker 1>perceive and control its movement </v>
<v Speaker 1>through the environment.</v>

142
00:10:08.720 --> 00:10:13.720
<v Speaker 1>It must also perceive everything about </v>
<v Speaker 1>the human driver and the passenger and </v>

143
00:10:13.720 --> 00:10:13.770
<v Speaker 1>interact,</v>
<v Speaker 1>communicate,</v>

144
00:10:13.771 --> 00:10:15.270
<v Speaker 1>and build trust with that driver.</v>

145
00:10:20.270 --> 00:10:25.270
<v Speaker 1>Because in my view,</v>
<v Speaker 1>as I will argue throughout this course,</v>

146
00:10:27.170 --> 00:10:32.170
<v Speaker 1>an autonomous vehicle is more of a </v>
<v Speaker 1>personal robot than it is a perfect </v>

147
00:10:32.601 --> 00:10:37.601
<v Speaker 1>perception control system.</v>
<v Speaker 1>Because perfect perception and control,</v>

148
00:10:38.090 --> 00:10:43.090
<v Speaker 1>so this world full of humans is </v>
<v Speaker 1>extremely difficult and could be two,</v>

149
00:10:44.601 --> 00:10:46.160
<v Speaker 1>three,</v>
<v Speaker 1>four decades away,</v>

150
00:10:46.940 --> 00:10:51.940
<v Speaker 1>full autonomy.</v>
<v Speaker 1>Autonomous Vehicles are going to be </v>

151
00:10:51.940 --> 00:10:56.920
<v Speaker 1>flawed,</v>
<v Speaker 1>they're going to have flaws and we'll </v>

152
00:10:56.920 --> 00:11:00.261
<v Speaker 1>have to design systems that are </v>
<v Speaker 1>effectively caught effectively transfer </v>

153
00:11:00.351 --> 00:11:03.950
<v Speaker 1>control to human beings when they can't </v>
<v Speaker 1>handle the situation,</v>

154
00:11:04.130 --> 00:11:09.130
<v Speaker 1>and that transfer of control isn't as a </v>
<v Speaker 1>fascinating opportunity for ai because </v>

155
00:11:14.780 --> 00:11:19.640
<v Speaker 1>the obstacle avoidance perception of </v>
<v Speaker 1>obstacles,</v>

156
00:11:19.670 --> 00:11:22.850
<v Speaker 1>an obstacle avoidance is the easy </v>
<v Speaker 1>problem.</v>

157
00:11:23.900 --> 00:11:28.900
<v Speaker 1>It's the safe problem.</v>
<v Speaker 1>Going 30 miles an hour and navigating </v>

158
00:11:28.900 --> 00:11:32.140
<v Speaker 1>through streets of Boston is easy.</v>
<v Speaker 1>It's when you have to get to work in </v>

159
00:11:33.651 --> 00:11:38.360
<v Speaker 1>your late or you're sick of the person </v>
<v Speaker 1>in front of you that you want to go into</v>

160
00:11:38.361 --> 00:11:41.000
<v Speaker 1>the er in the opposing lane and speed </v>
<v Speaker 1>up.</v>

161
00:11:41.540 --> 00:11:46.540
<v Speaker 1>That's human nature and we can't escape </v>
<v Speaker 1>it are artificial assist intelligence </v>

162
00:11:46.581 --> 00:11:50.210
<v Speaker 1>systems can't escape human nature.</v>
<v Speaker 1>They must work with it.</v>

163
00:11:50.990 --> 00:11:54.940
<v Speaker 1>What's shown here is one of the </v>
<v Speaker 1>algorithms will talk about next week for</v>

164
00:11:54.941 --> 00:11:59.941
<v Speaker 1>cognitive load or we take the raw 3d </v>
<v Speaker 1>accomplished in your networks,</v>

165
00:12:00.680 --> 00:12:03.280
<v Speaker 1>taken the eye region,</v>
<v Speaker 1>the blinking,</v>

166
00:12:03.310 --> 00:12:06.490
<v Speaker 1>and the pupil movement to determine the </v>
<v Speaker 1>cognitive load of the driver.</v>

167
00:12:06.910 --> 00:12:09.790
<v Speaker 1>We'll see how we can detect everything </v>
<v Speaker 1>about the driver,</v>

168
00:12:09.880 --> 00:12:12.100
<v Speaker 1>where they're looking.</v>
<v Speaker 1>Emotion,</v>

169
00:12:12.550 --> 00:12:14.530
<v Speaker 1>cognitive load,</v>
<v Speaker 1>body pose,</v>

170
00:12:14.531 --> 00:12:17.200
<v Speaker 1>estimation,</v>
<v Speaker 1>drowsiness,</v>

171
00:12:18.420 --> 00:12:22.900
<v Speaker 1>the the.</v>
<v Speaker 1>The movement towards full autonomy is so</v>

172
00:12:22.901 --> 00:12:27.901
<v Speaker 1>difficult.</v>
<v Speaker 1>I would argue that it almost requires </v>

173
00:12:27.901 --> 00:12:32.170
<v Speaker 1>human level intelligence that the,</v>
<v Speaker 1>as I said,</v>

174
00:12:32.200 --> 00:12:32.710
<v Speaker 1>two,</v>
<v Speaker 1>three,</v>

175
00:12:32.720 --> 00:12:37.720
<v Speaker 1>four decade out journey for artificial </v>
<v Speaker 1>intelligence researchers to achieve full</v>

176
00:12:38.291 --> 00:12:42.010
<v Speaker 1>autonomy will require achieving,</v>
<v Speaker 1>solving some of the problems,</v>

177
00:12:42.011 --> 00:12:45.010
<v Speaker 1>fundamental problems of creating </v>
<v Speaker 1>intelligence,</v>

178
00:12:46.720 --> 00:12:51.720
<v Speaker 1>and that's something we'll discuss in </v>
<v Speaker 1>much more depth in a broader view in two</v>

179
00:12:52.301 --> 00:12:57.301
<v Speaker 1>weeks.</v>
<v Speaker 1>For the artificial general intelligence </v>

180
00:12:57.301 --> 00:12:58.180
<v Speaker 1>course where we have Andrea neuropathy </v>
<v Speaker 1>from Tesla,</v>

181
00:12:58.181 --> 00:13:01.480
<v Speaker 1>Ray Kurzweil,</v>
<v Speaker 1>Mark Robert from Boston,</v>

182
00:13:01.481 --> 00:13:06.481
<v Speaker 1>dynamics who asked for the dimensions of</v>
<v Speaker 1>the room because he's bringing robots.</v>

183
00:13:08.500 --> 00:13:12.610
<v Speaker 1>Nothing else was told to me,</v>
<v Speaker 1>it'll be a surprise.</v>

184
00:13:16.060 --> 00:13:21.060
<v Speaker 1>So that is why I argued the human </v>
<v Speaker 1>centered artificial intelligence </v>

185
00:13:21.060 --> 00:13:23.200
<v Speaker 1>approach in every algorithm design </v>
<v Speaker 1>considers the human</v>

186
00:13:26.230 --> 00:13:31.060
<v Speaker 1>for autonomous vehicle on the left,</v>
<v Speaker 1>the perception seen understanding,</v>

187
00:13:31.450 --> 00:13:36.450
<v Speaker 1>and the control problem as we'll explore</v>
<v Speaker 1>through the competitions and the </v>

188
00:13:36.450 --> 00:13:39.841
<v Speaker 1>assignments of this course can handle 90</v>
<v Speaker 1>and increasing percent of the cases,</v>

189
00:13:42.430 --> 00:13:47.430
<v Speaker 1>but it's the ten one point one percent </v>
<v Speaker 1>of the cases as we get better and better</v>

190
00:13:48.370 --> 00:13:53.370
<v Speaker 1>that we have to,</v>
<v Speaker 1>we're not able to handle to these </v>

191
00:13:53.370 --> 00:13:56.731
<v Speaker 1>methods.</v>
<v Speaker 1>And that's where the human perceiving </v>

192
00:13:56.731 --> 00:13:59.190
<v Speaker 1>the human is really important.</v>
<v Speaker 1>This is the video from last year of Arc </v>

193
00:13:59.190 --> 00:14:00.100
<v Speaker 1>de Triomphe.</v>
<v Speaker 1>Thank you.</v>

194
00:14:00.190 --> 00:14:01.720
<v Speaker 1>I didn't know what last year.</v>
<v Speaker 1>I know now.</v>

195
00:14:03.180 --> 00:14:08.180
<v Speaker 1>That's one of millions of cases where </v>
<v Speaker 1>human to human interaction is the is the</v>

196
00:14:10.570 --> 00:14:15.570
<v Speaker 1>dominant driver,</v>
<v Speaker 1>not the basic perception control </v>

197
00:14:15.570 --> 00:14:20.191
<v Speaker 1>problem.</v>
<v Speaker 1>So why deep learning in this space,</v>

198
00:14:23.760 --> 00:14:28.760
<v Speaker 1>because deep learning is a set of </v>
<v Speaker 1>methods that do well from a lot of data </v>

199
00:14:31.500 --> 00:14:35.520
<v Speaker 1>and to solve these problems or human </v>
<v Speaker 1>life is a stake.</v>

200
00:14:35.760 --> 00:14:39.750
<v Speaker 1>We have to be able to have techniques </v>
<v Speaker 1>that learn from data,</v>

201
00:14:39.930 --> 00:14:44.930
<v Speaker 1>learn from real world data.</v>
<v Speaker 1>This is the fundamental reality of </v>

202
00:14:44.930 --> 00:14:46.890
<v Speaker 1>artificial intelligence systems that </v>
<v Speaker 1>operate in the real world.</v>

203
00:14:47.040 --> 00:14:51.090
<v Speaker 1>They must learn from real world data,</v>
<v Speaker 1>whether that's on the left,</v>

204
00:14:51.230 --> 00:14:53.000
<v Speaker 1>the perception,</v>
<v Speaker 1>the control side,</v>

205
00:14:54.830 --> 00:14:59.030
<v Speaker 1>on the right for the human,</v>
<v Speaker 1>the perception and the communication,</v>

206
00:14:59.031 --> 00:15:04.031
<v Speaker 1>interaction and collaboration with the </v>
<v Speaker 1>human and the human robot interaction.</v>

207
00:15:06.760 --> 00:15:09.580
<v Speaker 1>Okay,</v>
<v Speaker 1>so what is deep learning?</v>

208
00:15:13.200 --> 00:15:18.200
<v Speaker 1>It's a set of techniques.</v>
<v Speaker 1>If you allow me the definition of </v>

209
00:15:18.200 --> 00:15:20.520
<v Speaker 1>intelligence being the ability to </v>
<v Speaker 1>accomplish complex goals,</v>

210
00:15:21.480 --> 00:15:24.690
<v Speaker 1>then I would argue definition of </v>
<v Speaker 1>understanding,</v>

211
00:15:25.080 --> 00:15:30.080
<v Speaker 1>maybe reasoning is the ability to turn </v>
<v Speaker 1>complex information into simple,</v>

212
00:15:31.440 --> 00:15:36.440
<v Speaker 1>useful,</v>
<v Speaker 1>actionable information and that is what </v>

213
00:15:36.440 --> 00:15:39.300
<v Speaker 1>deep learning does.</v>
<v Speaker 1>Deep learning is representation,</v>

214
00:15:39.301 --> 00:15:42.300
<v Speaker 1>learning or feature learning,</v>
<v Speaker 1>if you will.</v>

215
00:15:43.200 --> 00:15:48.200
<v Speaker 1>It's able to take raw information,</v>
<v Speaker 1>raw complicated information that's hard </v>

216
00:15:48.541 --> 00:15:53.541
<v Speaker 1>to do.</v>
<v Speaker 1>Anything with and construct here are </v>

217
00:15:53.541 --> 00:15:56.030
<v Speaker 1>hierarchical representation of that </v>
<v Speaker 1>information to be able to do something </v>

218
00:15:56.030 --> 00:15:59.991
<v Speaker 1>interesting with it.</v>
<v Speaker 1>It is the branch of artificial </v>

219
00:15:59.991 --> 00:16:02.790
<v Speaker 1>intelligence which is most capable and </v>
<v Speaker 1>focused on this task.</v>

220
00:16:04.030 --> 00:16:06.030
<v Speaker 1>For me,</v>
<v Speaker 1>representations from data,</v>

221
00:16:06.360 --> 00:16:08.340
<v Speaker 1>whether it's supervised and </v>
<v Speaker 1>unsupervised,</v>

222
00:16:08.370 --> 00:16:10.410
<v Speaker 1>whether it's with the help of humans or </v>
<v Speaker 1>not,</v>

223
00:16:10.770 --> 00:16:15.770
<v Speaker 1>it's able to construct structure,</v>
<v Speaker 1>find structure in the data such that you</v>

224
00:16:16.591 --> 00:16:19.740
<v Speaker 1>can extract simple,</v>
<v Speaker 1>useful,</v>

225
00:16:19.741 --> 00:16:24.741
<v Speaker 1>actionable information.</v>
<v Speaker 1>On the left for me in Goodfellas book is</v>

226
00:16:27.720 --> 00:16:30.060
<v Speaker 1>the basic example of a </v>
<v Speaker 1>misclassification,</v>

227
00:16:30.840 --> 00:16:35.840
<v Speaker 1>the input of the image on the bottom </v>
<v Speaker 1>with the raw pixels,</v>

228
00:16:36.560 --> 00:16:41.560
<v Speaker 1>and as we go up the stack as a go up,</v>
<v Speaker 1>the layers hiring higher order </v>

229
00:16:41.560 --> 00:16:45.881
<v Speaker 1>representations of formed from edges to </v>
<v Speaker 1>contours the corners to object parts,</v>

230
00:16:46.400 --> 00:16:50.030
<v Speaker 1>and then finally the full object </v>
<v Speaker 1>semantic classification of what's in the</v>

231
00:16:50.031 --> 00:16:53.210
<v Speaker 1>image.</v>
<v Speaker 1>This is representation learning.</v>

232
00:16:54.300 --> 00:16:55.760
<v Speaker 1>A favorite example for me</v>

233
00:16:57.580 --> 00:17:02.580
<v Speaker 1>is one from for centuries ago,</v>
<v Speaker 1>our place in the universe and </v>

234
00:17:05.281 --> 00:17:09.510
<v Speaker 1>representing that place in the universe,</v>
<v Speaker 1>whether it's relative to Earth,</v>

235
00:17:09.810 --> 00:17:14.810
<v Speaker 1>are relative to the sun.</v>
<v Speaker 1>On the left is our current belief.</v>

236
00:17:16.930 --> 00:17:21.760
<v Speaker 1>On the right is the one that is held </v>
<v Speaker 1>widely for centuries ago.</v>

237
00:17:23.290 --> 00:17:28.290
<v Speaker 1>Representation matters because what's on</v>
<v Speaker 1>the right is much more complicated than </v>

238
00:17:28.331 --> 00:17:29.140
<v Speaker 1>what's on the left.</v>

239
00:17:34.400 --> 00:17:39.400
<v Speaker 1>You can think of in a simple case here,</v>
<v Speaker 1>when the task is to draw a line that </v>

240
00:17:39.400 --> 00:17:43.711
<v Speaker 1>separates green triangles and blue </v>
<v Speaker 1>circles in the cartesian coordinate </v>

241
00:17:43.711 --> 00:17:45.560
<v Speaker 1>space on the left,</v>
<v Speaker 1>the task is much more difficult.</v>

242
00:17:45.590 --> 00:17:49.320
<v Speaker 1>Impossible to do well on the right is </v>
<v Speaker 1>trivial.</v>

243
00:17:49.470 --> 00:17:54.470
<v Speaker 1>In polar coordinates,</v>
<v Speaker 1>this transformation is exactly what we </v>

244
00:17:54.661 --> 00:17:59.661
<v Speaker 1>need to learn.</v>
<v Speaker 1>This is representation learning so you </v>

245
00:17:59.661 --> 00:18:01.740
<v Speaker 1>can take the same task of having to draw</v>
<v Speaker 1>a line that separates the blue curve and</v>

246
00:18:01.741 --> 00:18:05.520
<v Speaker 1>the red curve on the left.</v>
<v Speaker 1>If we draw a straight line,</v>

247
00:18:05.730 --> 00:18:10.730
<v Speaker 1>it's going to be a high.</v>
<v Speaker 1>There is no way to do it was zero error </v>

248
00:18:11.380 --> 00:18:16.080
<v Speaker 1>with 100 percent accuracy.</v>
<v Speaker 1>Shown on the right is our best attempt,</v>

249
00:18:18.510 --> 00:18:23.510
<v Speaker 1>but what we can do with deep learning </v>
<v Speaker 1>with a single hidden layer network done </v>

250
00:18:23.510 --> 00:18:27.441
<v Speaker 1>here is formed the the topology,</v>
<v Speaker 1>the mapping of the space in such a way </v>

251
00:18:28.741 --> 00:18:31.980
<v Speaker 1>in the middle that allows for a straight</v>
<v Speaker 1>line to be drawn.</v>

252
00:18:31.981 --> 00:18:34.080
<v Speaker 1>This separates the blue curve and the </v>
<v Speaker 1>red curve.</v>

253
00:18:35.130 --> 00:18:40.130
<v Speaker 1>The learning of the function in the </v>
<v Speaker 1>middle is what we're able to achieve </v>

254
00:18:40.130 --> 00:18:43.770
<v Speaker 1>with deep learning.</v>
<v Speaker 1>It's taking raw,</v>

255
00:18:43.800 --> 00:18:47.820
<v Speaker 1>complicated information and making it </v>
<v Speaker 1>simple,</v>

256
00:18:48.600 --> 00:18:50.460
<v Speaker 1>actionable,</v>
<v Speaker 1>useful,</v>

257
00:18:51.840 --> 00:18:56.840
<v Speaker 1>and the point is that this kind of </v>
<v Speaker 1>ability to learn from raw sensory </v>

258
00:18:57.290 --> 00:19:01.620
<v Speaker 1>information means that we can do a lot </v>
<v Speaker 1>more with a lot more data,</v>

259
00:19:03.030 --> 00:19:06.150
<v Speaker 1>so deep learning gets better with more </v>
<v Speaker 1>data</v>

260
00:19:09.640 --> 00:19:12.220
<v Speaker 1>and that's important for real world </v>
<v Speaker 1>applications</v>

261
00:19:14.470 --> 00:19:19.470
<v Speaker 1>were edge cases are everything.</v>
<v Speaker 1>This is us driving to perception control</v>

262
00:19:20.801 --> 00:19:25.801
<v Speaker 1>systems.</v>
<v Speaker 1>One is an tesla vehicle with the </v>

263
00:19:25.801 --> 00:19:28.360
<v Speaker 1>autopilot version one system that's </v>
<v Speaker 1>using a monocular camera to perceive the</v>

264
00:19:28.361 --> 00:19:33.361
<v Speaker 1>external environment and produce control</v>
<v Speaker 1>decisions and our own neural network </v>

265
00:19:33.701 --> 00:19:38.701
<v Speaker 1>running an adjustment [inaudible] that's</v>
<v Speaker 1>taking in the same with a monocular </v>

266
00:19:38.701 --> 00:19:42.601
<v Speaker 1>camera and producing controlled </v>
<v Speaker 1>decisions and the two systems argue and </v>

267
00:19:43.181 --> 00:19:46.750
<v Speaker 1>when they disagree,</v>
<v Speaker 1>they raise up a flag to say that this is</v>

268
00:19:46.751 --> 00:19:49.210
<v Speaker 1>an edge case.</v>
<v Speaker 1>These that needs human intervention.</v>

269
00:19:50.350 --> 00:19:55.350
<v Speaker 1>There is covering such edge cases using </v>
<v Speaker 1>machine learning is the main problem,</v>

270
00:19:57.010 --> 00:20:00.850
<v Speaker 1>our artificial intelligence and in when </v>
<v Speaker 1>applied to the real world,</v>

271
00:20:01.150 --> 00:20:05.620
<v Speaker 1>it is the main problem to solve.</v>
<v Speaker 1>Okay,</v>

272
00:20:06.190 --> 00:20:11.020
<v Speaker 1>so what are neural networks inspired?</v>
<v Speaker 1>Very loosely,</v>

273
00:20:11.080 --> 00:20:16.080
<v Speaker 1>and I'll discuss about the key </v>
<v Speaker 1>difference here in our own brains and </v>

274
00:20:16.080 --> 00:20:19.630
<v Speaker 1>artificial brains because there's a lot </v>
<v Speaker 1>of insights in that difference,</v>

275
00:20:20.350 --> 00:20:23.890
<v Speaker 1>but inspired loosely by biological </v>
<v Speaker 1>neural networks.</v>

276
00:20:23.891 --> 00:20:28.450
<v Speaker 1>Here is a simulation of a </v>
<v Speaker 1>thalamocortical brain network,</v>

277
00:20:28.480 --> 00:20:33.400
<v Speaker 1>which is only 3 million neurons,</v>
<v Speaker 1>476 million synapses.</v>

278
00:20:33.430 --> 00:20:37.330
<v Speaker 1>The full human brain is a lot more than </v>
<v Speaker 1>that 100 billion neurons.</v>

279
00:20:37.840 --> 00:20:42.840
<v Speaker 1>One thousand trillion synapses.</v>
<v Speaker 1>There's inspirational music with this </v>

280
00:20:47.951 --> 00:20:52.951
<v Speaker 1>one that I didn't realize was here </v>
<v Speaker 1>should make you think artificial neural </v>

281
00:20:54.520 --> 00:20:56.010
<v Speaker 1>networks.</v>
<v Speaker 1>Yeah,</v>

282
00:20:56.020 --> 00:20:59.870
<v Speaker 1>let's just let it play.</v>
<v Speaker 1>The.</v>

283
00:21:00.500 --> 00:21:03.610
<v Speaker 1>The human neural network is 100 billion </v>
<v Speaker 1>neurons,</v>

284
00:21:03.611 --> 00:21:06.130
<v Speaker 1>right?</v>
<v Speaker 1>One thousand trillion synapses,</v>

285
00:21:06.910 --> 00:21:11.830
<v Speaker 1>one of the state of the state of the art</v>
<v Speaker 1>neural networks as resident at 1:52,</v>

286
00:21:12.010 --> 00:21:14.800
<v Speaker 1>which has $60,</v>
<v Speaker 1>million synapses.</v>

287
00:21:17.160 --> 00:21:22.160
<v Speaker 1>That's a difference of about a seven </v>
<v Speaker 1>order of magnitude difference.</v>

288
00:21:22.410 --> 00:21:27.410
<v Speaker 1>The human brains have 10 million times </v>
<v Speaker 1>more synapses than artificial neural </v>

289
00:21:27.421 --> 00:21:32.160
<v Speaker 1>networks plus or minus one order of </v>
<v Speaker 1>magnitude depending on the network.</v>

290
00:21:34.090 --> 00:21:38.820
<v Speaker 1>So what's the difference between a </v>
<v Speaker 1>biological neuron and artificial neuron?</v>

291
00:21:40.210 --> 00:21:42.760
<v Speaker 1>The topology of the human brain have no </v>
<v Speaker 1>layers.</v>

292
00:21:42.820 --> 00:21:47.740
<v Speaker 1>Neural networks are stacked and layers,</v>
<v Speaker 1>they're fixed for the most part.</v>

293
00:21:49.000 --> 00:21:53.410
<v Speaker 1>There is chaos.</v>
<v Speaker 1>Very little structure in our human brain</v>

294
00:21:53.411 --> 00:21:58.411
<v Speaker 1>in terms of Han neurons are connected.</v>
<v Speaker 1>They're connected often to 10,000</v>

295
00:21:58.540 --> 00:22:03.540
<v Speaker 1>plus other neurons.</v>
<v Speaker 1>The number of synopsis from individual </v>

296
00:22:03.540 --> 00:22:03.540
<v Speaker 1>neurons that are,</v>
<v Speaker 1>uh,</v>

297
00:22:03.540 --> 00:22:08.500
<v Speaker 1>that are input into the neuron is huge.</v>
<v Speaker 1>There are asynchronous.</v>

298
00:22:08.530 --> 00:22:11.020
<v Speaker 1>The human brain brain works </v>
<v Speaker 1>asynchronously.</v>

299
00:22:11.230 --> 00:22:13.270
<v Speaker 1>Artificial neural networks work </v>
<v Speaker 1>synchronously.</v>

300
00:22:15.450 --> 00:22:18.990
<v Speaker 1>The learning algorithm for artificial </v>
<v Speaker 1>neuron networks,</v>

301
00:22:19.500 --> 00:22:24.120
<v Speaker 1>the only one,</v>
<v Speaker 1>the best one is backpropagation.</v>

302
00:22:25.470 --> 00:22:30.470
<v Speaker 1>And we don't know how human brains learn</v>
<v Speaker 1>processing speed.</v>

303
00:22:35.680 --> 00:22:40.680
<v Speaker 1>This is one of the,</v>
<v Speaker 1>the only benefits we have with </v>

304
00:22:40.680 --> 00:22:44.320
<v Speaker 1>artificial neural networks is artificial</v>
<v Speaker 1>neurons are faster,</v>

305
00:22:45.430 --> 00:22:48.250
<v Speaker 1>but they're also extremely power and </v>
<v Speaker 1>efficient.</v>

306
00:22:50.730 --> 00:22:55.730
<v Speaker 1>And there is a division into stages of </v>
<v Speaker 1>training and testing when you're on that</v>

307
00:22:55.791 --> 00:22:56.850
<v Speaker 1>works,</v>
<v Speaker 1>uh,</v>

308
00:22:56.851 --> 00:22:57.720
<v Speaker 1>with,</v>
<v Speaker 1>uh,</v>

309
00:22:57.750 --> 00:23:00.870
<v Speaker 1>biological neural networks is,</v>
<v Speaker 1>you're sitting here today,</v>

310
00:23:00.990 --> 00:23:05.070
<v Speaker 1>they're always learning.</v>
<v Speaker 1>The only profound similarity,</v>

311
00:23:05.730 --> 00:23:09.060
<v Speaker 1>the inspiring one,</v>
<v Speaker 1>the captivating one,</v>

312
00:23:09.420 --> 00:23:13.380
<v Speaker 1>is that both are distributed computation</v>
<v Speaker 1>at scale.</v>

313
00:23:14.850 --> 00:23:19.850
<v Speaker 1>There is an emergent aspect to neural </v>
<v Speaker 1>networks where the basic element of </v>

314
00:23:21.241 --> 00:23:25.230
<v Speaker 1>computation,</v>
<v Speaker 1>a neuron is simple,</v>

315
00:23:25.510 --> 00:23:28.800
<v Speaker 1>is extremely simple,</v>
<v Speaker 1>but when connected together,</v>

316
00:23:29.220 --> 00:23:31.530
<v Speaker 1>beautiful,</v>
<v Speaker 1>amazing,</v>

317
00:23:32.130 --> 00:23:34.170
<v Speaker 1>powerful,</v>
<v Speaker 1>approximators can be formed.</v>

318
00:23:34.970 --> 00:23:39.300
<v Speaker 1>A neural network is built up with these </v>
<v Speaker 1>computational units where the inputs,</v>

319
00:23:39.540 --> 00:23:42.300
<v Speaker 1>there's a set of edges with weights on </v>
<v Speaker 1>them.</v>

320
00:23:43.170 --> 00:23:47.000
<v Speaker 1>The edges are the weights are by this </v>
<v Speaker 1>input signal.</v>

321
00:23:47.720 --> 00:23:52.720
<v Speaker 1>A bias is added with a nonlinear </v>
<v Speaker 1>function that determines whether the </v>

322
00:23:53.361 --> 00:23:58.361
<v Speaker 1>network gets activated or not.</v>
<v Speaker 1>The neuron gets activated or not </v>

323
00:23:58.361 --> 00:24:02.440
<v Speaker 1>visualized here,</v>
<v Speaker 1>and these neurons can be combined in a </v>

324
00:24:02.440 --> 00:24:06.401
<v Speaker 1>mall in number of ways.</v>
<v Speaker 1>It can form a feed forward and will not </v>

325
00:24:06.401 --> 00:24:09.820
<v Speaker 1>work or they can feed back into itself </v>
<v Speaker 1>to form to have state memory in </v>

326
00:24:13.761 --> 00:24:18.761
<v Speaker 1>recurrent neural networks.</v>
<v Speaker 1>The ones on the left are the ones that </v>

327
00:24:18.761 --> 00:24:23.141
<v Speaker 1>are most successful for most </v>
<v Speaker 1>applications in computer vision.</v>

328
00:24:24.050 --> 00:24:29.050
<v Speaker 1>The ones in the right are very popular </v>
<v Speaker 1>and specific when temporal dynamics or </v>

329
00:24:29.091 --> 00:24:31.550
<v Speaker 1>dynamics time series of any kind are </v>
<v Speaker 1>used.</v>

330
00:24:32.030 --> 00:24:37.030
<v Speaker 1>In fact,</v>
<v Speaker 1>the ones in the right a much closer to </v>

331
00:24:37.030 --> 00:24:39.230
<v Speaker 1>the way our human brains are and the </v>
<v Speaker 1>ones on the left,</v>

332
00:24:40.160 --> 00:24:42.020
<v Speaker 1>but that's why they're really hard to </v>
<v Speaker 1>train.</v>

333
00:24:45.090 --> 00:24:50.090
<v Speaker 1>One beautiful aspect of this emerging </v>
<v Speaker 1>power from multiple neurons being </v>

334
00:24:50.461 --> 00:24:55.461
<v Speaker 1>connected together is the universal </v>
<v Speaker 1>property that with a single hidden </v>

335
00:24:55.461 --> 00:24:58.560
<v Speaker 1>layer,</v>
<v Speaker 1>these networks can learn any function,</v>

336
00:24:58.620 --> 00:25:03.620
<v Speaker 1>learn to approximate at any function </v>
<v Speaker 1>which is an important property to be </v>

337
00:25:03.620 --> 00:25:07.671
<v Speaker 1>aware of because the limits here are not</v>
<v Speaker 1>in the power of the networks.</v>

338
00:25:11.040 --> 00:25:16.040
<v Speaker 1>The limits in the is in the methods by </v>
<v Speaker 1>which we construct them and train them.</v>

339
00:25:21.870 --> 00:25:25.740
<v Speaker 1>What kinds of machine learning deep </v>
<v Speaker 1>learning are there.</v>

340
00:25:26.430 --> 00:25:31.430
<v Speaker 1>We can separate into two categories,</v>
<v Speaker 1>memorizers now,</v>

341
00:25:34.831 --> 00:25:37.410
<v Speaker 1>uh,</v>
<v Speaker 1>the approaches that essentially memorize</v>

342
00:25:37.411 --> 00:25:42.411
<v Speaker 1>patterns in the data and approaches that</v>
<v Speaker 1>we can loosely say are beginning to </v>

343
00:25:43.800 --> 00:25:47.640
<v Speaker 1>reason to generalize over the data with </v>
<v Speaker 1>minimal human input.</v>

344
00:25:47.970 --> 00:25:52.970
<v Speaker 1>On top,</v>
<v Speaker 1>on the left are the quote unquote </v>

345
00:25:52.970 --> 00:25:55.490
<v Speaker 1>teachers is how much human input and </v>
<v Speaker 1>blue is needed to make the method </v>

346
00:25:55.490 --> 00:25:59.841
<v Speaker 1>successful for supervised learning,</v>
<v Speaker 1>which is what most of the deep learning </v>

347
00:25:59.841 --> 00:26:02.310
<v Speaker 1>success has come from.</v>
<v Speaker 1>Or most of the data's annotated by human</v>

348
00:26:02.311 --> 00:26:07.311
<v Speaker 1>beings.</v>
<v Speaker 1>The human is at the core of the success.</v>

349
00:26:07.560 --> 00:26:12.560
<v Speaker 1>Most of the data that's part of the </v>
<v Speaker 1>training needs to be annotated by human </v>

350
00:26:12.560 --> 00:26:15.831
<v Speaker 1>beings was some additional successes </v>
<v Speaker 1>coming from augmentation methods that </v>

351
00:26:16.560 --> 00:26:21.560
<v Speaker 1>extend that extend the data based on </v>
<v Speaker 1>which is networks have trained and the </v>

352
00:26:27.040 --> 00:26:31.140
<v Speaker 1>semi-supervised reinforcement learning </v>
<v Speaker 1>and unsupervised methods that we'll talk</v>

353
00:26:31.141 --> 00:26:36.141
<v Speaker 1>about later in the course.</v>
<v Speaker 1>That's where the near term successes we </v>

354
00:26:36.151 --> 00:26:39.480
<v Speaker 1>hope are and where the unsupervised </v>
<v Speaker 1>learning approaches,</v>

355
00:26:39.540 --> 00:26:44.540
<v Speaker 1>that's where the true excitement about </v>
<v Speaker 1>the possibilities of artificial lie </v>

356
00:26:44.700 --> 00:26:49.700
<v Speaker 1>being able to make sense of our world </v>
<v Speaker 1>with minimal input from humans.</v>

357
00:26:53.300 --> 00:26:58.300
<v Speaker 1>So we can think of two kinds of deep </v>
<v Speaker 1>learning impacts spaces.</v>

358
00:27:00.080 --> 00:27:04.610
<v Speaker 1>One is a special purpose intelligence is</v>
<v Speaker 1>taking a problem,</v>

359
00:27:04.670 --> 00:27:07.640
<v Speaker 1>formalizing it,</v>
<v Speaker 1>collecting enough data on it,</v>

360
00:27:07.700 --> 00:27:12.700
<v Speaker 1>and being able to solve a particular </v>
<v Speaker 1>case that's that provides value of </v>

361
00:27:16.371 --> 00:27:21.371
<v Speaker 1>particular interest.</v>
<v Speaker 1>Here is a a network that estimates </v>

362
00:27:21.371 --> 00:27:24.401
<v Speaker 1>apartment costs in the Boston area,</v>
<v Speaker 1>so you could take the number of </v>

363
00:27:24.401 --> 00:27:25.490
<v Speaker 1>bedrooms,</v>
<v Speaker 1>the square feet and the neighborhood and</v>

364
00:27:25.491 --> 00:27:29.120
<v Speaker 1>provide is.</v>
<v Speaker 1>I'll put the estimated costs on the.</v>

365
00:27:29.220 --> 00:27:33.680
<v Speaker 1>On the right is the actual data of </v>
<v Speaker 1>apartment cost.</v>

366
00:27:34.130 --> 00:27:39.130
<v Speaker 1>We're actually standing at a in a area </v>
<v Speaker 1>that has over $3,000</v>

367
00:27:40.131 --> 00:27:41.180
<v Speaker 1>for a studio apartment.</v>

368
00:27:44.200 --> 00:27:49.200
<v Speaker 1>Some of you may be feeling that pain and</v>
<v Speaker 1>then there's general purpose </v>

369
00:27:49.241 --> 00:27:54.241
<v Speaker 1>intelligence or something that feels </v>
<v Speaker 1>like approaching general purpose </v>

370
00:27:55.271 --> 00:28:00.271
<v Speaker 1>intelligence,</v>
<v Speaker 1>which is reinforcement and unsupervised </v>

371
00:28:00.271 --> 00:28:00.640
<v Speaker 1>learning.</v>
<v Speaker 1>Here with Andrea,</v>

372
00:28:00.641 --> 00:28:03.000
<v Speaker 1>come from Monica potties Pong,</v>
<v Speaker 1>the pixels,</v>

373
00:28:03.200 --> 00:28:08.200
<v Speaker 1>a system that takes in 80 by 80 pixel </v>
<v Speaker 1>image and with no other information is </v>

374
00:28:08.200 --> 00:28:10.420
<v Speaker 1>able to beat,</v>
<v Speaker 1>is able to win at this game,</v>

375
00:28:10.780 --> 00:28:13.330
<v Speaker 1>no information except a sequence of </v>
<v Speaker 1>images,</v>

376
00:28:13.450 --> 00:28:16.000
<v Speaker 1>raw sensory information,</v>
<v Speaker 1>the same way,</v>

377
00:28:16.090 --> 00:28:19.750
<v Speaker 1>the same kind of information that human </v>
<v Speaker 1>beings taken from the visual,</v>

378
00:28:19.751 --> 00:28:23.470
<v Speaker 1>audio touch,</v>
<v Speaker 1>sensory data,</v>

379
00:28:23.530 --> 00:28:28.530
<v Speaker 1>the very low level data and be able to </v>
<v Speaker 1>learn to win and this very simplistic </v>

380
00:28:28.530 --> 00:28:31.240
<v Speaker 1>and it's very artificially constructed </v>
<v Speaker 1>world,</v>

381
00:28:31.360 --> 00:28:35.170
<v Speaker 1>but nevertheless a world where no </v>
<v Speaker 1>feature learning is performed.</v>

382
00:28:35.440 --> 00:28:40.440
<v Speaker 1>Only raw sensory information is used to </v>
<v Speaker 1>win with very sparse minimal human </v>

383
00:28:40.721 --> 00:28:45.430
<v Speaker 1>input.</v>
<v Speaker 1>We'll talk about that on Wednesday.</v>

384
00:28:46.900 --> 00:28:51.900
<v Speaker 1>We're deep reinforcement learning so but</v>
<v Speaker 1>for now we'll focus on supervised </v>

385
00:28:52.721 --> 00:28:57.430
<v Speaker 1>learning where there is input data,</v>
<v Speaker 1>there is a network.</v>

386
00:28:57.431 --> 00:29:02.431
<v Speaker 1>We're trying to train a learning system </v>
<v Speaker 1>and there's a correct output that's </v>

387
00:29:02.431 --> 00:29:07.230
<v Speaker 1>labeled by human beings,</v>
<v Speaker 1>that's the general training process for </v>

388
00:29:07.230 --> 00:29:11.460
<v Speaker 1>neural network input,</v>
<v Speaker 1>data labels and the training of that </v>

389
00:29:11.530 --> 00:29:13.000
<v Speaker 1>network,</v>
<v Speaker 1>that model,</v>

390
00:29:13.360 --> 00:29:18.360
<v Speaker 1>so that in the testing stage,</v>
<v Speaker 1>our new input data that has never seen </v>

391
00:29:18.360 --> 00:29:22.501
<v Speaker 1>before as task with producing guesses </v>
<v Speaker 1>and is evaluated based on that for </v>

392
00:29:23.171 --> 00:29:28.171
<v Speaker 1>autonomous vehicles,</v>
<v Speaker 1>that means being released either in </v>

393
00:29:28.171 --> 00:29:28.660
<v Speaker 1>simulation or in the real world to </v>
<v Speaker 1>operate</v>

394
00:29:32.200 --> 00:29:37.200
<v Speaker 1>and how they learn,</v>
<v Speaker 1>how neural networks learn is given the </v>

395
00:29:37.200 --> 00:29:40.930
<v Speaker 1>forward pass of taking the input data,</v>
<v Speaker 1>whether it's from the training stage,</v>

396
00:29:42.190 --> 00:29:44.920
<v Speaker 1>in the training stage,</v>
<v Speaker 1>the taking the input data,</v>

397
00:29:44.921 --> 00:29:48.040
<v Speaker 1>producing a prediction,</v>
<v Speaker 1>and then given that there's ground truth</v>

398
00:29:48.041 --> 00:29:49.540
<v Speaker 1>in the training stage,</v>
<v Speaker 1>we can,</v>

399
00:29:49.710 --> 00:29:54.710
<v Speaker 1>we can have a measure of error based on </v>
<v Speaker 1>a loss function that then punishes the,</v>

400
00:29:55.920 --> 00:29:57.100
<v Speaker 1>uh,</v>
<v Speaker 1>the synapses,</v>

401
00:29:57.101 --> 00:30:02.101
<v Speaker 1>the connections,</v>
<v Speaker 1>the parameters that were involved with </v>

402
00:30:02.101 --> 00:30:04.840
<v Speaker 1>making that a,</v>
<v Speaker 1>that wrong prediction.</v>

403
00:30:07.300 --> 00:30:10.790
<v Speaker 1>A back propagates the error through </v>
<v Speaker 1>those weights.</v>

404
00:30:11.270 --> 00:30:13.730
<v Speaker 1>We'll discuss that a little bit more </v>
<v Speaker 1>detail in a bit here.</v>

405
00:30:14.810 --> 00:30:18.110
<v Speaker 1>So what can we do with deep learning?</v>
<v Speaker 1>You can do one to one mapping.</v>

406
00:30:18.800 --> 00:30:23.800
<v Speaker 1>Really,</v>
<v Speaker 1>you can think of input as being </v>

407
00:30:23.800 --> 00:30:23.800
<v Speaker 1>anything.</v>
<v Speaker 1>It can be a number of vector numbers,</v>

408
00:30:23.800 --> 00:30:25.220
<v Speaker 1>a sequence of numbers,</v>
<v Speaker 1>a sequence of vector,</v>

409
00:30:25.221 --> 00:30:27.980
<v Speaker 1>of numbers,</v>
<v Speaker 1>anything you can think of from images to</v>

410
00:30:27.981 --> 00:30:30.770
<v Speaker 1>video to audio to text and represented </v>
<v Speaker 1>in this way,</v>

411
00:30:31.010 --> 00:30:35.660
<v Speaker 1>and the output can the same be a single </v>
<v Speaker 1>number or it can be images,</v>

412
00:30:35.661 --> 00:30:36.860
<v Speaker 1>video,</v>
<v Speaker 1>text,</v>

413
00:30:37.250 --> 00:30:39.290
<v Speaker 1>audio,</v>
<v Speaker 1>one to one,</v>

414
00:30:39.291 --> 00:30:41.300
<v Speaker 1>mapping on the bottom,</v>
<v Speaker 1>one to many,</v>

415
00:30:41.301 --> 00:30:46.301
<v Speaker 1>many to many to many and many to many </v>
<v Speaker 1>with different starting points for the </v>

416
00:30:47.751 --> 00:30:50.120
<v Speaker 1>data,</v>
<v Speaker 1>a synchronous,</v>

417
00:30:53.340 --> 00:30:58.340
<v Speaker 1>some quick terms that will come up.</v>
<v Speaker 1>Deep learning is the same as neural </v>

418
00:30:58.340 --> 00:31:01.500
<v Speaker 1>networks.</v>
<v Speaker 1>It's really deep neural networks,</v>

419
00:31:01.830 --> 00:31:06.830
<v Speaker 1>large neural networks.</v>
<v Speaker 1>It's a subset of machine learning that </v>

420
00:31:06.830 --> 00:31:09.690
<v Speaker 1>has been extremely successful in the </v>
<v Speaker 1>past decade.</v>

421
00:31:10.530 --> 00:31:13.110
<v Speaker 1>Multilayer Perceptron,</v>
<v Speaker 1>deep neural network,</v>

422
00:31:13.170 --> 00:31:16.530
<v Speaker 1>recurrent neural network,</v>
<v Speaker 1>long short term memory network,</v>

423
00:31:16.531 --> 00:31:18.990
<v Speaker 1>Lstm,</v>
<v Speaker 1>convolutional neural network,</v>

424
00:31:19.290 --> 00:31:24.290
<v Speaker 1>and deep belief networks.</v>
<v Speaker 1>All of these will come up through the </v>

425
00:31:24.290 --> 00:31:26.751
<v Speaker 1>slides and there is specific operations </v>
<v Speaker 1>layers within these networks of </v>

426
00:31:28.651 --> 00:31:31.650
<v Speaker 1>convolution pooling activation and </v>
<v Speaker 1>backpropagation.</v>

427
00:31:31.920 --> 00:31:36.060
<v Speaker 1>This concepts that we'll discuss in this</v>
<v Speaker 1>class,</v>

428
00:31:36.840 --> 00:31:41.840
<v Speaker 1>activation functions.</v>
<v Speaker 1>There's a lot of variance than the left </v>

429
00:31:41.881 --> 00:31:43.620
<v Speaker 1>is the activation function and left </v>
<v Speaker 1>column,</v>

430
00:31:44.170 --> 00:31:47.910
<v Speaker 1>and the x axis is the input.</v>
<v Speaker 1>On the y axis is the output,</v>

431
00:31:49.440 --> 00:31:51.270
<v Speaker 1>the sigmoid function,</v>
<v Speaker 1>the output.</v>

432
00:31:52.080 --> 00:31:56.640
<v Speaker 1>If the font is too small,</v>
<v Speaker 1>the output is not centered at zero.</v>

433
00:31:58.770 --> 00:32:02.130
<v Speaker 1>For the Tan age function,</v>
<v Speaker 1>it's centered at zero,</v>

434
00:32:02.131 --> 00:32:04.170
<v Speaker 1>but it's still suffers from vantage </v>
<v Speaker 1>ingredients.</v>

435
00:32:04.890 --> 00:32:09.630
<v Speaker 1>Vanishing gradients is one of the value.</v>
<v Speaker 1>The input is low or high.</v>

436
00:32:11.770 --> 00:32:12.810
<v Speaker 1>The,</v>
<v Speaker 1>uh,</v>

437
00:32:12.820 --> 00:32:17.820
<v Speaker 1>the output of the network,</v>
<v Speaker 1>because you see in the right column </v>

438
00:32:17.820 --> 00:32:20.581
<v Speaker 1>there,</v>
<v Speaker 1>the derivative of the function is very </v>

439
00:32:20.581 --> 00:32:23.221
<v Speaker 1>low,</v>
<v Speaker 1>so the learning rate is very low for </v>

440
00:32:23.221 --> 00:32:27.180
<v Speaker 1>revenue,</v>
<v Speaker 1>not it's also not zero centered,</v>

441
00:32:28.630 --> 00:32:31.030
<v Speaker 1>but it does not suffer from vanishing </v>
<v Speaker 1>gradients.</v>

442
00:32:32.470 --> 00:32:34.510
<v Speaker 1>Backpropagation is the process of </v>
<v Speaker 1>learning.</v>

443
00:32:34.990 --> 00:32:37.720
<v Speaker 1>It's the way we take go from error </v>
<v Speaker 1>computers,</v>

444
00:32:37.721 --> 00:32:40.510
<v Speaker 1>the last function and bottom right of </v>
<v Speaker 1>the slide,</v>

445
00:32:40.580 --> 00:32:44.450
<v Speaker 1>taking the actual output of the network </v>
<v Speaker 1>with the Ford Pass,</v>

446
00:32:44.600 --> 00:32:49.600
<v Speaker 1>subtracting it from the ground truth </v>
<v Speaker 1>squaring dividing were to and using that</v>

447
00:32:51.471 --> 00:32:56.471
<v Speaker 1>lost function than back propagate </v>
<v Speaker 1>through to construct a great aunt to </v>

448
00:32:56.471 --> 00:32:59.560
<v Speaker 1>back propagate the error to the weights </v>
<v Speaker 1>that we're responsible for making either</v>

449
00:32:59.570 --> 00:33:04.570
<v Speaker 1>correct or incorrect decision.</v>
<v Speaker 1>So the subtests that there's a forward </v>

450
00:33:04.570 --> 00:33:08.810
<v Speaker 1>pass as a backward pass and a fraction </v>
<v Speaker 1>of the weights,</v>

451
00:33:08.811 --> 00:33:11.180
<v Speaker 1>gradients of tractor from the weight,</v>
<v Speaker 1>that's it.</v>

452
00:33:11.720 --> 00:33:16.720
<v Speaker 1>That process is modular,</v>
<v Speaker 1>so it's local to each individual neuron,</v>

453
00:33:17.000 --> 00:33:22.000
<v Speaker 1>which is why it's extremely dis.</v>
<v Speaker 1>We're able to distribute it across </v>

454
00:33:22.250 --> 00:33:27.250
<v Speaker 1>multiple across the GPU parallelize </v>
<v Speaker 1>across the GPU,</v>

455
00:33:31.010 --> 00:33:36.010
<v Speaker 1>so learning for a neural network.</v>
<v Speaker 1>These competition units are extremely </v>

456
00:33:36.441 --> 00:33:41.441
<v Speaker 1>simple,</v>
<v Speaker 1>extremely simple to then correct when </v>

457
00:33:41.441 --> 00:33:45.071
<v Speaker 1>they make an error,</v>
<v Speaker 1>when they're part of a larger network </v>

458
00:33:45.071 --> 00:33:47.231
<v Speaker 1>that makes an error and all that boils </v>
<v Speaker 1>down to is essentially an optimization </v>

459
00:33:47.231 --> 00:33:51.551
<v Speaker 1>problem where the objective utility </v>
<v Speaker 1>function is the loss function and the </v>

460
00:33:52.041 --> 00:33:54.980
<v Speaker 1>goal is to minimize it and we have to </v>
<v Speaker 1>update the parameters,</v>

461
00:33:54.981 --> 00:33:59.090
<v Speaker 1>the weights and the synapses and the </v>
<v Speaker 1>biases to decrease that loss function.</v>

462
00:34:01.900 --> 00:34:04.000
<v Speaker 1>And that last function is highly </v>
<v Speaker 1>nonlinear.</v>

463
00:34:06.520 --> 00:34:08.950
<v Speaker 1>Depending on the activation functions,</v>
<v Speaker 1>different properties,</v>

464
00:34:08.951 --> 00:34:13.951
<v Speaker 1>different issues arise.</v>
<v Speaker 1>There's vanishing gradients for sigmoid </v>

465
00:34:15.300 --> 00:34:18.900
<v Speaker 1>where the learning can be slow.</v>
<v Speaker 1>There's dying.</v>

466
00:34:18.901 --> 00:34:23.800
<v Speaker 1>Rarely use where the derivatives exactly</v>
<v Speaker 1>zero,</v>

467
00:34:24.610 --> 00:34:29.610
<v Speaker 1>four inputs less than zero.</v>
<v Speaker 1>There are solutions to this like leaky </v>

468
00:34:30.391 --> 00:34:35.391
<v Speaker 1>rallies and a bunch of details that you </v>
<v Speaker 1>may discover when you try to win the </v>

469
00:34:35.391 --> 00:34:38.460
<v Speaker 1>deep traffic competition,</v>
<v Speaker 1>but for the most part these are the main</v>

470
00:34:38.461 --> 00:34:43.461
<v Speaker 1>activation functions and it's the choice</v>
<v Speaker 1>of the you'll network designer,</v>

471
00:34:45.360 --> 00:34:49.070
<v Speaker 1>which one works best.</v>
<v Speaker 1>They're saddle points,</v>

472
00:34:49.100 --> 00:34:54.100
<v Speaker 1>all the problems from numerical,</v>
<v Speaker 1>nonlinear optimization that arise come </v>

473
00:34:54.100 --> 00:34:58.811
<v Speaker 1>up here.</v>
<v Speaker 1>It's hard to break symmetry and </v>

474
00:34:59.840 --> 00:35:04.840
<v Speaker 1>stochastic gradient descent without any </v>
<v Speaker 1>kind of tricks to it can take a very </v>

475
00:35:05.511 --> 00:35:10.511
<v Speaker 1>long time to arrive at the minimum.</v>
<v Speaker 1>One of the biggest problems in all of </v>

476
00:35:11.801 --> 00:35:14.860
<v Speaker 1>machine learning and certainly in deep </v>
<v Speaker 1>learning is overfitting.</v>

477
00:35:15.700 --> 00:35:20.700
<v Speaker 1>You can think of the blue dots and </v>
<v Speaker 1>applied here as the data to which we </v>

478
00:35:20.700 --> 00:35:20.980
<v Speaker 1>want to fit a curve.</v>

479
00:35:22.750 --> 00:35:27.310
<v Speaker 1>We want to design a learning system that</v>
<v Speaker 1>approximates the aggression of that,</v>

480
00:35:27.450 --> 00:35:28.540
<v Speaker 1>uh,</v>
<v Speaker 1>of this data.</v>

481
00:35:29.350 --> 00:35:34.350
<v Speaker 1>So in green is a sine curve,</v>
<v Speaker 1>simple fits well,</v>

482
00:35:35.470 --> 00:35:40.470
<v Speaker 1>and then there's a ninth degree </v>
<v Speaker 1>polynomial which fits even better in </v>

483
00:35:40.470 --> 00:35:43.170
<v Speaker 1>terms of the error,</v>
<v Speaker 1>but it clearly over fits this data.</v>

484
00:35:43.500 --> 00:35:48.500
<v Speaker 1>If there's other data that has not seen </v>
<v Speaker 1>yet that it has to fit,</v>

485
00:35:49.470 --> 00:35:52.250
<v Speaker 1>it's likely to produce a high error,</v>
<v Speaker 1>so it's overfitting.</v>

486
00:35:52.260 --> 00:35:57.260
<v Speaker 1>The training set.</v>
<v Speaker 1>This is a big problem for small data </v>

487
00:35:57.260 --> 00:36:00.210
<v Speaker 1>sets and so we have to fix that with </v>
<v Speaker 1>regularization.</v>

488
00:36:00.780 --> 00:36:05.780
<v Speaker 1>Regularization is a set of methodologies</v>
<v Speaker 1>that prevent overfitting learning the </v>

489
00:36:06.301 --> 00:36:11.301
<v Speaker 1>training too well in order and then to </v>
<v Speaker 1>not be able to generalize to the testing</v>

490
00:36:11.521 --> 00:36:16.521
<v Speaker 1>stage and overfitting.</v>
<v Speaker 1>The main symptom is the air decreases in</v>

491
00:36:18.241 --> 00:36:20.460
<v Speaker 1>training set but increases in the test </v>
<v Speaker 1>set,</v>

492
00:36:22.360 --> 00:36:27.360
<v Speaker 1>so there's a lot of techniques and </v>
<v Speaker 1>traditional machine learning that deal </v>

493
00:36:27.360 --> 00:36:27.360
<v Speaker 1>with this and cross validation,</v>
<v Speaker 1>so on,</v>

494
00:36:27.360 --> 00:36:30.520
<v Speaker 1>but because of the cost of training for </v>
<v Speaker 1>neural networks,</v>

495
00:36:31.120 --> 00:36:35.050
<v Speaker 1>it's traditional to use of what's called</v>
<v Speaker 1>the validation set,</v>

496
00:36:35.560 --> 00:36:39.040
<v Speaker 1>so you create a subset of the training </v>
<v Speaker 1>they use,</v>

497
00:36:39.220 --> 00:36:44.220
<v Speaker 1>keep away for which you have the ground </v>
<v Speaker 1>truth and use that as a representative </v>

498
00:36:44.470 --> 00:36:49.470
<v Speaker 1>of the testing set so you perform early </v>
<v Speaker 1>stoppage or more realistically.</v>

499
00:36:49.841 --> 00:36:54.841
<v Speaker 1>Just save a checkpoint often to see how </v>
<v Speaker 1>as the training evolves,</v>

500
00:36:57.310 --> 00:37:02.310
<v Speaker 1>the performance changes on the </v>
<v Speaker 1>validation set and so you can stop when </v>

501
00:37:03.041 --> 00:37:05.590
<v Speaker 1>the performance and the validation set </v>
<v Speaker 1>is getting a lot worse.</v>

502
00:37:05.770 --> 00:37:08.080
<v Speaker 1>It means you're overtraining on the </v>
<v Speaker 1>training set.</v>

503
00:37:11.840 --> 00:37:13.250
<v Speaker 1>In practice,</v>
<v Speaker 1>of course,</v>

504
00:37:13.370 --> 00:37:16.600
<v Speaker 1>we run training which longer and see </v>
<v Speaker 1>when a,</v>

505
00:37:16.790 --> 00:37:19.230
<v Speaker 1>what is the best performing,</v>
<v Speaker 1>uh,</v>

506
00:37:19.250 --> 00:37:24.250
<v Speaker 1>what,</v>
<v Speaker 1>what is the best performing snapshot </v>

507
00:37:24.250 --> 00:37:26.921
<v Speaker 1>checkpoint of the network dropout is </v>
<v Speaker 1>another very powerful regularization </v>

508
00:37:27.591 --> 00:37:29.780
<v Speaker 1>technique.</v>
<v Speaker 1>What were you randomly remove?</v>

509
00:37:29.781 --> 00:37:33.410
<v Speaker 1>Part of the network.</v>
<v Speaker 1>Randomly remove some of the nodes in the</v>

510
00:37:33.411 --> 00:37:37.790
<v Speaker 1>network along with its incoming and </v>
<v Speaker 1>outgoing edges.</v>

511
00:37:38.420 --> 00:37:43.420
<v Speaker 1>So what that really looks like is a </v>
<v Speaker 1>probability of keeping a node and in </v>

512
00:37:43.420 --> 00:37:47.510
<v Speaker 1>many deep learning frameworks today,</v>
<v Speaker 1>it comes with a dropout layer.</v>

513
00:37:47.540 --> 00:37:51.960
<v Speaker 1>So it's essentially a probability that's</v>
<v Speaker 1>usually greater than point five than a,</v>

514
00:37:51.961 --> 00:37:56.210
<v Speaker 1>that a node will be kept for the input </v>
<v Speaker 1>layer,</v>

515
00:37:56.300 --> 00:37:59.960
<v Speaker 1>the probability should be much higher or</v>
<v Speaker 1>more effectively.</v>

516
00:38:00.140 --> 00:38:03.410
<v Speaker 1>What works well is just adding noise.</v>
<v Speaker 1>What's the point here?</v>

517
00:38:03.830 --> 00:38:08.830
<v Speaker 1>You want to create enough diversity in </v>
<v Speaker 1>the training data such that it is </v>

518
00:38:09.291 --> 00:38:14.291
<v Speaker 1>generalizable to the testing and as </v>
<v Speaker 1>you'll see with deep traffic,</v>

519
00:38:15.041 --> 00:38:20.041
<v Speaker 1>competition is l two and l one penalty </v>
<v Speaker 1>weight decay way penalty where there's a</v>

520
00:38:22.121 --> 00:38:24.850
<v Speaker 1>penalization on the weights.</v>
<v Speaker 1>They get too large.</v>

521
00:38:25.060 --> 00:38:28.660
<v Speaker 1>The [inaudible] penalty keeps the </v>
<v Speaker 1>weights small unless the aero derivative</v>

522
00:38:28.661 --> 00:38:33.661
<v Speaker 1>is huge and produces a smoother model </v>
<v Speaker 1>and prefers to distribute when there is </v>

523
00:38:36.250 --> 00:38:41.250
<v Speaker 1>too similar inputs.</v>
<v Speaker 1>That prefers to put half the weights on </v>

524
00:38:41.250 --> 00:38:44.041
<v Speaker 1>each distribute the weights as opposed </v>
<v Speaker 1>to putting the weight on one of the </v>

525
00:38:44.041 --> 00:38:44.041
<v Speaker 1>edges,</v>

526
00:38:45.260 --> 00:38:49.940
<v Speaker 1>makes the network more robust.</v>
<v Speaker 1>Our one penalty has the one benefit that</v>

527
00:38:49.941 --> 00:38:53.810
<v Speaker 1>for really large weights,</v>
<v Speaker 1>they're allowed to be to stay,</v>

528
00:38:54.350 --> 00:38:57.020
<v Speaker 1>so it's allows her a few ways to remain </v>
<v Speaker 1>very large.</v>

529
00:38:57.680 --> 00:39:02.680
<v Speaker 1>These are the regularization techniques </v>
<v Speaker 1>and I wanted to mention them because </v>

530
00:39:02.680 --> 00:39:06.251
<v Speaker 1>they're useful to some of the </v>
<v Speaker 1>competitions here in the course and I </v>

531
00:39:06.251 --> 00:39:09.611
<v Speaker 1>recommend to go to a playground and </v>
<v Speaker 1>tenser and tenser flow playground to </v>

532
00:39:09.611 --> 00:39:13.040
<v Speaker 1>play around with some of these </v>
<v Speaker 1>parameters where you get to online,</v>

533
00:39:13.041 --> 00:39:15.560
<v Speaker 1>in the browser,</v>
<v Speaker 1>play around with different inputs,</v>

534
00:39:15.561 --> 00:39:20.561
<v Speaker 1>different features,</v>
<v Speaker 1>different number of layers and </v>

535
00:39:20.561 --> 00:39:20.561
<v Speaker 1>regularization techniques,</v>
<v Speaker 1>uh,</v>

536
00:39:20.561 --> 00:39:22.910
<v Speaker 1>and to build your intuition about </v>
<v Speaker 1>classification,</v>

537
00:39:22.911 --> 00:39:26.000
<v Speaker 1>regression problems given different </v>
<v Speaker 1>input data sets.</v>

538
00:39:28.920 --> 00:39:33.450
<v Speaker 1>So what changed why over the past many </v>
<v Speaker 1>decades,</v>

539
00:39:34.140 --> 00:39:39.140
<v Speaker 1>neural networks that have gone through </v>
<v Speaker 1>two winters are now again dominating the</v>

540
00:39:39.631 --> 00:39:43.720
<v Speaker 1>artificial intelligence community CPU </v>
<v Speaker 1>GPU,</v>

541
00:39:44.610 --> 00:39:49.610
<v Speaker 1>a six.</v>
<v Speaker 1>So computational power has skyrocketed </v>

542
00:39:49.610 --> 00:39:53.810
<v Speaker 1>from Moore's law to gps.</v>
<v Speaker 1>There is huge data set including image </v>

543
00:39:55.401 --> 00:39:56.840
<v Speaker 1>net and others.</v>

544
00:39:58.740 --> 00:40:03.740
<v Speaker 1>There is research backpropagation in the</v>
<v Speaker 1>eighties,</v>

545
00:40:04.760 --> 00:40:06.540
<v Speaker 1>uh,</v>
<v Speaker 1>uh,</v>

546
00:40:06.541 --> 00:40:09.250
<v Speaker 1>the convolutional neural networks,</v>
<v Speaker 1>Lstm,</v>

547
00:40:09.540 --> 00:40:14.540
<v Speaker 1>there's been a lot of interesting </v>
<v Speaker 1>breakthroughs about how to design these </v>

548
00:40:14.540 --> 00:40:18.531
<v Speaker 1>architectures,</v>
<v Speaker 1>how to build them such that they're </v>

549
00:40:18.531 --> 00:40:18.531
<v Speaker 1>trainable,</v>
<v Speaker 1>efficiently using gps.</v>

550
00:40:20.400 --> 00:40:25.400
<v Speaker 1>There is the software infrastructure </v>
<v Speaker 1>from being able to share the data will </v>

551
00:40:25.400 --> 00:40:28.910
<v Speaker 1>get to being able to train networks and </v>
<v Speaker 1>share code and effectively view neural </v>

552
00:40:30.390 --> 00:40:35.390
<v Speaker 1>networks as a stack of layers as opposed</v>
<v Speaker 1>to having to start from scratch with </v>

553
00:40:35.700 --> 00:40:40.700
<v Speaker 1>tensorflow,</v>
<v Speaker 1>Pi Torch and other than that and other </v>

554
00:40:40.700 --> 00:40:41.580
<v Speaker 1>deep learning frameworks and there's </v>
<v Speaker 1>huge financial backing from Google,</v>

555
00:40:41.581 --> 00:40:46.581
<v Speaker 1>facebook and so on.</v>
<v Speaker 1>Deep learning is it in order to </v>

556
00:40:52.121 --> 00:40:57.121
<v Speaker 1>understand why it works so well and </v>
<v Speaker 1>where it's limitations are,</v>

557
00:40:58.030 --> 00:41:03.030
<v Speaker 1>we need to understand where our own </v>
<v Speaker 1>intuition comes from about what is hard </v>

558
00:41:03.030 --> 00:41:06.451
<v Speaker 1>and what is easy.</v>
<v Speaker 1>The important thing about computer </v>

559
00:41:06.451 --> 00:41:09.541
<v Speaker 1>vision,</v>
<v Speaker 1>which is a lot of what this course is </v>

560
00:41:09.541 --> 00:41:09.541
<v Speaker 1>about even as in deeper enforcement </v>
<v Speaker 1>learning formulation,</v>

561
00:41:10.240 --> 00:41:15.240
<v Speaker 1>is that visual perception for us human </v>
<v Speaker 1>beings was formed 540 million years ago.</v>

562
00:41:17.470 --> 00:41:22.470
<v Speaker 1>That's $540.</v>
<v Speaker 1>Millions million years worth of data and</v>

563
00:41:23.351 --> 00:41:26.710
<v Speaker 1>abstract thought is only formed a a </v>
<v Speaker 1>100,000</v>

564
00:41:26.711 --> 00:41:31.711
<v Speaker 1>years ago.</v>
<v Speaker 1>That's several orders of magnitude less </v>

565
00:41:31.711 --> 00:41:35.621
<v Speaker 1>data so we can with neural networks </v>
<v Speaker 1>predictions that seemed trivial.</v>

566
00:41:40.450 --> 00:41:41.260
<v Speaker 1>The,</v>
<v Speaker 1>uh,</v>

567
00:41:41.440 --> 00:41:46.440
<v Speaker 1>the trivial to us human beings,</v>
<v Speaker 1>but completely challenging and wrong to </v>

568
00:41:47.611 --> 00:41:51.000
<v Speaker 1>neural networks.</v>
<v Speaker 1>Here on the left showing a prediction of</v>

569
00:41:51.001 --> 00:41:54.750
<v Speaker 1>a dog with a little bit of a distortion </v>
<v Speaker 1>and noise added to the image,</v>

570
00:41:54.840 --> 00:41:56.730
<v Speaker 1>producing the image on the right and you</v>
<v Speaker 1>know,</v>

571
00:41:56.740 --> 00:42:01.740
<v Speaker 1>network is confidently 99 percent plus </v>
<v Speaker 1>accuracy predicting that it's an ostrich</v>

572
00:42:05.630 --> 00:42:10.630
<v Speaker 1>and there's all these problems as to </v>
<v Speaker 1>deal with whether it's an computer </v>

573
00:42:10.630 --> 00:42:10.880
<v Speaker 1>vision data,</v>
<v Speaker 1>whether it's in text,</v>

574
00:42:10.881 --> 00:42:11.900
<v Speaker 1>data,</v>
<v Speaker 1>audio,</v>

575
00:42:12.230 --> 00:42:17.230
<v Speaker 1>all of this variation arises in vision.</v>
<v Speaker 1>It's elimination variability.</v>

576
00:42:18.590 --> 00:42:23.590
<v Speaker 1>The set of pixels in the numbers look </v>
<v Speaker 1>completely different depending on the </v>

577
00:42:23.590 --> 00:42:24.140
<v Speaker 1>lighting conditions.</v>
<v Speaker 1>It's the biggest problem.</v>

578
00:42:24.141 --> 00:42:29.141
<v Speaker 1>And driving is lighting conditions.</v>
<v Speaker 1>Letting variability pose variation.</v>

579
00:42:29.900 --> 00:42:33.140
<v Speaker 1>Objects need to be learned from every </v>
<v Speaker 1>different perspective.</v>

580
00:42:33.141 --> 00:42:36.020
<v Speaker 1>I'll discuss that for when sensing the </v>
<v Speaker 1>driver.</v>

581
00:42:36.080 --> 00:42:41.080
<v Speaker 1>Most of most of,</v>
<v Speaker 1>most of the deep learning work that's </v>

582
00:42:41.080 --> 00:42:44.111
<v Speaker 1>done in the face on the human is done on</v>
<v Speaker 1>the frontal face or semi frontal face.</v>

583
00:42:44.980 --> 00:42:49.980
<v Speaker 1>That has very little work done on the </v>
<v Speaker 1>full three 60 a pose variability that a </v>

584
00:42:51.051 --> 00:42:56.051
<v Speaker 1>human being can take on.</v>
<v Speaker 1>Interclass variability for the </v>

585
00:42:57.161 --> 00:42:59.530
<v Speaker 1>classification problem,</v>
<v Speaker 1>for the detection problem,</v>

586
00:42:59.860 --> 00:43:02.680
<v Speaker 1>there is a lot of different kinds of </v>
<v Speaker 1>objects for cats,</v>

587
00:43:02.681 --> 00:43:03.730
<v Speaker 1>dogs,</v>
<v Speaker 1>cars,</v>

588
00:43:03.731 --> 00:43:05.140
<v Speaker 1>bicyclists,</v>
<v Speaker 1>pedestrians,</v>

589
00:43:07.190 --> 00:43:12.190
<v Speaker 1>so that brings us to object </v>
<v Speaker 1>classification and I'd like to take you </v>

590
00:43:12.190 --> 00:43:15.761
<v Speaker 1>through where deep learning has taken </v>
<v Speaker 1>big strides for the past several years </v>

591
00:43:16.791 --> 00:43:21.791
<v Speaker 1>leading up to this year to 2018.</v>
<v Speaker 1>So let's start at object classification </v>

592
00:43:24.440 --> 00:43:29.440
<v Speaker 1>is when you take a single image and you </v>
<v Speaker 1>have to say one class that's most likely</v>

593
00:43:31.041 --> 00:43:36.041
<v Speaker 1>to belong in that image.</v>
<v Speaker 1>The most famous variant of that as the </v>

594
00:43:36.041 --> 00:43:40.301
<v Speaker 1>image net competition.</v>
<v Speaker 1>Image net challenge image not data set </v>

595
00:43:40.301 --> 00:43:41.660
<v Speaker 1>is a data set of 14 million images with </v>
<v Speaker 1>21,000</v>

596
00:43:41.661 --> 00:43:45.980
<v Speaker 1>categories and for say the category of </v>
<v Speaker 1>fruit,</v>

597
00:43:46.280 --> 00:43:51.280
<v Speaker 1>there's a total of 188,000</v>
<v Speaker 1>images of fruit and there is 1200 images</v>

598
00:43:53.121 --> 00:43:58.121
<v Speaker 1>of granny smith apples.</v>
<v Speaker 1>It gives you a sense of what we're </v>

599
00:43:58.121 --> 00:44:00.851
<v Speaker 1>talking about here.</v>
<v Speaker 1>So this is been the source of a lot of </v>

600
00:44:02.001 --> 00:44:06.080
<v Speaker 1>interesting breakthroughs in deep </v>
<v Speaker 1>learning and a lot of the excitement and</v>

601
00:44:06.081 --> 00:44:09.920
<v Speaker 1>deep learning is first.</v>
<v Speaker 1>The big successful network,</v>

602
00:44:10.310 --> 00:44:15.310
<v Speaker 1>at least one that became famous and deep</v>
<v Speaker 1>learning is Alex Net in 2012.</v>

603
00:44:17.120 --> 00:44:22.120
<v Speaker 1>That took a leap of a significant leap </v>
<v Speaker 1>in performance on the image net </v>

604
00:44:22.120 --> 00:44:27.071
<v Speaker 1>challenge,</v>
<v Speaker 1>so it was one of the first neural </v>

605
00:44:27.071 --> 00:44:30.191
<v Speaker 1>networks that have successfully trained </v>
<v Speaker 1>on the GPU and achieved an incredible </v>

606
00:44:30.191 --> 00:44:31.860
<v Speaker 1>performance boost over the previous </v>
<v Speaker 1>year.</v>

607
00:44:32.070 --> 00:44:34.980
<v Speaker 1>On the image net challenge.</v>
<v Speaker 1>The challenges,</v>

608
00:44:35.410 --> 00:44:37.080
<v Speaker 1>and I'll talk about some of these </v>
<v Speaker 1>networks,</v>

609
00:44:37.290 --> 00:44:40.620
<v Speaker 1>is to given a single image,</v>
<v Speaker 1>give five guesses,</v>

610
00:44:40.830 --> 00:44:45.830
<v Speaker 1>and you have five guests.</v>
<v Speaker 1>This to guess for one of them to be </v>

611
00:44:45.830 --> 00:44:49.431
<v Speaker 1>correct.</v>
<v Speaker 1>The human annotation is the question </v>

612
00:44:49.431 --> 00:44:50.340
<v Speaker 1>often comes up.</v>
<v Speaker 1>So how do you know the ground truth?</v>

613
00:44:51.030 --> 00:44:55.530
<v Speaker 1>Human level of performance is five point</v>
<v Speaker 1>one percent accuracy on this task,</v>

614
00:44:57.060 --> 00:45:02.060
<v Speaker 1>but the way the annotation for image net</v>
<v Speaker 1>is performed is there's a google search </v>

615
00:45:03.180 --> 00:45:06.480
<v Speaker 1>where you pull the images are already </v>
<v Speaker 1>labeled for you,</v>

616
00:45:06.630 --> 00:45:09.600
<v Speaker 1>and then the annotation that on </v>
<v Speaker 1>mechanical Turk,</v>

617
00:45:09.601 --> 00:45:11.610
<v Speaker 1>other humans perform.</v>
<v Speaker 1>It's just binary.</v>

618
00:45:11.611 --> 00:45:13.900
<v Speaker 1>Is this a cat or not a cat?</v>
<v Speaker 1>So they're.</v>

619
00:45:13.930 --> 00:45:18.930
<v Speaker 1>They're not tasked with performing the </v>
<v Speaker 1>very high resolution semantic labeling </v>

620
00:45:19.021 --> 00:45:22.260
<v Speaker 1>of the image.</v>
<v Speaker 1>Okay.</v>

621
00:45:22.261 --> 00:45:27.261
<v Speaker 1>So through from 2012 with Alex Net to </v>
<v Speaker 1>today and the big transition in 2018 of </v>

622
00:45:29.971 --> 00:45:33.180
<v Speaker 1>the image net challenge leaving Stanford</v>
<v Speaker 1>and go into Cagle,</v>

623
00:45:35.170 --> 00:45:40.170
<v Speaker 1>it's sort of a monumental step because </v>
<v Speaker 1>in 2015 with the resident network was </v>

624
00:45:40.511 --> 00:45:45.511
<v Speaker 1>the first time that the human level </v>
<v Speaker 1>performance was exceeded and I think </v>

625
00:45:45.511 --> 00:45:49.210
<v Speaker 1>this is a very important</v>

626
00:45:51.480 --> 00:45:56.480
<v Speaker 1>map of where deep learning is for </v>
<v Speaker 1>particular what I would argue as a toy </v>

627
00:45:56.480 --> 00:46:00.801
<v Speaker 1>example,</v>
<v Speaker 1>despite the fact that it's 14 million </v>

628
00:46:00.801 --> 00:46:03.621
<v Speaker 1>images.</v>
<v Speaker 1>So we're developing state of the art </v>

629
00:46:03.621 --> 00:46:06.651
<v Speaker 1>techniques here and the next stage as we</v>
<v Speaker 1>are now exceeding human level </v>

630
00:46:06.651 --> 00:46:10.941
<v Speaker 1>performance on this task is how to take </v>
<v Speaker 1>these methods into the real world to </v>

631
00:46:10.941 --> 00:46:15.150
<v Speaker 1>perform scene perception,</v>
<v Speaker 1>to perform driver's state perception</v>

632
00:46:18.630 --> 00:46:23.630
<v Speaker 1>in 2016 and 2017.</v>
<v Speaker 1>See you image and see net has a very </v>

633
00:46:24.451 --> 00:46:29.451
<v Speaker 1>unique new addition to the previous </v>
<v Speaker 1>formulations that has achieved an </v>

634
00:46:29.451 --> 00:46:33.330
<v Speaker 1>accuracy of two point two percent error,</v>
<v Speaker 1>two point two,</v>

635
00:46:33.480 --> 00:46:36.440
<v Speaker 1>five percent error on the image net </v>
<v Speaker 1>declassification challenge.</v>

636
00:46:36.560 --> 00:46:38.790
<v Speaker 1>This is an incredible result.</v>
<v Speaker 1>Okay,</v>

637
00:46:38.791 --> 00:46:43.791
<v Speaker 1>so you have this image classification </v>
<v Speaker 1>architecture that takes in a single </v>

638
00:46:43.791 --> 00:46:45.830
<v Speaker 1>image and produces convolution,</v>
<v Speaker 1>uh,</v>

639
00:46:45.840 --> 00:46:48.060
<v Speaker 1>and uh,</v>
<v Speaker 1>it takes it through pool and convolution</v>

640
00:46:48.420 --> 00:46:51.150
<v Speaker 1>and at the end fully connected layers </v>
<v Speaker 1>and performance,</v>

641
00:46:51.151 --> 00:46:53.250
<v Speaker 1>the classification task or regression </v>
<v Speaker 1>task,</v>

642
00:46:53.550 --> 00:46:56.580
<v Speaker 1>and you can swap out that layer to </v>
<v Speaker 1>perform any kind of,</v>

643
00:46:57.000 --> 00:47:02.000
<v Speaker 1>um,</v>
<v Speaker 1>other task including with the recurrent </v>

644
00:47:02.000 --> 00:47:03.030
<v Speaker 1>neural networks of image captioning and </v>
<v Speaker 1>so on,</v>

645
00:47:03.450 --> 00:47:08.450
<v Speaker 1>or localization of bonding boxes.</v>
<v Speaker 1>Or you can do fully convolutional </v>

646
00:47:09.061 --> 00:47:12.300
<v Speaker 1>networks,</v>
<v Speaker 1>which we'll talk about on Thursday,</v>

647
00:47:13.110 --> 00:47:18.110
<v Speaker 1>which is when you take a,</v>
<v Speaker 1>a images and input and producing images </v>

648
00:47:18.110 --> 00:47:18.110
<v Speaker 1>that output.</v>

649
00:47:18.530 --> 00:47:23.530
<v Speaker 1>But where the output image in this case </v>
<v Speaker 1>is the segmentation is a wear a color </v>

650
00:47:24.001 --> 00:47:25.020
<v Speaker 1>indicates what,</v>
<v Speaker 1>ah,</v>

651
00:47:25.070 --> 00:47:27.340
<v Speaker 1>what the object is of the category of </v>
<v Speaker 1>the,</v>

652
00:47:27.640 --> 00:47:30.190
<v Speaker 1>of the object.</v>
<v Speaker 1>So it's level of segmentation.</v>

653
00:47:30.191 --> 00:47:35.191
<v Speaker 1>Every single pixel in the image is </v>
<v Speaker 1>assigned a class of category of where </v>

654
00:47:35.191 --> 00:47:39.901
<v Speaker 1>that pixel belongs to.</v>
<v Speaker 1>This is the kind of task that's overlaid</v>

655
00:47:41.471 --> 00:47:45.760
<v Speaker 1>on top of other sensory information </v>
<v Speaker 1>coming from the car.</v>

656
00:47:45.761 --> 00:47:49.510
<v Speaker 1>In order to perceive the external </v>
<v Speaker 1>environment,</v>

657
00:47:50.290 --> 00:47:54.910
<v Speaker 1>you can continue to extract information </v>
<v Speaker 1>from images in this way to produce image</v>

658
00:47:54.911 --> 00:47:56.530
<v Speaker 1>to image mapping.</v>
<v Speaker 1>For example,</v>

659
00:47:56.531 --> 00:48:01.531
<v Speaker 1>to colorize images and take from gray </v>
<v Speaker 1>scale images to color images or you can </v>

660
00:48:04.621 --> 00:48:08.550
<v Speaker 1>use that kind of heat map information to</v>
<v Speaker 1>localize objects in the image,</v>

661
00:48:08.980 --> 00:48:13.980
<v Speaker 1>so as opposed to just classifying that </v>
<v Speaker 1>this is an image of a of a cow are CNN </v>

662
00:48:14.070 --> 00:48:19.070
<v Speaker 1>fast and faster.</v>
<v Speaker 1>Our CNN and a lot of other localization </v>

663
00:48:19.070 --> 00:48:22.911
<v Speaker 1>networks allow you to propose different </v>
<v Speaker 1>candidates for where exactly the car was</v>

664
00:48:23.791 --> 00:48:27.600
<v Speaker 1>located in this image and thereby being </v>
<v Speaker 1>able to perform object detection,</v>

665
00:48:27.720 --> 00:48:32.720
<v Speaker 1>not just object classification in 2017 </v>
<v Speaker 1>has been a lot of cool applications of </v>

666
00:48:36.111 --> 00:48:39.290
<v Speaker 1>these architectures.</v>
<v Speaker 1>One of which is back on removal.</v>

667
00:48:40.340 --> 00:48:42.230
<v Speaker 1>Again,</v>
<v Speaker 1>mapping from image to image,</v>

668
00:48:42.350 --> 00:48:47.350
<v Speaker 1>ability to remove a background from </v>
<v Speaker 1>selfies of humans or human like</v>

669
00:48:50.450 --> 00:48:55.450
<v Speaker 1>pictures of faces.</v>
<v Speaker 1>The references with some incredible </v>

670
00:48:57.281 --> 00:49:02.281
<v Speaker 1>animations are in the bottom of the </v>
<v Speaker 1>slide and the slides are now available </v>

671
00:49:02.281 --> 00:49:06.091
<v Speaker 1>online.</v>
<v Speaker 1>Big Stupid Hd.</v>

672
00:49:08.010 --> 00:49:12.310
<v Speaker 1>There's been a lot of work in gans </v>
<v Speaker 1>generative artifice.</v>

673
00:49:12.311 --> 00:49:17.311
<v Speaker 1>Ariel networks in particular in driving </v>
<v Speaker 1>gans have been used to generate examples</v>

674
00:49:20.280 --> 00:49:25.280
<v Speaker 1>that generate examples from source data.</v>
<v Speaker 1>Whether that's from raw data or in this </v>

675
00:49:26.491 --> 00:49:30.540
<v Speaker 1>case with pics to picks.</v>
<v Speaker 1>Hd is taking course,</v>

676
00:49:30.720 --> 00:49:35.720
<v Speaker 1>semantic labeling of the images,</v>
<v Speaker 1>pixel level and producing photo </v>

677
00:49:36.081 --> 00:49:41.081
<v Speaker 1>realistic,</v>
<v Speaker 1>high definition images of the forward </v>

678
00:49:41.081 --> 00:49:45.111
<v Speaker 1>roadway.</v>
<v Speaker 1>This is an exciting possibility for </v>

679
00:49:45.111 --> 00:49:48.360
<v Speaker 1>being able to generate a variety of </v>
<v Speaker 1>cases for self driving cars,</v>

680
00:49:48.510 --> 00:49:51.300
<v Speaker 1>for autonomous vehicles to be able to </v>
<v Speaker 1>learn to generate,</v>

681
00:49:51.301 --> 00:49:55.170
<v Speaker 1>to augment the data and be able to </v>
<v Speaker 1>change the way different rows look,</v>

682
00:49:55.200 --> 00:49:57.570
<v Speaker 1>road conditions to change the way </v>
<v Speaker 1>vehicles look,</v>

683
00:49:57.630 --> 00:49:58.860
<v Speaker 1>cyclists,</v>
<v Speaker 1>pedestrians.</v>

684
00:50:00.440 --> 00:50:02.540
<v Speaker 1>Then we can move on to recur in your own</v>
<v Speaker 1>networks.</v>

685
00:50:02.541 --> 00:50:05.180
<v Speaker 1>Everything I've talked about was one to </v>
<v Speaker 1>one,</v>

686
00:50:05.181 --> 00:50:08.030
<v Speaker 1>mapping from image to image or image to </v>
<v Speaker 1>number,</v>

687
00:50:08.390 --> 00:50:10.820
<v Speaker 1>but currently all networks or work with </v>
<v Speaker 1>sequences.</v>

688
00:50:11.410 --> 00:50:16.410
<v Speaker 1>We can use sequences to generate </v>
<v Speaker 1>handwriting to generate text captions </v>

689
00:50:21.650 --> 00:50:26.210
<v Speaker 1>from an image based on the localization </v>
<v Speaker 1>is the various detections in that image.</v>

690
00:50:28.350 --> 00:50:32.080
<v Speaker 1>What can provide video description </v>
<v Speaker 1>generation,</v>

691
00:50:32.230 --> 00:50:37.230
<v Speaker 1>so taking a video and combining </v>
<v Speaker 1>convolution neural networks with </v>

692
00:50:37.230 --> 00:50:41.560
<v Speaker 1>recurrent neural networks,</v>
<v Speaker 1>using convolutional neural networks to </v>

693
00:50:41.560 --> 00:50:44.551
<v Speaker 1>extract features frame to frame and </v>
<v Speaker 1>using those extracted features to input </v>

694
00:50:44.551 --> 00:50:49.531
<v Speaker 1>into our the rns to then generate a a,</v>
<v Speaker 1>a labeling,</v>

695
00:50:50.260 --> 00:50:52.510
<v Speaker 1>a description,</v>
<v Speaker 1>what's going on in the video.</v>

696
00:50:54.910 --> 00:50:57.610
<v Speaker 1>A lot of exciting approaches for </v>
<v Speaker 1>autonomous systems,</v>

697
00:50:57.970 --> 00:51:02.970
<v Speaker 1>especially in drones were the time to </v>
<v Speaker 1>make a decision a is short,</v>

698
00:51:04.720 --> 00:51:09.720
<v Speaker 1>same with the RC car,</v>
<v Speaker 1>traveling 30 miles an hour at tensional </v>

699
00:51:09.720 --> 00:51:13.321
<v Speaker 1>mechanisms for steering the attention of</v>
<v Speaker 1>the network had been very popular for </v>

700
00:51:13.420 --> 00:51:18.420
<v Speaker 1>the localization task and for just </v>
<v Speaker 1>saving how much interpretation of the </v>

701
00:51:18.420 --> 00:51:20.020
<v Speaker 1>image,</v>
<v Speaker 1>how many pixels need to be considered in</v>

702
00:51:20.021 --> 00:51:25.021
<v Speaker 1>the classification task so we can steer,</v>
<v Speaker 1>we can model the way a human being looks</v>

703
00:51:27.371 --> 00:51:32.371
<v Speaker 1>around and image to interpret it and use</v>
<v Speaker 1>the network to do the same and we can </v>

704
00:51:32.371 --> 00:51:35.800
<v Speaker 1>use that kind of steering to a draw </v>
<v Speaker 1>images as well.</v>

705
00:51:41.550 --> 00:51:46.550
<v Speaker 1>Finally,</v>
<v Speaker 1>the big breakthroughs in 2017 came from </v>

706
00:51:46.550 --> 00:51:48.390
<v Speaker 1>this,</v>
<v Speaker 1>the pong to pixels,</v>

707
00:51:48.391 --> 00:51:51.450
<v Speaker 1>the reinforcement learning,</v>
<v Speaker 1>using sensory data,</v>

708
00:51:51.451 --> 00:51:56.451
<v Speaker 1>raw sensory data,</v>
<v Speaker 1>and use reinforcement learning methods </v>

709
00:51:56.451 --> 00:51:56.610
<v Speaker 1>deeper.</v>
<v Speaker 1>All methods of which we'll talk about on</v>

710
00:51:56.611 --> 00:52:01.611
<v Speaker 1>Wednesday.</v>
<v Speaker 1>I'm really excited about the underlying </v>

711
00:52:01.611 --> 00:52:05.331
<v Speaker 1>methodology of deep traffic and deep </v>
<v Speaker 1>crash is using neural networks as the </v>

712
00:52:07.861 --> 00:52:11.610
<v Speaker 1>approximators inside reinforcement </v>
<v Speaker 1>learning approaches.</v>

713
00:52:11.940 --> 00:52:16.940
<v Speaker 1>So Alphago in 2016 have achieved a </v>
<v Speaker 1>monumental task that when I first </v>

714
00:52:17.671 --> 00:52:22.671
<v Speaker 1>started in artificial intelligence was </v>
<v Speaker 1>told to me it was impossible for any </v>

715
00:52:22.671 --> 00:52:26.181
<v Speaker 1>system to accomplish,</v>
<v Speaker 1>which is to win at the game of go </v>

716
00:52:26.181 --> 00:52:27.120
<v Speaker 1>against the top human player in the </v>
<v Speaker 1>world.</v>

717
00:52:29.250 --> 00:52:34.250
<v Speaker 1>However,</v>
<v Speaker 1>that method was trained on human expert </v>

718
00:52:34.250 --> 00:52:37.491
<v Speaker 1>positions.</v>
<v Speaker 1>The alphago system was trained on </v>

719
00:52:37.491 --> 00:52:41.691
<v Speaker 1>previous games played by human experts </v>
<v Speaker 1>and an incredible accomplishment.</v>

720
00:52:43.020 --> 00:52:48.020
<v Speaker 1>Alphago zero in 2017 was able to beat </v>
<v Speaker 1>Alphago and many of its variance by </v>

721
00:52:52.781 --> 00:52:57.781
<v Speaker 1>playing itself from zero information.</v>
<v Speaker 1>So no knowledge of human experts,</v>

722
00:53:01.840 --> 00:53:04.510
<v Speaker 1>no games,</v>
<v Speaker 1>no training data,</v>

723
00:53:04.690 --> 00:53:09.690
<v Speaker 1>very little human input.</v>
<v Speaker 1>And what more it was able to generate </v>

724
00:53:10.870 --> 00:53:13.720
<v Speaker 1>moves that were surprising to human </v>
<v Speaker 1>experts.</v>

725
00:53:15.290 --> 00:53:19.340
<v Speaker 1>I think it's Einstein that said that </v>
<v Speaker 1>intelligence,</v>

726
00:53:19.940 --> 00:53:22.610
<v Speaker 1>that the key mark of intelligence is </v>
<v Speaker 1>imagination.</v>

727
00:53:23.810 --> 00:53:28.810
<v Speaker 1>I think it's beautiful.</v>
<v Speaker 1>See an artificial intelligence system </v>

728
00:53:28.810 --> 00:53:30.360
<v Speaker 1>come up with something that surprises </v>
<v Speaker 1>human experts,</v>

729
00:53:31.670 --> 00:53:32.900
<v Speaker 1>truly surprises</v>

730
00:53:36.050 --> 00:53:41.050
<v Speaker 1>for the gambling junkies.</v>
<v Speaker 1>Deep Stack and a few other variants have</v>

731
00:53:41.121 --> 00:53:44.630
<v Speaker 1>been used in 2017 to when a heads up </v>
<v Speaker 1>poker.</v>

732
00:53:45.260 --> 00:53:47.090
<v Speaker 1>Again,</v>
<v Speaker 1>another incredible results.</v>

733
00:53:47.360 --> 00:53:50.760
<v Speaker 1>I was always told and artificial </v>
<v Speaker 1>intelligence will be impossible for dave</v>

734
00:53:51.020 --> 00:53:56.020
<v Speaker 1>for any machine learning method to </v>
<v Speaker 1>achieve and it was able to beat a </v>

735
00:53:56.020 --> 00:54:00.401
<v Speaker 1>professional player and several </v>
<v Speaker 1>competitors have come along since we're </v>

736
00:54:00.920 --> 00:54:04.040
<v Speaker 1>yet to be able to beat to win a </v>
<v Speaker 1>tournament setting.</v>

737
00:54:04.041 --> 00:54:06.230
<v Speaker 1>So multiple players,</v>
<v Speaker 1>for those of you familiar heads up,</v>

738
00:54:06.231 --> 00:54:08.450
<v Speaker 1>poker is one on one.</v>
<v Speaker 1>It's a much,</v>

739
00:54:08.480 --> 00:54:10.730
<v Speaker 1>much smaller,</v>
<v Speaker 1>easier space to,</v>

740
00:54:10.731 --> 00:54:11.930
<v Speaker 1>uh,</v>
<v Speaker 1>solve.</v>

741
00:54:12.620 --> 00:54:17.620
<v Speaker 1>There's a lot more humidity,</v>
<v Speaker 1>human dynamics going on from when </v>

742
00:54:17.620 --> 00:54:19.010
<v Speaker 1>there's multiple players,</v>
<v Speaker 1>but that's the task for 2018</v>

743
00:54:22.000 --> 00:54:24.880
<v Speaker 1>and the drawbacks.</v>
<v Speaker 1>So one of my favorite videos,</v>

744
00:54:24.881 --> 00:54:29.881
<v Speaker 1>a show it often have coast runners for </v>
<v Speaker 1>these deep reinforcement learning </v>

745
00:54:30.941 --> 00:54:35.560
<v Speaker 1>approaches.</v>
<v Speaker 1>The learning of the reward function,</v>

746
00:54:35.860 --> 00:54:40.860
<v Speaker 1>the definition of the word function </v>
<v Speaker 1>controls how the actual system behaves.</v>

747
00:54:42.880 --> 00:54:47.880
<v Speaker 1>And this will come.</v>
<v Speaker 1>This will be extremely important for us </v>

748
00:54:47.880 --> 00:54:51.301
<v Speaker 1>with autonomous vehicles.</v>
<v Speaker 1>Here the boat is tasked with gaining the</v>

749
00:54:51.970 --> 00:54:56.470
<v Speaker 1>highest number of points and it figures </v>
<v Speaker 1>out that it does not need to race,</v>

750
00:54:56.471 --> 00:54:59.410
<v Speaker 1>which is the whole point of the game in </v>
<v Speaker 1>order to gain points.</v>

751
00:54:59.440 --> 00:55:04.440
<v Speaker 1>But instead pickup green circles that </v>
<v Speaker 1>regenerate themselves over and over.</v>

752
00:55:05.890 --> 00:55:10.890
<v Speaker 1>This is the the counter intuitive </v>
<v Speaker 1>behavior of a system that would not be </v>

753
00:55:14.471 --> 00:55:16.750
<v Speaker 1>expected when you first designed the </v>
<v Speaker 1>reward function,</v>

754
00:55:17.080 --> 00:55:22.080
<v Speaker 1>and this is a very formal simple system,</v>
<v Speaker 1>nevertheless is extremely difficult to </v>

755
00:55:22.601 --> 00:55:26.670
<v Speaker 1>come up with a reward function that </v>
<v Speaker 1>makes it operate in the way you expected</v>

756
00:55:26.680 --> 00:55:31.680
<v Speaker 1>to operate.</v>
<v Speaker 1>Very applicable for autonomous vehicles </v>

757
00:55:31.680 --> 00:55:36.270
<v Speaker 1>and of course on the perception side,</v>
<v Speaker 1>as I mentioned with the hostage and the </v>

758
00:55:36.270 --> 00:55:37.510
<v Speaker 1>dog,</v>
<v Speaker 1>a little bit of noise.</v>

759
00:55:38.020 --> 00:55:43.020
<v Speaker 1>The 99 point six percent confidence,</v>
<v Speaker 1>we can predict that the noise up top is </v>

760
00:55:43.020 --> 00:55:44.020
<v Speaker 1>a robin,</v>
<v Speaker 1>a Cheetah,</v>

761
00:55:44.170 --> 00:55:45.760
<v Speaker 1>Armadillo,</v>
<v Speaker 1>lesser panda.</v>

762
00:55:45.880 --> 00:55:49.450
<v Speaker 1>These are outputs from actual state of </v>
<v Speaker 1>the art and neural networks</v>

763
00:55:51.650 --> 00:55:54.560
<v Speaker 1>taking into noise and producing a </v>
<v Speaker 1>confident prediction.</v>

764
00:55:55.880 --> 00:55:58.820
<v Speaker 1>It should build our intuition to </v>
<v Speaker 1>understand that we don't,</v>

765
00:55:59.090 --> 00:56:02.040
<v Speaker 1>that the visual characteristics,</v>
<v Speaker 1>the vision,</v>

766
00:56:02.070 --> 00:56:06.800
<v Speaker 1>the special characteristics of an image </v>
<v Speaker 1>that not necessarily convey the level of</v>

767
00:56:06.801 --> 00:56:11.801
<v Speaker 1>hierarchy necessary to function in this </v>
<v Speaker 1>world in a similar way with a dog and </v>

768
00:56:14.181 --> 00:56:19.181
<v Speaker 1>the ostrich and everything in an ostrich</v>
<v Speaker 1>and network confidently with a little </v>

769
00:56:19.521 --> 00:56:21.770
<v Speaker 1>bit of noise can make the wrong </v>
<v Speaker 1>prediction.</v>

770
00:56:22.570 --> 00:56:26.830
<v Speaker 1>Thinking the bus is an ostrich and as an</v>
<v Speaker 1>ostrich,</v>

771
00:56:29.090 --> 00:56:34.090
<v Speaker 1>they're easily fooled,</v>
<v Speaker 1>but not really because they performed </v>

772
00:56:34.501 --> 00:56:37.120
<v Speaker 1>the task that they were trained to do </v>
<v Speaker 1>well,</v>

773
00:56:38.200 --> 00:56:41.860
<v Speaker 1>so we have to make sure we keep our </v>
<v Speaker 1>intuition</v>

774
00:56:44.130 --> 00:56:49.130
<v Speaker 1>optimized to the way machines learn,</v>
<v Speaker 1>not the way humans have learned over the</v>

775
00:56:49.711 --> 00:56:54.590
<v Speaker 1>540 million years of data that we've </v>
<v Speaker 1>gained through developing the eye,</v>

776
00:56:54.591 --> 00:56:58.290
<v Speaker 1>the revolution,</v>
<v Speaker 1>the current challenge is we're taking on</v>

777
00:56:58.650 --> 00:57:03.650
<v Speaker 1>first transfer learning.</v>
<v Speaker 1>There's a lot of success in transfer </v>

778
00:57:03.650 --> 00:57:05.940
<v Speaker 1>learning between domains that are very </v>
<v Speaker 1>close to each other,</v>

779
00:57:06.300 --> 00:57:09.090
<v Speaker 1>so image classification from one domain </v>
<v Speaker 1>to the next.</v>

780
00:57:10.530 --> 00:57:15.530
<v Speaker 1>There's a lot of value in forming </v>
<v Speaker 1>representations of the way scenes look </v>

781
00:57:15.530 --> 00:57:18.630
<v Speaker 1>in order to see natural scenes look in </v>
<v Speaker 1>order to do scene segmentation,</v>

782
00:57:18.631 --> 00:57:20.040
<v Speaker 1>the driving case,</v>
<v Speaker 1>for example,</v>

783
00:57:20.370 --> 00:57:25.370
<v Speaker 1>but we're not able to do any any bigger </v>
<v Speaker 1>leaps in the way we perform transfer </v>

784
00:57:26.701 --> 00:57:31.701
<v Speaker 1>learning.</v>
<v Speaker 1>The biggest challenge for deep learning </v>

785
00:57:31.701 --> 00:57:32.670
<v Speaker 1>is to generalize,</v>
<v Speaker 1>generalize across domains.</v>

786
00:57:33.480 --> 00:57:38.480
<v Speaker 1>It lacks the ability to reason and the </v>
<v Speaker 1>way that we've defined understanding </v>

787
00:57:38.480 --> 00:57:42.681
<v Speaker 1>previously,</v>
<v Speaker 1>which is the ability to turn complex </v>

788
00:57:42.681 --> 00:57:42.930
<v Speaker 1>information into simple,</v>
<v Speaker 1>useful information,</v>

789
00:57:44.870 --> 00:57:49.870
<v Speaker 1>convert domain specific complicated </v>
<v Speaker 1>sensory information that doesn't relate </v>

790
00:57:51.830 --> 00:57:56.830
<v Speaker 1>to the initial training set.</v>
<v Speaker 1>That's the open challenge for deep </v>

791
00:57:56.830 --> 00:57:57.020
<v Speaker 1>learning,</v>
<v Speaker 1>training,</v>

792
00:57:57.050 --> 00:58:02.050
<v Speaker 1>very little data,</v>
<v Speaker 1>and then go and reason and operate in </v>

793
00:58:02.050 --> 00:58:03.830
<v Speaker 1>the real world right now.</v>
<v Speaker 1>You know now it's a very inefficient.</v>

794
00:58:04.020 --> 00:58:08.330
<v Speaker 1>They're acquiring a big data.</v>
<v Speaker 1>They require supervised data,</v>

795
00:58:08.360 --> 00:58:10.820
<v Speaker 1>which means they need human costs,</v>
<v Speaker 1>the human input.</v>

796
00:58:12.440 --> 00:58:17.440
<v Speaker 1>They're not fully automated despite the </v>
<v Speaker 1>fact that the feature learning </v>

797
00:58:17.440 --> 00:58:18.620
<v Speaker 1>incredibly,</v>
<v Speaker 1>the big breakthrough feature learning is</v>

798
00:58:18.621 --> 00:58:23.621
<v Speaker 1>performed automatically.</v>
<v Speaker 1>You're still have to do a lot of design </v>

799
00:58:23.621 --> 00:58:27.591
<v Speaker 1>or the actual architecture of the </v>
<v Speaker 1>network and all the different hyper </v>

800
00:58:27.591 --> 00:58:30.671
<v Speaker 1>parameter tuning and he used to perform </v>
<v Speaker 1>human input perhaps a little bit more </v>

801
00:58:30.801 --> 00:58:33.770
<v Speaker 1>educated human input and former phd </v>
<v Speaker 1>students.</v>

802
00:58:33.860 --> 00:58:38.860
<v Speaker 1>Postdocs faculty is required to high </v>
<v Speaker 1>during these hyper parameters,</v>

803
00:58:39.230 --> 00:58:41.270
<v Speaker 1>but nevertheless human input is still </v>
<v Speaker 1>necessary.</v>

804
00:58:41.840 --> 00:58:45.560
<v Speaker 1>They cannot be left alone.</v>
<v Speaker 1>For the most part,</v>

805
00:58:47.130 --> 00:58:49.410
<v Speaker 1>their award defining the award is with </v>
<v Speaker 1>south coast.</v>

806
00:58:49.411 --> 00:58:54.090
<v Speaker 1>Ron is extremely difficult for systems </v>
<v Speaker 1>that operate in the real world.</v>

807
00:58:54.150 --> 00:58:58.650
<v Speaker 1>Transparency quite possibly is not an </v>
<v Speaker 1>important one,</v>

808
00:58:58.890 --> 00:59:02.010
<v Speaker 1>but neural networks currently our black </v>
<v Speaker 1>box for the most part,</v>

809
00:59:02.220 --> 00:59:07.220
<v Speaker 1>they're not able to accept through a few</v>
<v Speaker 1>successful visualization methods that </v>

810
00:59:07.220 --> 00:59:09.060
<v Speaker 1>visualize different aspects of the </v>
<v Speaker 1>activations.</v>

811
00:59:09.330 --> 00:59:14.330
<v Speaker 1>They're not able to reveal to us humans </v>
<v Speaker 1>why they work or where they fail</v>

812
00:59:17.290 --> 00:59:22.290
<v Speaker 1>and this.</v>
<v Speaker 1>This is a philosophical question for </v>

813
00:59:22.290 --> 00:59:23.990
<v Speaker 1>autonomous vehicles that we may not care</v>
<v Speaker 1>as human beings if the system works well</v>

814
00:59:23.991 --> 00:59:28.910
<v Speaker 1>enough,</v>
<v Speaker 1>but I would argue that it be a long time</v>

815
00:59:29.120 --> 00:59:34.120
<v Speaker 1>before systems work well enough or we </v>
<v Speaker 1>don't care well care and will have to </v>

816
00:59:35.121 --> 00:59:37.850
<v Speaker 1>work together with these systems and </v>
<v Speaker 1>that's where transparency,</v>

817
00:59:37.851 --> 00:59:42.851
<v Speaker 1>communication,</v>
<v Speaker 1>collaboration is critical and edge </v>

818
00:59:42.851 --> 00:59:46.121
<v Speaker 1>cases.</v>
<v Speaker 1>It's all about edge cases in robotics </v>

819
00:59:46.121 --> 00:59:50.140
<v Speaker 1>and autonomous vehicles.</v>
<v Speaker 1>The 99 point nine percent of driving is </v>

820
00:59:50.140 --> 00:59:53.420
<v Speaker 1>really boring.</v>
<v Speaker 1>It's the same especially highway driving</v>

821
00:59:53.480 --> 00:59:56.030
<v Speaker 1>traffic driving.</v>
<v Speaker 1>It's the same.</v>

822
00:59:56.450 --> 00:59:59.630
<v Speaker 1>The obstacle avoidance,</v>
<v Speaker 1>the car following the lane centering.</v>

823
00:59:59.780 --> 01:00:02.870
<v Speaker 1>All of these problems with trivial is </v>
<v Speaker 1>the edge cases,</v>

824
01:00:03.260 --> 01:00:08.260
<v Speaker 1>the trillions of edge cases that need to</v>
<v Speaker 1>be generalized over on a very small </v>

825
01:00:08.781 --> 01:00:13.781
<v Speaker 1>amount of training data.</v>
<v Speaker 1>So again,</v>

826
01:00:16.091 --> 01:00:21.091
<v Speaker 1>I returned to why deep learning.</v>
<v Speaker 1>I mentioned a bunch of challenges and </v>

827
01:00:24.921 --> 01:00:29.921
<v Speaker 1>this is an opportunity.</v>
<v Speaker 1>It's an opportunity to come up with </v>

828
01:00:31.130 --> 01:00:35.840
<v Speaker 1>techniques that opera is successful in </v>
<v Speaker 1>this world,</v>

829
01:00:36.230 --> 01:00:41.230
<v Speaker 1>so I hope the competitions were </v>
<v Speaker 1>presented in this class and the </v>

830
01:00:41.230 --> 01:00:44.381
<v Speaker 1>autonomous vehicle domain.</v>
<v Speaker 1>We'll give you some insight and </v>

831
01:00:44.381 --> 01:00:47.321
<v Speaker 1>opportunity to apply in.</v>
<v Speaker 1>Some of these cases are open research </v>

832
01:00:47.321 --> 01:00:51.431
<v Speaker 1>problems with semantic segmentation of </v>
<v Speaker 1>external perception with control of the </v>

833
01:00:51.861 --> 01:00:56.861
<v Speaker 1>vehicle and deep traffic and with deep </v>
<v Speaker 1>crash of control of the vehicle and </v>

834
01:00:59.810 --> 01:01:04.810
<v Speaker 1>under actuator.</v>
<v Speaker 1>Good high speed conditions and the </v>

835
01:01:04.941 --> 01:01:06.110
<v Speaker 1>driver's state perception.</v>

836
01:01:07.350 --> 01:01:08.940
<v Speaker 2>Okay,</v>

837
01:01:10.940 --> 01:01:15.940
<v Speaker 1>so would that.</v>
<v Speaker 1>I wanted to introduce deep learning to </v>

838
01:01:15.940 --> 01:01:16.640
<v Speaker 1>you today before we get to the fun </v>
<v Speaker 1>tomorrow of autonomous vehicles.</v>

839
01:01:17.270 --> 01:01:21.360
<v Speaker 1>So we'd like to thank and video,</v>
<v Speaker 1>Google auto live,</v>

840
01:01:22.260 --> 01:01:27.110
<v Speaker 1>Toyota and the risk of setting off </v>
<v Speaker 1>people's phones.</v>

841
01:01:27.440 --> 01:01:28.850
<v Speaker 1>Amazon,</v>
<v Speaker 1>Alexa Auto,</v>

842
01:01:31.280 --> 01:01:36.280
<v Speaker 1>but truly I would like to say that I've </v>
<v Speaker 1>been humbled over the past year by the </v>

843
01:01:41.090 --> 01:01:46.090
<v Speaker 1>thousands of messages were received by </v>
<v Speaker 1>the attention by the 18,000</v>

844
01:01:46.220 --> 01:01:50.240
<v Speaker 1>competition entries by the many people </v>
<v Speaker 1>across the world.</v>

845
01:01:50.241 --> 01:01:55.241
<v Speaker 1>Not just here at Mit that are brilliant </v>
<v Speaker 1>that I got a chance to interact with and</v>

846
01:01:55.671 --> 01:01:59.630
<v Speaker 1>I hope we go bigger and do some </v>
<v Speaker 1>impressive stuff in 2018.</v>

847
01:02:00.410 --> 01:02:02.660
<v Speaker 1>Thank you very much and tomorrow is self</v>
<v Speaker 1>driving.</v>

