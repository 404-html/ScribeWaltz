WEBVTT

1
00:00:00.600 --> 00:00:04.170
<v Speaker 1>Welcome to course six as zero,</v>
<v Speaker 1>nine,</v>

2
00:00:04.171 --> 00:00:09.171
<v Speaker 1>nine artificial general intelligence.</v>
<v Speaker 1>We will explore the nature of </v>

3
00:00:09.691 --> 00:00:14.610
<v Speaker 1>intelligence from as much as possible.</v>
<v Speaker 1>An engineering perspective.</v>

4
00:00:15.630 --> 00:00:20.630
<v Speaker 1>You will hear many voices.</v>
<v Speaker 1>My voice will be that of an engineer.</v>

5
00:00:23.130 --> 00:00:28.130
<v Speaker 1>Our mission is to engineer intelligence.</v>
<v Speaker 1>The mit motto is mined in hand.</v>

6
00:00:32.580 --> 00:00:37.580
<v Speaker 1>What that means is we want to explore </v>
<v Speaker 1>the fundamental science of what makes an</v>

7
00:00:41.131 --> 00:00:46.131
<v Speaker 1>intelligent system,</v>
<v Speaker 1>the core concepts behind our </v>

8
00:00:46.321 --> 00:00:51.321
<v Speaker 1>understanding of what is intelligence,</v>
<v Speaker 1>but we always want to ground it in the </v>

9
00:00:52.561 --> 00:00:57.561
<v Speaker 1>creation of intelligence systems.</v>
<v Speaker 1>We always want to be in the now in today</v>

10
00:00:59.760 --> 00:01:04.080
<v Speaker 1>in understanding how today we can build </v>
<v Speaker 1>artificial intelligence systems that can</v>

11
00:01:04.081 --> 00:01:09.000
<v Speaker 1>make for a better world that is the core</v>
<v Speaker 1>for us here at Mit,</v>

12
00:01:10.020 --> 00:01:13.770
<v Speaker 1>first and foremost,</v>
<v Speaker 1>where scientists and engineers,</v>

13
00:01:14.280 --> 00:01:16.680
<v Speaker 1>our goal is to engineer intelligence.</v>

14
00:01:19.710 --> 00:01:24.710
<v Speaker 1>We want to provide with this approach a </v>
<v Speaker 1>balanced to the very important but </v>

15
00:01:28.110 --> 00:01:31.740
<v Speaker 1>overrepresented view of artificial </v>
<v Speaker 1>general intelligence.</v>

16
00:01:32.400 --> 00:01:37.200
<v Speaker 1>That black box reasoning view,</v>
<v Speaker 1>where the idea is,</v>

17
00:01:37.201 --> 00:01:41.580
<v Speaker 1>once we know how to create a human level</v>
<v Speaker 1>intelligence system,</v>

18
00:01:41.880 --> 00:01:46.880
<v Speaker 1>how will society be impacted?</v>
<v Speaker 1>Will robots take over and kill everyone?</v>

19
00:01:50.340 --> 00:01:55.340
<v Speaker 1>Will we achieve a utopia that will </v>
<v Speaker 1>remove the need to do any of the messy </v>

20
00:01:55.591 --> 00:01:58.560
<v Speaker 1>jobs that will make us all extremely </v>
<v Speaker 1>happy?</v>

21
00:01:59.040 --> 00:02:03.450
<v Speaker 1>Those kinds of beautiful philosophical </v>
<v Speaker 1>concepts are interesting to explore,</v>

22
00:02:03.451 --> 00:02:05.520
<v Speaker 1>but that's not what we're interested in </v>
<v Speaker 1>doing.</v>

23
00:02:06.210 --> 00:02:09.660
<v Speaker 1>I believe that from an engineering </v>
<v Speaker 1>perspective,</v>

24
00:02:09.810 --> 00:02:13.110
<v Speaker 1>we want to focus on the black box of </v>
<v Speaker 1>Agi,</v>

25
00:02:14.040 --> 00:02:19.040
<v Speaker 1>start to build insights and intuitions </v>
<v Speaker 1>about how we create systems that </v>

26
00:02:19.291 --> 00:02:24.291
<v Speaker 1>approach human level intelligence.</v>
<v Speaker 1>I believe we're very far away from </v>

27
00:02:25.741 --> 00:02:29.970
<v Speaker 1>creating anything resembling human level</v>
<v Speaker 1>intelligence.</v>

28
00:02:31.530 --> 00:02:36.530
<v Speaker 1>However,</v>
<v Speaker 1>the dimension of the metric behind the </v>

29
00:02:37.321 --> 00:02:42.321
<v Speaker 1>ward far may not be time in time,</v>
<v Speaker 1>perhaps through a few breakthroughs may </v>

30
00:02:48.381 --> 00:02:50.130
<v Speaker 1>be even one breakthrough.</v>

31
00:02:50.370 --> 00:02:53.670
<v Speaker 1>Everything can change,</v>
<v Speaker 1>but as we stand now,</v>

32
00:02:54.120 --> 00:02:59.120
<v Speaker 1>our current methods as we will explore </v>
<v Speaker 1>from the various ideas and approaches </v>

33
00:02:59.120 --> 00:03:00.750
<v Speaker 1>and the guest speakers coming here,</v>
<v Speaker 1>uh,</v>

34
00:03:00.930 --> 00:03:05.880
<v Speaker 1>over the next two weeks and beyond,</v>
<v Speaker 1>our best understanding,</v>

35
00:03:05.881 --> 00:03:10.881
<v Speaker 1>our best intuition insights are not yet </v>
<v Speaker 1>at the level of reaching without a major</v>

36
00:03:13.991 --> 00:03:17.890
<v Speaker 1>leap and breakthrough and paradigm shift</v>
<v Speaker 1>towards human level intelligence.</v>

37
00:03:18.670 --> 00:03:23.670
<v Speaker 1>So it's not constructive to consider the</v>
<v Speaker 1>impact of artificial intelligence to </v>

38
00:03:23.681 --> 00:03:28.681
<v Speaker 1>consider questions of safety and ethics.</v>
<v Speaker 1>Fundamental,</v>

39
00:03:30.970 --> 00:03:35.970
<v Speaker 1>extremely important questions,</v>
<v Speaker 1>we it's not constructive to consider </v>

40
00:03:35.970 --> 00:03:40.861
<v Speaker 1>those questions without also deeply </v>
<v Speaker 1>considering the black box of the actual </v>

41
00:03:41.261 --> 00:03:45.190
<v Speaker 1>methods of artificial intelligence,</v>
<v Speaker 1>human level,</v>

42
00:03:45.191 --> 00:03:48.670
<v Speaker 1>artificial intelligence,</v>
<v Speaker 1>and that's what I see.</v>

43
00:03:48.820 --> 00:03:52.540
<v Speaker 1>What I hope this course can be,</v>
<v Speaker 1>its first iteration,</v>

44
00:03:52.960 --> 00:03:57.960
<v Speaker 1>it's first exploratory attempt to try to</v>
<v Speaker 1>look at different approaches of how we </v>

45
00:03:59.921 --> 00:04:04.921
<v Speaker 1>can engineer intelligence.</v>
<v Speaker 1>That's the role of mit is tradition of </v>

46
00:04:04.921 --> 00:04:07.480
<v Speaker 1>mine in hand is to consider the big </v>
<v Speaker 1>picture,</v>

47
00:04:07.630 --> 00:04:10.030
<v Speaker 1>the future impact of society 10,</v>
<v Speaker 1>20,</v>

48
00:04:10.031 --> 00:04:11.470
<v Speaker 1>30,</v>
<v Speaker 1>40 years out,</v>

49
00:04:11.770 --> 00:04:16.770
<v Speaker 1>but fundamentally grounded in what kind </v>
<v Speaker 1>of methods do we have today and what are</v>

50
00:04:17.741 --> 00:04:21.700
<v Speaker 1>the limitations and possibilities of </v>
<v Speaker 1>achieving that.</v>

51
00:04:21.760 --> 00:04:26.760
<v Speaker 1>The black box of Agi and in the future </v>
<v Speaker 1>impact on society of creating artificial</v>

52
00:04:31.451 --> 00:04:35.740
<v Speaker 1>intelligence systems that get become </v>
<v Speaker 1>increasingly more intelligent.</v>

53
00:04:36.190 --> 00:04:41.190
<v Speaker 1>The fundamental disagreement lies in the</v>
<v Speaker 1>fact the very core of that black box,</v>

54
00:04:43.360 --> 00:04:48.160
<v Speaker 1>which is how hard is it to build an Agi </v>
<v Speaker 1>system?</v>

55
00:04:48.520 --> 00:04:52.150
<v Speaker 1>How hard is it to create a human level </v>
<v Speaker 1>artificial intelligence system?</v>

56
00:04:52.360 --> 00:04:55.120
<v Speaker 1>That's the open question for all of us,</v>
<v Speaker 1>from,</v>

57
00:04:55.480 --> 00:05:00.480
<v Speaker 1>from Josh Tenenbaum to Andrea carpathy </v>
<v Speaker 1>to folks some open ai to Boston </v>

58
00:05:03.371 --> 00:05:08.371
<v Speaker 1>dynamics,</v>
<v Speaker 1>the brilliant leaders in various fields </v>

59
00:05:08.371 --> 00:05:09.370
<v Speaker 1>of artificial intelligence that will </v>
<v Speaker 1>come here.</v>

60
00:05:09.371 --> 00:05:11.620
<v Speaker 1>That's the open question.</v>
<v Speaker 1>How hard is.</v>

61
00:05:11.621 --> 00:05:16.621
<v Speaker 1>It has been a lot of incredibly </v>
<v Speaker 1>impressive results in deep learning in </v>

62
00:05:17.291 --> 00:05:22.291
<v Speaker 1>neuroscience and computational cognitive</v>
<v Speaker 1>science in robotics,</v>

63
00:05:23.620 --> 00:05:28.210
<v Speaker 1>but how far are we still to go to the </v>
<v Speaker 1>Agi?</v>

64
00:05:28.211 --> 00:05:33.211
<v Speaker 1>That's the fundamental question that we </v>
<v Speaker 1>need to explore before we consider the </v>

65
00:05:33.610 --> 00:05:36.340
<v Speaker 1>questions,</v>
<v Speaker 1>the future impact on society.</v>

66
00:05:38.550 --> 00:05:41.610
<v Speaker 1>And the goal for this class is to build </v>
<v Speaker 1>intuition.</v>

67
00:05:41.650 --> 00:05:42.810
<v Speaker 1>One,</v>
<v Speaker 1>talk at a time,</v>

68
00:05:43.320 --> 00:05:48.320
<v Speaker 1>a project at a time build intuition </v>
<v Speaker 1>about where we stand,</v>

69
00:05:48.750 --> 00:05:51.180
<v Speaker 1>about what the limitations of current </v>
<v Speaker 1>approaches are.</v>

70
00:05:51.240 --> 00:05:52.680
<v Speaker 1>How can we close the gap?</v>

71
00:05:55.140 --> 00:06:00.140
<v Speaker 1>A Nice meme that I caught on twitter </v>
<v Speaker 1>recently of a,</v>

72
00:06:01.480 --> 00:06:06.480
<v Speaker 1>the difference between the engineering </v>
<v Speaker 1>approach at the very simplest of a </v>

73
00:06:07.460 --> 00:06:12.460
<v Speaker 1>google intern typing a for loop that </v>
<v Speaker 1>just does a grid search on parameters </v>

74
00:06:12.460 --> 00:06:14.660
<v Speaker 1>for neural network.</v>
<v Speaker 1>Uh,</v>

75
00:06:14.780 --> 00:06:19.780
<v Speaker 1>and on the right is the way media would </v>
<v Speaker 1>report this for loop the Google ai </v>

76
00:06:21.711 --> 00:06:26.711
<v Speaker 1>created its own baby ai.</v>
<v Speaker 1>I think it's easy for us to go one way </v>

77
00:06:31.191 --> 00:06:33.890
<v Speaker 1>or the other,</v>
<v Speaker 1>but we'd like to do both.</v>

78
00:06:34.490 --> 00:06:39.490
<v Speaker 1>Our first goal is to avoid the pitfalls </v>
<v Speaker 1>of black box thinking of the futurism </v>

79
00:06:39.621 --> 00:06:44.621
<v Speaker 1>thinking that results in hype,</v>
<v Speaker 1>that's detached from scientific </v>

80
00:06:44.621 --> 00:06:46.550
<v Speaker 1>engineering,</v>
<v Speaker 1>understanding of what the actual systems</v>

81
00:06:46.560 --> 00:06:50.120
<v Speaker 1>are doing.</v>
<v Speaker 1>That's what the media often reports.</v>

82
00:06:50.300 --> 00:06:55.300
<v Speaker 1>That's what some of our speakers will </v>
<v Speaker 1>explore in a rigorous way.</v>

83
00:06:57.231 --> 00:06:59.600
<v Speaker 1>It's still an important topic to </v>
<v Speaker 1>explore.</v>

84
00:06:59.780 --> 00:07:02.310
<v Speaker 1>Ray Kurzweil on Wednesday.</v>
<v Speaker 1>We'll look at.</v>

85
00:07:02.450 --> 00:07:07.450
<v Speaker 1>We'll explore this topic next week </v>
<v Speaker 1>talking about Ai Safety and autonomous </v>

86
00:07:07.450 --> 00:07:08.270
<v Speaker 1>weapons systems.</v>

87
00:07:08.270 --> 00:07:11.000
<v Speaker 1>We'll explore this topic that future </v>
<v Speaker 1>impact 10,</v>

88
00:07:11.001 --> 00:07:16.001
<v Speaker 1>20 years out.</v>
<v Speaker 1>How do we design systems today that </v>

89
00:07:16.001 --> 00:07:17.690
<v Speaker 1>would lead to safe systems tomorrow.</v>
<v Speaker 1>Still very important,</v>

90
00:07:17.900 --> 00:07:22.790
<v Speaker 1>but the reality is a lot of us need to </v>
<v Speaker 1>put a lot more emphasis on the left,</v>

91
00:07:23.000 --> 00:07:28.000
<v Speaker 1>on the for loops,</v>
<v Speaker 1>on creating these systems at the same </v>

92
00:07:28.000 --> 00:07:31.901
<v Speaker 1>time.</v>
<v Speaker 1>The second goal of what we're trying to </v>

93
00:07:31.901 --> 00:07:34.100
<v Speaker 1>do here is not emphasize the silliness,</v>
<v Speaker 1>the simplicity,</v>

94
00:07:34.101 --> 00:07:39.101
<v Speaker 1>the naive basic nature of this four loop</v>
<v Speaker 1>and the same way as was the process in </v>

95
00:07:41.421 --> 00:07:46.340
<v Speaker 1>creating nuclear weapons before,</v>
<v Speaker 1>during World War Two.</v>

96
00:07:48.170 --> 00:07:50.630
<v Speaker 1>The idea that as an engineer,</v>
<v Speaker 1>as a scientist,</v>

97
00:07:50.631 --> 00:07:55.580
<v Speaker 1>that I am just the scientist is also a </v>
<v Speaker 1>flawed way of thinking.</v>

98
00:07:55.910 --> 00:08:00.910
<v Speaker 1>We have to consider the big picture </v>
<v Speaker 1>impact the near term negative </v>

99
00:08:00.910 --> 00:08:03.650
<v Speaker 1>consequences that are preventable,</v>
<v Speaker 1>the low hanging fruit,</v>

100
00:08:03.651 --> 00:08:07.010
<v Speaker 1>the that can be prevented through that </v>
<v Speaker 1>engineering process.</v>

101
00:08:07.400 --> 00:08:12.400
<v Speaker 1>We have to do both and in this </v>
<v Speaker 1>engineering approach we always have to </v>

102
00:08:15.801 --> 00:08:20.801
<v Speaker 1>be cautious that just because we don't </v>
<v Speaker 1>understand,</v>

103
00:08:21.650 --> 00:08:26.650
<v Speaker 1>we're just because we our intuition,</v>
<v Speaker 1>our best understanding of the </v>

104
00:08:27.231 --> 00:08:32.210
<v Speaker 1>capabilities of modern systems that </v>
<v Speaker 1>learn to act in this world seem limited,</v>

105
00:08:32.211 --> 00:08:34.340
<v Speaker 1>seem far from human level intelligence.</v>

106
00:08:34.490 --> 00:08:39.020
<v Speaker 1>Our ability to learn and represent </v>
<v Speaker 1>common sense reasoning seems limited.</v>

107
00:08:39.830 --> 00:08:44.570
<v Speaker 1>The exponential potentially exponential.</v>
<v Speaker 1>It's could be argued and he will.</v>

108
00:08:45.020 --> 00:08:50.020
<v Speaker 1>A growth of technology of these ideas </v>
<v Speaker 1>means that just around the corner is a </v>

109
00:08:51.051 --> 00:08:56.051
<v Speaker 1>singularity is a breakthrough idea that </v>
<v Speaker 1>will change everything.</v>

110
00:08:57.390 --> 00:09:00.330
<v Speaker 1>We have to be cautious of that.</v>
<v Speaker 1>Moreover,</v>

111
00:09:00.990 --> 00:09:05.990
<v Speaker 1>we have to be cautious of the fact that </v>
<v Speaker 1>every decade over the past century,</v>

112
00:09:07.590 --> 00:09:11.550
<v Speaker 1>our adoption of new technologies has </v>
<v Speaker 1>gotten faster and faster.</v>

113
00:09:11.580 --> 00:09:16.580
<v Speaker 1>The rate at which a new technology from </v>
<v Speaker 1>its birth to its wide mass adoption has </v>

114
00:09:19.381 --> 00:09:24.381
<v Speaker 1>shortened and shortened and shortened.</v>
<v Speaker 1>That means that new idea,</v>

115
00:09:26.040 --> 00:09:31.040
<v Speaker 1>the moment it drops into the world can </v>
<v Speaker 1>have widespread effects overnight,</v>

116
00:09:33.180 --> 00:09:38.180
<v Speaker 1>so as an I think the in in the </v>
<v Speaker 1>engineering approach is fundamentally </v>

117
00:09:38.180 --> 00:09:42.561
<v Speaker 1>cynical on artificial general </v>
<v Speaker 1>intelligence because every aspect of it </v>

118
00:09:42.561 --> 00:09:46.561
<v Speaker 1>is so difficult.</v>
<v Speaker 1>We have to always remember that </v>

119
00:09:46.561 --> 00:09:49.131
<v Speaker 1>overnight.</v>
<v Speaker 1>Everything can change through this </v>

120
00:09:49.131 --> 00:09:53.010
<v Speaker 1>question of beginning to approach from a</v>
<v Speaker 1>deep learning perspective,</v>

121
00:09:53.011 --> 00:09:55.580
<v Speaker 1>from deeper enforcement learning from </v>
<v Speaker 1>brain simulation,</v>

122
00:09:55.730 --> 00:10:00.600
<v Speaker 1>complex cognitive science from </v>
<v Speaker 1>computational neuroscience,</v>

123
00:10:00.601 --> 00:10:05.601
<v Speaker 1>from cognitive architecture,</v>
<v Speaker 1>some robotics from a legal perspective </v>

124
00:10:07.710 --> 00:10:09.480
<v Speaker 1>and autonomous weapons systems.</v>

125
00:10:09.870 --> 00:10:14.430
<v Speaker 1>As we begin to approach these questions,</v>
<v Speaker 1>we need to start to build intuition.</v>

126
00:10:14.910 --> 00:10:18.150
<v Speaker 1>How far away are we from creating </v>
<v Speaker 1>intelligence systems?</v>

127
00:10:18.830 --> 00:10:23.830
<v Speaker 1>The singularity here is that spark,</v>
<v Speaker 1>that moment when we're truly surprised </v>

128
00:10:25.830 --> 00:10:28.650
<v Speaker 1>by the intelligence of the systems we </v>
<v Speaker 1>create.</v>

129
00:10:30.600 --> 00:10:35.600
<v Speaker 1>I'd like to visualize it by the,</v>
<v Speaker 1>by the certain analogy that we're in </v>

130
00:10:36.451 --> 00:10:41.451
<v Speaker 1>this dark room looking for a light </v>
<v Speaker 1>switch with no knowledge of where the </v>

131
00:10:42.121 --> 00:10:43.170
<v Speaker 1>lights,</v>
<v Speaker 1>which is.</v>

132
00:10:43.440 --> 00:10:45.570
<v Speaker 1>There's going to be people that say,</v>
<v Speaker 1>well,</v>

133
00:10:45.780 --> 00:10:49.250
<v Speaker 1>it's a small rooms are all small.</v>
<v Speaker 1>We're right there and say anywhere.</v>

134
00:10:49.260 --> 00:10:53.550
<v Speaker 1>We'll be able to find it anytime time.</v>
<v Speaker 1>The reality is we know very little so we</v>

135
00:10:53.551 --> 00:10:58.551
<v Speaker 1>have to stumble around,</v>
<v Speaker 1>feel our way around to build the </v>

136
00:10:58.551 --> 00:10:59.310
<v Speaker 1>intuition of far,</v>
<v Speaker 1>far away.</v>

137
00:10:59.311 --> 00:11:00.330
<v Speaker 1>We really are.</v>

138
00:11:03.810 --> 00:11:06.450
<v Speaker 1>And many will.</v>
<v Speaker 1>Speakers here,</v>

139
00:11:06.451 --> 00:11:09.330
<v Speaker 1>we'll talk about how we define </v>
<v Speaker 1>intelligence,</v>

140
00:11:09.331 --> 00:11:14.331
<v Speaker 1>how we can begin to see intelligence.</v>
<v Speaker 1>What are the fundamental impacts of </v>

141
00:11:14.331 --> 00:11:18.771
<v Speaker 1>creating intelligence systems?</v>
<v Speaker 1>I'd like to sort of see the positive </v>

142
00:11:20.580 --> 00:11:25.580
<v Speaker 1>reason for this little class and for </v>
<v Speaker 1>these efforts that have fascinated </v>

143
00:11:26.700 --> 00:11:31.700
<v Speaker 1>people throughout the century of trying </v>
<v Speaker 1>to create intelligence systems is that </v>

144
00:11:31.700 --> 00:11:36.141
<v Speaker 1>there is something about human beings </v>
<v Speaker 1>that want that craze to explore,</v>

145
00:11:39.600 --> 00:11:41.700
<v Speaker 1>to uncover the mysteries of the </v>
<v Speaker 1>universe.</v>

146
00:11:42.660 --> 00:11:46.290
<v Speaker 1>Fundamental in itself,</v>
<v Speaker 1>a desire to uncover the mysteries of the</v>

147
00:11:46.291 --> 00:11:48.630
<v Speaker 1>universe,</v>
<v Speaker 1>not for a purpose,</v>

148
00:11:49.380 --> 00:11:51.840
<v Speaker 1>and there's often an underlying purpose </v>
<v Speaker 1>of money,</v>

149
00:11:51.841 --> 00:11:53.520
<v Speaker 1>of greed,</v>
<v Speaker 1>of,</v>

150
00:11:53.610 --> 00:11:54.980
<v Speaker 1>uh,</v>
<v Speaker 1>the,</v>

151
00:11:54.981 --> 00:11:57.550
<v Speaker 1>uh,</v>
<v Speaker 1>power craving for power and so on.</v>

152
00:11:57.551 --> 00:12:00.880
<v Speaker 1>But there's seems to be an underlying </v>
<v Speaker 1>desire to explore.</v>

153
00:12:01.990 --> 00:12:04.220
<v Speaker 1>Nice little book,</v>
<v Speaker 1>an exploration,</v>

154
00:12:04.240 --> 00:12:06.250
<v Speaker 1>a very short introduction by Stewart </v>
<v Speaker 1>Weaver.</v>

155
00:12:06.251 --> 00:12:11.251
<v Speaker 1>He says,</v>
<v Speaker 1>for all the different forums that takes </v>

156
00:12:11.251 --> 00:12:14.760
<v Speaker 1>in different historical periods for for </v>
<v Speaker 1>all the worthy and unworthy motives that</v>

157
00:12:15.581 --> 00:12:20.581
<v Speaker 1>lie behind it.</v>
<v Speaker 1>Exploration travel for the sake of </v>

158
00:12:21.071 --> 00:12:24.010
<v Speaker 1>discovery and adventure is a human </v>
<v Speaker 1>compulsion,</v>

159
00:12:24.760 --> 00:12:29.760
<v Speaker 1>a human obsession even.</v>
<v Speaker 1>It is defining element of a distinctly </v>

160
00:12:29.760 --> 00:12:33.730
<v Speaker 1>human identity and it will never arrest </v>
<v Speaker 1>at any frontier,</v>

161
00:12:33.850 --> 00:12:38.850
<v Speaker 1>whether terrestrial or extraterrestrial.</v>
<v Speaker 1>From 325 BC.</v>

162
00:12:40.200 --> 00:12:43.880
<v Speaker 1>He with a long,</v>
<v Speaker 1>7,500</v>

163
00:12:43.881 --> 00:12:45.020
<v Speaker 1>mile journey</v>

164
00:12:46.350 --> 00:12:51.350
<v Speaker 1>on the ocean to explore the Arctic,</v>
<v Speaker 1>to Christopher Columbus and his flawed </v>

165
00:12:55.030 --> 00:12:59.440
<v Speaker 1>harshly criticize the modern </v>
<v Speaker 1>scholarshipped trip that ultimately pave</v>

166
00:12:59.441 --> 00:13:01.600
<v Speaker 1>the way,</v>
<v Speaker 1>didn't discover,</v>

167
00:13:02.290 --> 00:13:05.440
<v Speaker 1>paved the way to colonization of the </v>
<v Speaker 1>Americas,</v>

168
00:13:08.660 --> 00:13:12.290
<v Speaker 1>to the Darwin trip,</v>
<v Speaker 1>the voyage of the Beagle.</v>

169
00:13:13.800 --> 00:13:17.220
<v Speaker 1>Whilst this planet has gone,</v>
<v Speaker 1>cycling on according to the fixed law of</v>

170
00:13:17.221 --> 00:13:19.830
<v Speaker 1>gravity from so simple,</v>
<v Speaker 1>a beginning,</v>

171
00:13:20.230 --> 00:13:25.230
<v Speaker 1>endless forms most beautiful and most </v>
<v Speaker 1>wonderful have been and are being </v>

172
00:13:25.230 --> 00:13:29.421
<v Speaker 1>evolved to the first venture into space </v>
<v Speaker 1>by Urunga,</v>

173
00:13:34.541 --> 00:13:38.620
<v Speaker 1>Guardian,</v>
<v Speaker 1>first human in space in 1961.</v>

174
00:13:40.550 --> 00:13:44.060
<v Speaker 1>What he said over the radio is,</v>
<v Speaker 1>the earth is blue.</v>

175
00:13:44.120 --> 00:13:49.120
<v Speaker 1>It is amazing this.</v>
<v Speaker 1>These are the words that I think drive </v>

176
00:13:50.070 --> 00:13:55.070
<v Speaker 1>our exploration in the sciences and the </v>
<v Speaker 1>engineering and today in ai from the </v>

177
00:13:56.611 --> 00:14:01.611
<v Speaker 1>first walk on the moon and now the </v>
<v Speaker 1>desire to colonize Mars and beyond.</v>

178
00:14:11.270 --> 00:14:15.050
<v Speaker 1>That's where I see this desire to create</v>
<v Speaker 1>intelligence systems,</v>

179
00:14:16.430 --> 00:14:20.150
<v Speaker 1>talking about the positive and negative </v>
<v Speaker 1>impact of ai on society.</v>

180
00:14:20.390 --> 00:14:23.030
<v Speaker 1>Talking about the business case so the </v>
<v Speaker 1>jobs lost,</v>

181
00:14:23.060 --> 00:14:24.170
<v Speaker 1>jobs gained,</v>
<v Speaker 1>jobs,</v>

182
00:14:24.171 --> 00:14:29.171
<v Speaker 1>created diseases cured the autonomous </v>
<v Speaker 1>vehicles,</v>

183
00:14:30.470 --> 00:14:33.800
<v Speaker 1>the ethical questions,</v>
<v Speaker 1>the safety of autonomous weapons,</v>

184
00:14:34.130 --> 00:14:36.950
<v Speaker 1>of the misuse of ai in the financial </v>
<v Speaker 1>markets.</v>

185
00:14:37.550 --> 00:14:39.500
<v Speaker 1>Underneath it all,</v>
<v Speaker 1>and there are people,</v>

186
00:14:39.510 --> 00:14:44.510
<v Speaker 1>many people have spoken about this.</v>
<v Speaker 1>What drives myself and many in the </v>

187
00:14:44.510 --> 00:14:48.911
<v Speaker 1>community is a desire to explore,</v>
<v Speaker 1>to uncover the mystery of the universe </v>

188
00:14:48.911 --> 00:14:52.160
<v Speaker 1>and that hope that you join me in that </v>
<v Speaker 1>very effort with speakers that come here</v>

189
00:14:52.161 --> 00:14:54.830
<v Speaker 1>in the next two weeks and beyond.</v>

190
00:14:57.890 --> 00:15:02.000
<v Speaker 1>The website for the course is Agi that </v>
<v Speaker 1>mit did you.</v>

191
00:15:03.140 --> 00:15:08.140
<v Speaker 1>I am a part of an amazing team,</v>
<v Speaker 1>many of whom you know Agi at Mit.</v>

192
00:15:10.961 --> 00:15:14.540
<v Speaker 1>That edu is the email.</v>
<v Speaker 1>We're on slack.</v>

193
00:15:14.570 --> 00:15:19.570
<v Speaker 1>Deep Dash Mit does slack up for </v>
<v Speaker 1>registered at Mit students.</v>

194
00:15:21.890 --> 00:15:26.890
<v Speaker 1>It created account on the website and </v>
<v Speaker 1>submit five new links and vote on 10 to </v>

195
00:15:28.251 --> 00:15:33.251
<v Speaker 1>vote Ai,</v>
<v Speaker 1>which is an aggregator of information </v>

196
00:15:33.251 --> 00:15:36.461
<v Speaker 1>and material we've put together for the </v>
<v Speaker 1>topic of Agi and submit a entry to one </v>

197
00:15:39.081 --> 00:15:44.081
<v Speaker 1>of the competitions,</v>
<v Speaker 1>one of the three competitions projects </v>

198
00:15:44.081 --> 00:15:46.991
<v Speaker 1>that we have in this course and the </v>
<v Speaker 1>projects are dream vision.</v>

199
00:15:47.271 --> 00:15:49.580
<v Speaker 1>I'll go over them in a little bit.</v>
<v Speaker 1>Dream Vision,</v>

200
00:15:49.670 --> 00:15:54.530
<v Speaker 1>Angele ethical car,</v>
<v Speaker 1>and the aggregator of material.</v>

201
00:15:54.531 --> 00:15:56.840
<v Speaker 1>Vote Ai.</v>
<v Speaker 1>We have guest speakers,</v>

202
00:15:56.841 --> 00:16:01.841
<v Speaker 1>incredible guest speakers.</v>
<v Speaker 1>I will go over them today and as before </v>

203
00:16:03.540 --> 00:16:06.110
<v Speaker 1>with the deep learning for self driving </v>
<v Speaker 1>cars course,</v>

204
00:16:06.111 --> 00:16:10.100
<v Speaker 1>we have shirts and they're free for in </v>
<v Speaker 1>person,</v>

205
00:16:10.190 --> 00:16:13.010
<v Speaker 1>for people that attend in person for the</v>
<v Speaker 1>last lecture,</v>

206
00:16:13.011 --> 00:16:15.590
<v Speaker 1>most likely or you can order them </v>
<v Speaker 1>online.</v>

207
00:16:17.720 --> 00:16:22.720
<v Speaker 1>Okay.</v>
<v Speaker 1>Dream vision will take the Google g </v>

208
00:16:22.720 --> 00:16:25.411
<v Speaker 1>dream idea.</v>
<v Speaker 1>We explore the idea of creativity where </v>

209
00:16:26.690 --> 00:16:31.250
<v Speaker 1>Einstein's view of intelligence,</v>
<v Speaker 1>the mark of intelligence is creativity.</v>

210
00:16:32.330 --> 00:16:37.330
<v Speaker 1>This idea is something we explore by </v>
<v Speaker 1>using neural networks and interesting </v>

211
00:16:37.371 --> 00:16:42.371
<v Speaker 1>ways to visualize what the network see </v>
<v Speaker 1>and in so doing,</v>

212
00:16:43.491 --> 00:16:47.660
<v Speaker 1>create beautiful visualizations in time </v>
<v Speaker 1>through video.</v>

213
00:16:48.050 --> 00:16:53.050
<v Speaker 1>So taking the ideas of deep dream and </v>
<v Speaker 1>combining them together with multiple </v>

214
00:16:53.241 --> 00:16:57.140
<v Speaker 1>video streams to mix,</v>
<v Speaker 1>dream and reality,</v>

215
00:16:58.730 --> 00:17:03.730
<v Speaker 1>and the competition is through </v>
<v Speaker 1>mechanical Turk was set up a competition</v>

216
00:17:05.241 --> 00:17:10.241
<v Speaker 1>of who produces the most beautiful </v>
<v Speaker 1>visualization will provide code to </v>

217
00:17:10.971 --> 00:17:15.971
<v Speaker 1>generate this visualization and ideas of</v>
<v Speaker 1>how you can make it more and more </v>

218
00:17:15.971 --> 00:17:20.441
<v Speaker 1>beautiful and how to submit it to the </v>
<v Speaker 1>competition.</v>

219
00:17:22.410 --> 00:17:27.410
<v Speaker 1>Angel,</v>
<v Speaker 1>the artificial neural generator of </v>

220
00:17:27.410 --> 00:17:30.251
<v Speaker 1>emotion and language is a different </v>
<v Speaker 1>twist on the turing test where we don't </v>

221
00:17:32.841 --> 00:17:37.841
<v Speaker 1>use words,</v>
<v Speaker 1>we only use emotions to speak expression</v>

222
00:17:38.871 --> 00:17:43.530
<v Speaker 1>of those emotions and we create.</v>
<v Speaker 1>We use an age a,</v>

223
00:17:43.540 --> 00:17:44.330
<v Speaker 1>a,</v>
<v Speaker 1>a,</v>

224
00:17:44.720 --> 00:17:49.720
<v Speaker 1>a face customizable with 26 muscles.</v>
<v Speaker 1>All of which can be controlled or </v>

225
00:17:50.340 --> 00:17:55.340
<v Speaker 1>controlled with an Lstm we use in your </v>
<v Speaker 1>network to train the generation of </v>

226
00:17:56.851 --> 00:17:57.630
<v Speaker 1>emotion</v>

227
00:17:59.430 --> 00:18:04.430
<v Speaker 1>and the competition in you.</v>
<v Speaker 1>Submitting the code to the competition </v>

228
00:18:05.400 --> 00:18:10.400
<v Speaker 1>is you get 10 seconds to impress with </v>
<v Speaker 1>the these expressions of emotion,</v>

229
00:18:12.901 --> 00:18:15.510
<v Speaker 1>the viewer.</v>
<v Speaker 1>It's Ab testing.</v>

230
00:18:15.930 --> 00:18:20.930
<v Speaker 1>Your goal is to impress the viewer </v>
<v Speaker 1>enough to where they choose your agent </v>

231
00:18:21.091 --> 00:18:26.091
<v Speaker 1>versus another agent,</v>
<v Speaker 1>and those that are most loved agents,</v>

232
00:18:26.521 --> 00:18:31.521
<v Speaker 1>most loved will be the ones that are </v>
<v Speaker 1>declared winners in a twist.</v>

233
00:18:32.580 --> 00:18:37.580
<v Speaker 1>We will add human beings into this mix,</v>
<v Speaker 1>so we've created a system that maps are </v>

234
00:18:39.181 --> 00:18:44.181
<v Speaker 1>human faces,</v>
<v Speaker 1>myself and the Ta's to where we </v>

235
00:18:44.181 --> 00:18:49.140
<v Speaker 1>ourselves enter an outcome in the </v>
<v Speaker 1>competition and try to convince you to </v>

236
00:18:49.261 --> 00:18:52.710
<v Speaker 1>keep us as your friend.</v>
<v Speaker 1>That's the turing test.</v>

237
00:18:56.070 --> 00:19:01.070
<v Speaker 1>Okay.</v>
<v Speaker 1>Ethical car building in the ideas of the</v>

238
00:19:01.200 --> 00:19:04.530
<v Speaker 1>trolley problem and the moral machine </v>
<v Speaker 1>done here in the media lab.</v>

239
00:19:04.710 --> 00:19:06.390
<v Speaker 1>They incredible,</v>
<v Speaker 1>interesting work.</v>

240
00:19:06.660 --> 00:19:10.980
<v Speaker 1>We take a machine learning approach to </v>
<v Speaker 1>it and take what we've developed,</v>

241
00:19:11.010 --> 00:19:15.090
<v Speaker 1>the deep reinforcement learning </v>
<v Speaker 1>competition for a six zero,</v>

242
00:19:15.091 --> 00:19:20.091
<v Speaker 1>nine for the deep traffic and we add </v>
<v Speaker 1>pedestrians into it to cast stochastic </v>

243
00:19:24.820 --> 00:19:28.150
<v Speaker 1>irrational,</v>
<v Speaker 1>unpredictable pedestrians,</v>

244
00:19:28.840 --> 00:19:33.840
<v Speaker 1>and we add human life to the loss </v>
<v Speaker 1>function where there's a tradeoff </v>

245
00:19:33.840 --> 00:19:37.490
<v Speaker 1>between getting from point a to point b.</v>
<v Speaker 1>So in deep traffic,</v>

246
00:19:37.491 --> 00:19:39.140
<v Speaker 1>the deeper enforcement learning </v>
<v Speaker 1>competition,</v>

247
00:19:39.141 --> 00:19:44.141
<v Speaker 1>the goal was to go as fast as possible.</v>
<v Speaker 1>Here it's up to you to decide what you,</v>

248
00:19:46.070 --> 00:19:51.070
<v Speaker 1>what your agents goal is.</v>
<v Speaker 1>There's a parade of front tradeoff </v>

249
00:19:51.080 --> 00:19:56.080
<v Speaker 1>between getting from point a to point B </v>
<v Speaker 1>as fast as possible and hurting </v>

250
00:19:59.630 --> 00:20:00.530
<v Speaker 1>pedestrians.</v>

251
00:20:08.940 --> 00:20:13.940
<v Speaker 1>This is not a ethical question.</v>
<v Speaker 1>It's an engineering question and it's a </v>

252
00:20:18.901 --> 00:20:23.901
<v Speaker 1>serious one because fundamentally in </v>
<v Speaker 1>creating autonomous vehicles that </v>

253
00:20:23.901 --> 00:20:28.821
<v Speaker 1>function in this world,</v>
<v Speaker 1>we want them to get from point a to </v>

254
00:20:28.821 --> 00:20:33.561
<v Speaker 1>point B as quickly as possible.</v>
<v Speaker 1>The United States government insurance </v>

255
00:20:34.741 --> 00:20:39.741
<v Speaker 1>companies put a price tag on human life.</v>
<v Speaker 1>We put that power in your hands in </v>

256
00:20:41.161 --> 00:20:45.690
<v Speaker 1>designing these agents to ask the </v>
<v Speaker 1>question of a,</v>

257
00:20:45.780 --> 00:20:50.320
<v Speaker 1>how can we create machine learning </v>
<v Speaker 1>systems where the objective function,</v>

258
00:20:50.321 --> 00:20:55.321
<v Speaker 1>the loss function has human life as part</v>
<v Speaker 1>of it and vote ai is an aggregator of </v>

259
00:20:59.950 --> 00:21:03.400
<v Speaker 1>different links,</v>
<v Speaker 1>different articles,</v>

260
00:21:03.401 --> 00:21:08.401
<v Speaker 1>papers,</v>
<v Speaker 1>videos on the topic of artificial </v>

261
00:21:08.401 --> 00:21:10.120
<v Speaker 1>general intelligence where people vote </v>
<v Speaker 1>on a vote,</v>

262
00:21:10.150 --> 00:21:15.150
<v Speaker 1>quality articles up and down and choose </v>
<v Speaker 1>on the sentiment of positive and </v>

263
00:21:17.291 --> 00:21:22.291
<v Speaker 1>negative.</v>
<v Speaker 1>We'd like to explore the different ways </v>

264
00:21:22.291 --> 00:21:24.010
<v Speaker 1>to the different arguments for and </v>
<v Speaker 1>against artificial general intelligence.</v>

265
00:21:26.980 --> 00:21:31.980
<v Speaker 1>There is an incredible list of speakers </v>
<v Speaker 1>the best in their disciplines from Josh </v>

266
00:21:34.450 --> 00:21:35.160
<v Speaker 1>Tenenbaum,</v>
<v Speaker 1>Ghana,</v>

267
00:21:35.161 --> 00:21:38.980
<v Speaker 1>mit to ray Kurzweil at Google,</v>
<v Speaker 1>to Lisa Feldman,</v>

268
00:21:38.981 --> 00:21:43.570
<v Speaker 1>Barrett and nature Bensky from </v>
<v Speaker 1>northeastern university,</v>

269
00:21:43.840 --> 00:21:48.840
<v Speaker 1>Andre Carpathy,</v>
<v Speaker 1>Steven Wolf from Richard Moise,</v>

270
00:21:49.210 --> 00:21:51.970
<v Speaker 1>Mark Reiber,</v>
<v Speaker 1>ltss giver,</v>

271
00:21:53.230 --> 00:21:56.140
<v Speaker 1>and myself,</v>
<v Speaker 1>Josh Tenenbaum.</v>

272
00:21:56.170 --> 00:22:01.170
<v Speaker 1>Tomorrow I'd like to go through each of </v>
<v Speaker 1>these speakers and talk about the </v>

273
00:22:01.331 --> 00:22:06.331
<v Speaker 1>perspectives they bring that to try to </v>
<v Speaker 1>try to see the approach,</v>

274
00:22:06.610 --> 00:22:09.670
<v Speaker 1>the ideas they bring to the table.</v>
<v Speaker 1>They're not,</v>

275
00:22:10.270 --> 00:22:15.270
<v Speaker 1>in most cases interested in the </v>
<v Speaker 1>discussion of the future impact on </v>

276
00:22:16.601 --> 00:22:20.470
<v Speaker 1>society without grounding it into the </v>
<v Speaker 1>expertise,</v>

277
00:22:20.620 --> 00:22:25.620
<v Speaker 1>into the actual engineering,</v>
<v Speaker 1>into creating these intelligence </v>

278
00:22:25.620 --> 00:22:28.641
<v Speaker 1>systems.</v>
<v Speaker 1>So Josh is a computation and cognitive </v>

279
00:22:28.641 --> 00:22:31.480
<v Speaker 1>science expert.</v>
<v Speaker 1>Professor Faculty here at Mit.</v>

280
00:22:31.720 --> 00:22:36.720
<v Speaker 1>He will talk about how we can create </v>
<v Speaker 1>common sense understanding systems that </v>

281
00:22:37.900 --> 00:22:42.900
<v Speaker 1>see a world of physical objects and </v>
<v Speaker 1>their interactions and our own </v>

282
00:22:42.900 --> 00:22:44.920
<v Speaker 1>possibilities to act,</v>
<v Speaker 1>interact with others,</v>

283
00:22:44.980 --> 00:22:46.060
<v Speaker 1>the intuitive physics.</v>

284
00:22:46.060 --> 00:22:50.860
<v Speaker 1>How do we build into systems the </v>
<v Speaker 1>intuitive physics of the world more than</v>

285
00:22:50.861 --> 00:22:55.861
<v Speaker 1>just the deep learning memorization </v>
<v Speaker 1>engines that take patterns and learn </v>

286
00:22:56.511 --> 00:23:00.070
<v Speaker 1>through supervised way to map those </v>
<v Speaker 1>patterns to classification.</v>

287
00:23:01.690 --> 00:23:06.690
<v Speaker 1>Actually begin to understand the </v>
<v Speaker 1>intuitive common sense physics of the </v>

288
00:23:06.690 --> 00:23:10.000
<v Speaker 1>world and learn rapid model based </v>
<v Speaker 1>learning.</v>

289
00:23:10.090 --> 00:23:12.310
<v Speaker 1>Learn from nothing,</v>
<v Speaker 1>learned from very little,</v>

290
00:23:12.490 --> 00:23:17.490
<v Speaker 1>just like we do as children,</v>
<v Speaker 1>just like we do as human being </v>

291
00:23:17.490 --> 00:23:20.451
<v Speaker 1>successfully,</v>
<v Speaker 1>often only need one example to learn a </v>

292
00:23:20.451 --> 00:23:22.270
<v Speaker 1>concept.</v>
<v Speaker 1>How do we create systems that learn from</v>

293
00:23:22.390 --> 00:23:27.280
<v Speaker 1>very few,</v>
<v Speaker 1>sometimes a single example and integrate</v>

294
00:23:27.281 --> 00:23:29.830
<v Speaker 1>ideas from various disciplines,</v>
<v Speaker 1>of course,</v>

295
00:23:29.831 --> 00:23:33.520
<v Speaker 1>from neural networks,</v>
<v Speaker 1>but also probabilistic generative models</v>

296
00:23:33.521 --> 00:23:38.521
<v Speaker 1>and symbol processing architectures.</v>
<v Speaker 1>It's gonna be incredible of course,</v>

297
00:23:40.300 --> 00:23:42.610
<v Speaker 1>from a,</v>
<v Speaker 1>from a different area of the world.</v>

298
00:23:43.030 --> 00:23:45.530
<v Speaker 1>Uh,</v>
<v Speaker 1>another incredible thinker,</v>

299
00:23:45.890 --> 00:23:50.890
<v Speaker 1>intellectual speaker is Ray Kurzweil.</v>
<v Speaker 1>He'll be here on Wednesday at 1:00</v>

300
00:23:51.410 --> 00:23:56.410
<v Speaker 1>PM and he will do a whirlwind discussion</v>
<v Speaker 1>of where we stand with intelligence,</v>

301
00:23:59.541 --> 00:24:03.020
<v Speaker 1>creating intelligence systems,</v>
<v Speaker 1>how we see natural intelligence,</v>

302
00:24:03.021 --> 00:24:05.180
<v Speaker 1>our own human intelligence,</v>
<v Speaker 1>how we define it,</v>

303
00:24:05.600 --> 00:24:10.070
<v Speaker 1>how we understand it,</v>
<v Speaker 1>and how that transfers to the increasing</v>

304
00:24:10.071 --> 00:24:13.970
<v Speaker 1>exponential growth of development,</v>
<v Speaker 1>of artificial general intelligence.</v>

305
00:24:16.820 --> 00:24:19.820
<v Speaker 1>Something I'm very excited about</v>

306
00:24:20.660 --> 00:24:24.820
<v Speaker 1>is Lisa Feldman Barrett coming here on </v>
<v Speaker 1>Thursday.</v>

307
00:24:25.450 --> 00:24:27.760
<v Speaker 1>She's written a book,</v>
<v Speaker 1>I believe,</v>

308
00:24:27.761 --> 00:24:32.761
<v Speaker 1>how emotions are made.</v>
<v Speaker 1>He argues that emotions are created,</v>

309
00:24:34.300 --> 00:24:39.300
<v Speaker 1>that there is a distinction,</v>
<v Speaker 1>there is a detachment between what we </v>

310
00:24:39.300 --> 00:24:42.670
<v Speaker 1>feel in our bodies,</v>
<v Speaker 1>the physical state of our bodies,</v>

311
00:24:42.820 --> 00:24:47.820
<v Speaker 1>and the expression of emotion from,</v>
<v Speaker 1>from body to the contextually grounded </v>

312
00:24:48.970 --> 00:24:53.970
<v Speaker 1>to the face expressing that emotion,</v>
<v Speaker 1>which means now why is this a person who</v>

313
00:24:54.941 --> 00:24:59.941
<v Speaker 1>is a psychology person in a </v>
<v Speaker 1>fundamentally engineer and computer </v>

314
00:24:59.941 --> 00:25:03.511
<v Speaker 1>science topic like Agi?</v>
<v Speaker 1>Because if emotions are created and the </v>

315
00:25:03.611 --> 00:25:06.310
<v Speaker 1>way she argues and she'll systematically</v>
<v Speaker 1>break it down,</v>

316
00:25:06.610 --> 00:25:11.290
<v Speaker 1>that means we're learning societal.</v>
<v Speaker 1>As human beings,</v>

317
00:25:11.291 --> 00:25:14.020
<v Speaker 1>we're learning societal norms of how to </v>
<v Speaker 1>express emotion.</v>

318
00:25:14.260 --> 00:25:16.330
<v Speaker 1>The idea of emotional intelligence has </v>
<v Speaker 1>learned,</v>

319
00:25:16.540 --> 00:25:20.230
<v Speaker 1>which means we can have machines learn </v>
<v Speaker 1>this idea.</v>

320
00:25:20.740 --> 00:25:23.140
<v Speaker 1>It's a machine learn just like it's a </v>
<v Speaker 1>human learning problem.</v>

321
00:25:23.141 --> 00:25:27.880
<v Speaker 1>It's some machine learning problem in a </v>
<v Speaker 1>little bit of a twist.</v>

322
00:25:28.270 --> 00:25:33.270
<v Speaker 1>She asked that instead of giving a talk,</v>
<v Speaker 1>I have a conversation with her so </v>

323
00:25:33.791 --> 00:25:37.150
<v Speaker 1>there's going to be a little bit </v>
<v Speaker 1>challenging and fun and,</v>

324
00:25:37.200 --> 00:25:42.200
<v Speaker 1>uh,</v>
<v Speaker 1>she's great looking forward to it and </v>

325
00:25:42.200 --> 00:25:45.800
<v Speaker 1>we'll explore different ways that we can</v>
<v Speaker 1>get emotion expressed through video,</v>

326
00:25:47.251 --> 00:25:50.190
<v Speaker 1>through audio,</v>
<v Speaker 1>through the project.</v>

327
00:25:50.490 --> 00:25:55.490
<v Speaker 1>The Angel Project that I mentioned.</v>
<v Speaker 1>So there's has been worked and </v>

328
00:25:55.490 --> 00:25:58.911
<v Speaker 1>reenacting intelligence,</v>
<v Speaker 1>so a well reenacting mapping face to </v>

329
00:25:59.761 --> 00:26:03.750
<v Speaker 1>face mapping different emotions on video</v>
<v Speaker 1>that was previously recorded.</v>

330
00:26:04.440 --> 00:26:09.440
<v Speaker 1>So if you can imagine that means we can </v>
<v Speaker 1>take emotions that we've created,</v>

331
00:26:09.930 --> 00:26:14.930
<v Speaker 1>the kind of emotion creation we've been </v>
<v Speaker 1>discussing and remap it on previous </v>

332
00:26:15.831 --> 00:26:20.831
<v Speaker 1>video.</v>
<v Speaker 1>That's one way to see intelligence is </v>

333
00:26:20.831 --> 00:26:23.771
<v Speaker 1>taking raw human data that we already </v>
<v Speaker 1>have and mapping new computer generated </v>

334
00:26:25.360 --> 00:26:29.030
<v Speaker 1>the the,</v>
<v Speaker 1>the underlying fundamentals of human,</v>

335
00:26:29.600 --> 00:26:33.020
<v Speaker 1>but the surface appearance,</v>
<v Speaker 1>the representation of emotion,</v>

336
00:26:33.021 --> 00:26:37.970
<v Speaker 1>visual or auditory is generated by </v>
<v Speaker 1>computer.</v>

337
00:26:40.460 --> 00:26:43.160
<v Speaker 1>It could be in the embodied form like </v>
<v Speaker 1>with Sophia,</v>

338
00:26:52.310 --> 00:26:57.310
<v Speaker 2>so different if you take a long time for</v>
<v Speaker 2>to context and jealousy and it might be </v>

339
00:27:07.211 --> 00:27:09.200
<v Speaker 2>possible than any.</v>
<v Speaker 2>The more ethical,</v>

340
00:27:10.330 --> 00:27:12.530
<v Speaker 2>a good partnership.</v>

341
00:27:17.860 --> 00:27:22.860
<v Speaker 1>Very important to note for those </v>
<v Speaker 1>captivated by Sophia in the press or </v>

342
00:27:22.860 --> 00:27:27.370
<v Speaker 1>have seen these videos.</v>
<v Speaker 1>Sophia is an art exhibit.</v>

343
00:27:28.240 --> 00:27:32.500
<v Speaker 1>She's not a strong natural language </v>
<v Speaker 1>processing system.</v>

344
00:27:32.501 --> 00:27:37.501
<v Speaker 1>This is not an agi system,</v>
<v Speaker 1>but it's a beautiful visualization of </v>

345
00:27:38.741 --> 00:27:43.741
<v Speaker 1>embodying of.</v>
<v Speaker 1>It's a beautiful visualization of how </v>

346
00:27:43.741 --> 00:27:45.760
<v Speaker 1>easy it is to trick us human beings.</v>
<v Speaker 1>That there is intelligence,</v>

347
00:27:46.300 --> 00:27:50.290
<v Speaker 1>an underlying something that the </v>
<v Speaker 1>emotional expression,</v>

348
00:27:50.590 --> 00:27:55.590
<v Speaker 1>the physical embodiment and the </v>
<v Speaker 1>emotional expression that has that has </v>

349
00:27:55.901 --> 00:28:00.901
<v Speaker 1>some degree of humor that has some </v>
<v Speaker 1>degree of wit and intelligence is enough</v>

350
00:28:01.691 --> 00:28:06.691
<v Speaker 1>to captivate us,</v>
<v Speaker 1>so that's an argument for not creating </v>

351
00:28:06.691 --> 00:28:10.210
<v Speaker 1>intelligence from scratch,</v>
<v Speaker 1>but having machines at the very surface,</v>

352
00:28:10.450 --> 00:28:13.390
<v Speaker 1>the display of that emotion,</v>
<v Speaker 1>the generation,</v>

353
00:28:13.510 --> 00:28:18.280
<v Speaker 1>the mapping of the visual and the </v>
<v Speaker 1>auditory elements were underneath.</v>

354
00:28:18.281 --> 00:28:23.020
<v Speaker 1>It is really trivial technology that's </v>
<v Speaker 1>fundamentally relying on humans.</v>

355
00:28:23.080 --> 00:28:27.550
<v Speaker 1>Like in Sophia's case and in the </v>
<v Speaker 1>simplest form,</v>

356
00:28:27.670 --> 00:28:31.310
<v Speaker 1>we remove all elements of shit.</v>

357
00:28:31.720 --> 00:28:34.250
<v Speaker 1>How should I say,</v>
<v Speaker 1>attractive appearance from a,</v>

358
00:28:34.540 --> 00:28:39.540
<v Speaker 1>from an agent.</v>
<v Speaker 1>We really keep it to the simplest </v>

359
00:28:39.540 --> 00:28:41.400
<v Speaker 1>muscles aspect,</v>
<v Speaker 1>characteristics of the face and see with</v>

360
00:28:41.401 --> 00:28:44.980
<v Speaker 1>26 muscles controlled by a neural </v>
<v Speaker 1>network through time,</v>

361
00:28:44.981 --> 00:28:46.670
<v Speaker 1>so recurrent neural network.</v>
<v Speaker 1>I was tm.</v>

362
00:28:47.410 --> 00:28:50.710
<v Speaker 1>How can we explore the generation of </v>
<v Speaker 1>emotion?</v>

363
00:28:50.890 --> 00:28:53.740
<v Speaker 1>Can we get this thing,</v>
<v Speaker 1>and this is an open question for us too.</v>

364
00:28:53.741 --> 00:28:55.870
<v Speaker 1>We just created the system.</v>
<v Speaker 1>We don't know if we can.</v>

365
00:28:56.170 --> 00:29:01.170
<v Speaker 1>Can we get it to make us feel something,</v>
<v Speaker 1>make us feel something.</v>

366
00:29:01.541 --> 00:29:06.541
<v Speaker 1>By watching it express its feelings,</v>
<v Speaker 1>can it become human before our eyes can </v>

367
00:29:09.451 --> 00:29:12.400
<v Speaker 1>now learn to back competing against </v>
<v Speaker 1>other agents?</v>

368
00:29:12.930 --> 00:29:16.940
<v Speaker 1>Ab testing on Turk.</v>
<v Speaker 1>I'm mechanical Turk.</v>

369
00:29:17.810 --> 00:29:22.810
<v Speaker 1>Can the winters be very convincing to </v>
<v Speaker 1>make us feel entertained?</v>

370
00:29:24.920 --> 00:29:27.350
<v Speaker 1>Pity,</v>
<v Speaker 1>love.</v>

371
00:29:27.560 --> 00:29:30.320
<v Speaker 1>Maybe some of you will fall in love with</v>
<v Speaker 1>Angela here,</v>

372
00:29:32.840 --> 00:29:37.840
<v Speaker 1>mate Devenski.</v>
<v Speaker 1>On Friday we'll talk about cognitive </v>

373
00:29:37.840 --> 00:29:41.471
<v Speaker 1>modeling architectures,</v>
<v Speaker 1>so you will speak about the cognitive </v>

374
00:29:41.471 --> 00:29:42.950
<v Speaker 1>modeling aspect.</v>
<v Speaker 1>Can have a a Ma.</v>

375
00:29:43.180 --> 00:29:48.180
<v Speaker 1>Can we model cognition in some kind of </v>
<v Speaker 1>systematic way to try to build intuition</v>

376
00:29:48.611 --> 00:29:53.611
<v Speaker 1>of Hok?</v>
<v Speaker 1>Complicated cognition is Andrea </v>

377
00:29:54.260 --> 00:29:59.260
<v Speaker 1>[inaudible],</v>
<v Speaker 1>famous for being the state of the art </v>

378
00:29:59.260 --> 00:30:02.650
<v Speaker 1>human on the image net challenge,</v>
<v Speaker 1>the representative,</v>

379
00:30:02.710 --> 00:30:07.710
<v Speaker 1>the 95 percent accuracy performance </v>
<v Speaker 1>among other things he's also famous for </v>

380
00:30:09.220 --> 00:30:11.890
<v Speaker 1>is now a tesla.</v>
<v Speaker 1>He will talk about</v>

381
00:30:12.990 --> 00:30:15.570
<v Speaker 1>the role,</v>
<v Speaker 1>the limitations,</v>

382
00:30:15.571 --> 00:30:20.571
<v Speaker 1>the possibilities of deep learning.</v>
<v Speaker 1>We'll talk,</v>

383
00:30:21.400 --> 00:30:26.400
<v Speaker 1>as I have spoken about in the past few </v>
<v Speaker 1>weeks and throughout about our </v>

384
00:30:28.060 --> 00:30:33.060
<v Speaker 1>misunderstanding or are flawed intuition</v>
<v Speaker 1>about what are the difficult and what </v>

385
00:30:33.161 --> 00:30:38.161
<v Speaker 1>are the easy problems in deep learning </v>
<v Speaker 1>and the power of the representational </v>

386
00:30:38.861 --> 00:30:43.861
<v Speaker 1>learning,</v>
<v Speaker 1>the ability of neural networks to form </v>

387
00:30:43.861 --> 00:30:47.071
<v Speaker 1>deeper and deeper representations that </v>
<v Speaker 1>the underlying raw data that ultimately </v>

388
00:30:47.071 --> 00:30:51.451
<v Speaker 1>forms that takes complex information </v>
<v Speaker 1>that's hard to make sense of and a </v>

389
00:30:53.580 --> 00:30:56.070
<v Speaker 1>converted into useful actionable </v>
<v Speaker 1>knowledge</v>

390
00:30:57.980 --> 00:31:02.980
<v Speaker 1>that is from a certain Lens in a certain</v>
<v Speaker 1>certain Lens and a certain problem space</v>

391
00:31:07.280 --> 00:31:12.280
<v Speaker 1>can be clearly defined as understanding </v>
<v Speaker 1>of the complex information understanding</v>

392
00:31:13.021 --> 00:31:18.021
<v Speaker 1>is ultimately taking complex information</v>
<v Speaker 1>and reducing it to a simple essential </v>

393
00:31:18.021 --> 00:31:22.701
<v Speaker 1>elements,</v>
<v Speaker 1>representational learning and the </v>

394
00:31:22.701 --> 00:31:26.871
<v Speaker 1>trivial case here in drawing a having to</v>
<v Speaker 1>draw a straight line to separate the </v>

395
00:31:27.451 --> 00:31:32.451
<v Speaker 1>blue and the red curves.</v>
<v Speaker 1>That's impossible to do in a in a Nigel </v>

396
00:31:32.790 --> 00:31:37.790
<v Speaker 1>input space on the left.</v>
<v Speaker 1>What the act of learning is for deep </v>

397
00:31:37.790 --> 00:31:41.931
<v Speaker 1>neural networks in this formulation is </v>
<v Speaker 1>to construct the topology under which </v>

398
00:31:41.931 --> 00:31:45.960
<v Speaker 1>there exists a straight line to </v>
<v Speaker 1>accurately classify blue versus red.</v>

399
00:31:47.010 --> 00:31:50.250
<v Speaker 1>That's the problem,</v>
<v Speaker 1>and for a simple blue and red line,</v>

400
00:31:50.400 --> 00:31:55.400
<v Speaker 1>it seems trivial here,</v>
<v Speaker 1>but this works in the general case for </v>

401
00:31:55.400 --> 00:31:56.910
<v Speaker 1>arbitrary input spaces for arbitrary,</v>
<v Speaker 1>nonlinear,</v>

402
00:31:56.911 --> 00:32:01.911
<v Speaker 1>highly dimensional input spaces and the </v>
<v Speaker 1>ability to automatically learn features </v>

403
00:32:02.850 --> 00:32:07.850
<v Speaker 1>too,</v>
<v Speaker 1>to learn hierarchical representations of</v>

404
00:32:08.341 --> 00:32:11.400
<v Speaker 1>the raw sensory data means that you </v>
<v Speaker 1>could do a lot more with data,</v>

405
00:32:11.401 --> 00:32:16.401
<v Speaker 1>which means you can expand further and </v>
<v Speaker 1>further and further to create </v>

406
00:32:16.401 --> 00:32:18.400
<v Speaker 1>intelligence systems that,</v>
<v Speaker 1>uh,</v>

407
00:32:18.430 --> 00:32:20.520
<v Speaker 1>operate successfully with real world </v>
<v Speaker 1>data.</v>

408
00:32:20.670 --> 00:32:22.350
<v Speaker 1>That's what representation learning </v>
<v Speaker 1>means.</v>

409
00:32:22.351 --> 00:32:26.580
<v Speaker 1>That deep learning allows because the </v>
<v Speaker 1>arbitrary number of features that can be</v>

410
00:32:26.581 --> 00:32:31.581
<v Speaker 1>automatically determined,</v>
<v Speaker 1>you can learn a lot of things about a </v>

411
00:32:31.581 --> 00:32:34.050
<v Speaker 1>pretty complex world.</v>
<v Speaker 1>Unfortunately,</v>

412
00:32:34.470 --> 00:32:36.420
<v Speaker 1>there needs to be a lot of supervised </v>
<v Speaker 1>data.</v>

413
00:32:36.421 --> 00:32:38.550
<v Speaker 1>There still needs to be a lot of human </v>
<v Speaker 1>input.</v>

414
00:32:41.420 --> 00:32:46.420
<v Speaker 1>Andre and others,</v>
<v Speaker 1>Josh will talk about the difference </v>

415
00:32:46.420 --> 00:32:50.981
<v Speaker 1>between our human brain are biological </v>
<v Speaker 1>and neural network and the artificial </v>

416
00:32:50.981 --> 00:32:55.301
<v Speaker 1>neural network,</v>
<v Speaker 1>the full human brain with 100 billion </v>

417
00:32:55.301 --> 00:33:00.131
<v Speaker 1>neurons,</v>
<v Speaker 1>1000 trillion synapses and the biggest </v>

418
00:33:00.131 --> 00:33:04.931
<v Speaker 1>neural networks out there,</v>
<v Speaker 1>the artificial neural networks having </v>

419
00:33:04.931 --> 00:33:06.200
<v Speaker 1>much smaller,</v>
<v Speaker 1>$60,</v>

420
00:33:06.201 --> 00:33:11.201
<v Speaker 1>million synapses for resident at 1:52.</v>
<v Speaker 1>The biggest difference,</v>

421
00:33:12.170 --> 00:33:17.170
<v Speaker 1>the parameter is the human brain being </v>
<v Speaker 1>several orders of magnitude more </v>

422
00:33:17.170 --> 00:33:20.300
<v Speaker 1>synapses.</v>
<v Speaker 1>That topology being much more complex,</v>

423
00:33:20.540 --> 00:33:25.540
<v Speaker 1>chaotic,</v>
<v Speaker 1>the asynchronous nature of the human </v>

424
00:33:25.540 --> 00:33:28.601
<v Speaker 1>brain and the learning algorithm of </v>
<v Speaker 1>artificial neural networks is trivial </v>

425
00:33:29.331 --> 00:33:34.331
<v Speaker 1>and constrained with backpropagation is </v>
<v Speaker 1>essentially an optimization function </v>

426
00:33:34.331 --> 00:33:38.561
<v Speaker 1>over a,</v>
<v Speaker 1>over a clearly defined last function </v>

427
00:33:38.561 --> 00:33:39.410
<v Speaker 1>from the output to the,</v>
<v Speaker 1>uh,</v>

428
00:33:39.411 --> 00:33:42.770
<v Speaker 1>to the input using backpropagation to </v>
<v Speaker 1>teach,</v>

429
00:33:43.160 --> 00:33:48.160
<v Speaker 1>to adjust the waist on that network.</v>
<v Speaker 1>The learning algorithm for our human </v>

430
00:33:48.171 --> 00:33:52.400
<v Speaker 1>brain is most of the unknown,</v>
<v Speaker 1>but it's certainly much more complicated</v>

431
00:33:52.870 --> 00:33:54.230
<v Speaker 1>than backpropagation.</v>

432
00:33:56.270 --> 00:34:01.270
<v Speaker 1>The power consumption.</v>
<v Speaker 1>The human brain is a lot more efficient </v>

433
00:34:01.270 --> 00:34:04.880
<v Speaker 1>than artificial neural networks.</v>
<v Speaker 1>And there's a very kind of artificial,</v>

434
00:34:05.990 --> 00:34:10.990
<v Speaker 1>a trivial supervised learning process </v>
<v Speaker 1>for training artificial neural networks.</v>

435
00:34:12.170 --> 00:34:16.700
<v Speaker 1>You have to have a training stage and </v>
<v Speaker 1>you have to have an evaluation stage and</v>

436
00:34:16.701 --> 00:34:21.701
<v Speaker 1>once the network is trained,</v>
<v Speaker 1>there's no clear way to continue </v>

437
00:34:21.701 --> 00:34:21.701
<v Speaker 1>training it or there's,</v>
<v Speaker 1>there's a lot of ways,</v>

438
00:34:21.701 --> 00:34:25.550
<v Speaker 1>but they're inefficient.</v>
<v Speaker 1>It's not designed to do online learning,</v>

439
00:34:26.210 --> 00:34:31.210
<v Speaker 1>uh,</v>
<v Speaker 1>naturally to always be learning is </v>

440
00:34:31.210 --> 00:34:32.960
<v Speaker 1>designed to be,</v>
<v Speaker 1>to learn and then be applied.</v>

441
00:34:33.560 --> 00:34:36.110
<v Speaker 1>Obviously our human brains are always </v>
<v Speaker 1>learning,</v>

442
00:34:36.950 --> 00:34:41.950
<v Speaker 1>but the beautiful,</v>
<v Speaker 1>fascinating thing is that they're both </v>

443
00:34:41.950 --> 00:34:43.850
<v Speaker 1>distributed computation systems on a </v>
<v Speaker 1>large scale,</v>

444
00:34:44.030 --> 00:34:46.430
<v Speaker 1>so it's not a,</v>
<v Speaker 1>uh,</v>

445
00:34:46.710 --> 00:34:51.710
<v Speaker 1>there's,</v>
<v Speaker 1>it doesn't ultimately boil down to a </v>

446
00:34:51.710 --> 00:34:53.360
<v Speaker 1>single compute unit.</v>
<v Speaker 1>The computation is distributed.</v>

447
00:34:53.720 --> 00:34:58.190
<v Speaker 1>The backpropagation learning process </v>
<v Speaker 1>distributed can be paralyzed in a GPU,</v>

448
00:34:58.490 --> 00:34:59.750
<v Speaker 1>massively parallelized.</v>

449
00:35:00.290 --> 00:35:04.520
<v Speaker 1>The underlying computational unit of a </v>
<v Speaker 1>neuron is trivial,</v>

450
00:35:04.580 --> 00:35:07.910
<v Speaker 1>but can be stacked together to form </v>
<v Speaker 1>forward neural networks,</v>

451
00:35:07.911 --> 00:35:12.911
<v Speaker 1>recurrent neural networks to represent </v>
<v Speaker 1>both spacial information with images and</v>

452
00:35:14.930 --> 00:35:18.980
<v Speaker 1>temporal information with a audio </v>
<v Speaker 1>speech,</v>

453
00:35:19.520 --> 00:35:24.520
<v Speaker 1>text sequences of images and video and </v>
<v Speaker 1>so on.</v>

454
00:35:25.580 --> 00:35:27.380
<v Speaker 1>Mapping from one to one,</v>
<v Speaker 1>one to many,</v>

455
00:35:27.381 --> 00:35:29.540
<v Speaker 1>many to one,</v>
<v Speaker 1>so the mapping,</v>

456
00:35:29.570 --> 00:35:34.570
<v Speaker 1>any kind of structure vector and time </v>
<v Speaker 1>data as an input to any kind of </v>

457
00:35:35.691 --> 00:35:38.460
<v Speaker 1>classification,</v>
<v Speaker 1>regression sequences,</v>

458
00:35:38.760 --> 00:35:40.440
<v Speaker 1>captioning,</v>
<v Speaker 1>video,</v>

459
00:35:40.441 --> 00:35:44.010
<v Speaker 1>audio as output,</v>
<v Speaker 1>learning in the general sense,</v>

460
00:35:44.670 --> 00:35:49.670
<v Speaker 1>but in a domain that's precisely defined</v>
<v Speaker 1>for the supervised training process.</v>

461
00:35:53.730 --> 00:35:57.330
<v Speaker 1>We can think of the in deep learning </v>
<v Speaker 1>case.</v>

462
00:35:57.331 --> 00:36:02.331
<v Speaker 1>You can think of the supervised methods </v>
<v Speaker 1>where humans have to annotate the data </v>

463
00:36:02.331 --> 00:36:07.310
<v Speaker 1>as memorization of the data.</v>
<v Speaker 1>We can think of the exciting new and </v>

464
00:36:07.310 --> 00:36:11.451
<v Speaker 1>growing field of semi supervised </v>
<v Speaker 1>learning when most of the data through </v>

465
00:36:11.451 --> 00:36:15.920
<v Speaker 1>off through generative adversarial </v>
<v Speaker 1>networks or through significant data </v>

466
00:36:15.920 --> 00:36:17.640
<v Speaker 1>augmentation,</v>
<v Speaker 1>clever data augmentation,</v>

467
00:36:17.880 --> 00:36:22.880
<v Speaker 1>most of it is done automatically.</v>
<v Speaker 1>The annotation process or through </v>

468
00:36:22.880 --> 00:36:25.440
<v Speaker 1>simulation and then reinforcement </v>
<v Speaker 1>learning where most of the,</v>

469
00:36:25.530 --> 00:36:30.530
<v Speaker 1>uh,</v>
<v Speaker 1>most of the labels are extremely sparse </v>

470
00:36:30.530 --> 00:36:33.740
<v Speaker 1>and come rarely.</v>
<v Speaker 1>And so the system has to figure out how </v>

471
00:36:33.740 --> 00:36:34.290
<v Speaker 1>to operate in the world with very little</v>
<v Speaker 1>human input,</v>

472
00:36:34.320 --> 00:36:35.550
<v Speaker 1>very little human data.</v>

473
00:36:38.550 --> 00:36:42.030
<v Speaker 1>We can think of that as reasoning </v>
<v Speaker 1>because you take very little information</v>

474
00:36:42.031 --> 00:36:45.360
<v Speaker 1>from our teachers,</v>
<v Speaker 1>the humans and transfer it across,</v>

475
00:36:45.361 --> 00:36:48.480
<v Speaker 1>generalize it across a to reason about </v>
<v Speaker 1>the world.</v>

476
00:36:49.050 --> 00:36:49.800
<v Speaker 1>And finally,</v>
<v Speaker 1>uh,</v>

477
00:36:49.920 --> 00:36:54.920
<v Speaker 1>unsupervised learning,</v>
<v Speaker 1>the excitement of the community that </v>

478
00:36:54.920 --> 00:36:54.920
<v Speaker 1>promise,</v>
<v Speaker 1>the hope.</v>

479
00:36:54.920 --> 00:36:58.410
<v Speaker 1>You could think of that as understanding</v>
<v Speaker 1>because ultimately it's taking data with</v>

480
00:36:58.411 --> 00:37:03.411
<v Speaker 1>very little or no human input.</v>
<v Speaker 1>And for me representations that that </v>

481
00:37:03.411 --> 00:37:05.700
<v Speaker 1>data is how we think of understanding,</v>
<v Speaker 1>requiring,</v>

482
00:37:06.630 --> 00:37:11.630
<v Speaker 1>making sense of the world without strict</v>
<v Speaker 1>input of how to make sense of the world.</v>

483
00:37:13.350 --> 00:37:16.770
<v Speaker 1>The kind of process of discovering </v>
<v Speaker 1>information,</v>

484
00:37:17.790 --> 00:37:22.790
<v Speaker 1>maybe discovering new ideas,</v>
<v Speaker 1>new ways to simplify the world to </v>

485
00:37:22.790 --> 00:37:24.720
<v Speaker 1>represent the world that you can do new </v>
<v Speaker 1>things with it.</v>

486
00:37:25.050 --> 00:37:30.050
<v Speaker 1>The new is the key element there.</v>
<v Speaker 1>Understanding and uh,</v>

487
00:37:30.300 --> 00:37:35.130
<v Speaker 1>Andrea and Eylea and others will talk </v>
<v Speaker 1>about the certainly the past,</v>

488
00:37:35.131 --> 00:37:36.480
<v Speaker 1>but the future of deep learning.</v>

489
00:37:36.720 --> 00:37:41.720
<v Speaker 1>Whereas going to go is it over hyped,</v>
<v Speaker 1>under hyped?</v>

490
00:37:42.180 --> 00:37:47.180
<v Speaker 1>What is the future?</v>
<v Speaker 1>Will the compute of CPU GPU as six </v>

491
00:37:47.180 --> 00:37:51.360
<v Speaker 1>continue with the breakthroughs,</v>
<v Speaker 1>the Moore's law and its various forms of</v>

492
00:37:51.361 --> 00:37:56.361
<v Speaker 1>massive parallelization continue and the</v>
<v Speaker 1>large data sets with tens of millions of</v>

493
00:37:57.420 --> 00:38:02.420
<v Speaker 1>images grow to billions and trillions.</v>
<v Speaker 1>Will the algorithms improve?</v>

494
00:38:02.580 --> 00:38:06.300
<v Speaker 1>Is there a groundbreaking idea that's </v>
<v Speaker 1>still coming with,</v>

495
00:38:06.430 --> 00:38:07.610
<v Speaker 1>uh,</v>
<v Speaker 1>with Geoff Hinton's?</v>

496
00:38:07.620 --> 00:38:12.620
<v Speaker 1>Capsule networks is a fundamental </v>
<v Speaker 1>architectural changes in your networks </v>

497
00:38:12.620 --> 00:38:15.120
<v Speaker 1>that we can come up with that will </v>
<v Speaker 1>change everything,</v>

498
00:38:15.121 --> 00:38:20.121
<v Speaker 1>that will ease the learning process.</v>
<v Speaker 1>They'll make the learning process more </v>

499
00:38:20.121 --> 00:38:23.781
<v Speaker 1>efficient or will be able to represent </v>
<v Speaker 1>higher and higher orders of information </v>

500
00:38:24.521 --> 00:38:29.521
<v Speaker 1>is such that you can transfer knowledge </v>
<v Speaker 1>between domains and the software </v>

501
00:38:30.631 --> 00:38:34.530
<v Speaker 1>architectures that support intensive </v>
<v Speaker 1>Florida Pi Torch.</v>

502
00:38:34.840 --> 00:38:39.840
<v Speaker 1>Uh,</v>
<v Speaker 1>I would say the last year and this year </v>

503
00:38:39.840 --> 00:38:39.840
<v Speaker 1>will be the year of deep learning </v>
<v Speaker 1>frameworks.</v>

504
00:38:39.840 --> 00:38:44.251
<v Speaker 1>So will,</v>
<v Speaker 1>those will certainly keep coming in </v>

505
00:38:44.251 --> 00:38:46.321
<v Speaker 1>their various forms and the financial </v>
<v Speaker 1>backing is growing and growing the open </v>

506
00:38:48.761 --> 00:38:50.740
<v Speaker 1>challenges for deep learning.</v>

507
00:38:51.400 --> 00:38:56.400
<v Speaker 1>Really a lot of this course is kind of </v>
<v Speaker 1>connected to deep learning because </v>

508
00:38:56.400 --> 00:39:01.201
<v Speaker 1>that's where a lot of the recent </v>
<v Speaker 1>breakthroughs that inspire us to think </v>

509
00:39:01.961 --> 00:39:05.310
<v Speaker 1>about intelligence systems come from.</v>
<v Speaker 1>But the challenges are many,</v>

510
00:39:05.520 --> 00:39:06.580
<v Speaker 1>the,</v>
<v Speaker 1>the need,</v>

511
00:39:06.610 --> 00:39:11.610
<v Speaker 1>the ability to transfer between </v>
<v Speaker 1>different domains as in reinforcement </v>

512
00:39:11.610 --> 00:39:15.511
<v Speaker 1>learning and robotics.</v>
<v Speaker 1>The need for huge data and an efficient </v>

513
00:39:15.511 --> 00:39:16.270
<v Speaker 1>learning.</v>
<v Speaker 1>Uh,</v>

514
00:39:16.330 --> 00:39:19.090
<v Speaker 1>we're,</v>
<v Speaker 1>we're still need supervised data.</v>

515
00:39:19.270 --> 00:39:24.270
<v Speaker 1>Uh,</v>
<v Speaker 1>inability to learn in an unsupervised </v>

516
00:39:24.270 --> 00:39:26.650
<v Speaker 1>way is a huge problem and not fully </v>
<v Speaker 1>automated learning.</v>

517
00:39:27.030 --> 00:39:32.030
<v Speaker 1>There's still a degree,</v>
<v Speaker 1>a significant degree of hyper parameter </v>

518
00:39:32.030 --> 00:39:32.860
<v Speaker 1>tuning necessary with the reward </v>
<v Speaker 1>functions.</v>

519
00:39:32.861 --> 00:39:37.861
<v Speaker 1>The loss functions are ultimately </v>
<v Speaker 1>defined by humans and therefore are </v>

520
00:39:38.081 --> 00:39:43.081
<v Speaker 1>deeply flawed.</v>
<v Speaker 1>When we released those systems into the </v>

521
00:39:43.081 --> 00:39:46.831
<v Speaker 1>real world where there is no ground </v>
<v Speaker 1>truth for the testing set and the goal </v>

522
00:39:46.831 --> 00:39:50.380
<v Speaker 1>isn't achieving a class,</v>
<v Speaker 1>a high classification on a trivial,</v>

523
00:39:50.670 --> 00:39:54.460
<v Speaker 1>a image classification,</v>
<v Speaker 1>localization detection problem,</v>

524
00:39:54.640 --> 00:39:59.640
<v Speaker 1>but rather to have an autonomous vehicle</v>
<v Speaker 1>that doesn't kill pedestrians or an </v>

525
00:40:01.451 --> 00:40:06.451
<v Speaker 1>industrial robot that operates in </v>
<v Speaker 1>jointly with other human beings and all </v>

526
00:40:06.521 --> 00:40:08.410
<v Speaker 1>the edge cases that come up.</v>

527
00:40:08.650 --> 00:40:13.650
<v Speaker 1>How does deep learning methods,</v>
<v Speaker 1>how to machine learning methods </v>

528
00:40:13.650 --> 00:40:14.920
<v Speaker 1>generalize over the edge cases,</v>
<v Speaker 1>the weird stuff that happens in the real</v>

529
00:40:14.921 --> 00:40:16.900
<v Speaker 1>world?</v>
<v Speaker 1>Those are all the problems there.</v>

530
00:40:18.040 --> 00:40:23.040
<v Speaker 1>Stephen Wolfram will be here on Monday </v>
<v Speaker 1>evening at 7:00</v>

531
00:40:23.230 --> 00:40:26.410
<v Speaker 1>PM,</v>
<v Speaker 1>has done a lot of amazing things,</v>

532
00:40:26.411 --> 00:40:31.411
<v Speaker 1>I would say is very interesting from his</v>
<v Speaker 1>recent interest in knowledge based </v>

533
00:40:31.411 --> 00:40:36.120
<v Speaker 1>programming.</v>
<v Speaker 1>Wolfram Alpha I think is the fuel for </v>

534
00:40:36.120 --> 00:40:38.890
<v Speaker 1>most middle school and high school </v>
<v Speaker 1>students.</v>

535
00:40:38.891 --> 00:40:43.891
<v Speaker 1>Now,</v>
<v Speaker 1>for the first time taking calculus I </v>

536
00:40:43.891 --> 00:40:47.071
<v Speaker 1>pray,</v>
<v Speaker 1>probably go to Wolfram Alpha to answer </v>

537
00:40:47.071 --> 00:40:47.071
<v Speaker 1>their own questions,</v>
<v Speaker 1>but more seriously,</v>

538
00:40:47.071 --> 00:40:51.480
<v Speaker 1>there is a,</v>
<v Speaker 1>a deep connected graph of knowledge as </v>

539
00:40:51.480 --> 00:40:53.030
<v Speaker 1>being built there with the wool from </v>
<v Speaker 1>wool,</v>

540
00:40:53.050 --> 00:40:58.050
<v Speaker 1>from Alpha and wool from language that </v>
<v Speaker 1>still will explore in terms of language </v>

541
00:40:59.410 --> 00:41:04.410
<v Speaker 1>and interesting thing.</v>
<v Speaker 1>He was part of the team on arrival that,</v>

542
00:41:05.040 --> 00:41:06.550
<v Speaker 1>uh,</v>
<v Speaker 1>worked on the language.</v>

543
00:41:06.730 --> 00:41:11.730
<v Speaker 1>If for those of you are familiar to </v>
<v Speaker 1>arrival where a alien species spoke with</v>

544
00:41:12.400 --> 00:41:16.510
<v Speaker 1>us,</v>
<v Speaker 1>US humans through a very interesting,</v>

545
00:41:16.511 --> 00:41:21.511
<v Speaker 1>beautiful,</v>
<v Speaker 1>complicated language and he was brought </v>

546
00:41:21.511 --> 00:41:24.301
<v Speaker 1>in as a representative human to </v>
<v Speaker 1>interpret that language just like in the</v>

547
00:41:24.941 --> 00:41:27.640
<v Speaker 1>movie,</v>
<v Speaker 1>who's represent that in real life.</v>

548
00:41:28.150 --> 00:41:33.150
<v Speaker 1>And you use the skills that him and his </v>
<v Speaker 1>son Christopher used to analyze this </v>

549
00:41:33.381 --> 00:41:34.550
<v Speaker 1>language.</v>
<v Speaker 1>Very interesting.</v>

550
00:41:34.580 --> 00:41:39.580
<v Speaker 1>That process is extremely interesting.</v>
<v Speaker 1>I hope he talks about it and his </v>

551
00:41:39.580 --> 00:41:42.710
<v Speaker 1>background with Mathematica and a new </v>
<v Speaker 1>kind of science.</v>

552
00:41:44.300 --> 00:41:49.300
<v Speaker 1>The sort of another set of ideas that </v>
<v Speaker 1>have inspired people in terms of </v>

553
00:41:53.360 --> 00:41:58.360
<v Speaker 1>creating intelligence systems is the </v>
<v Speaker 1>idea that from very simple things,</v>

554
00:42:03.650 --> 00:42:08.330
<v Speaker 1>very simple rules,</v>
<v Speaker 1>extremely complex patterns can emerge.</v>

555
00:42:09.010 --> 00:42:14.010
<v Speaker 1>His work with cellular Automata did just</v>
<v Speaker 1>that take an extremely simple </v>

556
00:42:14.780 --> 00:42:18.830
<v Speaker 1>mathematical constructs here with </v>
<v Speaker 1>cellular Automata.</v>

557
00:42:18.831 --> 00:42:23.831
<v Speaker 1>These are,</v>
<v Speaker 1>these are grids of computational units </v>

558
00:42:23.831 --> 00:42:28.061
<v Speaker 1>that switch on and off and some kind of </v>
<v Speaker 1>predefined way and only operate locally </v>

559
00:42:28.061 --> 00:42:32.801
<v Speaker 1>based on their local neighborhood and </v>
<v Speaker 1>somehow based on different kinds of </v>

560
00:42:32.801 --> 00:42:33.890
<v Speaker 1>rules,</v>
<v Speaker 1>different patterns emerge.</v>

561
00:42:33.891 --> 00:42:38.891
<v Speaker 1>Here's the three dimensional cellular </v>
<v Speaker 1>automata with a simple rule starting </v>

562
00:42:38.891 --> 00:42:41.300
<v Speaker 1>with nothing with a single cell.</v>
<v Speaker 1>They grow and really interesting,</v>

563
00:42:41.301 --> 00:42:42.260
<v Speaker 1>complex ways.</v>

564
00:42:42.440 --> 00:42:47.440
<v Speaker 1>This emergent complexity is inspiring.</v>
<v Speaker 1>It's the same kind of thing that </v>

565
00:42:47.751 --> 00:42:51.980
<v Speaker 1>inspires us about neural networks that </v>
<v Speaker 1>you can take a simple computational unit</v>

566
00:42:52.190 --> 00:42:57.190
<v Speaker 1>and when combined together in arbitrary </v>
<v Speaker 1>ways can form complex representations.</v>

567
00:42:57.890 --> 00:43:02.890
<v Speaker 1>That's also very interesting.</v>
<v Speaker 1>You can see knowledge from a knowledge </v>

568
00:43:02.890 --> 00:43:03.590
<v Speaker 1>perspective.</v>
<v Speaker 1>You could see knowledge formation in the</v>

569
00:43:03.591 --> 00:43:08.591
<v Speaker 1>same kind of way.</v>
<v Speaker 1>Simplicity at a mass distributed scale,</v>

570
00:43:09.740 --> 00:43:13.880
<v Speaker 1>resulting complexity.</v>
<v Speaker 1>Next Tuesday,</v>

571
00:43:14.480 --> 00:43:17.780
<v Speaker 1>Richard,</v>
<v Speaker 1>noise from article 36 coming all the way</v>

572
00:43:17.781 --> 00:43:22.781
<v Speaker 1>from UK for us.</v>
<v Speaker 1>We'll talk about it works with </v>

573
00:43:22.781 --> 00:43:26.870
<v Speaker 1>autonomous weapons systems,</v>
<v Speaker 1>works with also a nuclear weapons,</v>

574
00:43:26.990 --> 00:43:31.990
<v Speaker 1>but primarily autonomous weapon systems </v>
<v Speaker 1>and concern legal policy and </v>

575
00:43:32.961 --> 00:43:35.780
<v Speaker 1>technological aspects of banning these </v>
<v Speaker 1>weapons.</v>

576
00:43:35.970 --> 00:43:40.970
<v Speaker 1>There's been a lot of agreement about </v>
<v Speaker 1>the safety hazards of autonomous systems</v>

577
00:43:41.361 --> 00:43:43.880
<v Speaker 1>that make decisions to kill a human </v>
<v Speaker 1>being.</v>

578
00:43:45.500 --> 00:43:47.490
<v Speaker 1>Mara Criber,</v>
<v Speaker 1>CEO,</v>

579
00:43:47.520 --> 00:43:51.860
<v Speaker 1>Boston Dynamics,</v>
<v Speaker 1>previously long time ago,</v>

580
00:43:51.890 --> 00:43:54.920
<v Speaker 1>faculty here at Mit,</v>
<v Speaker 1>we'll talk about.</v>

581
00:43:54.980 --> 00:43:59.980
<v Speaker 1>We'll bring robots and talked to us </v>
<v Speaker 1>about his work of robots in the real </v>

582
00:44:00.471 --> 00:44:05.471
<v Speaker 1>world as a,</v>
<v Speaker 1>doing a lot of exciting stuff with </v>

583
00:44:05.471 --> 00:44:06.830
<v Speaker 1>humanoid robotics at 80 kinds of robots </v>
<v Speaker 1>operating on legs.</v>

584
00:44:07.280 --> 00:44:09.200
<v Speaker 1>Uh,</v>
<v Speaker 1>it's incredible work,</v>

585
00:44:09.201 --> 00:44:13.910
<v Speaker 1>extremely exciting and gets to explore </v>
<v Speaker 1>the idea of how difficult it is to build</v>

586
00:44:13.911 --> 00:44:17.120
<v Speaker 1>these robots systems that operate in the</v>
<v Speaker 1>real world,</v>

587
00:44:18.020 --> 00:44:23.020
<v Speaker 1>uh,</v>
<v Speaker 1>from both the Qa control aspect and from</v>

588
00:44:24.230 --> 00:44:28.070
<v Speaker 1>the way the final result is perceived by</v>
<v Speaker 1>our society.</v>

589
00:44:28.580 --> 00:44:33.580
<v Speaker 1>It's very interesting to see when </v>
<v Speaker 1>intelligence in robotics is embodied and</v>

590
00:44:34.171 --> 00:44:37.680
<v Speaker 1>then taking in by us and what that </v>
<v Speaker 1>inspires.</v>

591
00:44:37.890 --> 00:44:39.540
<v Speaker 1>Fear,</v>
<v Speaker 1>excitement,</v>

592
00:44:39.660 --> 00:44:41.310
<v Speaker 1>hope,</v>
<v Speaker 1>concern,</v>

593
00:44:42.330 --> 00:44:47.330
<v Speaker 1>and all of the above.</v>
<v Speaker 1>Les is a expert in many aspects of </v>

594
00:44:49.001 --> 00:44:52.150
<v Speaker 1>machine learning.</v>
<v Speaker 1>Is the cofounder of open Ai.</v>

595
00:44:53.700 --> 00:44:58.700
<v Speaker 1>Talk about there different aspects of </v>
<v Speaker 1>game playing that they've recently been </v>

596
00:44:59.551 --> 00:45:03.900
<v Speaker 1>exploring by using deeper enforcement,</v>
<v Speaker 1>learning to play arcade games</v>

597
00:45:05.890 --> 00:45:10.890
<v Speaker 1>and d on the deep mind side,</v>
<v Speaker 1>using deep reinforcement learning to </v>

598
00:45:10.890 --> 00:45:15.620
<v Speaker 1>beat the best in the world that the game</v>
<v Speaker 1>of go in 2017.</v>

599
00:45:15.621 --> 00:45:19.370
<v Speaker 1>The big fascinating breakthrough </v>
<v Speaker 1>achieved by that team with Alphago,</v>

600
00:45:19.371 --> 00:45:23.270
<v Speaker 1>zero training and agent that through </v>
<v Speaker 1>self play playing itself,</v>

601
00:45:23.271 --> 00:45:26.540
<v Speaker 1>not an expert games so truly from </v>
<v Speaker 1>scratch,</v>

602
00:45:26.690 --> 00:45:31.690
<v Speaker 1>learning to beat the best in the world,</v>
<v Speaker 1>including the previous iteration of </v>

603
00:45:31.690 --> 00:45:35.591
<v Speaker 1>Alphago.</v>
<v Speaker 1>We'll explore what aspects of the stack </v>

604
00:45:35.720 --> 00:45:40.720
<v Speaker 1>of intelligent robotics systems </v>
<v Speaker 1>intelligent agents can be learned in </v>

605
00:45:40.720 --> 00:45:42.310
<v Speaker 1>this way.</v>
<v Speaker 1>So deep learning,</v>

606
00:45:42.340 --> 00:45:47.340
<v Speaker 1>the memorization,</v>
<v Speaker 1>the supervised learning memorization </v>

607
00:45:47.340 --> 00:45:50.291
<v Speaker 1>approach.</v>
<v Speaker 1>It looks at the sensor data feature </v>

608
00:45:50.291 --> 00:45:52.220
<v Speaker 1>extraction representation,</v>
<v Speaker 1>learning aspect of this,</v>

609
00:45:52.700 --> 00:45:55.700
<v Speaker 1>taking the sensor data from camera,</v>
<v Speaker 1>a lidar audio,</v>

610
00:45:56.300 --> 00:46:01.300
<v Speaker 1>extracting the features for me,</v>
<v Speaker 1>higher order of representations and on </v>

611
00:46:01.300 --> 00:46:05.921
<v Speaker 1>those representations.</v>
<v Speaker 1>Learning to actually accomplish some </v>

612
00:46:05.921 --> 00:46:08.381
<v Speaker 1>kind of classification regression task,</v>
<v Speaker 1>figuring out based on the representation</v>

613
00:46:09.410 --> 00:46:14.270
<v Speaker 1>what is going on in the raw sensory data</v>
<v Speaker 1>and then combining that data together to</v>

614
00:46:14.271 --> 00:46:18.640
<v Speaker 1>reason about it and finally in the </v>
<v Speaker 1>robotic domains,</v>

615
00:46:18.670 --> 00:46:22.600
<v Speaker 1>taking it all together as with humanoid,</v>
<v Speaker 1>robotics,</v>

616
00:46:22.660 --> 00:46:27.660
<v Speaker 1>industrial robotics,</v>
<v Speaker 1>autonomous vehicles taking altogether </v>

617
00:46:27.660 --> 00:46:31.380
<v Speaker 1>and actually acting in this world where </v>
<v Speaker 1>the effectors and the open question is,</v>

618
00:46:31.811 --> 00:46:34.150
<v Speaker 1>how much of this ai stack can be </v>
<v Speaker 1>learned?</v>

619
00:46:35.830 --> 00:46:38.770
<v Speaker 1>That's something for us to discuss,</v>
<v Speaker 1>to think about.</v>

620
00:46:40.000 --> 00:46:42.550
<v Speaker 1>The eylea will touch on with deeper </v>
<v Speaker 1>enforcement learning.</v>

621
00:46:42.910 --> 00:46:46.630
<v Speaker 1>We can certainly learn representations </v>
<v Speaker 1>and perform classifications.</v>

622
00:46:46.750 --> 00:46:49.490
<v Speaker 1>They are better than human I damaged </v>
<v Speaker 1>classification,</v>

623
00:46:49.510 --> 00:46:52.360
<v Speaker 1>image,</v>
<v Speaker 1>net and segmentation tasks</v>

624
00:46:54.450 --> 00:46:59.450
<v Speaker 1>and the excitement of deep learning is </v>
<v Speaker 1>what's highlighted there in the red box </v>

625
00:46:59.450 --> 00:47:00.900
<v Speaker 1>can be done end to ends.</v>
<v Speaker 1>Raw sensory data out to the knowledge,</v>

626
00:47:00.901 --> 00:47:02.580
<v Speaker 1>to the output,</v>
<v Speaker 1>to the classification.</v>

627
00:47:03.240 --> 00:47:08.240
<v Speaker 1>Can we begin to reason is the open </v>
<v Speaker 1>question with the knowledge based </v>

628
00:47:08.240 --> 00:47:09.990
<v Speaker 1>programming that Stephen Wolfman,</v>
<v Speaker 1>we'll talk about.</v>

629
00:47:09.991 --> 00:47:14.991
<v Speaker 1>Can we begin to take these automatically</v>
<v Speaker 1>generated high order representations and</v>

630
00:47:16.201 --> 00:47:19.170
<v Speaker 1>combine them together to form knowledge </v>
<v Speaker 1>basis,</v>

631
00:47:19.860 --> 00:47:24.720
<v Speaker 1>to form a aggregate grass of ideas that </v>
<v Speaker 1>can then be used the reason</v>

632
00:47:26.780 --> 00:47:31.780
<v Speaker 1>and can we then combine them together to</v>
<v Speaker 1>act in the world for whether in </v>

633
00:47:32.621 --> 00:47:37.621
<v Speaker 1>simulation with arcade games or </v>
<v Speaker 1>simulation of autonomous vehicles or box</v>

634
00:47:37.681 --> 00:47:42.681
<v Speaker 1>systems are actually in the physical </v>
<v Speaker 1>world with robots moving about that end </v>

635
00:47:42.681 --> 00:47:46.210
<v Speaker 1>to end from raw sensory data to action </v>
<v Speaker 1>be learned.</v>

636
00:47:47.140 --> 00:47:52.140
<v Speaker 1>That's the open question for for </v>
<v Speaker 1>artificial general intelligence for this</v>

637
00:47:52.211 --> 00:47:56.920
<v Speaker 1>class.</v>
<v Speaker 1>Can this entire process be end to end?</v>

638
00:47:58.090 --> 00:48:03.090
<v Speaker 1>Can we build systems and how do we do it</v>
<v Speaker 1>that achieve this process end to end in </v>

639
00:48:03.641 --> 00:48:08.641
<v Speaker 1>the same way that humans do.</v>
<v Speaker 1>We're born in this raw sensory </v>

640
00:48:08.641 --> 00:48:12.301
<v Speaker 1>environment,</v>
<v Speaker 1>taking in very little information and </v>

641
00:48:12.301 --> 00:48:15.961
<v Speaker 1>learn to operate successfully an </v>
<v Speaker 1>arbitrary constraints,</v>

642
00:48:17.470 --> 00:48:21.370
<v Speaker 1>arbitrary goals,</v>
<v Speaker 1>and to do so.</v>

643
00:48:21.610 --> 00:48:26.560
<v Speaker 1>We have lectures,</v>
<v Speaker 1>we have three projects and we have guest</v>

644
00:48:26.561 --> 00:48:31.561
<v Speaker 1>speakers from various disciplines.</v>
<v Speaker 1>I hope that all these voices will be </v>

645
00:48:32.081 --> 00:48:37.081
<v Speaker 1>heard and will feed a conversation about</v>
<v Speaker 1>artificial intelligence and it's </v>

646
00:48:39.581 --> 00:48:44.581
<v Speaker 1>positive and it's concerning effects in </v>
<v Speaker 1>society and how do we move forward from </v>

647
00:48:45.821 --> 00:48:47.200
<v Speaker 1>an engineering approach.</v>

648
00:48:47.620 --> 00:48:51.010
<v Speaker 1>The topics will be deep learning,</v>
<v Speaker 1>deep reinforcement learning,</v>

649
00:48:51.700 --> 00:48:53.700
<v Speaker 1>cognitive modeling,</v>
<v Speaker 1>competition,</v>

650
00:48:53.720 --> 00:48:55.450
<v Speaker 1>cognitive science,</v>
<v Speaker 1>emotion creation,</v>

651
00:48:55.451 --> 00:49:00.451
<v Speaker 1>knowledge based programming,</v>
<v Speaker 1>ai safety with autonomous weapons </v>

652
00:49:00.451 --> 00:49:03.160
<v Speaker 1>systems and personal robotics with human</v>
<v Speaker 1>centered artificial intelligence.</v>

653
00:49:03.280 --> 00:49:05.260
<v Speaker 1>That's for the first two weeks of this </v>
<v Speaker 1>class.</v>

654
00:49:05.530 --> 00:49:09.070
<v Speaker 1>That's the part where if you're actually</v>
<v Speaker 1>registered students,</v>

655
00:49:09.071 --> 00:49:10.960
<v Speaker 1>that's where you need to submit the </v>
<v Speaker 1>project.</v>

656
00:49:11.170 --> 00:49:15.310
<v Speaker 1>That's when we all meet here every,</v>
<v Speaker 1>every night with an incredible speakers,</v>

657
00:49:15.790 --> 00:49:20.790
<v Speaker 1>but this will continue.</v>
<v Speaker 1>We're already have several speakers </v>

658
00:49:20.790 --> 00:49:22.240
<v Speaker 1>scheduled the next couple of months yet </v>
<v Speaker 1>to be announced,</v>

659
00:49:22.600 --> 00:49:27.220
<v Speaker 1>but they're incredible and we have </v>
<v Speaker 1>conversations on video.</v>

660
00:49:27.460 --> 00:49:32.460
<v Speaker 1>We'll have new projects.</v>
<v Speaker 1>I hope this continues throughout 2018 on</v>

661
00:49:32.591 --> 00:49:37.591
<v Speaker 1>the topics of Ai Ethics and bias.</v>
<v Speaker 1>There's a lot of incredible work in a </v>

662
00:49:38.680 --> 00:49:43.680
<v Speaker 1>way know of a speaker.</v>
<v Speaker 1>There are coming on the topic of how do </v>

663
00:49:43.680 --> 00:49:45.160
<v Speaker 1>we create artificial intelligence </v>
<v Speaker 1>systems that are do not discriminate,</v>

664
00:49:45.400 --> 00:49:50.400
<v Speaker 1>did not form the kind of biases that US </v>
<v Speaker 1>humans do in this world that are </v>

665
00:49:51.310 --> 00:49:56.310
<v Speaker 1>operating under social norms,</v>
<v Speaker 1>but our reasoning beyond the flawed </v>

666
00:49:57.160 --> 00:50:02.160
<v Speaker 1>aspects of those social norms with bias,</v>
<v Speaker 1>creativity as well.</v>

667
00:50:02.800 --> 00:50:07.800
<v Speaker 1>The project of dream vision and beyond.</v>
<v Speaker 1>There's so much exciting work qa and </v>

668
00:50:08.930 --> 00:50:13.270
<v Speaker 1>using machine learning methods to create</v>
<v Speaker 1>beautiful art and music,</v>

669
00:50:15.380 --> 00:50:17.680
<v Speaker 1>a brain stimulation,</v>
<v Speaker 1>neuroscience,</v>

670
00:50:17.681 --> 00:50:18.910
<v Speaker 1>computation,</v>
<v Speaker 1>neuroscience.</v>

671
00:50:18.940 --> 00:50:23.940
<v Speaker 1>Shockingly,</v>
<v Speaker 1>in the first two weeks we don't have a </v>

672
00:50:23.940 --> 00:50:26.670
<v Speaker 1>computation neuroscience speaker,</v>
<v Speaker 1>which is a fascinating perspective.</v>

673
00:50:26.930 --> 00:50:30.410
<v Speaker 1>Brain simulation or neuroscience in </v>
<v Speaker 1>general.</v>

674
00:50:30.560 --> 00:50:35.560
<v Speaker 1>Computation neuroscience is a </v>
<v Speaker 1>fascinating approach from the from the </v>

675
00:50:35.560 --> 00:50:40.121
<v Speaker 1>mark of actual brain work to get the </v>
<v Speaker 1>perspective of how our brain works and </v>

676
00:50:40.341 --> 00:50:45.341
<v Speaker 1>how we can create something that mimics,</v>
<v Speaker 1>that resembles the fundamentals of what </v>

677
00:50:45.341 --> 00:50:49.160
<v Speaker 1>makes our brain intelligent.</v>
<v Speaker 1>And finally the turing test.</v>

678
00:50:49.161 --> 00:50:54.161
<v Speaker 1>The traditional definite shouldn't have </v>
<v Speaker 1>intelligence defined by Alan Turing was </v>

679
00:50:54.161 --> 00:50:57.740
<v Speaker 1>grounded in natural language processing </v>
<v Speaker 1>and creating chat bots that impress us,</v>

680
00:50:57.920 --> 00:51:00.890
<v Speaker 1>that amaze us and trick us into thinking</v>
<v Speaker 1>they're human.</v>

681
00:51:02.030 --> 00:51:07.030
<v Speaker 1>We will have a project and a speaker on </v>
<v Speaker 1>natural language processing in March </v>

682
00:51:09.250 --> 00:51:14.250
<v Speaker 1>that I like to thank you for coming </v>
<v Speaker 1>today and look forward to seeing your </v>

683
00:51:14.250 --> 00:51:15.740
<v Speaker 1>submissions for the three projects.</v>
<v Speaker 1>Thank you very much.</v>

