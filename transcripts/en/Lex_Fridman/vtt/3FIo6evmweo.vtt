WEBVTT

1
00:00:00.090 --> 00:00:03.000
<v Speaker 1>The following is a conversation with </v>
<v Speaker 1>Juergen Schmidhuber.</v>

2
00:00:03.590 --> 00:00:04.423
<v Speaker 1>He's the CO director of at [inaudible] </v>
<v Speaker 1>Swiss ai lab and a cocreator of long </v>

3
00:00:08.061 --> 00:00:08.894
<v Speaker 1>short term memory networks.</v>
<v Speaker 1>Lsts are used in billions of devices </v>

4
00:00:12.961 --> 00:00:17.961
<v Speaker 1>today for speech recognition,</v>
<v Speaker 1>translation and much more over 30 years.</v>

5
00:00:18.690 --> 00:00:22.170
<v Speaker 1>He has proposed a lot of interesting out</v>
<v Speaker 1>of the box ideas,</v>

6
00:00:22.410 --> 00:00:25.860
<v Speaker 1>a metal learning adversarial networks,</v>
<v Speaker 1>computer vision,</v>

7
00:00:26.070 --> 00:00:29.730
<v Speaker 1>and even a formal theory of quote,</v>
<v Speaker 1>creativity,</v>

8
00:00:29.790 --> 00:00:30.623
<v Speaker 1>curiosity and fun.</v>
<v Speaker 1>This conversation is part of the mit </v>

9
00:00:34.651 --> 00:00:35.484
<v Speaker 1>course and artificial general </v>
<v Speaker 1>intelligence and the artificial </v>

10
00:00:37.411 --> 00:00:41.070
<v Speaker 1>intelligence podcast.</v>
<v Speaker 1>If you enjoy subscribe on Youtube,</v>

11
00:00:41.100 --> 00:00:45.090
<v Speaker 1>itunes or simply connect with me on </v>
<v Speaker 1>twitter at [inaudible] Friedman,</v>

12
00:00:45.240 --> 00:00:46.530
<v Speaker 1>spelled f,</v>
<v Speaker 1>r I.</v>

13
00:00:46.531 --> 00:00:47.364
<v Speaker 1>D.</v>
<v Speaker 1>And now here's my conversation with </v>

14
00:00:49.981 --> 00:00:50.814
<v Speaker 1>Juergen Schmidhuber early on you dreamed</v>
<v Speaker 1>of AI systems that self improve </v>

15
00:00:57.410 --> 00:01:00.230
<v Speaker 1>cursively when was that dream born</v>

16
00:01:01.690 --> 00:01:05.310
<v Speaker 2>man and was a baby now has not true when</v>
<v Speaker 2>I was a teenager.</v>

17
00:01:06.470 --> 00:01:09.680
<v Speaker 1>And what was the catalyst for that </v>
<v Speaker 1>birth?</v>

18
00:01:09.681 --> 00:01:11.480
<v Speaker 1>What was the thing that first inspired </v>
<v Speaker 1>you</v>

19
00:01:13.090 --> 00:01:14.660
<v Speaker 2>when it wasn't?</v>
<v Speaker 2>Why I'm,</v>

20
00:01:17.680 --> 00:01:18.513
<v Speaker 2>I was thinking about what to do in my </v>
<v Speaker 2>life and then I thought the most </v>

21
00:01:23.080 --> 00:01:26.380
<v Speaker 2>exciting thing as to soul,</v>
<v Speaker 2>the riddles,</v>

22
00:01:26.520 --> 00:01:27.790
<v Speaker 2>the universe.</v>
<v Speaker 2>And,</v>

23
00:01:28.150 --> 00:01:30.130
<v Speaker 2>and that means you have to become a </v>
<v Speaker 2>physicist.</v>

24
00:01:30.880 --> 00:01:35.080
<v Speaker 2>However,</v>
<v Speaker 2>then I realized that that is something,</v>

25
00:01:35.081 --> 00:01:35.914
<v Speaker 2>even grandma,</v>
<v Speaker 2>you can't try to build a machine that </v>

26
00:01:40.061 --> 00:01:40.894
<v Speaker 2>isn't really a machine any longer.</v>
<v Speaker 2>That learns to become a much better </v>

27
00:01:43.781 --> 00:01:48.460
<v Speaker 2>physicist then I could ever hope to be.</v>
<v Speaker 2>And that's how I thought.</v>

28
00:01:48.461 --> 00:01:53.290
<v Speaker 2>Maybe I can multiply my tiny little bit </v>
<v Speaker 2>of creativity and to engineer</v>

29
00:01:53.380 --> 00:01:54.213
<v Speaker 1>team,</v>
<v Speaker 1>but ultimately that creativity will be </v>

30
00:01:56.561 --> 00:01:59.170
<v Speaker 1>multiplied to understand the universe </v>
<v Speaker 1>around us.</v>

31
00:01:59.200 --> 00:02:01.030
<v Speaker 1>That's,</v>
<v Speaker 1>that's the,</v>

32
00:02:02.200 --> 00:02:05.380
<v Speaker 1>the curiosity for that mystery that that</v>
<v Speaker 1>drove you.</v>

33
00:02:05.740 --> 00:02:06.220
<v Speaker 2>Yes.</v>
<v Speaker 2>Uh,</v>

34
00:02:06.220 --> 00:02:11.220
<v Speaker 2>so if you can build a machine that lance</v>
<v Speaker 2>to solve more and more complex problems,</v>

35
00:02:13.841 --> 00:02:16.330
<v Speaker 2>I'm more and more general problem </v>
<v Speaker 2>solver,</v>

36
00:02:16.840 --> 00:02:21.840
<v Speaker 2>then you basically have solved all the </v>
<v Speaker 2>problems,</v>

37
00:02:22.630 --> 00:02:25.300
<v Speaker 2>at least all the solvable problems.</v>

38
00:02:26.030 --> 00:02:26.863
<v Speaker 1>So how do you think,</v>
<v Speaker 1>what is the mechanism for that kind of </v>

39
00:02:28.971 --> 00:02:33.971
<v Speaker 1>general solver look like?</v>
<v Speaker 1>Obviously we don't quite yet have one or</v>

40
00:02:35.121 --> 00:02:35.954
<v Speaker 1>know how to build one boy of ideas.</v>
<v Speaker 1>And you have had throughout your career </v>

41
00:02:39.171 --> 00:02:40.004
<v Speaker 1>several ideas about it.</v>
<v Speaker 1>So how do you think about that </v>

42
00:02:41.961 --> 00:02:42.794
<v Speaker 1>mechanism?</v>

43
00:02:43.650 --> 00:02:44.483
<v Speaker 2>So in the 80s,</v>
<v Speaker 2>I thought about how to build this </v>

44
00:02:48.181 --> 00:02:53.181
<v Speaker 2>machine that lance was so of all these </v>
<v Speaker 2>columns and I cannot solve myself.</v>

45
00:02:54.180 --> 00:02:55.013
<v Speaker 2>And I thought it is clear that it has to</v>
<v Speaker 2>be a machine that not only learns too </v>

46
00:02:59.440 --> 00:03:02.320
<v Speaker 2>solve this problem here and this problem</v>
<v Speaker 2>here,</v>

47
00:03:02.680 --> 00:03:07.680
<v Speaker 2>but it also has to learn to improve the </v>
<v Speaker 2>learning algorithm itself,</v>

48
00:03:08.640 --> 00:03:12.520
<v Speaker 2>right?</v>
<v Speaker 2>So it has to have the learning algorithm</v>

49
00:03:12.521 --> 00:03:15.550
<v Speaker 2>and um,</v>
<v Speaker 2>representation that allows it to inspect</v>

50
00:03:15.551 --> 00:03:20.551
<v Speaker 2>it and modify it so that it can come up </v>
<v Speaker 2>with a better learning algorithm.</v>

51
00:03:22.090 --> 00:03:23.620
<v Speaker 2>So when I called that and metal </v>
<v Speaker 2>learning,</v>

52
00:03:24.010 --> 00:03:27.670
<v Speaker 2>learning to loan and recursive self </v>
<v Speaker 2>improvement,</v>

53
00:03:28.060 --> 00:03:32.440
<v Speaker 2>that is really the pinnacle of that </v>
<v Speaker 2>where you then not only you learn,</v>

54
00:03:32.870 --> 00:03:33.703
<v Speaker 2>um,</v>
<v Speaker 2>how to improve on that problem and on </v>

55
00:03:37.211 --> 00:03:40.210
<v Speaker 2>that,</v>
<v Speaker 2>but you also improve the way the machine</v>

56
00:03:40.220 --> 00:03:44.440
<v Speaker 2>improves and you also improve the way it</v>
<v Speaker 2>improves the way and improves itself.</v>

57
00:03:45.760 --> 00:03:46.593
<v Speaker 2>And that was my 1987 diploma thesis,</v>
<v Speaker 2>which was all about that hierarchy of </v>

58
00:03:52.120 --> 00:03:52.953
<v Speaker 2>metal rnrs that have no computational </v>
<v Speaker 2>limits except for the well known limits </v>

59
00:03:59.920 --> 00:04:04.210
<v Speaker 2>that Google identified in 1931 and a </v>
<v Speaker 2>four.</v>

60
00:04:04.211 --> 00:04:05.500
<v Speaker 2>The limits of physics</v>

61
00:04:06.500 --> 00:04:10.320
<v Speaker 1>in the recent years matter learning has </v>
<v Speaker 1>gained popularity in a,</v>

62
00:04:10.630 --> 00:04:11.463
<v Speaker 1>in a specific kind of form.</v>
<v Speaker 1>You've talked about how that's not </v>

63
00:04:14.151 --> 00:04:17.230
<v Speaker 1>really metal learning with,</v>
<v Speaker 1>with neural networks,</v>

64
00:04:17.260 --> 00:04:18.093
<v Speaker 1>that's more basic transfer learning.</v>
<v Speaker 1>Can you talk about the difference </v>

65
00:04:22.721 --> 00:04:23.554
<v Speaker 1>between the big general metal learning </v>
<v Speaker 1>and a more narrow sense of metal </v>

66
00:04:27.671 --> 00:04:30.730
<v Speaker 1>learning the way it's used today,</v>
<v Speaker 1>the waste talked about today.</v>

67
00:04:30.880 --> 00:04:31.450
<v Speaker 1>Let's take,</v>

68
00:04:31.450 --> 00:04:32.283
<v Speaker 2>what's the example of a deep neural </v>
<v Speaker 2>network that has a learn to classify </v>

69
00:04:35.710 --> 00:04:36.543
<v Speaker 2>images and maybe you have trained that </v>
<v Speaker 2>network on 100 different databases of </v>

70
00:04:43.061 --> 00:04:43.894
<v Speaker 2>images and now a new database comes </v>
<v Speaker 2>along and you want to quickly learn the </v>

71
00:04:50.471 --> 00:04:51.304
<v Speaker 2>new thing as well.</v>
<v Speaker 2>So when a simpler way of doing that as </v>

72
00:04:55.151 --> 00:04:55.984
<v Speaker 2>you take the network,</v>
<v Speaker 2>which already knows 100 types of </v>

73
00:05:00.850 --> 00:05:01.683
<v Speaker 2>databases and then you would just take </v>
<v Speaker 2>the top layer of that and you retrain </v>

74
00:05:07.451 --> 00:05:09.790
<v Speaker 2>that,</v>
<v Speaker 2>uh,</v>

75
00:05:09.820 --> 00:05:13.930
<v Speaker 2>using the new label data that you have </v>
<v Speaker 2>in the new image database.</v>

76
00:05:14.950 --> 00:05:19.390
<v Speaker 2>And then it turns out that it really,</v>
<v Speaker 2>really quickly kind of learn that to one</v>

77
00:05:19.391 --> 00:05:24.130
<v Speaker 2>shot basically,</v>
<v Speaker 2>because from the first 100 datasets,</v>

78
00:05:24.370 --> 00:05:25.203
<v Speaker 2>it already has learned so much about,</v>
<v Speaker 2>about computer vision that it can reuse </v>

79
00:05:28.691 --> 00:05:29.524
<v Speaker 2>that.</v>
<v Speaker 2>And that is then almost good enough to </v>

80
00:05:32.201 --> 00:05:36.940
<v Speaker 2>solve the new task except you need a </v>
<v Speaker 2>little bit of adjustment on the top.</v>

81
00:05:38.460 --> 00:05:42.370
<v Speaker 2>So that is transfer learning and it has </v>
<v Speaker 2>been done.</v>

82
00:05:42.371 --> 00:05:43.204
<v Speaker 2>And principal for many decades,</v>
<v Speaker 2>people have done similar things with </v>

83
00:05:45.961 --> 00:05:50.961
<v Speaker 2>decades met aligning.</v>
<v Speaker 2>True mental learning is about having the</v>

84
00:05:52.590 --> 00:05:53.423
<v Speaker 2>learning algorithm itself open to </v>
<v Speaker 2>introspection by the system that is </v>

85
00:05:59.661 --> 00:06:00.494
<v Speaker 2>using it and also open to modification </v>
<v Speaker 2>such that the lighting system has an </v>

86
00:06:06.980 --> 00:06:11.980
<v Speaker 2>opportunity to modify any part of the </v>
<v Speaker 2>learning algorithm and then evaluate the</v>

87
00:06:14.271 --> 00:06:15.104
<v Speaker 2>consequences of that modification and </v>
<v Speaker 2>then learn from that to create a better </v>

88
00:06:21.471 --> 00:06:22.304
<v Speaker 2>learning algorithm and so on.</v>
<v Speaker 2>Recursively so that's a very different </v>

89
00:06:27.610 --> 00:06:28.443
<v Speaker 2>animal where you are opening the space </v>
<v Speaker 2>off possible learning algorithms to the </v>

90
00:06:34.061 --> 00:06:35.380
<v Speaker 2>learning system itself.</v>

91
00:06:35.530 --> 00:06:37.060
<v Speaker 1>Right.</v>
<v Speaker 1>So you've,</v>

92
00:06:37.061 --> 00:06:37.894
<v Speaker 1>uh,</v>
<v Speaker 1>like in the 2004 paper he described a </v>

93
00:06:40.181 --> 00:06:43.540
<v Speaker 1>gate on machines and programs that were </v>
<v Speaker 1>right themselves.</v>

94
00:06:43.600 --> 00:06:44.433
<v Speaker 1>Yeah.</v>
<v Speaker 1>Right.</v>

95
00:06:44.500 --> 00:06:47.500
<v Speaker 1>Philosophically,</v>
<v Speaker 1>and even in your paper mathematically,</v>

96
00:06:47.501 --> 00:06:48.334
<v Speaker 1>these are really compelling ideas.</v>
<v Speaker 1>But practically do you see the self </v>

97
00:06:54.060 --> 00:06:54.893
<v Speaker 1>referential programs being successful in</v>
<v Speaker 1>the near term to having an impact where </v>

98
00:07:00.030 --> 00:07:05.030
<v Speaker 1>sort of a demonstrates to the world that</v>
<v Speaker 1>this direction is a</v>

99
00:07:06.240 --> 00:07:08.160
<v Speaker 2>is a good one to pursue in the near </v>
<v Speaker 2>term?</v>

100
00:07:08.670 --> 00:07:09.503
<v Speaker 2>Yes.</v>
<v Speaker 2>We had these two different types of </v>

101
00:07:12.050 --> 00:07:15.470
<v Speaker 2>fundamental research,</v>
<v Speaker 2>how to build a universal problem solver.</v>

102
00:07:15.800 --> 00:07:16.633
<v Speaker 2>One basically exploiting poof such and </v>
<v Speaker 2>things like that that you need to come </v>

103
00:07:24.791 --> 00:07:29.791
<v Speaker 2>up with a some topically optimal </v>
<v Speaker 2>theoretically optimal self improvers and</v>

104
00:07:31.960 --> 00:07:36.960
<v Speaker 2>problem solvers.</v>
<v Speaker 2>However one has to admit that.</v>

105
00:07:37.790 --> 00:07:42.790
<v Speaker 2>So it was this proof.</v>
<v Speaker 2>So ads comes in an additive constant,</v>

106
00:07:43.630 --> 00:07:48.630
<v Speaker 2>an overhead and additive overhead that </v>
<v Speaker 2>vantages in comparison to uh,</v>

107
00:07:52.420 --> 00:07:54.700
<v Speaker 2>what you have to do to solve large </v>
<v Speaker 2>problems.</v>

108
00:07:55.180 --> 00:07:56.013
<v Speaker 2>However,</v>
<v Speaker 2>for many of the small problems that we </v>

109
00:07:58.391 --> 00:08:03.220
<v Speaker 2>want to solve in our everyday life,</v>
<v Speaker 2>we cannot ignore this constant overhead.</v>

110
00:08:03.460 --> 00:08:07.840
<v Speaker 2>And that's why we also have been doing </v>
<v Speaker 2>other things,</v>

111
00:08:08.110 --> 00:08:12.160
<v Speaker 2>non universal things such as recurrent </v>
<v Speaker 2>neural networks,</v>

112
00:08:12.161 --> 00:08:17.161
<v Speaker 2>which are trained by gradient descent </v>
<v Speaker 2>and local search techniques which aren't</v>

113
00:08:17.711 --> 00:08:21.130
<v Speaker 2>universally adored,</v>
<v Speaker 2>which aren't provably optimal at all.</v>

114
00:08:21.280 --> 00:08:25.960
<v Speaker 2>Like the other stuff that we did but </v>
<v Speaker 2>which are much more practical as long as</v>

115
00:08:25.961 --> 00:08:30.961
<v Speaker 2>we only want to solve the small problems</v>
<v Speaker 2>that we are typically trying to solve in</v>

116
00:08:33.520 --> 00:08:35.420
<v Speaker 2>this environment here.</v>
<v Speaker 2>Yeah,</v>

117
00:08:35.620 --> 00:08:36.453
<v Speaker 2>so it's a universal problem solvers and </v>
<v Speaker 2>like the Google machine but also marcus </v>

118
00:08:40.061 --> 00:08:40.894
<v Speaker 2>hooters,</v>
<v Speaker 2>fastest way of solving all possible </v>

119
00:08:43.301 --> 00:08:44.134
<v Speaker 2>problems,</v>
<v Speaker 2>which he developed around 2002 in my </v>

120
00:08:47.471 --> 00:08:48.304
<v Speaker 2>lab.</v>
<v Speaker 2>They are associated with these constant </v>

121
00:08:51.761 --> 00:08:52.594
<v Speaker 2>overheads for proof search,</v>
<v Speaker 2>which guarantees that the that you're </v>

122
00:08:55.441 --> 00:08:58.320
<v Speaker 2>doing is optimum,</v>
<v Speaker 2>for example,</v>

123
00:08:59.090 --> 00:09:04.090
<v Speaker 2>that is this fastest way off solving all</v>
<v Speaker 2>problems with a computable solution,</v>

124
00:09:05.310 --> 00:09:09.020
<v Speaker 2>which is due to a macros macro Ceuta and</v>
<v Speaker 2>uh,</v>

125
00:09:09.810 --> 00:09:12.250
<v Speaker 2>um,</v>
<v Speaker 2>to explain what's going on there.</v>

126
00:09:12.251 --> 00:09:17.251
<v Speaker 2>Let's take traveling salesmen problems </v>
<v Speaker 2>with traveling salesman problems.</v>

127
00:09:17.400 --> 00:09:18.233
<v Speaker 2>You have a number of cities in cities </v>
<v Speaker 2>and you try to find the shortest path </v>

128
00:09:23.670 --> 00:09:27.670
<v Speaker 2>through all these cities without </v>
<v Speaker 2>visiting any city twice.</v>

129
00:09:29.470 --> 00:09:34.470
<v Speaker 2>And nobody knows the fastest way of </v>
<v Speaker 2>solving traveling salesman problems.</v>

130
00:09:35.380 --> 00:09:36.213
<v Speaker 2>Tsp is,</v>
<v Speaker 2>but let's assume there is a method of </v>

131
00:09:40.661 --> 00:09:41.494
<v Speaker 2>solving them within end to the five </v>
<v Speaker 2>operations where n is the number of </v>

132
00:09:47.861 --> 00:09:48.694
<v Speaker 2>cities.</v>
<v Speaker 2>Then the universal method of Macros is </v>

133
00:09:54.761 --> 00:09:58.570
<v Speaker 2>going to solve the same traveling </v>
<v Speaker 2>salesman problem.</v>

134
00:09:58.571 --> 00:09:59.404
<v Speaker 2>Also within enter the five steps plus a </v>
<v Speaker 2>couple of one plus a constant number of </v>

135
00:10:05.561 --> 00:10:09.000
<v Speaker 2>steps that you need for the proofs </v>
<v Speaker 2>archer,</v>

136
00:10:09.250 --> 00:10:10.083
<v Speaker 2>which you need to show that this </v>
<v Speaker 2>particular class of problems that </v>

137
00:10:14.831 --> 00:10:18.250
<v Speaker 2>traveling salesman,</v>
<v Speaker 2>salesman problems can be solved within a</v>

138
00:10:18.251 --> 00:10:20.500
<v Speaker 2>certain time bound,</v>
<v Speaker 2>um,</v>

139
00:10:20.530 --> 00:10:23.680
<v Speaker 2>within Oda into the five steps </v>
<v Speaker 2>basically.</v>

140
00:10:24.400 --> 00:10:25.233
<v Speaker 2>And there's a additive constant doesn't </v>
<v Speaker 2>care for and which means as end is </v>

141
00:10:29.681 --> 00:10:34.240
<v Speaker 2>getting larger and larger as you have </v>
<v Speaker 2>more and more cities,</v>

142
00:10:34.900 --> 00:10:35.733
<v Speaker 2>the constant overhead pales in </v>
<v Speaker 2>comparison and that means that almost </v>

143
00:10:40.241 --> 00:10:45.241
<v Speaker 2>are large problems are solved in the </v>
<v Speaker 2>best possible way of a today.</v>

144
00:10:46.630 --> 00:10:49.720
<v Speaker 2>We already have a universal problem </v>
<v Speaker 2>solver like that.</v>

145
00:10:50.590 --> 00:10:54.370
<v Speaker 2>However,</v>
<v Speaker 2>it's not practical because the overhead,</v>

146
00:10:54.610 --> 00:10:55.443
<v Speaker 2>the constant overhead is so large that </v>
<v Speaker 2>for the smaller kinds of problems that </v>

147
00:11:00.490 --> 00:11:03.670
<v Speaker 2>you want to solve in this level </v>
<v Speaker 2>biosphere,</v>

148
00:11:04.680 --> 00:11:06.270
<v Speaker 1>by the way,</v>
<v Speaker 1>when you say small,</v>

149
00:11:06.480 --> 00:11:07.313
<v Speaker 1>you're talking about things that fall </v>
<v Speaker 1>within the constraints of our </v>

150
00:11:09.721 --> 00:11:13.110
<v Speaker 1>computational systems that they can,</v>
<v Speaker 1>they can seem quite large joints,</v>

151
00:11:13.111 --> 00:11:13.944
<v Speaker 1>mere humans,</v>

152
00:11:14.210 --> 00:11:14.961
<v Speaker 2>right?</v>
<v Speaker 2>That's right.</v>

153
00:11:14.961 --> 00:11:15.794
<v Speaker 2>Yeah.</v>
<v Speaker 2>So they seem large and even unsolvable </v>

154
00:11:19.100 --> 00:11:19.933
<v Speaker 2>in a practical sense today,</v>
<v Speaker 2>but they are still small compared to </v>

155
00:11:23.570 --> 00:11:24.403
<v Speaker 2>almost all problems because almost all </v>
<v Speaker 2>problems are large problems which are </v>

156
00:11:29.030 --> 00:11:30.830
<v Speaker 2>much larger than any constant.</v>

157
00:11:32.040 --> 00:11:32.873
<v Speaker 1>Do you find it useful as a person who is</v>
<v Speaker 1>dreamed of creating a general learning </v>

158
00:11:37.621 --> 00:11:40.680
<v Speaker 1>system,</v>
<v Speaker 1>has worked on creating one is done a lot</v>

159
00:11:40.681 --> 00:11:43.470
<v Speaker 1>of interesting ideas there to think </v>
<v Speaker 1>about</v>

160
00:11:44.190 --> 00:11:45.023
<v Speaker 2>p</v>

161
00:11:45.110 --> 00:11:45.943
<v Speaker 1>versus np,</v>
<v Speaker 1>this a formalization of how hard </v>

162
00:11:49.701 --> 00:11:50.534
<v Speaker 1>problems are,</v>
<v Speaker 1>how they scale this kind of case </v>

163
00:11:53.621 --> 00:11:54.454
<v Speaker 1>analysis type of thinking.</v>
<v Speaker 1>Do you find that useful or is it only </v>

164
00:11:57.701 --> 00:12:02.701
<v Speaker 1>just a mathematical,</v>
<v Speaker 1>it's a set of mathematical techniques to</v>

165
00:12:02.801 --> 00:12:05.080
<v Speaker 1>give you intuition about what's good and</v>
<v Speaker 1>bad.</v>

166
00:12:05.210 --> 00:12:07.760
<v Speaker 2>Hmm.</v>
<v Speaker 2>So p versus NP,</v>

167
00:12:07.790 --> 00:12:12.740
<v Speaker 2>that's super interesting from a </v>
<v Speaker 2>theoretical point of view and in fact as</v>

168
00:12:12.741 --> 00:12:13.574
<v Speaker 2>you thinking about that problem,</v>
<v Speaker 2>you can also get inspiration for better </v>

169
00:12:18.380 --> 00:12:20.630
<v Speaker 2>practical problems.</v>
<v Speaker 2>All of us,</v>

170
00:12:21.340 --> 00:12:22.173
<v Speaker 2>on the other hand,</v>
<v Speaker 2>we have to admit that at the moment as </v>

171
00:12:24.701 --> 00:12:29.701
<v Speaker 2>the best practical problems,</v>
<v Speaker 2>all of us for all kinds of problems that</v>

172
00:12:30.321 --> 00:12:33.380
<v Speaker 2>we are now solving through what is </v>
<v Speaker 2>called ai at the moment.</v>

173
00:12:35.100 --> 00:12:35.933
<v Speaker 2>No,</v>
<v Speaker 2>not the kind that is inspired by these </v>

174
00:12:37.441 --> 00:12:38.220
<v Speaker 2>questions.</v>
<v Speaker 2>Yeah,</v>

175
00:12:38.220 --> 00:12:39.200
<v Speaker 2>no,</v>
<v Speaker 2>they have,</v>

176
00:12:39.201 --> 00:12:40.870
<v Speaker 2>you are using,</v>
<v Speaker 2>um,</v>

177
00:12:41.350 --> 00:12:44.620
<v Speaker 2>general purpose computer such as </v>
<v Speaker 2>recurrent neural networks,</v>

178
00:12:44.830 --> 00:12:49.050
<v Speaker 2>but we have a such technique which is </v>
<v Speaker 2>just local search,</v>

179
00:12:49.051 --> 00:12:49.884
<v Speaker 2>great in descend to try to find a </v>
<v Speaker 2>program that is running on the </v>

180
00:12:52.950 --> 00:12:53.783
<v Speaker 2>[inaudible] such that it can solve some </v>
<v Speaker 2>interesting problems such as speech </v>

181
00:12:59.431 --> 00:13:02.850
<v Speaker 2>recognition or machine translation and </v>
<v Speaker 2>something like that.</v>

182
00:13:03.360 --> 00:13:04.193
<v Speaker 2>And there is very little theory behind </v>
<v Speaker 2>the best solutions that we have at the </v>

183
00:13:09.181 --> 00:13:09.750
<v Speaker 2>moment</v>

184
00:13:09.750 --> 00:13:12.670
<v Speaker 1>that can do that.</v>
<v Speaker 1>Do you think that needs to change?</v>

185
00:13:12.671 --> 00:13:14.970
<v Speaker 1>Do you think that will change or can we </v>
<v Speaker 1>go,</v>

186
00:13:15.150 --> 00:13:19.440
<v Speaker 1>can we create a general intelligence </v>
<v Speaker 1>systems without ever really proving that</v>

187
00:13:19.441 --> 00:13:23.670
<v Speaker 1>that system was intelligent and some </v>
<v Speaker 1>kind of mathematical way solving machine</v>

188
00:13:23.671 --> 00:13:24.504
<v Speaker 1>translation perfectly or something like </v>
<v Speaker 1>that within some kind of syntactic </v>

189
00:13:27.700 --> 00:13:31.770
<v Speaker 1>definition of a language?</v>
<v Speaker 1>Or can we just be super impressed by the</v>

190
00:13:31.771 --> 00:13:34.560
<v Speaker 1>thing working extremely well and that's </v>
<v Speaker 1>sufficient?</v>

191
00:13:35.090 --> 00:13:39.050
<v Speaker 2>There's an old saying and I don't know </v>
<v Speaker 2>who brought it up first,</v>

192
00:13:39.350 --> 00:13:44.350
<v Speaker 2>which says there's nothing more </v>
<v Speaker 2>practical than a good theory and um,</v>

193
00:13:46.320 --> 00:13:50.330
<v Speaker 2>yeah,</v>
<v Speaker 2>and a good theory off problem solving.</v>

194
00:13:52.380 --> 00:13:52.800
<v Speaker 3>Okay.</v>

195
00:13:52.800 --> 00:13:57.800
<v Speaker 2>Under limited resources like he in this </v>
<v Speaker 2>universe or on this little planet has to</v>

196
00:13:58.891 --> 00:14:00.990
<v Speaker 2>take into account these limited </v>
<v Speaker 2>resources.</v>

197
00:14:01.830 --> 00:14:02.663
<v Speaker 2>And so probably that is locking a theory</v>
<v Speaker 2>which is related to what we already </v>

198
00:14:10.361 --> 00:14:11.194
<v Speaker 2>have.</v>
<v Speaker 2>Fees isn't tightly optimal problems </v>

199
00:14:13.570 --> 00:14:14.950
<v Speaker 2>almost,</v>
<v Speaker 2>which,</v>

200
00:14:15.340 --> 00:14:16.173
<v Speaker 2>which tells us what we need.</v>
<v Speaker 2>In addition to that to come up with a </v>

201
00:14:19.331 --> 00:14:20.164
<v Speaker 2>practically optimal problems over psalm,</v>
<v Speaker 2>I believe we will have something like </v>

202
00:14:26.081 --> 00:14:31.030
<v Speaker 2>that and maybe just a few little tiny </v>
<v Speaker 2>twists unnecessary to,</v>

203
00:14:31.960 --> 00:14:35.710
<v Speaker 2>to change what we already have to come </v>
<v Speaker 2>up with that as well.</v>

204
00:14:36.340 --> 00:14:37.173
<v Speaker 2>As long as we don't have that,</v>
<v Speaker 2>we admit that we are taking sub optimal </v>

205
00:14:41.981 --> 00:14:46.981
<v Speaker 2>ways and recurrent neural network isn't </v>
<v Speaker 2>long short term memory for equipped with</v>

206
00:14:48.831 --> 00:14:53.570
<v Speaker 2>local search techniques.</v>
<v Speaker 2>And we are happy that it works better as</v>

207
00:14:53.571 --> 00:14:56.370
<v Speaker 2>in any competing methods.</v>
<v Speaker 2>But um,</v>

208
00:14:56.600 --> 00:15:00.140
<v Speaker 2>that doesn't mean that we would be,</v>
<v Speaker 2>think we had done.</v>

209
00:15:00.870 --> 00:15:04.320
<v Speaker 1>You've said that an Agi system will </v>
<v Speaker 1>ultimately be a simple one,</v>

210
00:15:04.570 --> 00:15:07.620
<v Speaker 1>a general intelligence system,</v>
<v Speaker 1>and ultimately be as simple one,</v>

211
00:15:08.010 --> 00:15:11.430
<v Speaker 1>maybe a pseudocode have a few lines,</v>
<v Speaker 1>we'll be able to describe it.</v>

212
00:15:11.820 --> 00:15:16.410
<v Speaker 1>Can you talk through your intuition </v>
<v Speaker 1>behind this idea,</v>

213
00:15:16.800 --> 00:15:21.800
<v Speaker 1>why you feel that us as core </v>
<v Speaker 1>intelligence is a simple</v>

214
00:15:24.810 --> 00:15:29.810
<v Speaker 2>algorithm experience tells us that the </v>
<v Speaker 2>stuff that works best as really simple.</v>

215
00:15:33.150 --> 00:15:38.150
<v Speaker 2>So the [inaudible] ugly optimal ways of </v>
<v Speaker 2>solving problems if you look at them and</v>

216
00:15:38.971 --> 00:15:41.010
<v Speaker 2>just a few lines of code,</v>
<v Speaker 2>it's really true,</v>

217
00:15:41.850 --> 00:15:45.210
<v Speaker 2>although they ask these amazing property</v>
<v Speaker 2>is just a few lines of code.</v>

218
00:15:45.810 --> 00:15:46.643
<v Speaker 2>Then the most promising and most useful </v>
<v Speaker 2>practical things maybe don't have this </v>

219
00:15:54.901 --> 00:15:57.600
<v Speaker 2>proof of optimality associated with </v>
<v Speaker 2>them.</v>

220
00:15:57.810 --> 00:16:00.000
<v Speaker 2>However they are.</v>
<v Speaker 2>So just a few lines of code.</v>

221
00:16:00.870 --> 00:16:01.703
<v Speaker 2>The most successful and recurrent neural</v>
<v Speaker 2>networks you can write them down and </v>

222
00:16:06.421 --> 00:16:07.950
<v Speaker 2>five lions up pseudo code.</v>

223
00:16:08.290 --> 00:16:10.870
<v Speaker 1>That's a beautiful,</v>
<v Speaker 1>almost poetic idea.</v>

224
00:16:10.930 --> 00:16:13.510
<v Speaker 1>But what you're</v>

225
00:16:14.010 --> 00:16:14.380
<v Speaker 2>okay</v>

226
00:16:14.380 --> 00:16:15.213
<v Speaker 1>describing there is this,</v>
<v Speaker 1>the lines of pseudocode are sitting on </v>

227
00:16:17.921 --> 00:16:21.280
<v Speaker 1>top of layers and layers of abstractions</v>
<v Speaker 1>in a sense.</v>

228
00:16:22.270 --> 00:16:27.270
<v Speaker 1>So you're saying at the very top,</v>
<v Speaker 1>it'll be a beautifully written sort of a</v>

229
00:16:30.070 --> 00:16:30.903
<v Speaker 1>algorithm,</v>
<v Speaker 1>but do you think that there's many </v>

230
00:16:33.101 --> 00:16:36.880
<v Speaker 1>layers of abstraction we have to first </v>
<v Speaker 1>learn to construct?</v>

231
00:16:37.470 --> 00:16:40.930
<v Speaker 2>Of course we are building on all these </v>
<v Speaker 2>um,</v>

232
00:16:41.340 --> 00:16:45.330
<v Speaker 2>great obstructions that people have </v>
<v Speaker 2>invented over the millennia.</v>

233
00:16:46.020 --> 00:16:46.853
<v Speaker 2>Such as Matrix multiplications and roll </v>
<v Speaker 2>numbers and basic arithmetic x and </v>

234
00:16:56.370 --> 00:16:57.203
<v Speaker 2>Calculus and durations of um,</v>
<v Speaker 2>error functions and derivatives off </v>

235
00:17:02.551 --> 00:17:07.551
<v Speaker 2>error functions and stuff like that.</v>
<v Speaker 2>So without that language,</v>

236
00:17:08.100 --> 00:17:13.100
<v Speaker 2>that greatly simplifies our way of </v>
<v Speaker 2>thinking about these problems.</v>

237
00:17:13.860 --> 00:17:15.780
<v Speaker 2>We couldn't do anything.</v>
<v Speaker 2>So in that sentence,</v>

238
00:17:15.781 --> 00:17:16.614
<v Speaker 2>as always,</v>
<v Speaker 2>we are standing on the shoulders of the </v>

239
00:17:18.901 --> 00:17:21.920
<v Speaker 2>giants who in the past,</v>
<v Speaker 2>um,</v>

240
00:17:22.210 --> 00:17:25.470
<v Speaker 2>simply fired the problem off problem </v>
<v Speaker 2>solving.</v>

241
00:17:25.500 --> 00:17:29.130
<v Speaker 2>So much that now we have a chance to do </v>
<v Speaker 2>the final step</v>

242
00:17:29.900 --> 00:17:34.380
<v Speaker 1>to the final step will be as simple one.</v>
<v Speaker 1>If we,</v>

243
00:17:34.420 --> 00:17:35.253
<v Speaker 1>if we take a step back through all of </v>
<v Speaker 1>human civilization and just the </v>

244
00:17:37.081 --> 00:17:39.000
<v Speaker 1>university chair,</v>
<v Speaker 1>uh,</v>

245
00:17:40.000 --> 00:17:40.833
<v Speaker 1>how do you think about evolution and </v>
<v Speaker 1>what if creating a universe is required </v>

246
00:17:45.401 --> 00:17:50.401
<v Speaker 1>to achieve this final step?</v>
<v Speaker 1>What if going through very painful,</v>

247
00:17:50.970 --> 00:17:51.803
<v Speaker 1>an inefficient process of evolution is </v>
<v Speaker 1>needed to come up with this set of </v>

248
00:17:55.291 --> 00:17:57.360
<v Speaker 1>abstractions that ultimately to </v>
<v Speaker 1>intelligence?</v>

249
00:17:57.780 --> 00:17:58.613
<v Speaker 1>Do you think</v>

250
00:17:59.030 --> 00:18:02.330
<v Speaker 4>there's a shortcut or do you think we </v>
<v Speaker 4>have to create</v>

251
00:18:03.360 --> 00:18:04.193
<v Speaker 1>something like our universe in order to </v>
<v Speaker 1>create something like human level </v>

252
00:18:06.991 --> 00:18:07.824
<v Speaker 1>intelligence?</v>

253
00:18:07.880 --> 00:18:09.940
<v Speaker 2>Mm.</v>
<v Speaker 2>So far,</v>

254
00:18:09.941 --> 00:18:14.941
<v Speaker 2>the only example we have is this one is </v>
<v Speaker 2>this universe in which we live.</v>

255
00:18:15.161 --> 00:18:20.161
<v Speaker 2>You better,</v>
<v Speaker 2>maybe not,</v>

256
00:18:22.100 --> 00:18:23.320
<v Speaker 2>but um,</v>
<v Speaker 2>yeah,</v>

257
00:18:23.390 --> 00:18:24.960
<v Speaker 2>part of this whole process,</v>
<v Speaker 2>right?</v>

258
00:18:27.430 --> 00:18:28.263
<v Speaker 2>Apparently.</v>
<v Speaker 2>So it might be the case that the code </v>

259
00:18:30.851 --> 00:18:31.684
<v Speaker 2>that runs the universe Israeli really </v>
<v Speaker 2>simple everything points to that </v>

260
00:18:35.891 --> 00:18:40.891
<v Speaker 2>possibility because gravity and other </v>
<v Speaker 2>basic forces are really simple laws that</v>

261
00:18:42.701 --> 00:18:46.300
<v Speaker 2>can be easily described also in just a </v>
<v Speaker 2>few lines of code basically.</v>

262
00:18:47.080 --> 00:18:48.850
<v Speaker 2>And uh,</v>
<v Speaker 2>and then,</v>

263
00:18:48.900 --> 00:18:49.733
<v Speaker 2>uh,</v>
<v Speaker 2>the use of the events that the </v>

264
00:18:53.291 --> 00:18:56.380
<v Speaker 2>apparently random events in the history </v>
<v Speaker 2>of the universe,</v>

265
00:18:56.530 --> 00:19:00.370
<v Speaker 2>which as far as we know at the moment </v>
<v Speaker 2>don't have a compact code,</v>

266
00:19:00.700 --> 00:19:01.533
<v Speaker 2>but who knows,</v>
<v Speaker 2>maybe somebody and the near future is </v>

267
00:19:03.341 --> 00:19:06.790
<v Speaker 2>going to figure it out.</v>
<v Speaker 2>Pseudo random generator,</v>

268
00:19:06.791 --> 00:19:08.200
<v Speaker 2>which is,</v>
<v Speaker 2>um,</v>

269
00:19:08.710 --> 00:19:13.030
<v Speaker 2>which is computing,</v>
<v Speaker 2>whether it's the measurement of that,</v>

270
00:19:13.060 --> 00:19:14.620
<v Speaker 2>um,</v>
<v Speaker 2>spin up and down.</v>

271
00:19:14.800 --> 00:19:18.310
<v Speaker 2>The thing here is I'm going to be </v>
<v Speaker 2>positive or negative</v>

272
00:19:18.380 --> 00:19:19.213
<v Speaker 1>underlying quantum mechanics.</v>
<v Speaker 1>Do you ultimately think quantum </v>

273
00:19:22.161 --> 00:19:26.630
<v Speaker 1>mechanics is a pseudo random number </v>
<v Speaker 1>generator all deterministic?</v>

274
00:19:26.930 --> 00:19:28.550
<v Speaker 1>There's no randomness scenario.</v>
<v Speaker 1>Our universe</v>

275
00:19:30.430 --> 00:19:32.600
<v Speaker 4>does God play dice?</v>
<v Speaker 4>Okay.</v>

276
00:19:33.390 --> 00:19:35.950
<v Speaker 2>A couple of years ago on a famous </v>
<v Speaker 2>physicist,</v>

277
00:19:37.060 --> 00:19:39.460
<v Speaker 2>quantum physicists,</v>
<v Speaker 2>Anton Zeilinger,</v>

278
00:19:39.490 --> 00:19:40.323
<v Speaker 2>he wrote an essay in nature and it </v>
<v Speaker 2>started more or less like that one </v>

279
00:19:47.630 --> 00:19:49.730
<v Speaker 2>aussie fundamental insights,</v>
<v Speaker 2>ah,</v>

280
00:19:49.760 --> 00:19:50.593
<v Speaker 2>see offset 20th century was that the </v>
<v Speaker 2>universe is fundamentally random on the </v>

281
00:20:00.441 --> 00:20:01.274
<v Speaker 2>quantum level.</v>

282
00:20:02.600 --> 00:20:02.930
<v Speaker 5>Yeah.</v>

283
00:20:02.930 --> 00:20:07.590
<v Speaker 2>And that whenever you measure spin up or</v>
<v Speaker 2>down or something like that,</v>

284
00:20:08.290 --> 00:20:11.100
<v Speaker 2>a new bit of information enters the </v>
<v Speaker 2>history.</v>

285
00:20:11.101 --> 00:20:16.020
<v Speaker 2>I'll see you on it.</v>
<v Speaker 2>And while I was reading that,</v>

286
00:20:16.021 --> 00:20:16.854
<v Speaker 2>I was honored the typing,</v>
<v Speaker 2>the responds and they had to publish it </v>

287
00:20:20.401 --> 00:20:24.270
<v Speaker 2>because it was right that there is no </v>
<v Speaker 2>evidence,</v>

288
00:20:24.271 --> 00:20:29.271
<v Speaker 2>no physical evidence for that.</v>
<v Speaker 2>So there is an alternative explanation,</v>

289
00:20:30.450 --> 00:20:31.283
<v Speaker 2>but everything that'd be considered </v>
<v Speaker 2>around them is actually the random such </v>

290
00:20:36.121 --> 00:20:40.980
<v Speaker 2>as the decimal expansion of Pi 3.141</v>
<v Speaker 2>and so on,</v>

291
00:20:41.730 --> 00:20:42.870
<v Speaker 2>which looks around,</v>
<v Speaker 2>Huh,</v>

292
00:20:43.080 --> 00:20:43.913
<v Speaker 2>but isn't.</v>

293
00:20:44.400 --> 00:20:49.120
<v Speaker 2>So Pi is interesting because every three</v>
<v Speaker 2>digit sequence,</v>

294
00:20:49.900 --> 00:20:50.733
<v Speaker 2>every sequence off three digits,</v>
<v Speaker 2>a p is roughly one in a thousand times </v>

295
00:20:55.990 --> 00:21:00.990
<v Speaker 2>and every five digit sequence a p has </v>
<v Speaker 2>roughly one in 10,000</v>

296
00:21:02.621 --> 00:21:03.700
<v Speaker 2>times.</v>
<v Speaker 2>What do you,</v>

297
00:21:03.710 --> 00:21:06.850
<v Speaker 2>what you would expect if it was run </v>
<v Speaker 2>random.</v>

298
00:21:07.000 --> 00:21:10.720
<v Speaker 2>But that's a very short algorithm,</v>
<v Speaker 2>a short program that computers,</v>

299
00:21:10.721 --> 00:21:13.420
<v Speaker 2>all of that.</v>
<v Speaker 2>So it's extremely compressible.</v>

300
00:21:13.870 --> 00:21:14.703
<v Speaker 2>And who knows,</v>
<v Speaker 2>maybe tomorrow somebody and some Grad </v>

301
00:21:16.421 --> 00:21:20.800
<v Speaker 2>student at som goes back over all these </v>
<v Speaker 2>data points,</v>

302
00:21:20.920 --> 00:21:23.440
<v Speaker 2>better decay and whatever and figures </v>
<v Speaker 2>out,</v>

303
00:21:23.470 --> 00:21:24.303
<v Speaker 2>oh,</v>
<v Speaker 2>it's the second billion digits of Pi or </v>

304
00:21:27.341 --> 00:21:28.174
<v Speaker 2>something like that.</v>
<v Speaker 2>We don't have any fundamental reason at </v>

305
00:21:31.001 --> 00:21:31.834
<v Speaker 2>the moment to believe that this is truly</v>
<v Speaker 2>random and not just a deterministic </v>

306
00:21:37.871 --> 00:21:41.110
<v Speaker 2>video game.</v>
<v Speaker 2>If it was a deterministic video game,</v>

307
00:21:41.111 --> 00:21:45.010
<v Speaker 2>it would be much more beautiful because </v>
<v Speaker 2>beauty,</v>

308
00:21:45.110 --> 00:21:45.943
<v Speaker 2>simplicity and many of the basic laws of</v>
<v Speaker 2>the universe like gravity and the other </v>

309
00:21:52.481 --> 00:21:54.130
<v Speaker 2>basic forces are very simple.</v>

310
00:21:54.130 --> 00:21:59.130
<v Speaker 2>So very short programs can explain what </v>
<v Speaker 2>these are doing and um,</v>

311
00:22:00.550 --> 00:22:04.540
<v Speaker 2>and it would be awful and ugly.</v>
<v Speaker 2>The universe would be ugly.</v>

312
00:22:04.541 --> 00:22:08.140
<v Speaker 2>The history of the universe would be </v>
<v Speaker 2>ugly if for the extra things,</v>

313
00:22:08.141 --> 00:22:12.700
<v Speaker 2>the random seemingly random data points </v>
<v Speaker 2>that we get all the time,</v>

314
00:22:13.840 --> 00:22:18.840
<v Speaker 2>that we really need a huge number of </v>
<v Speaker 2>extra bits to strive all these,</v>

315
00:22:19.960 --> 00:22:23.170
<v Speaker 2>um,</v>
<v Speaker 2>these extra bits of information.</v>

316
00:22:24.790 --> 00:22:29.790
<v Speaker 2>So as long as we don't have evidence </v>
<v Speaker 2>that that is no short programs,</v>

317
00:22:29.801 --> 00:22:33.790
<v Speaker 2>that computes the entire history of the </v>
<v Speaker 2>entire universe,</v>

318
00:22:35.320 --> 00:22:40.320
<v Speaker 2>we are as scientists compelled to look </v>
<v Speaker 2>further for that shortest program.</v>

319
00:22:43.730 --> 00:22:46.910
<v Speaker 6>Your intuition says there exists a </v>
<v Speaker 6>shortage,</v>

320
00:22:46.970 --> 00:22:51.320
<v Speaker 6>a program that can backtrack to the,</v>
<v Speaker 6>to the creation of the universe,</v>

321
00:22:52.550 --> 00:22:54.590
<v Speaker 6>the shortest path to the creation.</v>
<v Speaker 6>Yes.</v>

322
00:22:54.870 --> 00:22:55.703
<v Speaker 2>Including all the um,</v>
<v Speaker 2>entanglement things and all the spin up </v>

323
00:23:00.541 --> 00:23:05.541
<v Speaker 2>and down measurements that have been </v>
<v Speaker 2>taken place,</v>

324
00:23:05.700 --> 00:23:09.840
<v Speaker 2>um,</v>
<v Speaker 2>since 13.8</v>

325
00:23:09.841 --> 00:23:10.850
<v Speaker 2>billion years ago.</v>
<v Speaker 2>And so,</v>

326
00:23:11.370 --> 00:23:12.203
<v Speaker 2>yeah,</v>
<v Speaker 2>so we don't have a proof that it is a </v>

327
00:23:15.300 --> 00:23:16.133
<v Speaker 2>random,</v>
<v Speaker 2>we don't have a proof of that it is </v>

328
00:23:18.840 --> 00:23:22.350
<v Speaker 2>compressible to a short program.</v>
<v Speaker 2>But as long as we don't have that fruit,</v>

329
00:23:22.380 --> 00:23:27.360
<v Speaker 2>we are obliged as scientists to keep </v>
<v Speaker 2>looking for that simple explanation.</v>

330
00:23:27.680 --> 00:23:28.513
<v Speaker 6>Absolutely.</v>
<v Speaker 6>So you said simplicity is beautiful or </v>

331
00:23:30.321 --> 00:23:32.660
<v Speaker 6>beauties simple.</v>
<v Speaker 6>Either one works,</v>

332
00:23:33.260 --> 00:23:36.920
<v Speaker 6>but you also work on curiosity,</v>
<v Speaker 6>discovery,</v>

333
00:23:37.600 --> 00:23:41.300
<v Speaker 6>you know,</v>
<v Speaker 6>the romantic notion of randomness,</v>

334
00:23:41.690 --> 00:23:43.310
<v Speaker 6>of serendipity,</v>
<v Speaker 6>of,</v>

335
00:23:43.820 --> 00:23:44.840
<v Speaker 6>of,</v>
<v Speaker 6>um,</v>

336
00:23:45.050 --> 00:23:46.280
<v Speaker 6>being surprised</v>

337
00:23:46.340 --> 00:23:51.340
<v Speaker 2>by things that are about you,</v>
<v Speaker 2>kind of in our poetic notion of reality.</v>

338
00:23:53.480 --> 00:23:58.480
<v Speaker 2>We think as humans require randomness.</v>
<v Speaker 2>So you don't find randomness beautiful.</v>

339
00:23:58.930 --> 00:24:03.260
<v Speaker 2>You,</v>
<v Speaker 2>you s you find simple determinism.</v>

340
00:24:03.530 --> 00:24:05.360
<v Speaker 2>Beautiful.</v>
<v Speaker 2>Yeah.</v>

341
00:24:06.890 --> 00:24:08.240
<v Speaker 2>Okay.</v>
<v Speaker 2>So why,</v>

342
00:24:08.630 --> 00:24:09.980
<v Speaker 2>why?</v>
<v Speaker 2>Because see,</v>

343
00:24:09.981 --> 00:24:10.814
<v Speaker 2>explanation becomes shorter.</v>
<v Speaker 2>A universe that is compressible to a </v>

344
00:24:17.761 --> 00:24:18.594
<v Speaker 2>short program as much more elegant and </v>
<v Speaker 2>much more beautiful than another one </v>

345
00:24:24.080 --> 00:24:29.080
<v Speaker 2>which needs an almost infinite number of</v>
<v Speaker 2>bits to be described as far as we know.</v>

346
00:24:31.100 --> 00:24:31.730
<v Speaker 5>Okay.</v>

347
00:24:31.730 --> 00:24:32.563
<v Speaker 2>Many things that are happening in this </v>
<v Speaker 2>universe are really simple in terms of </v>

348
00:24:35.600 --> 00:24:38.930
<v Speaker 2>um,</v>
<v Speaker 2>short programs does that compute gravity</v>

349
00:24:39.110 --> 00:24:39.943
<v Speaker 2>and uh,</v>
<v Speaker 2>see interaction between elementary </v>

350
00:24:42.201 --> 00:24:45.050
<v Speaker 2>particles and so on.</v>
<v Speaker 2>So all of that seems to be very,</v>

351
00:24:45.051 --> 00:24:45.884
<v Speaker 2>very simple.</v>
<v Speaker 2>Every electron seems to reuse the same </v>

352
00:24:49.370 --> 00:24:50.203
<v Speaker 2>sub program all the time as it is </v>
<v Speaker 2>interacting with other elementary </v>

353
00:24:53.811 --> 00:24:58.811
<v Speaker 2>particles.</v>
<v Speaker 2>If b now</v>

354
00:25:01.150 --> 00:25:01.650
<v Speaker 5>okay,</v>

355
00:25:01.650 --> 00:25:02.483
<v Speaker 2>required an extra article,</v>
<v Speaker 2>injecting new bits of information all </v>

356
00:25:07.151 --> 00:25:11.620
<v Speaker 2>the time for these extra things which </v>
<v Speaker 2>are commonly not understood,</v>

357
00:25:11.920 --> 00:25:16.920
<v Speaker 2>such as better tk,</v>
<v Speaker 2>then,</v>

358
00:25:19.120 --> 00:25:20.470
<v Speaker 2>um,</v>
<v Speaker 2>the whole</v>

359
00:25:22.120 --> 00:25:22.953
<v Speaker 2>description length,</v>
<v Speaker 2>awesome data that we can observe the </v>

360
00:25:26.170 --> 00:25:27.003
<v Speaker 2>history,</v>
<v Speaker 2>I'll say you'll never else would become </v>

361
00:25:29.790 --> 00:25:34.360
<v Speaker 2>a much longer and therefore uglier and </v>
<v Speaker 2>uglier.</v>

362
00:25:34.920 --> 00:25:37.830
<v Speaker 2>Again,</v>
<v Speaker 2>simplicities elegant and beautiful.</v>

363
00:25:38.580 --> 00:25:42.270
<v Speaker 2>All the history of science has a history</v>
<v Speaker 2>of compression progress.</v>

364
00:25:42.690 --> 00:25:43.640
<v Speaker 2>Yeah.</v>
<v Speaker 2>So you,</v>

365
00:25:43.790 --> 00:25:44.623
<v Speaker 2>you've described sort of as we build up </v>
<v Speaker 2>of distractions and you've talked about </v>

366
00:25:49.951 --> 00:25:54.570
<v Speaker 2>the idea of compression.</v>
<v Speaker 2>How do you see this,</v>

367
00:25:54.571 --> 00:25:57.630
<v Speaker 2>the history of science,</v>
<v Speaker 2>the history of humanity,</v>

368
00:25:57.631 --> 00:25:58.464
<v Speaker 2>our civilization and life on earth as </v>
<v Speaker 2>some kind of a path towards greater and </v>

369
00:26:02.851 --> 00:26:05.010
<v Speaker 2>greater compression?</v>
<v Speaker 2>What do you mean by that?</v>

370
00:26:05.011 --> 00:26:07.460
<v Speaker 2>How do you think about that?</v>
<v Speaker 2>And deeds?</v>

371
00:26:07.461 --> 00:26:08.294
<v Speaker 2>He,</v>
<v Speaker 2>history of science is a history of </v>

372
00:26:10.261 --> 00:26:13.860
<v Speaker 2>compression progress.</v>
<v Speaker 2>What does that mean?</v>

373
00:26:14.580 --> 00:26:15.413
<v Speaker 2>Hundreds of years ago there was an </v>
<v Speaker 2>astronomer who his name was Kepler and </v>

374
00:26:20.341 --> 00:26:25.341
<v Speaker 2>he looked at the data points that he got</v>
<v Speaker 2>by watching planets move.</v>

375
00:26:25.740 --> 00:26:30.330
<v Speaker 2>And then you had all these data points </v>
<v Speaker 2>and suddenly you out that he can greatly</v>

376
00:26:30.331 --> 00:26:35.331
<v Speaker 2>compress the data by predicting it </v>
<v Speaker 2>through an ellipse lawn.</v>

377
00:26:38.050 --> 00:26:38.883
<v Speaker 2>So it turns out that all these data </v>
<v Speaker 2>points are more or less on ellipsis </v>

378
00:26:42.640 --> 00:26:43.473
<v Speaker 2>around sun.</v>
<v Speaker 2>And another guy came along whose name </v>

379
00:26:48.241 --> 00:26:49.074
<v Speaker 2>was Newton and before him hook and they </v>
<v Speaker 2>set the same thing that is making these </v>

380
00:26:55.831 --> 00:26:56.664
<v Speaker 2>planets move.</v>
<v Speaker 2>Like that is what makes the apples fall </v>

381
00:27:00.511 --> 00:27:02.460
<v Speaker 2>down.</v>
<v Speaker 2>And uh,</v>

382
00:27:03.210 --> 00:27:08.210
<v Speaker 2>also holds form stones and form all </v>
<v Speaker 2>kinds of other objects.</v>

383
00:27:11.040 --> 00:27:11.873
<v Speaker 2>And some of the many,</v>
<v Speaker 2>many of these compressions off these </v>

384
00:27:14.401 --> 00:27:15.234
<v Speaker 2>observations became much more </v>
<v Speaker 2>compressible because as long as you can </v>

385
00:27:18.181 --> 00:27:21.420
<v Speaker 2>predict the next thing,</v>
<v Speaker 2>given what you have seen so far,</v>

386
00:27:21.720 --> 00:27:24.990
<v Speaker 2>you can compress it.</v>
<v Speaker 2>You don't have to store that data extra.</v>

387
00:27:25.370 --> 00:27:30.370
<v Speaker 2>This is called predictive coding.</v>
<v Speaker 2>And then there was still something wrong</v>

388
00:27:31.411 --> 00:27:32.244
<v Speaker 2>with that theory of the universe.</v>
<v Speaker 2>And you had deviations from these </v>

389
00:27:35.821 --> 00:27:39.090
<v Speaker 2>predictions of the theory.</v>
<v Speaker 2>And 300 years later,</v>

390
00:27:39.091 --> 00:27:42.510
<v Speaker 2>another guy came along whose name was </v>
<v Speaker 2>Einstein and he,</v>

391
00:27:42.560 --> 00:27:45.270
<v Speaker 2>um,</v>
<v Speaker 2>he was able to explain a way,</v>

392
00:27:45.271 --> 00:27:50.271
<v Speaker 2>all these deviations from the </v>
<v Speaker 2>predictions are the old theory through a</v>

393
00:27:51.541 --> 00:27:52.374
<v Speaker 2>new theory,</v>
<v Speaker 2>which was called the general theory of </v>

394
00:27:55.531 --> 00:27:56.364
<v Speaker 2>relativity,</v>
<v Speaker 2>which at first glance it looks a little </v>

395
00:27:59.581 --> 00:28:02.640
<v Speaker 2>bit more complicated and you have to </v>
<v Speaker 2>warp space and time.</v>

396
00:28:02.760 --> 00:28:05.370
<v Speaker 2>But you can phrase it within one single </v>
<v Speaker 2>sentence,</v>

397
00:28:05.640 --> 00:28:10.640
<v Speaker 2>which is no matter how fast you </v>
<v Speaker 2>accelerate and how fast are hard,</v>

398
00:28:10.890 --> 00:28:13.380
<v Speaker 2>you decelerate.</v>
<v Speaker 2>And,</v>

399
00:28:13.430 --> 00:28:14.263
<v Speaker 2>um,</v>
<v Speaker 2>no matter what is the gravity in your </v>

400
00:28:17.431 --> 00:28:21.180
<v Speaker 2>local framework,</v>
<v Speaker 2>lightspeed always looks the same.</v>

401
00:28:21.420 --> 00:28:22.260
<v Speaker 2>And from,</v>
<v Speaker 2>from that,</v>

402
00:28:22.261 --> 00:28:23.094
<v Speaker 2>you can calculate all the consequences.</v>
<v Speaker 2>So it's a very simple thing and that </v>

403
00:28:26.131 --> 00:28:26.964
<v Speaker 2>allows you to further compress all the </v>
<v Speaker 2>observations because suddenly there are </v>

404
00:28:33.390 --> 00:28:34.223
<v Speaker 2>hardly any deviations any longer that </v>
<v Speaker 2>you can measure from the predictions of </v>

405
00:28:38.011 --> 00:28:38.844
<v Speaker 2>this new theory.</v>
<v Speaker 2>And so on of signs is a history of </v>

406
00:28:43.140 --> 00:28:43.973
<v Speaker 2>compression progress.</v>
<v Speaker 2>You would never arrive immediately at </v>

407
00:28:47.251 --> 00:28:52.251
<v Speaker 2>the shortest explanation of the data,</v>
<v Speaker 2>but you're making progress.</v>

408
00:28:52.590 --> 00:28:55.700
<v Speaker 2>Whenever you are making progress,</v>
<v Speaker 2>you have an insight,</v>

409
00:28:56.150 --> 00:28:57.300
<v Speaker 2>you will see,</v>
<v Speaker 2>oh,</v>

410
00:28:57.360 --> 00:29:00.870
<v Speaker 2>first I needed so many bits of </v>
<v Speaker 2>information to describe the data,</v>

411
00:29:01.170 --> 00:29:03.360
<v Speaker 2>to describe my falling apples,</v>
<v Speaker 2>my video,</v>

412
00:29:03.361 --> 00:29:05.850
<v Speaker 2>or falling apples.</v>
<v Speaker 2>I need so many data now,</v>

413
00:29:05.880 --> 00:29:08.130
<v Speaker 2>so many pixels we'll have to be stored.</v>

414
00:29:08.160 --> 00:29:09.870
<v Speaker 2>But then suddenly I realize,</v>
<v Speaker 2>no,</v>

415
00:29:10.080 --> 00:29:10.913
<v Speaker 2>that is a very simple way of predicting </v>
<v Speaker 2>the third frame in the video from the </v>

416
00:29:14.911 --> 00:29:16.960
<v Speaker 2>first tool.</v>
<v Speaker 2>And um,</v>

417
00:29:17.550 --> 00:29:20.100
<v Speaker 2>and maybe not every little detail can be</v>
<v Speaker 2>predicted,</v>

418
00:29:20.101 --> 00:29:22.050
<v Speaker 2>but more or less,</v>
<v Speaker 2>most of these orange blogs,</v>

419
00:29:22.230 --> 00:29:25.620
<v Speaker 2>blobs that are coming down,</v>
<v Speaker 2>they accelerate in the same way,</v>

420
00:29:25.830 --> 00:29:26.663
<v Speaker 2>which means that I can greatly compress </v>
<v Speaker 2>the video and the amount of compression </v>

421
00:29:32.100 --> 00:29:32.933
<v Speaker 2>progress.</v>
<v Speaker 2>That is the depths of the insight that </v>

422
00:29:35.791 --> 00:29:38.880
<v Speaker 2>you have at that moment.</v>
<v Speaker 2>That's the fun that you have,</v>

423
00:29:38.881 --> 00:29:39.714
<v Speaker 2>the scientific fun,</v>
<v Speaker 2>that fun and that discovery and we can </v>

424
00:29:43.541 --> 00:29:45.850
<v Speaker 2>build artificial systems that do the </v>
<v Speaker 2>same thing.</v>

425
00:29:46.060 --> 00:29:51.060
<v Speaker 2>So measure as a depth off their insights</v>
<v Speaker 2>as they are looking at the data which is</v>

426
00:29:51.071 --> 00:29:55.570
<v Speaker 2>coming in through their own experiments </v>
<v Speaker 2>and we give them a reward.</v>

427
00:29:55.720 --> 00:29:56.553
<v Speaker 2>And in terms of getting ward and </v>
<v Speaker 2>proportion to this depth of insight w </v>

428
00:30:01.180 --> 00:30:06.180
<v Speaker 2>and since they are trying to maximize </v>
<v Speaker 2>the rewards they get,</v>

429
00:30:08.140 --> 00:30:08.973
<v Speaker 2>they are suddenly motivated to come up </v>
<v Speaker 2>with new actions sequences with new </v>

430
00:30:13.301 --> 00:30:14.134
<v Speaker 2>experiments that half the property that </v>
<v Speaker 2>the data that is coming in as a </v>

431
00:30:18.101 --> 00:30:18.934
<v Speaker 2>consequence is experiments has the </v>
<v Speaker 2>property that they can learn something </v>

432
00:30:23.711 --> 00:30:27.070
<v Speaker 2>about,</v>
<v Speaker 2>see a pattern in there which they hadn't</v>

433
00:30:27.071 --> 00:30:28.120
<v Speaker 2>seen yet before.</v>

434
00:30:28.730 --> 00:30:29.563
<v Speaker 6>So there's an idea of power play.</v>
<v Speaker 6>You described a training in general </v>

435
00:30:33.600 --> 00:30:37.280
<v Speaker 6>problem solver in this kind of way of </v>
<v Speaker 6>looking for the unsolved problems.</v>

436
00:30:38.090 --> 00:30:40.310
<v Speaker 6>Can you describe that idea a little </v>
<v Speaker 6>further?</v>

437
00:30:40.430 --> 00:30:41.263
<v Speaker 2>It's another very simple idea.</v>
<v Speaker 2>So normally what you do and computer </v>

438
00:30:44.331 --> 00:30:45.164
<v Speaker 2>science you have,</v>
<v Speaker 2>you have some guy who gives you a </v>

439
00:30:49.341 --> 00:30:50.174
<v Speaker 2>problem and then there is a,</v>
<v Speaker 2>a huge search space of potential </v>

440
00:30:55.491 --> 00:30:59.480
<v Speaker 2>solution candidates and you somehow try </v>
<v Speaker 2>them out.</v>

441
00:30:59.510 --> 00:31:02.690
<v Speaker 2>And um,</v>
<v Speaker 2>you have more or less sophisticated ways</v>

442
00:31:02.691 --> 00:31:07.691
<v Speaker 2>of moving around in that search space </v>
<v Speaker 2>until you finally found a solution which</v>

443
00:31:10.341 --> 00:31:11.174
<v Speaker 2>you consider a satisfactory.</v>
<v Speaker 2>That's what most of computer science is </v>

444
00:31:14.721 --> 00:31:15.554
<v Speaker 2>about.</v>
<v Speaker 2>Power play just goes one little step </v>

445
00:31:18.291 --> 00:31:23.291
<v Speaker 2>further and says,</v>
<v Speaker 2>let's not only search for solutions to a</v>

446
00:31:23.631 --> 00:31:24.464
<v Speaker 2>given problem,</v>
<v Speaker 2>but let such to pass of problems and </v>

447
00:31:29.241 --> 00:31:30.074
<v Speaker 2>their solutions where the system itself </v>
<v Speaker 2>has the opportunity to phrase its own </v>

448
00:31:35.451 --> 00:31:36.284
<v Speaker 2>problem.</v>
<v Speaker 2>So we are looking suddenly at pairs of </v>

449
00:31:40.551 --> 00:31:41.384
<v Speaker 2>problems and their solutions or </v>
<v Speaker 2>modifications off the problem solver </v>

450
00:31:46.250 --> 00:31:49.790
<v Speaker 2>that is opposed to generate a solution </v>
<v Speaker 2>to that new problem.</v>

451
00:31:51.080 --> 00:31:51.913
<v Speaker 2>And,</v>
<v Speaker 2>and this additional degree of freedom </v>

452
00:31:56.930 --> 00:31:57.763
<v Speaker 2>allows us to build who you are.</v>
<v Speaker 2>Systems that are like scientists in the </v>

453
00:32:01.791 --> 00:32:02.624
<v Speaker 2>sense that they not only trying to solve</v>
<v Speaker 2>and try to find answers to existing </v>

454
00:32:07.611 --> 00:32:08.510
<v Speaker 2>questions.</v>
<v Speaker 2>No,</v>

455
00:32:08.511 --> 00:32:13.040
<v Speaker 2>there are also free to pose their own </v>
<v Speaker 2>questions.</v>

456
00:32:13.250 --> 00:32:15.260
<v Speaker 2>So if you want to build an artificial </v>
<v Speaker 2>scientists,</v>

457
00:32:15.410 --> 00:32:18.860
<v Speaker 2>we have to give it that freedom and </v>
<v Speaker 2>power play is exactly doing that.</v>

458
00:32:19.580 --> 00:32:21.040
<v Speaker 2>So that's,</v>
<v Speaker 2>that's a dimension of</v>

459
00:32:21.090 --> 00:32:23.570
<v Speaker 6>freedom that's important to have.</v>
<v Speaker 6>But how do you,</v>

460
00:32:23.930 --> 00:32:24.763
<v Speaker 6>how hard do you think that,</v>
<v Speaker 6>how multidimensional and difficult the </v>

461
00:32:31.081 --> 00:32:35.220
<v Speaker 6>space of then coming up with your own </v>
<v Speaker 6>questions is as,</v>

462
00:32:35.221 --> 00:32:38.400
<v Speaker 6>it's one of the things that as human </v>
<v Speaker 6>beings we are considered to be,</v>

463
00:32:38.590 --> 00:32:39.423
<v Speaker 6>the thing makes us special.</v>
<v Speaker 6>The intelligence that makes us special </v>

464
00:32:42.200 --> 00:32:44.940
<v Speaker 6>is that brilliant insight.</v>
<v Speaker 6>Yeah.</v>

465
00:32:45.050 --> 00:32:47.300
<v Speaker 6>That can create something totally new.</v>

466
00:32:47.600 --> 00:32:51.320
<v Speaker 2>Yes.</v>
<v Speaker 2>So now let's look at the extreme case.</v>

467
00:32:51.350 --> 00:32:52.183
<v Speaker 2>Let's look at the set of all possible </v>
<v Speaker 2>problems that you can formally this </v>

468
00:32:56.841 --> 00:32:59.240
<v Speaker 2>crime,</v>
<v Speaker 2>which is infinite,</v>

469
00:33:00.170 --> 00:33:01.003
<v Speaker 2>which should be the next problem that a </v>
<v Speaker 2>scientist or a power play is going to </v>

470
00:33:07.041 --> 00:33:08.540
<v Speaker 2>solve.</v>
<v Speaker 2>Well,</v>

471
00:33:09.860 --> 00:33:10.693
<v Speaker 2>it should be</v>

472
00:33:12.460 --> 00:33:15.940
<v Speaker 2>the easiest problem that goes beyond </v>
<v Speaker 2>what you already know.</v>

473
00:33:17.570 --> 00:33:22.230
<v Speaker 2>So it should be the simplest problem </v>
<v Speaker 2>that the current problems,</v>

474
00:33:22.231 --> 00:33:23.064
<v Speaker 2>all of that you have,</v>
<v Speaker 2>which can already solve 100 problems </v>

475
00:33:26.610 --> 00:33:30.060
<v Speaker 2>that he cannot sold yet by just </v>
<v Speaker 2>generalizing.</v>

476
00:33:31.080 --> 00:33:34.540
<v Speaker 2>So it has to be new.</v>
<v Speaker 2>So it has to require a modification.</v>

477
00:33:34.541 --> 00:33:38.610
<v Speaker 2>On the problem solver such that the new </v>
<v Speaker 2>problem solver canceled this new thing,</v>

478
00:33:38.880 --> 00:33:41.100
<v Speaker 2>but the only problem solve,</v>
<v Speaker 2>I cannot do it.</v>

479
00:33:41.550 --> 00:33:42.383
<v Speaker 2>And in addition to that,</v>
<v Speaker 2>we have to make sure that the problem </v>

480
00:33:46.681 --> 00:33:47.514
<v Speaker 2>solver,</v>
<v Speaker 2>it doesn't forget any of the previous </v>

481
00:33:49.501 --> 00:33:50.640
<v Speaker 2>solutions.</v>
<v Speaker 2>Right.</v>

482
00:33:51.240 --> 00:33:52.073
<v Speaker 2>And so by definition,</v>
<v Speaker 2>power play is now trying to search and </v>

483
00:33:55.681 --> 00:33:58.070
<v Speaker 2>this pair and,</v>
<v Speaker 2>and,</v>

484
00:33:58.160 --> 00:34:01.440
<v Speaker 2>and the set of pairs of problems and </v>
<v Speaker 2>problem solve,</v>

485
00:34:01.441 --> 00:34:04.440
<v Speaker 2>um,</v>
<v Speaker 2>modifications for our combination that,</v>

486
00:34:04.760 --> 00:34:05.593
<v Speaker 2>uh,</v>
<v Speaker 2>minimize the time to achieve these </v>

487
00:34:07.291 --> 00:34:08.820
<v Speaker 2>criteria.</v>
<v Speaker 2>So as honest,</v>

488
00:34:08.840 --> 00:34:09.673
<v Speaker 2>trying to find the problem,</v>
<v Speaker 2>which is easiest to add to the </v>

489
00:34:13.171 --> 00:34:15.650
<v Speaker 2>repertoire.</v>
<v Speaker 2>So just like grads</v>

490
00:34:15.710 --> 00:34:16.543
<v Speaker 6>Zudans and academics and researchers can</v>
<v Speaker 6>spend their whole career in a local </v>

491
00:34:20.571 --> 00:34:23.950
<v Speaker 6>minima hmm.</v>
<v Speaker 6>Stuck trying to,</v>

492
00:34:23.951 --> 00:34:25.890
<v Speaker 6>uh,</v>
<v Speaker 6>come up with interesting questions,</v>

493
00:34:25.891 --> 00:34:27.530
<v Speaker 6>but ultimately doing very little.</v>
<v Speaker 6>Yeah.</v>

494
00:34:27.620 --> 00:34:28.940
<v Speaker 2>Do you think it's easy?</v>

495
00:34:29.760 --> 00:34:30.593
<v Speaker 6>Well,</v>
<v Speaker 6>in this approach of looking for the </v>

496
00:34:32.111 --> 00:34:32.944
<v Speaker 6>simplest,</v>
<v Speaker 6>unsolvable problem to get stuck in a </v>

497
00:34:34.541 --> 00:34:37.390
<v Speaker 6>local minima is not never really </v>
<v Speaker 6>discovering</v>

498
00:34:38.820 --> 00:34:39.653
<v Speaker 2>mew,</v>

499
00:34:39.940 --> 00:34:40.541
<v Speaker 6>uh,</v>
<v Speaker 6>you know,</v>

500
00:34:40.541 --> 00:34:44.620
<v Speaker 6>really jumping outside of the hunter </v>
<v Speaker 6>problems that you've already solved in a</v>

501
00:34:44.621 --> 00:34:46.150
<v Speaker 6>genuine creative way.</v>

502
00:34:47.060 --> 00:34:47.630
<v Speaker 3>Okay.</v>

503
00:34:47.630 --> 00:34:48.463
<v Speaker 2>No,</v>
<v Speaker 2>because that's the nature of power play </v>

504
00:34:49.960 --> 00:34:50.793
<v Speaker 2>that it's always trying to break.</v>
<v Speaker 2>It's crown generalization abilities by </v>

505
00:34:56.181 --> 00:35:00.350
<v Speaker 2>coming up with a new problem,</v>
<v Speaker 2>which is beyond the current horizon.</v>

506
00:35:00.920 --> 00:35:05.000
<v Speaker 2>Just shifting the horizon,</v>
<v Speaker 2>I'm knowledge a little bit out there.</v>

507
00:35:05.750 --> 00:35:10.750
<v Speaker 2>Breaking the existing rules such as a </v>
<v Speaker 2>new thing becomes solvable,</v>

508
00:35:10.970 --> 00:35:15.320
<v Speaker 2>but it wasn't solvable by the old thing.</v>
<v Speaker 2>So like adding a new axiom,</v>

509
00:35:15.610 --> 00:35:16.443
<v Speaker 2>um,</v>
<v Speaker 2>like what Google did when he came up </v>

510
00:35:18.981 --> 00:35:19.814
<v Speaker 2>with these new sentences,</v>
<v Speaker 2>new he runs that didn't have a proof in </v>

511
00:35:23.081 --> 00:35:23.914
<v Speaker 2>the former system,</v>
<v Speaker 2>which means you can add them to the </v>

512
00:35:25.940 --> 00:35:27.060
<v Speaker 2>repertoire.</v>
<v Speaker 2>Yeah.</v>

513
00:35:27.670 --> 00:35:30.340
<v Speaker 2>Hoping that,</v>
<v Speaker 2>that they,</v>

514
00:35:30.341 --> 00:35:31.174
<v Speaker 2>um,</v>
<v Speaker 2>are not going to damage the consistency </v>

515
00:35:33.480 --> 00:35:34.313
<v Speaker 2>also whole thing.</v>

516
00:35:35.850 --> 00:35:37.140
<v Speaker 6>So in the,</v>
<v Speaker 6>uh,</v>

517
00:35:37.200 --> 00:35:41.280
<v Speaker 6>paper with the amazing title,</v>
<v Speaker 6>formal theory of creativity,</v>

518
00:35:41.700 --> 00:35:42.533
<v Speaker 6>fun and intrinsic motivation,</v>
<v Speaker 6>you talk about discovery as intrinsic </v>

519
00:35:46.411 --> 00:35:47.244
<v Speaker 6>reward.</v>
<v Speaker 6>So if you view human as intelligent </v>

520
00:35:50.611 --> 00:35:51.444
<v Speaker 6>agents,</v>
<v Speaker 6>what do you think is the purpose and </v>

521
00:35:53.521 --> 00:35:58.521
<v Speaker 6>meaning of life for us humans is,</v>
<v Speaker 6>you've talked about this discovery.</v>

522
00:35:58.641 --> 00:36:02.580
<v Speaker 6>I do you see humans as an instance of </v>
<v Speaker 6>power play agents?</v>

523
00:36:04.220 --> 00:36:08.760
<v Speaker 2>Yeah.</v>
<v Speaker 2>So humans are curious and um,</v>

524
00:36:09.030 --> 00:36:13.190
<v Speaker 2>that means they behave like scientists.</v>
<v Speaker 2>Not only the official scientists,</v>

525
00:36:13.191 --> 00:36:15.860
<v Speaker 2>but even the baby is behave like </v>
<v Speaker 2>scientists.</v>

526
00:36:15.861 --> 00:36:16.694
<v Speaker 2>And they play around with that toy is to</v>
<v Speaker 2>figure out how the world works and how </v>

527
00:36:20.601 --> 00:36:21.434
<v Speaker 2>it is responding to that actions.</v>
<v Speaker 2>And that's how they learned about </v>

528
00:36:25.131 --> 00:36:28.190
<v Speaker 2>gravity and everything.</v>
<v Speaker 2>And Yeah,</v>

529
00:36:28.250 --> 00:36:30.980
<v Speaker 2>in 1995 we had the first systems like </v>
<v Speaker 2>that.</v>

530
00:36:31.010 --> 00:36:31.843
<v Speaker 2>We just try to,</v>
<v Speaker 2>to play around with the environment and </v>

531
00:36:34.970 --> 00:36:39.970
<v Speaker 2>come up with situations that go beyond </v>
<v Speaker 2>what they knew at that time and then get</v>

532
00:36:40.761 --> 00:36:43.670
<v Speaker 2>a reward for creating these situations </v>
<v Speaker 2>and then becoming,</v>

533
00:36:44.000 --> 00:36:45.440
<v Speaker 2>um,</v>
<v Speaker 2>more general problems,</v>

534
00:36:45.441 --> 00:36:48.320
<v Speaker 2>all of us and being able to understand </v>
<v Speaker 2>more of the wild.</v>

535
00:36:48.920 --> 00:36:51.440
<v Speaker 2>So yeah,</v>
<v Speaker 2>I think in principle that,</v>

536
00:36:51.500 --> 00:36:54.620
<v Speaker 2>um,</v>
<v Speaker 2>that,</v>

537
00:36:54.621 --> 00:36:56.810
<v Speaker 2>that curiosity,</v>
<v Speaker 2>um,</v>

538
00:36:57.830 --> 00:36:58.663
<v Speaker 6>strategy</v>

539
00:36:59.920 --> 00:37:03.980
<v Speaker 2>or sophist more sophisticated versions </v>
<v Speaker 2>of what a justice crime they are,</v>

540
00:37:04.660 --> 00:37:05.493
<v Speaker 2>what we have built in as well because </v>
<v Speaker 2>evolution discovered that that's a good </v>

541
00:37:08.621 --> 00:37:09.454
<v Speaker 2>way of exploring the unknown wild.</v>
<v Speaker 2>And the guy who explores the unknown </v>

542
00:37:13.151 --> 00:37:13.984
<v Speaker 2>wild has a higher chance of solving </v>
<v Speaker 2>problems that he needs to survive in </v>

543
00:37:18.431 --> 00:37:20.230
<v Speaker 2>this world.</v>
<v Speaker 2>On the other hand,</v>

544
00:37:21.080 --> 00:37:21.460
<v Speaker 6>yeah,</v>

545
00:37:21.460 --> 00:37:25.240
<v Speaker 2>those guys who were too curious,</v>
<v Speaker 2>they were weeded out as well.</v>

546
00:37:25.290 --> 00:37:28.870
<v Speaker 2>So you have to find this tradeoff </v>
<v Speaker 2>evolution and found a certain trade off.</v>

547
00:37:29.260 --> 00:37:30.093
<v Speaker 2>Apparently in our society there is a </v>
<v Speaker 2>certain percentage of extremely </v>

548
00:37:34.211 --> 00:37:35.044
<v Speaker 2>expansive guys and it doesn't matter if </v>
<v Speaker 2>they die because many of the others are </v>

549
00:37:40.120 --> 00:37:43.390
<v Speaker 2>more conservative.</v>
<v Speaker 2>And um,</v>

550
00:37:43.990 --> 00:37:47.290
<v Speaker 2>and so yeah,</v>
<v Speaker 2>it would be surprising to me if I'm</v>

551
00:37:49.120 --> 00:37:49.390
<v Speaker 6>okay</v>

552
00:37:49.390 --> 00:37:50.223
<v Speaker 2>if that principal of artificial </v>
<v Speaker 2>curiosity wouldn't be present in almost </v>

553
00:37:56.091 --> 00:37:57.980
<v Speaker 2>exactly the same form here</v>

554
00:37:58.390 --> 00:37:59.223
<v Speaker 6>in our brains.</v>
<v Speaker 6>So you're a bit of a musician and an </v>

555
00:38:01.631 --> 00:38:02.464
<v Speaker 6>artist.</v>
<v Speaker 6>So continuing on this topic of </v>

556
00:38:05.681 --> 00:38:06.514
<v Speaker 6>creativity,</v>
<v Speaker 6>what do you think is the role of </v>

557
00:38:08.531 --> 00:38:09.364
<v Speaker 6>creativity and intelligence?</v>
<v Speaker 6>So you've kind of implied that it's </v>

558
00:38:12.401 --> 00:38:13.234
<v Speaker 6>essential for intelligence if you think </v>
<v Speaker 6>of intelligence as a problem solving </v>

559
00:38:20.230 --> 00:38:24.550
<v Speaker 6>system is ability to solve problems.</v>
<v Speaker 6>But do you think it's essential,</v>

560
00:38:25.300 --> 00:38:26.740
<v Speaker 6>this idea of creativity?</v>

561
00:38:28.990 --> 00:38:29.823
<v Speaker 2>We never have a program,</v>
<v Speaker 2>a sub program that is called creativity </v>

562
00:38:33.551 --> 00:38:34.384
<v Speaker 2>or something.</v>
<v Speaker 2>It's just a effect of what our problems </v>

563
00:38:37.001 --> 00:38:40.240
<v Speaker 2>all of us do.</v>
<v Speaker 2>They are searching a space of problems.</v>

564
00:38:40.270 --> 00:38:41.103
<v Speaker 2>Oh,</v>
<v Speaker 2>I space off a cannon dates off solution </v>

565
00:38:43.391 --> 00:38:47.620
<v Speaker 2>candidates until they hopefully find a </v>
<v Speaker 2>solution to a given problem.</v>

566
00:38:48.190 --> 00:38:51.110
<v Speaker 2>But then there are these two types of </v>
<v Speaker 2>creativity and uh,</v>

567
00:38:51.190 --> 00:38:53.590
<v Speaker 2>both of them are now present in our </v>
<v Speaker 2>machines.</v>

568
00:38:53.920 --> 00:38:56.050
<v Speaker 2>Um,</v>
<v Speaker 2>the first one has been around for a long</v>

569
00:38:56.051 --> 00:38:59.620
<v Speaker 2>time,</v>
<v Speaker 2>which is human gives problem to machine,</v>

570
00:38:59.650 --> 00:39:03.100
<v Speaker 2>machine,</v>
<v Speaker 2>tries to find a solution to that.</v>

571
00:39:03.460 --> 00:39:04.293
<v Speaker 2>And this has been happening for many </v>
<v Speaker 2>decades and for many decades machines </v>

572
00:39:07.211 --> 00:39:08.044
<v Speaker 2>have found creative solutions to </v>
<v Speaker 2>interesting problems where humans were </v>

573
00:39:12.940 --> 00:39:14.710
<v Speaker 2>not aware of these,</v>
<v Speaker 2>um,</v>

574
00:39:15.520 --> 00:39:16.353
<v Speaker 2>particularly in creative solutions but </v>
<v Speaker 2>then appreciate it that the machine </v>

575
00:39:19.691 --> 00:39:24.160
<v Speaker 2>found that.</v>
<v Speaker 2>The second is the pure creativity that I</v>

576
00:39:24.161 --> 00:39:25.600
<v Speaker 2>would call it what I just mentioned.</v>

577
00:39:25.600 --> 00:39:30.600
<v Speaker 2>I would call the applied creativity like</v>
<v Speaker 2>applied art where somebody tells you now</v>

578
00:39:31.880 --> 00:39:36.490
<v Speaker 2>make a nice picture of off this pope and</v>
<v Speaker 2>you will get money for that.</v>

579
00:39:36.760 --> 00:39:37.593
<v Speaker 2>Okay,</v>
<v Speaker 2>so here's the artist and he makes a </v>

580
00:39:40.151 --> 00:39:43.900
<v Speaker 2>convincing picture as the pope and the </v>
<v Speaker 2>pope lakes it and gives them the money.</v>

581
00:39:45.880 --> 00:39:48.760
<v Speaker 2>And then there is the pure creative </v>
<v Speaker 2>creativity,</v>

582
00:39:48.761 --> 00:39:52.960
<v Speaker 2>which is more like the power play and </v>
<v Speaker 2>the artificial curiosity thing where you</v>

583
00:39:52.961 --> 00:39:56.440
<v Speaker 2>have the freedom to select your own </v>
<v Speaker 2>problem.</v>

584
00:39:57.070 --> 00:40:02.070
<v Speaker 2>Like a scientist who defines his on </v>
<v Speaker 2>question two study.</v>

585
00:40:03.400 --> 00:40:06.790
<v Speaker 2>And so that is the pure creativity,</v>
<v Speaker 2>if you will,</v>

586
00:40:07.840 --> 00:40:12.840
<v Speaker 2>as opposed to the applied creativity,</v>
<v Speaker 2>which serves another</v>

587
00:40:14.380 --> 00:40:15.213
<v Speaker 6>in that distinction,</v>
<v Speaker 6>there's almost echoes of narrow ai </v>

588
00:40:17.651 --> 00:40:18.484
<v Speaker 6>versus generally I say this kind of </v>
<v Speaker 6>constrained painting or pope seems like </v>

589
00:40:25.580 --> 00:40:26.413
<v Speaker 6>the,</v>
<v Speaker 6>the approaches of what people are </v>

590
00:40:28.101 --> 00:40:32.590
<v Speaker 6>calling narrow ai and pure creativity </v>
<v Speaker 6>seems to be okay.</v>

591
00:40:33.360 --> 00:40:34.193
<v Speaker 6>Maybe I'm just biased as a human,</v>
<v Speaker 6>but it seems to be an essential element </v>

592
00:40:38.400 --> 00:40:42.150
<v Speaker 6>of human level intelligence.</v>
<v Speaker 6>Is that what you're implying?</v>

593
00:40:44.330 --> 00:40:48.320
<v Speaker 2>To a degree,</v>
<v Speaker 2>if you zoom back a little bit and you're</v>

594
00:40:48.321 --> 00:40:51.230
<v Speaker 2>just look at 'em gentlemen problem </v>
<v Speaker 2>solving machine,</v>

595
00:40:51.260 --> 00:40:53.420
<v Speaker 2>which is trying to solve arbitrary </v>
<v Speaker 2>problems,</v>

596
00:40:53.600 --> 00:40:54.433
<v Speaker 2>then this machine will figure out in the</v>
<v Speaker 2>course are solving problems that it's </v>

597
00:40:58.641 --> 00:40:59.474
<v Speaker 2>good to be curious.</v>
<v Speaker 2>So all of what I said just now about </v>

598
00:41:02.991 --> 00:41:03.824
<v Speaker 2>this pre one curiosity and there's </v>
<v Speaker 2>Seville to invent new problems that the </v>

599
00:41:08.721 --> 00:41:09.554
<v Speaker 2>system doesn't know how to solve yet </v>
<v Speaker 2>should be just a byproduct of the </v>

600
00:41:13.651 --> 00:41:15.690
<v Speaker 2>general signage.</v>
<v Speaker 2>However,</v>

601
00:41:17.590 --> 00:41:21.040
<v Speaker 2>apparently evolution has built it into </v>
<v Speaker 2>us.</v>

602
00:41:21.860 --> 00:41:24.020
<v Speaker 2>The cards are turned out to be so </v>
<v Speaker 2>successful.</v>

603
00:41:24.050 --> 00:41:25.080
<v Speaker 2>Uh,</v>
<v Speaker 2>uh,</v>

604
00:41:25.130 --> 00:41:26.290
<v Speaker 2>pre wiring,</v>
<v Speaker 2>uh,</v>

605
00:41:26.291 --> 00:41:30.830
<v Speaker 2>buyers are very successful exploratory </v>
<v Speaker 2>buyers that,</v>

606
00:41:30.831 --> 00:41:32.750
<v Speaker 2>um,</v>
<v Speaker 2>that'd be a born with.</v>

607
00:41:33.890 --> 00:41:34.723
<v Speaker 6>And you've also said that consciousness </v>
<v Speaker 6>in the same kind of way may be a </v>

608
00:41:37.461 --> 00:41:40.700
<v Speaker 6>byproduct of,</v>
<v Speaker 6>of problem solving.</v>

609
00:41:41.210 --> 00:41:42.043
<v Speaker 6>Do you think,</v>
<v Speaker 6>do you find this an interesting </v>

610
00:41:44.061 --> 00:41:46.420
<v Speaker 6>byproduct?</v>
<v Speaker 6>Do you think is a useful byproduct?</v>

611
00:41:47.320 --> 00:41:49.340
<v Speaker 6>What are your thoughts on consciousness </v>
<v Speaker 6>in general?</v>

612
00:41:49.341 --> 00:41:50.174
<v Speaker 6>Or is it simply a byproduct of greater </v>
<v Speaker 6>and greater capabilities of problem </v>

613
00:41:54.171 --> 00:41:57.110
<v Speaker 6>solving that's,</v>
<v Speaker 6>uh,</v>

614
00:41:57.560 --> 00:41:59.870
<v Speaker 6>that's similar to creativity in that </v>
<v Speaker 6>sense?</v>

615
00:42:00.940 --> 00:42:01.773
<v Speaker 2>Yeah.</v>
<v Speaker 2>We never have a procedure called </v>

616
00:42:03.521 --> 00:42:04.354
<v Speaker 2>consciousness and now let machines,</v>
<v Speaker 2>however we get as side effects of what </v>

617
00:42:08.740 --> 00:42:09.573
<v Speaker 2>these machines are doing,</v>
<v Speaker 2>things that seem to be closely related </v>

618
00:42:13.521 --> 00:42:17.780
<v Speaker 2>to what people can and consciousness.</v>
<v Speaker 2>So for example,</v>

619
00:42:18.890 --> 00:42:19.723
<v Speaker 2>in 1990,</v>
<v Speaker 2>we had simple systems which were </v>

620
00:42:21.860 --> 00:42:23.100
<v Speaker 2>basically,</v>
<v Speaker 2>um,</v>

621
00:42:23.150 --> 00:42:23.983
<v Speaker 2>recurrent networks and therefore </v>
<v Speaker 2>university of computers trying to map </v>

622
00:42:28.040 --> 00:42:32.720
<v Speaker 2>incoming data into actions that lead to </v>
<v Speaker 2>success.</v>

623
00:42:33.210 --> 00:42:34.043
<v Speaker 2>Uh,</v>
<v Speaker 2>maximizing reward and a given </v>

624
00:42:35.691 --> 00:42:36.524
<v Speaker 2>environment always findings a charging </v>
<v Speaker 2>station in time whenever the battery is </v>

625
00:42:41.331 --> 00:42:43.850
<v Speaker 2>low and negative signals are coming from</v>
<v Speaker 2>the battery.</v>

626
00:42:44.190 --> 00:42:45.023
<v Speaker 2>Always find the charging station in time</v>
<v Speaker 2>without bumping against painful </v>

627
00:42:49.281 --> 00:42:50.114
<v Speaker 2>obstacles on the way.</v>
<v Speaker 2>So complicated things but very easily </v>

628
00:42:53.091 --> 00:42:55.310
<v Speaker 2>motivated.</v>
<v Speaker 2>And then,</v>

629
00:42:55.330 --> 00:43:00.050
<v Speaker 2>uh,</v>
<v Speaker 2>we give these little guys a separate,</v>

630
00:43:00.760 --> 00:43:01.593
<v Speaker 2>we can't run a truck,</v>
<v Speaker 2>which is just predicting what's </v>

631
00:43:03.081 --> 00:43:04.200
<v Speaker 2>happening.</v>
<v Speaker 2>If I do,</v>

632
00:43:04.201 --> 00:43:05.034
<v Speaker 2>that happened that what will happen as a</v>
<v Speaker 2>consequence are these actions that I'm </v>

633
00:43:08.631 --> 00:43:09.464
<v Speaker 2>executing and it's just trained on the </v>
<v Speaker 2>long and long history of interactions </v>

634
00:43:12.771 --> 00:43:13.760
<v Speaker 2>with the wild.</v>

635
00:43:14.030 --> 00:43:17.540
<v Speaker 2>So it becomes a predictive model.</v>
<v Speaker 2>Lots of wild basically.</v>

636
00:43:18.110 --> 00:43:18.943
<v Speaker 2>And therefore also a compressor arsene </v>
<v Speaker 2>observations after awhile because </v>

637
00:43:23.451 --> 00:43:26.550
<v Speaker 2>whatever you can predict you don't have </v>
<v Speaker 2>to store extra.</v>

638
00:43:26.551 --> 00:43:29.840
<v Speaker 2>And so compression as a side effect our </v>
<v Speaker 2>prediction.</v>

639
00:43:30.560 --> 00:43:32.990
<v Speaker 2>And how does this require network </v>
<v Speaker 2>compress?</v>

640
00:43:33.230 --> 00:43:34.063
<v Speaker 2>Well it's inventing little subprograms </v>
<v Speaker 2>little sub natural networks that stand </v>

641
00:43:38.271 --> 00:43:39.104
<v Speaker 2>for everything that frequently appears </v>
<v Speaker 2>and the environment like bottles and </v>

642
00:43:43.191 --> 00:43:47.040
<v Speaker 2>microphones and faces maybe lots of </v>
<v Speaker 2>faces in my um,</v>

643
00:43:47.410 --> 00:43:48.243
<v Speaker 2>uh,</v>
<v Speaker 2>environments or I'm learning to create </v>

644
00:43:50.031 --> 00:43:50.864
<v Speaker 2>something like a prototype phase and the</v>
<v Speaker 2>new phase comes along and all I have to </v>

645
00:43:53.660 --> 00:43:55.520
<v Speaker 2>encode the deviations from the </v>
<v Speaker 2>prototype.</v>

646
00:43:56.390 --> 00:43:59.960
<v Speaker 2>So it's compressing all the time.</v>
<v Speaker 2>The stuff that frequently appears.</v>

647
00:44:00.920 --> 00:44:01.753
<v Speaker 2>There's one thing that appears all the </v>
<v Speaker 2>time that is present all the time when </v>

648
00:44:06.621 --> 00:44:09.410
<v Speaker 2>the agent is interacting with its </v>
<v Speaker 2>environment,</v>

649
00:44:09.530 --> 00:44:14.240
<v Speaker 2>which is the agent itself.</v>
<v Speaker 2>So just for data compression reasons,</v>

650
00:44:14.510 --> 00:44:19.510
<v Speaker 2>it is extremely natural for this </v>
<v Speaker 2>recurrent network to come up with little</v>

651
00:44:19.731 --> 00:44:23.600
<v Speaker 2>sub networks that stand for the </v>
<v Speaker 2>properties off the agents,</v>

652
00:44:23.601 --> 00:44:25.790
<v Speaker 2>the Hams,</v>
<v Speaker 2>you know the,</v>

653
00:44:25.791 --> 00:44:26.624
<v Speaker 2>the,</v>
<v Speaker 2>the other actuators and all the stuff </v>

654
00:44:29.090 --> 00:44:29.923
<v Speaker 2>said you need to better in code the data</v>
<v Speaker 2>which is influenced by the actions of </v>

655
00:44:33.391 --> 00:44:34.224
<v Speaker 2>the agent.</v>

656
00:44:34.350 --> 00:44:39.350
<v Speaker 2>So they're just as a side effect of they</v>
<v Speaker 2>are compression during problem solving,</v>

657
00:44:40.420 --> 00:44:41.253
<v Speaker 2>you have internal self models now you </v>
<v Speaker 2>can use this model of the wand to plan </v>

658
00:44:50.170 --> 00:44:51.003
<v Speaker 2>your future and that's what you also </v>
<v Speaker 2>have done since 1990 so the recurrent </v>

659
00:44:55.121 --> 00:44:57.400
<v Speaker 2>network,</v>
<v Speaker 2>which is c controller,</v>

660
00:44:57.670 --> 00:44:58.503
<v Speaker 2>which is trying to maximize reward can </v>
<v Speaker 2>use this model as a network of the </v>

661
00:45:02.141 --> 00:45:02.974
<v Speaker 2>wilds.</v>
<v Speaker 2>It says model network Arthur wild </v>

662
00:45:04.390 --> 00:45:05.223
<v Speaker 2>predictive model after wilde to plan </v>
<v Speaker 2>ahead and say let's not do this action </v>

663
00:45:08.501 --> 00:45:09.334
<v Speaker 2>sequence.</v>
<v Speaker 2>Let's do this action sequence instead </v>

664
00:45:11.411 --> 00:45:13.780
<v Speaker 2>because it leads to more predicted three</v>
<v Speaker 2>rewards.</v>

665
00:45:14.590 --> 00:45:15.423
<v Speaker 2>And whenever it's waking up,</v>
<v Speaker 2>these learners up networks that stand </v>

666
00:45:19.191 --> 00:45:22.420
<v Speaker 2>for itself,</v>
<v Speaker 2>it's like it's thinking about itself and</v>

667
00:45:22.421 --> 00:45:23.254
<v Speaker 2>it's thinking about itself and it's okay</v>
<v Speaker 2>exploring mentally the consequences of </v>

668
00:45:29.651 --> 00:45:30.484
<v Speaker 2>its own actions.</v>
<v Speaker 2>And now you tell me what is still </v>

669
00:45:35.061 --> 00:45:35.894
<v Speaker 2>missing</v>

670
00:45:37.190 --> 00:45:39.680
<v Speaker 6>missing the next,</v>
<v Speaker 6>the the gap to consciousness.</v>

671
00:45:39.730 --> 00:45:40.371
<v Speaker 6>Yeah,</v>
<v Speaker 6>I,</v>

672
00:45:40.371 --> 00:45:41.061
<v Speaker 6>there,</v>
<v Speaker 6>there isn't,</v>

673
00:45:41.061 --> 00:45:44.150
<v Speaker 6>that's a really beautiful idea that um,</v>
<v Speaker 6>you know,</v>

674
00:45:44.390 --> 00:45:45.223
<v Speaker 6>if life is a collection of data and in </v>
<v Speaker 6>life is a process of compressing that </v>

675
00:45:49.431 --> 00:45:54.431
<v Speaker 6>data to act efficiently in that data,</v>
<v Speaker 6>you yourself appear very often.</v>

676
00:45:57.590 --> 00:45:58.423
<v Speaker 6>So it's useful to a form compressions of</v>
<v Speaker 6>yourself and it's a really beautiful </v>

677
00:46:02.091 --> 00:46:05.330
<v Speaker 6>formulation or cautiousness is as </v>
<v Speaker 6>unnecessary side effect.</v>

678
00:46:05.690 --> 00:46:10.690
<v Speaker 6>It's actually quite compelling to me.</v>
<v Speaker 6>You've described Rnn ins and developed a</v>

679
00:46:15.741 --> 00:46:16.574
<v Speaker 6>Lstm as long short term memory networks </v>
<v Speaker 6>that are there a type of recurrent </v>

680
00:46:20.960 --> 00:46:23.960
<v Speaker 6>neural networks and they have gotten a </v>
<v Speaker 6>lot of success recently.</v>

681
00:46:23.961 --> 00:46:28.961
<v Speaker 6>So these are networks that model the </v>
<v Speaker 6>temporal aspects in the data to temporal</v>

682
00:46:29.871 --> 00:46:30.704
<v Speaker 6>patterns in the data.</v>
<v Speaker 6>And you've called them the deepest of </v>

683
00:46:34.101 --> 00:46:35.450
<v Speaker 6>the new on that works.</v>
<v Speaker 6>Right.</v>

684
00:46:36.290 --> 00:46:37.123
<v Speaker 6>So what do you think is the value of </v>
<v Speaker 6>depth in the models that we use to </v>

685
00:46:40.911 --> 00:46:41.744
<v Speaker 6>learn?</v>

686
00:46:43.940 --> 00:46:44.773
<v Speaker 2>Yeah,</v>
<v Speaker 2>since you mentioned the long short term </v>

687
00:46:46.131 --> 00:46:48.240
<v Speaker 2>memory and the Lstm,</v>
<v Speaker 2>um,</v>

688
00:46:48.350 --> 00:46:52.190
<v Speaker 2>I have to mention the names off the </v>
<v Speaker 2>brilliant students who has of course,</v>

689
00:46:52.191 --> 00:46:53.350
<v Speaker 2>of course.</v>
<v Speaker 2>Um,</v>

690
00:46:53.420 --> 00:46:54.253
<v Speaker 2>first of all,</v>
<v Speaker 2>and my first student ever set for Haida </v>

691
00:46:56.720 --> 00:46:57.553
<v Speaker 2>who had fundamental insights already and</v>
<v Speaker 2>this diploma thesis then Felix </v>

692
00:47:01.080 --> 00:47:04.430
<v Speaker 2>[inaudible] had additional important </v>
<v Speaker 2>contributions.</v>

693
00:47:04.610 --> 00:47:07.520
<v Speaker 2>Alex Grey's a guy from Scotland who,</v>
<v Speaker 2>um,</v>

694
00:47:07.860 --> 00:47:11.300
<v Speaker 2>is mostly responsible for this CTC </v>
<v Speaker 2>algorithm,</v>

695
00:47:11.301 --> 00:47:12.134
<v Speaker 2>which is now how often use to,</v>
<v Speaker 2>to train the Lstm to do the speech </v>

696
00:47:15.681 --> 00:47:16.514
<v Speaker 2>recognition on all the Google,</v>
<v Speaker 2>android phones and whatever and CV and </v>

697
00:47:20.571 --> 00:47:21.860
<v Speaker 2>so on.</v>
<v Speaker 2>So,</v>

698
00:47:22.040 --> 00:47:23.170
<v Speaker 2>um,</v>
<v Speaker 2>uh,</v>

699
00:47:23.210 --> 00:47:24.800
<v Speaker 2>these guys,</v>
<v Speaker 2>without these guys,</v>

700
00:47:24.801 --> 00:47:26.780
<v Speaker 2>um,</v>
<v Speaker 2>I would be nothing.</v>

701
00:47:26.810 --> 00:47:29.580
<v Speaker 2>It's a lot of incredible work.</v>
<v Speaker 2>What does,</v>

702
00:47:29.581 --> 00:47:30.414
<v Speaker 2>now the depth,</v>

703
00:47:30.570 --> 00:47:32.820
<v Speaker 6>what is the importance of depth?</v>
<v Speaker 6>Well,</v>

704
00:47:32.850 --> 00:47:36.180
<v Speaker 6>um,</v>
<v Speaker 6>most problems in the real world,</v>

705
00:47:36.210 --> 00:47:37.710
<v Speaker 6>uh,</v>
<v Speaker 6>deep in the sense that,</v>

706
00:47:37.711 --> 00:47:38.544
<v Speaker 6>um,</v>
<v Speaker 6>the kind input doesn't tell you all you </v>

707
00:47:41.371 --> 00:47:46.140
<v Speaker 6>need to know about the environment.</v>
<v Speaker 6>So instead,</v>

708
00:47:46.430 --> 00:47:47.263
<v Speaker 6>um,</v>
<v Speaker 6>you have to have a memory of what </v>

709
00:47:48.871 --> 00:47:53.871
<v Speaker 6>happened in the past and often important</v>
<v Speaker 6>pads of that memory I dated.</v>

710
00:47:54.780 --> 00:47:56.970
<v Speaker 6>They are pretty old.</v>
<v Speaker 6>And so,</v>

711
00:47:56.990 --> 00:47:59.340
<v Speaker 6>um,</v>
<v Speaker 6>when you're doing speech recognition for</v>

712
00:47:59.341 --> 00:48:02.520
<v Speaker 6>example,</v>
<v Speaker 6>and somebody says 11,</v>

713
00:48:04.260 --> 00:48:08.700
<v Speaker 6>then that's about half a second or </v>
<v Speaker 6>something like that,</v>

714
00:48:09.090 --> 00:48:11.250
<v Speaker 6>which means it's already a 50 time </v>
<v Speaker 6>steps.</v>

715
00:48:11.970 --> 00:48:15.120
<v Speaker 6>And another guy or the same guys that </v>
<v Speaker 6>says seven.</v>

716
00:48:16.200 --> 00:48:17.033
<v Speaker 6>So the ending is the same Evan,</v>
<v Speaker 6>but now the system has to see the </v>

717
00:48:20.131 --> 00:48:20.964
<v Speaker 6>distinction between seven and 11.</v>
<v Speaker 6>And the only way I can see the </v>

718
00:48:24.571 --> 00:48:28.290
<v Speaker 6>differences it has to store that,</v>
<v Speaker 6>uh,</v>

719
00:48:28.410 --> 00:48:33.410
<v Speaker 6>50 steps ago there was an s or an uber </v>
<v Speaker 6>11 or seven.</v>

720
00:48:34.920 --> 00:48:37.560
<v Speaker 6>So there you have already a problem of </v>
<v Speaker 6>depth 50,</v>

721
00:48:38.070 --> 00:48:42.210
<v Speaker 6>because for each time step you have </v>
<v Speaker 6>something like a virtual,</v>

722
00:48:42.211 --> 00:48:45.900
<v Speaker 6>a layer in the expanded and evolved </v>
<v Speaker 6>version of [inaudible] network,</v>

723
00:48:45.901 --> 00:48:50.160
<v Speaker 6>which is doing the speech recognition.</v>
<v Speaker 6>So these long time lax,</v>

724
00:48:50.161 --> 00:48:55.161
<v Speaker 6>they translate into problem depth and </v>
<v Speaker 6>most rotten ones.</v>

725
00:48:56.250 --> 00:48:57.083
<v Speaker 6>And this wild I that you're rarely have </v>
<v Speaker 6>to look far back in time to understand </v>

726
00:49:03.360 --> 00:49:07.610
<v Speaker 6>what is the problem and to solve it.</v>
<v Speaker 6>But just like with Lstm,</v>

727
00:49:07.910 --> 00:49:11.090
<v Speaker 6>you don't necessarily need to,</v>
<v Speaker 6>when you look back in time,</v>

728
00:49:11.091 --> 00:49:11.924
<v Speaker 6>remember every aspect,</v>
<v Speaker 6>you just need to remember the important </v>

729
00:49:13.881 --> 00:49:14.714
<v Speaker 6>aspects.</v>

730
00:49:14.840 --> 00:49:15.673
<v Speaker 2>That's fine.</v>
<v Speaker 2>It's a network has to learn to put the </v>

731
00:49:17.841 --> 00:49:22.841
<v Speaker 2>important stuff and into memory and to </v>
<v Speaker 2>ignore the unimportant noise.</v>

732
00:49:23.840 --> 00:49:25.580
<v Speaker 6>So,</v>
<v Speaker 6>but in that sense,</v>

733
00:49:26.420 --> 00:49:29.810
<v Speaker 6>deeper and deeper is better.</v>
<v Speaker 6>Or is there a limitation?</v>

734
00:49:29.811 --> 00:49:34.340
<v Speaker 6>Is there,</v>
<v Speaker 6>I mean Lstm is one of the great examples</v>

735
00:49:34.670 --> 00:49:39.230
<v Speaker 6>of architectures that,</v>
<v Speaker 6>uh,</v>

736
00:49:39.260 --> 00:49:41.810
<v Speaker 6>do something beyond just deeper and </v>
<v Speaker 6>deeper networks,</v>

737
00:49:42.370 --> 00:49:47.120
<v Speaker 6>this clever mechanisms for filtering </v>
<v Speaker 6>data for remembering and forgetting.</v>

738
00:49:47.780 --> 00:49:51.110
<v Speaker 6>So do you think that kind of thinking is</v>
<v Speaker 6>necessary?</v>

739
00:49:51.290 --> 00:49:53.360
<v Speaker 6>If you think about it,</v>
<v Speaker 6>Lstm is a leap,</v>

740
00:49:53.390 --> 00:49:56.630
<v Speaker 6>a big leap forward over traditional </v>
<v Speaker 6>Vanilla rnn.</v>

741
00:49:57.650 --> 00:50:02.650
<v Speaker 6>What do you think is the next leap it </v>
<v Speaker 6>within this context?</v>

742
00:50:02.841 --> 00:50:03.674
<v Speaker 6>So as Sam was a very clever improvement,</v>
<v Speaker 6>but lcm still don't have the same kind </v>

743
00:50:09.951 --> 00:50:12.270
<v Speaker 6>of ability to see far back in the future</v>
<v Speaker 6>in the,</v>

744
00:50:12.340 --> 00:50:17.340
<v Speaker 6>in the past as us humans do the credit </v>
<v Speaker 6>assignment problem across way back,</v>

745
00:50:18.830 --> 00:50:21.920
<v Speaker 6>not just 50 times stuff.</v>
<v Speaker 6>So a hundred or a thousand,</v>

746
00:50:21.921 --> 00:50:23.990
<v Speaker 6>but millions and billions,</v>

747
00:50:24.840 --> 00:50:25.673
<v Speaker 2>not clear.</v>
<v Speaker 2>What are the practical limits as the </v>

748
00:50:28.611 --> 00:50:33.140
<v Speaker 2>LSTM when it comes to looking back </v>
<v Speaker 2>already in 2006,</v>

749
00:50:33.141 --> 00:50:33.974
<v Speaker 2>I think we had examples where it not </v>
<v Speaker 2>only look back tens or thousands of </v>

750
00:50:37.581 --> 00:50:41.480
<v Speaker 2>steps,</v>
<v Speaker 2>but really millions of steps and um,</v>

751
00:50:41.500 --> 00:50:42.070
<v Speaker 2>who,</v>
<v Speaker 2>um,</v>

752
00:50:42.070 --> 00:50:43.200
<v Speaker 2>Paris,</v>
<v Speaker 2>um,</v>

753
00:50:43.370 --> 00:50:46.730
<v Speaker 2>artists in my lap,</v>
<v Speaker 2>I think once the first author of a paper</v>

754
00:50:47.060 --> 00:50:47.893
<v Speaker 2>where we really was a 2006 or something,</v>
<v Speaker 2>had examples where I'd learn to look </v>

755
00:50:52.671 --> 00:50:56.940
<v Speaker 2>back for more than 10 million steps.</v>
<v Speaker 2>Right?</v>

756
00:50:57.500 --> 00:51:02.030
<v Speaker 2>So for most problems I've speech </v>
<v Speaker 2>recognition,</v>

757
00:51:02.060 --> 00:51:04.640
<v Speaker 2>it's not necessary to look that far </v>
<v Speaker 2>back.</v>

758
00:51:04.670 --> 00:51:09.670
<v Speaker 2>But the examples where does now,</v>
<v Speaker 2>so looking back thing that's rather easy</v>

759
00:51:11.600 --> 00:51:12.433
<v Speaker 2>because that has only one past,</v>
<v Speaker 2>but there are many possible futures and </v>

760
00:51:17.961 --> 00:51:18.794
<v Speaker 2>so our reinforcement learning system,</v>
<v Speaker 2>which is trying to maximize its future </v>

761
00:51:22.371 --> 00:51:23.204
<v Speaker 2>expected reward and doesn't know yet </v>
<v Speaker 2>which of these many possible future </v>

762
00:51:27.621 --> 00:51:32.621
<v Speaker 2>should I select give him this one single</v>
<v Speaker 2>pass is facing problems that the Lstm by</v>

763
00:51:34.191 --> 00:51:35.150
<v Speaker 2>itself cannot solve.</v>

764
00:51:36.530 --> 00:51:37.363
<v Speaker 2>So the other Sam is good for coming up </v>
<v Speaker 2>with a compact representation of the </v>

765
00:51:41.331 --> 00:51:42.410
<v Speaker 2>history.</v>
<v Speaker 2>So far.</v>

766
00:51:42.411 --> 00:51:46.010
<v Speaker 2>I'll say history and observations and </v>
<v Speaker 2>action so far.</v>

767
00:51:46.310 --> 00:51:51.310
<v Speaker 2>But now how do you plan in an efficient </v>
<v Speaker 2>and good way among all these,</v>

768
00:51:54.320 --> 00:51:55.153
<v Speaker 2>how do you select one of these many </v>
<v Speaker 2>possible action sequences that are </v>

769
00:51:58.431 --> 00:51:59.264
<v Speaker 2>reinforcement learning system has to </v>
<v Speaker 2>consider to maximize reward in this </v>

770
00:52:04.340 --> 00:52:06.350
<v Speaker 2>unknown future?</v>
<v Speaker 2>So again,</v>

771
00:52:06.620 --> 00:52:11.150
<v Speaker 2>we have this basic setup where you have </v>
<v Speaker 2>one that we cannot work,</v>

772
00:52:11.390 --> 00:52:15.740
<v Speaker 2>which gets in the video and the speech </v>
<v Speaker 2>and whatever,</v>

773
00:52:15.920 --> 00:52:19.490
<v Speaker 2>and it's executing the actions and is </v>
<v Speaker 2>trying to maximize reward.</v>

774
00:52:19.610 --> 00:52:23.660
<v Speaker 2>So that is no teacher who tells it what </v>
<v Speaker 2>to do at which point in time.</v>

775
00:52:24.440 --> 00:52:29.440
<v Speaker 2>And then there's the other network,</v>
<v Speaker 2>which is just predicting what's going to</v>

776
00:52:30.621 --> 00:52:32.180
<v Speaker 2>happen if I do that.</v>
<v Speaker 2>And then,</v>

777
00:52:32.960 --> 00:52:33.793
<v Speaker 2>and that could be an lstm network and it</v>
<v Speaker 2>allows us to look back all the way to </v>

778
00:52:38.721 --> 00:52:40.950
<v Speaker 2>make better predictions off the next </v>
<v Speaker 2>time step.</v>

779
00:52:41.600 --> 00:52:42.433
<v Speaker 2>So essentially,</v>
<v Speaker 2>although it's predicting only the next </v>

780
00:52:44.750 --> 00:52:45.583
<v Speaker 2>time step and is motivated to learn to </v>
<v Speaker 2>put into memory something that happened </v>

781
00:52:51.051 --> 00:52:53.470
<v Speaker 2>maybe a million steps ago,</v>
<v Speaker 2>because it's important,</v>

782
00:52:53.670 --> 00:52:54.740
<v Speaker 2>uh,</v>
<v Speaker 2>to memorize that.</v>

783
00:52:54.741 --> 00:52:57.620
<v Speaker 2>If you want to predict that at the next </v>
<v Speaker 2>time step,</v>

784
00:52:57.621 --> 00:52:58.670
<v Speaker 2>the next event,</v>
<v Speaker 2>you know,</v>

785
00:52:59.600 --> 00:53:00.510
<v Speaker 2>now,</v>
<v Speaker 2>um,</v>

786
00:53:01.010 --> 00:53:01.843
<v Speaker 2>how can a model of the one,</v>
<v Speaker 2>I like that a predictive model of the </v>

787
00:53:04.870 --> 00:53:05.703
<v Speaker 2>wild be used by the first guy,</v>
<v Speaker 2>it's called it the controller and the </v>

788
00:53:09.771 --> 00:53:11.390
<v Speaker 2>model,</v>
<v Speaker 2>the controller and the model.</v>

789
00:53:11.510 --> 00:53:12.343
<v Speaker 2>How can the model be used by the </v>
<v Speaker 2>controller to efficiently select a ma </v>

790
00:53:17.500 --> 00:53:21.560
<v Speaker 2>among these many possible futures?</v>
<v Speaker 2>So now eve way we had,</v>

791
00:53:21.561 --> 00:53:22.394
<v Speaker 2>um,</v>
<v Speaker 2>about 30 years ago was let's just is </v>

792
00:53:25.500 --> 00:53:28.560
<v Speaker 2>some model last awhile as a stand in,</v>
<v Speaker 2>as a simulation,</v>

793
00:53:28.570 --> 00:53:31.290
<v Speaker 2>as a wild and millisecond by </v>
<v Speaker 2>millisecond.</v>

794
00:53:31.291 --> 00:53:35.070
<v Speaker 2>We plan the future and that means we </v>
<v Speaker 2>have to roll it out.</v>

795
00:53:35.070 --> 00:53:38.370
<v Speaker 2>It's really in detail and it will work </v>
<v Speaker 2>only if the model is really good.</v>

796
00:53:38.610 --> 00:53:39.443
<v Speaker 2>And it will still be inefficient because</v>
<v Speaker 2>we have to look at all these possible </v>

797
00:53:42.481 --> 00:53:46.560
<v Speaker 2>futures and there are so many awesome.</v>
<v Speaker 2>So instead,</v>

798
00:53:46.680 --> 00:53:47.513
<v Speaker 2>what do we do now since 2015 and </v>
<v Speaker 2>[inaudible] systems control model </v>

799
00:53:51.510 --> 00:53:52.343
<v Speaker 2>systems.</v>
<v Speaker 2>If you give as the controller the </v>

800
00:53:54.181 --> 00:53:58.980
<v Speaker 2>opportunity to learn by itself,</v>
<v Speaker 2>how to use theory,</v>

801
00:53:59.010 --> 00:53:59.843
<v Speaker 2>potentially relevant parts of the m of </v>
<v Speaker 2>the model and trying to solve new </v>

802
00:54:04.591 --> 00:54:07.350
<v Speaker 2>problems more quickly and if it wants </v>
<v Speaker 2>to,</v>

803
00:54:08.010 --> 00:54:08.843
<v Speaker 2>it can learn to ignore the m and </v>
<v Speaker 2>sometimes there's a good idea to ignore </v>

804
00:54:11.881 --> 00:54:12.714
<v Speaker 2>the m because it's really bad,</v>
<v Speaker 2>it's a bad predictor and this </v>

805
00:54:16.171 --> 00:54:17.670
<v Speaker 2>particular,</v>
<v Speaker 2>um,</v>

806
00:54:17.730 --> 00:54:19.180
<v Speaker 2>situation of life,</v>
<v Speaker 2>uh,</v>

807
00:54:19.230 --> 00:54:22.470
<v Speaker 2>where the control is currently trying to</v>
<v Speaker 2>maximize rewind,</v>

808
00:54:23.040 --> 00:54:23.873
<v Speaker 2>however it can also allow them to </v>
<v Speaker 2>address and exploit some of the sub </v>

809
00:54:27.721 --> 00:54:32.721
<v Speaker 2>programs that came about in the model </v>
<v Speaker 2>network through compressing as a data by</v>

810
00:54:35.161 --> 00:54:35.994
<v Speaker 2>predicting it.</v>
<v Speaker 2>So it now has an opportunity to reuse </v>

811
00:54:40.201 --> 00:54:41.034
<v Speaker 2>that code,</v>
<v Speaker 2>the algorithmic inflammation in the </v>

812
00:54:43.321 --> 00:54:44.154
<v Speaker 2>modern or trying to reduce its own </v>
<v Speaker 2>search space search that it can solve a </v>

813
00:54:49.981 --> 00:54:52.770
<v Speaker 2>new problem more quickly then without </v>
<v Speaker 2>the model</v>

814
00:54:53.810 --> 00:54:54.643
<v Speaker 6>compression.</v>
<v Speaker 6>So you're ultimately optimistic and </v>

815
00:54:58.761 --> 00:55:03.761
<v Speaker 6>excited about the power of our,</v>
<v Speaker 6>of reinforcement learning in the context</v>

816
00:55:04.011 --> 00:55:05.960
<v Speaker 6>of real systems.</v>
<v Speaker 6>Absolutely.</v>

817
00:55:05.961 --> 00:55:09.650
<v Speaker 6>Yeah.</v>
<v Speaker 6>So you see rl as a potential,</v>

818
00:55:10.110 --> 00:55:10.943
<v Speaker 6>having a huge impact beyond just sort of</v>
<v Speaker 6>the m part is often develop on </v>

819
00:55:17.870 --> 00:55:22.870
<v Speaker 6>supervised learning methods.</v>
<v Speaker 6>You see rl as a,</v>

820
00:55:22.941 --> 00:55:26.060
<v Speaker 6>uh,</v>
<v Speaker 6>for problems of self driving cars or any</v>

821
00:55:26.061 --> 00:55:31.040
<v Speaker 6>kind of applied side of robotics.</v>
<v Speaker 6>That's the correct,</v>

822
00:55:31.130 --> 00:55:33.680
<v Speaker 6>interesting direction for research in </v>
<v Speaker 6>your view.</v>

823
00:55:34.690 --> 00:55:35.523
<v Speaker 2>I do think so.</v>
<v Speaker 2>We have a company called NASCENCE </v>

824
00:55:37.391 --> 00:55:39.280
<v Speaker 2>nascence which,</v>
<v Speaker 2>um,</v>

825
00:55:39.340 --> 00:55:43.780
<v Speaker 2>has applied during placement learning </v>
<v Speaker 2>too little audis.</v>

826
00:55:44.090 --> 00:55:44.960
<v Speaker 6>There are these</v>

827
00:55:45.180 --> 00:55:50.180
<v Speaker 2>where's land to park without a teacher.</v>
<v Speaker 2>The same principles where you were stock</v>

828
00:55:50.390 --> 00:55:52.740
<v Speaker 2>cars.</v>
<v Speaker 2>So these little Audi is,</v>

829
00:55:52.741 --> 00:55:54.990
<v Speaker 2>they are small,</v>
<v Speaker 2>maybe like that,</v>

830
00:55:55.020 --> 00:55:59.370
<v Speaker 2>so much smaller than the real audis,</v>
<v Speaker 2>but they have all the sends Aras,</v>

831
00:55:59.371 --> 00:56:00.204
<v Speaker 2>uh,</v>
<v Speaker 2>that you find in the real audi is you </v>

832
00:56:01.261 --> 00:56:05.580
<v Speaker 2>find the cameras that Leanne sends us,</v>
<v Speaker 2>they'd go up to 120,</v>

833
00:56:05.610 --> 00:56:07.430
<v Speaker 2>20 kilometers an hour if you,</v>
<v Speaker 2>if,</v>

834
00:56:07.590 --> 00:56:09.420
<v Speaker 2>if they want to.</v>
<v Speaker 2>And,</v>

835
00:56:09.421 --> 00:56:10.254
<v Speaker 2>um,</v>
<v Speaker 2>and they are pain sensor ass basically </v>

836
00:56:12.451 --> 00:56:13.284
<v Speaker 2>and they don't want to bump against </v>
<v Speaker 2>obstacles and the Audis and so on as </v>

837
00:56:17.781 --> 00:56:18.760
<v Speaker 2>they,</v>
<v Speaker 2>um,</v>

838
00:56:19.000 --> 00:56:24.000
<v Speaker 2>my salon like little babies to park </v>
<v Speaker 2>takes the raw vision input and translate</v>

839
00:56:25.151 --> 00:56:28.840
<v Speaker 2>that into actions that lead to </v>
<v Speaker 2>successful packing behavior,</v>

840
00:56:29.380 --> 00:56:31.270
<v Speaker 2>which is a rewarding thing.</v>
<v Speaker 2>And yes,</v>

841
00:56:31.271 --> 00:56:36.130
<v Speaker 2>they learned that.</v>
<v Speaker 2>We have examples like that and it's only</v>

842
00:56:36.131 --> 00:56:37.330
<v Speaker 2>in the beginning,</v>
<v Speaker 2>um,</v>

843
00:56:37.390 --> 00:56:38.223
<v Speaker 2>know this is just the tip of the iceberg</v>
<v Speaker 2>and I believe the next wave of ai is </v>

844
00:56:43.091 --> 00:56:44.710
<v Speaker 2>going to be all about that.</v>

845
00:56:45.250 --> 00:56:46.083
<v Speaker 2>So at the moment,</v>
<v Speaker 2>the current wave of AI is about passive </v>

846
00:56:49.240 --> 00:56:53.260
<v Speaker 2>pattern observation and the prediction </v>
<v Speaker 2>and um,</v>

847
00:56:53.680 --> 00:56:54.513
<v Speaker 2>and that's what you have on your </v>
<v Speaker 2>smartphone and what the major companies </v>

848
00:56:57.221 --> 00:57:02.080
<v Speaker 2>on the Pacific of Mri using to sell you </v>
<v Speaker 2>ads to do marketing.</v>

849
00:57:02.320 --> 00:57:05.050
<v Speaker 2>That's the crown,</v>
<v Speaker 2>a source of profit in ai.</v>

850
00:57:05.590 --> 00:57:08.030
<v Speaker 2>And that's only one or 2% of the wild </v>
<v Speaker 2>economy.</v>

851
00:57:08.040 --> 00:57:08.873
<v Speaker 2>Him.</v>
<v Speaker 2>Yeah.</v>

852
00:57:08.960 --> 00:57:09.793
<v Speaker 2>Um,</v>
<v Speaker 2>which is big enough to make these </v>

853
00:57:12.051 --> 00:57:15.080
<v Speaker 2>companies is pretty much the most </v>
<v Speaker 2>valuable companies in the hand.</v>

854
00:57:15.500 --> 00:57:19.250
<v Speaker 2>But there's a much,</v>
<v Speaker 2>much bigger practice,</v>

855
00:57:19.251 --> 00:57:21.780
<v Speaker 2>enough the economy going to be affected </v>
<v Speaker 2>by the next wave,</v>

856
00:57:21.960 --> 00:57:22.793
<v Speaker 2>which is really about machines that </v>
<v Speaker 2>shape the data through it was our own </v>

857
00:57:27.040 --> 00:57:27.873
<v Speaker 2>axons.</v>
<v Speaker 2>Think simulation is ultimately the </v>

858
00:57:30.721 --> 00:57:31.554
<v Speaker 2>biggest way that that though those </v>
<v Speaker 2>methods will be successful in the next </v>

859
00:57:35.911 --> 00:57:36.840
<v Speaker 2>10,</v>
<v Speaker 2>20 years.</v>

860
00:57:36.841 --> 00:57:38.460
<v Speaker 2>We're not talking about a hundred years </v>
<v Speaker 2>from now.</v>

861
00:57:38.850 --> 00:57:42.650
<v Speaker 2>We're talking about sort of the near </v>
<v Speaker 2>term impact of rl.</v>

862
00:57:42.660 --> 00:57:43.493
<v Speaker 2>Do you think really good simulation is </v>
<v Speaker 2>required or is there other techniques </v>

863
00:57:47.251 --> 00:57:48.420
<v Speaker 2>like imitation,</v>
<v Speaker 2>learning,</v>

864
00:57:48.950 --> 00:57:49.783
<v Speaker 2>you know,</v>
<v Speaker 2>observing other humans operating in the </v>

865
00:57:53.251 --> 00:57:53.821
<v Speaker 2>real world,</v>
<v Speaker 2>where,</v>

866
00:57:53.821 --> 00:57:56.550
<v Speaker 2>where do you think the success will come</v>
<v Speaker 2>from?</v>

867
00:57:57.660 --> 00:57:58.493
<v Speaker 2>So at the moment we have a tendency of </v>
<v Speaker 2>using physics simulations to learn </v>

868
00:58:05.150 --> 00:58:08.350
<v Speaker 2>behavior for machines that,</v>
<v Speaker 2>um,</v>

869
00:58:08.690 --> 00:58:12.620
<v Speaker 2>learn to solve problems that humans also</v>
<v Speaker 2>do not know how to solve.</v>

870
00:58:13.970 --> 00:58:14.803
<v Speaker 2>However,</v>
<v Speaker 2>this is not the future because the </v>

871
00:58:16.401 --> 00:58:17.234
<v Speaker 2>future is and what little babies do or </v>
<v Speaker 2>they don't use a physics engine to </v>

872
00:58:21.501 --> 00:58:22.640
<v Speaker 2>simulate the wild.</v>
<v Speaker 2>No,</v>

873
00:58:22.970 --> 00:58:25.460
<v Speaker 2>they learn a predictive model of the </v>
<v Speaker 2>wild,</v>

874
00:58:26.180 --> 00:58:27.140
<v Speaker 2>which,</v>
<v Speaker 2>um,</v>

875
00:58:27.650 --> 00:58:28.483
<v Speaker 2>maybe sometimes it's wrong in many ways,</v>
<v Speaker 2>but captures all kinds of important </v>

876
00:58:33.051 --> 00:58:33.884
<v Speaker 2>abstract,</v>
<v Speaker 2>high level predictions which are really </v>

877
00:58:35.721 --> 00:58:38.820
<v Speaker 2>important to be successful.</v>
<v Speaker 2>And,</v>

878
00:58:38.850 --> 00:58:40.550
<v Speaker 2>um,</v>
<v Speaker 2>and that's what is,</v>

879
00:58:41.230 --> 00:58:44.300
<v Speaker 2>what's the future 30 years ago when he </v>
<v Speaker 2>started that type of free sites.</v>

880
00:58:44.330 --> 00:58:47.660
<v Speaker 2>But it's still the future and now we </v>
<v Speaker 2>know much better how to go there,</v>

881
00:58:47.690 --> 00:58:48.530
<v Speaker 2>um,</v>
<v Speaker 2>uh,</v>

882
00:58:49.060 --> 00:58:50.000
<v Speaker 2>to,</v>
<v Speaker 2>to move that,</v>

883
00:58:50.180 --> 00:58:51.013
<v Speaker 2>to move forward and to really make work </v>
<v Speaker 2>in systems based on that where you have </v>

884
00:58:55.820 --> 00:58:56.653
<v Speaker 2>a learning model,</v>
<v Speaker 2>lots of odd and model off the wild that </v>

885
00:58:58.461 --> 00:59:01.550
<v Speaker 2>learns to predict what's going to happen</v>
<v Speaker 2>if I do that and that.</v>

886
00:59:01.880 --> 00:59:02.940
<v Speaker 2>And then,</v>
<v Speaker 2>uh,</v>

887
00:59:04.310 --> 00:59:05.143
<v Speaker 2>the controller uses and model to more </v>
<v Speaker 2>quickly learn successful action </v>

888
00:59:10.131 --> 00:59:12.560
<v Speaker 2>sequences.</v>
<v Speaker 2>And then of course,</v>

889
00:59:12.580 --> 00:59:15.260
<v Speaker 2>always this curiosity thing and the </v>
<v Speaker 2>beginning of the model and stupid.</v>

890
00:59:15.261 --> 00:59:16.094
<v Speaker 2>So the controller should be motivated to</v>
<v Speaker 2>come up with experiments with action </v>

891
00:59:19.971 --> 00:59:23.780
<v Speaker 2>sequences that lead to data.</v>
<v Speaker 2>Does that improve as a model,</v>

892
00:59:24.110 --> 00:59:25.110
<v Speaker 6>do you think,</v>
<v Speaker 6>uh,</v>

893
00:59:26.150 --> 00:59:26.983
<v Speaker 6>improving the model,</v>
<v Speaker 6>constructing and understanding of the </v>

894
00:59:28.281 --> 00:59:32.150
<v Speaker 6>world in this connection?</v>
<v Speaker 6>Is that now the,</v>

895
00:59:32.350 --> 00:59:33.183
<v Speaker 6>the popular approaches that have been </v>
<v Speaker 6>successful or you're grounded in ideas </v>

896
00:59:37.011 --> 00:59:40.700
<v Speaker 6>of neural networks,</v>
<v Speaker 6>but in the 80s with expert systems,</v>

897
00:59:40.701 --> 00:59:41.534
<v Speaker 6>there's symbolic ai approaches which uh,</v>
<v Speaker 6>to us humans are more intuitive in the </v>

898
00:59:47.901 --> 00:59:48.734
<v Speaker 6>sense that it makes sense that you build</v>
<v Speaker 6>up knowledge and just knowledge </v>

899
00:59:51.471 --> 00:59:52.304
<v Speaker 6>representation.</v>
<v Speaker 6>What kind of lessons can we draw into </v>

900
00:59:53.960 --> 00:59:58.960
<v Speaker 6>our current approaches in four from </v>
<v Speaker 6>expert systems from symbolic Ai.</v>

901
01:00:00.570 --> 01:00:01.403
<v Speaker 2>So I um,</v>
<v Speaker 2>became aware of all of that in the ats </v>

902
01:00:04.621 --> 01:00:08.850
<v Speaker 2>and back then a lottery program logic </v>
<v Speaker 2>programming was a huge thing.</v>

903
01:00:08.920 --> 01:00:10.590
<v Speaker 2>It was inspiring to you yourself.</v>

904
01:00:10.850 --> 01:00:14.450
<v Speaker 6>Did you find it compelling because most,</v>
<v Speaker 6>a lot of your work was,</v>

905
01:00:14.451 --> 01:00:16.610
<v Speaker 6>uh,</v>
<v Speaker 6>not so much in that realm,</v>

906
01:00:16.611 --> 01:00:18.380
<v Speaker 6>right?</v>
<v Speaker 6>Is more in the learning systems,</v>

907
01:00:18.530 --> 01:00:20.850
<v Speaker 2>yes or no,</v>
<v Speaker 2>but we did all of that is,</v>

908
01:00:20.910 --> 01:00:23.030
<v Speaker 2>are we,</v>
<v Speaker 2>my first,</v>

909
01:00:23.031 --> 01:00:25.010
<v Speaker 2>um,</v>
<v Speaker 2>publication ever actually was,</v>

910
01:00:25.011 --> 01:00:28.080
<v Speaker 2>um,</v>
<v Speaker 2>1987 was a,</v>

911
01:00:28.130 --> 01:00:29.800
<v Speaker 2>the implementation of,</v>
<v Speaker 2>um,</v>

912
01:00:29.840 --> 01:00:33.980
<v Speaker 2>genetic algorithm of a genetic </v>
<v Speaker 2>programming system in prolog,</v>

913
01:00:35.300 --> 01:00:37.790
<v Speaker 2>prolog.</v>
<v Speaker 2>That's what you learned back then,</v>

914
01:00:37.791 --> 01:00:41.300
<v Speaker 2>which is a logic programming language </v>
<v Speaker 2>and the Japanese,</v>

915
01:00:41.301 --> 01:00:45.440
<v Speaker 2>the anthis huge fifth generation ai </v>
<v Speaker 2>project,</v>

916
01:00:45.500 --> 01:00:48.950
<v Speaker 2>which was mostly about logic programming</v>
<v Speaker 2>back then.</v>

917
01:00:49.310 --> 01:00:51.560
<v Speaker 2>Although in your network exists,</v>
<v Speaker 2>existed and,</v>

918
01:00:51.810 --> 01:00:56.810
<v Speaker 2>and well known back then and deep </v>
<v Speaker 2>learning has existed since 1965.</v>

919
01:00:57.561 --> 01:00:59.750
<v Speaker 2>Um,</v>
<v Speaker 2>since this guy in the Ukraine,</v>

920
01:00:59.800 --> 01:01:01.700
<v Speaker 2>um,</v>
<v Speaker 2>eva can echo started it,</v>

921
01:01:02.180 --> 01:01:03.240
<v Speaker 2>but,</v>
<v Speaker 2>um,</v>

922
01:01:03.710 --> 01:01:04.543
<v Speaker 2>the Japanese and many other people,</v>
<v Speaker 2>they focus really on this logic </v>

923
01:01:07.071 --> 01:01:07.904
<v Speaker 2>programming.</v>
<v Speaker 2>And I was influenced to the extent that </v>

924
01:01:09.771 --> 01:01:10.521
<v Speaker 2>I said,</v>
<v Speaker 2>okay,</v>

925
01:01:10.521 --> 01:01:15.290
<v Speaker 2>let's take these biologically inspired </v>
<v Speaker 2>Ireland's like evolution,</v>

926
01:01:15.760 --> 01:01:16.610
<v Speaker 2>uh,</v>
<v Speaker 2>programs,</v>

927
01:01:16.910 --> 01:01:18.050
<v Speaker 2>uh,</v>
<v Speaker 2>and um,</v>

928
01:01:18.110 --> 01:01:19.020
<v Speaker 2>and,</v>
<v Speaker 2>and,</v>

929
01:01:20.090 --> 01:01:22.310
<v Speaker 2>and implement that in the language,</v>
<v Speaker 2>which I know,</v>

930
01:01:22.311 --> 01:01:25.490
<v Speaker 2>which was prologue for example back then</v>
<v Speaker 2>and then,</v>

931
01:01:25.520 --> 01:01:26.820
<v Speaker 2>um,</v>
<v Speaker 2>in,</v>

932
01:01:26.821 --> 01:01:31.220
<v Speaker 2>in many ways as came back later because </v>
<v Speaker 2>the Google machine for example,</v>

933
01:01:31.880 --> 01:01:35.540
<v Speaker 2>has a proof search on board and without </v>
<v Speaker 2>that it would not be optimal.</v>

934
01:01:35.770 --> 01:01:36.603
<v Speaker 2>While mark was hooked as a universal </v>
<v Speaker 2>algorithm for solving all well defined </v>

935
01:01:39.701 --> 01:01:44.701
<v Speaker 2>problems as approved search on board.</v>
<v Speaker 2>So that's very much logic programming.</v>

936
01:01:46.430 --> 01:01:48.530
<v Speaker 2>Without that,</v>
<v Speaker 2>it would not be a,</v>

937
01:01:48.531 --> 01:01:51.170
<v Speaker 2>some talking optimum.</v>
<v Speaker 2>But then on the other hand,</v>

938
01:01:51.171 --> 01:01:53.540
<v Speaker 2>because we have a very pragmatic guys </v>
<v Speaker 2>also,</v>

939
01:01:53.950 --> 01:01:54.783
<v Speaker 2>um,</v>
<v Speaker 2>we focused on recon you on and that's </v>

940
01:01:58.351 --> 01:01:59.780
<v Speaker 2>where I was and,</v>
<v Speaker 2>and,</v>

941
01:02:00.090 --> 01:02:02.090
<v Speaker 2>and sub optimal,</v>
<v Speaker 2>uh,</v>

942
01:02:02.360 --> 01:02:05.720
<v Speaker 2>stuff such as gradient base search and </v>
<v Speaker 2>program space.</v>

943
01:02:05.870 --> 01:02:09.060
<v Speaker 2>Rather than prove up the optimal thing,</v>
<v Speaker 2>things</v>

944
01:02:09.140 --> 01:02:13.290
<v Speaker 6>that logic programming does it certain </v>
<v Speaker 6>certainly has a usefulness in,</v>

945
01:02:13.700 --> 01:02:14.533
<v Speaker 6>uh,</v>
<v Speaker 6>when you're trying to construct </v>

946
01:02:15.361 --> 01:02:18.780
<v Speaker 6>something provably optimal approvable </v>
<v Speaker 6>good or something like that.</v>

947
01:02:18.960 --> 01:02:21.450
<v Speaker 6>But is it useful for,</v>
<v Speaker 6>for practical problems?</v>

948
01:02:21.950 --> 01:02:22.783
<v Speaker 2>It's really useful for our theory.</v>
<v Speaker 2>Improving the best deer improvers today </v>

949
01:02:25.711 --> 01:02:27.950
<v Speaker 2>are not neural networks,</v>
<v Speaker 2>right?</v>

950
01:02:28.000 --> 01:02:31.340
<v Speaker 2>No.</v>
<v Speaker 2>Say a logic programming systems and they</v>

951
01:02:31.341 --> 01:02:32.174
<v Speaker 2>are much better theater improvers then </v>
<v Speaker 2>most math students in the first or </v>

952
01:02:36.531 --> 01:02:37.460
<v Speaker 2>second semester.</v>

953
01:02:37.830 --> 01:02:40.400
<v Speaker 6>Hmm.</v>
<v Speaker 6>But for reasoning to,</v>

954
01:02:40.401 --> 01:02:44.750
<v Speaker 6>for playing games of go or chess or for </v>
<v Speaker 6>robots,</v>

955
01:02:44.810 --> 01:02:49.010
<v Speaker 6>autonomous vehicles that operate in the </v>
<v Speaker 6>real world or a object manipulation,</v>

956
01:02:49.490 --> 01:02:50.810
<v Speaker 6>you think learning.</v>

957
01:02:51.220 --> 01:02:53.230
<v Speaker 2>Yeah.</v>
<v Speaker 2>As long as the problem is have little to</v>

958
01:02:53.231 --> 01:02:58.231
<v Speaker 2>do with um,</v>
<v Speaker 2>with theo improving themselves,</v>

959
01:02:58.660 --> 01:03:01.480
<v Speaker 2>then um,</v>
<v Speaker 2>as long as that is not the case,</v>

960
01:03:01.481 --> 01:03:02.314
<v Speaker 2>um,</v>
<v Speaker 2>you,</v>

961
01:03:02.890 --> 01:03:05.260
<v Speaker 2>you were just wanting to have better </v>
<v Speaker 2>pattern recognition.</v>

962
01:03:05.290 --> 01:03:06.123
<v Speaker 2>So to build a self driving car you want </v>
<v Speaker 2>to have better pattern recognition and </v>

963
01:03:09.401 --> 01:03:10.234
<v Speaker 2>um,</v>
<v Speaker 2>and a pedestrian recognition and all </v>

964
01:03:12.761 --> 01:03:16.120
<v Speaker 2>these things and you want to your </v>
<v Speaker 2>minimum,</v>

965
01:03:16.150 --> 01:03:19.030
<v Speaker 2>you want to minimize the number of false</v>
<v Speaker 2>positives,</v>

966
01:03:19.031 --> 01:03:21.310
<v Speaker 2>which is currently is slowing down self </v>
<v Speaker 2>driving cars.</v>

967
01:03:21.311 --> 01:03:23.290
<v Speaker 2>In many ways.</v>
<v Speaker 2>And um,</v>

968
01:03:23.380 --> 01:03:26.170
<v Speaker 2>and all of that has very little to do </v>
<v Speaker 2>with logic programming.</v>

969
01:03:26.260 --> 01:03:27.093
<v Speaker 2>Yeah.</v>

970
01:03:27.510 --> 01:03:32.510
<v Speaker 6>What are you most excited about in terms</v>
<v Speaker 6>of directions of artificial intelligence</v>

971
01:03:34.051 --> 01:03:38.460
<v Speaker 6>at this moment and then the next few </v>
<v Speaker 6>years in your own research,</v>

972
01:03:38.490 --> 01:03:39.840
<v Speaker 6>in the broader community?</v>

973
01:03:41.560 --> 01:03:42.393
<v Speaker 7>So I think in the not so distant future,</v>
<v Speaker 7>we will have for the first time little </v>

974
01:03:49.571 --> 01:03:52.930
<v Speaker 7>robots that learn like kids.</v>
<v Speaker 7>Um,</v>

975
01:03:53.020 --> 01:03:56.280
<v Speaker 7>I will be able to say to the robot,</v>
<v Speaker 7>um,</v>

976
01:03:57.390 --> 01:03:58.223
<v Speaker 7>lucky a robot,</v>
<v Speaker 7>we are going to assemble as much fun </v>

977
01:04:00.910 --> 01:04:04.250
<v Speaker 7>that's takes a slab of plastic,</v>
<v Speaker 7>um,</v>

978
01:04:04.570 --> 01:04:08.080
<v Speaker 7>and the school driver and let's screw </v>
<v Speaker 7>and the screwed like that,</v>

979
01:04:08.110 --> 01:04:09.130
<v Speaker 7>you know,</v>
<v Speaker 7>not,</v>

980
01:04:09.160 --> 01:04:10.670
<v Speaker 7>not like that,</v>
<v Speaker 7>like that,</v>

981
01:04:11.620 --> 01:04:12.730
<v Speaker 7>not like that,</v>
<v Speaker 7>like that.</v>

982
01:04:13.600 --> 01:04:17.020
<v Speaker 7>And I don't have a data lover or </v>
<v Speaker 7>something.</v>

983
01:04:17.050 --> 01:04:17.883
<v Speaker 7>He will see me and he will hear me and </v>
<v Speaker 7>he tried try to do something with his </v>

984
01:04:23.231 --> 01:04:24.064
<v Speaker 7>own actuators,</v>
<v Speaker 7>which will be really different from </v>

985
01:04:25.691 --> 01:04:26.524
<v Speaker 7>mine,</v>
<v Speaker 7>but he will understand the difference </v>

986
01:04:28.090 --> 01:04:33.090
<v Speaker 7>and we'll learn to imitate me,</v>
<v Speaker 7>but not in the supervised way.</v>

987
01:04:34.440 --> 01:04:35.273
<v Speaker 7>Um,</v>
<v Speaker 7>where a teacher has giving targets </v>

988
01:04:37.440 --> 01:04:40.030
<v Speaker 7>signals for all his muscles all the </v>
<v Speaker 7>time.</v>

989
01:04:40.180 --> 01:04:43.300
<v Speaker 7>No.</v>
<v Speaker 7>By doing this high level imitation where</v>

990
01:04:43.301 --> 01:04:44.134
<v Speaker 7>he first has to learn to imitate me and </v>
<v Speaker 7>then to interpret these additional </v>

991
01:04:48.041 --> 01:04:50.270
<v Speaker 7>noises coming from my mouth,</v>
<v Speaker 7>um,</v>

992
01:04:50.410 --> 01:04:51.243
<v Speaker 7>as helping helpful signals to,</v>
<v Speaker 7>to do that banner and then it will by </v>

993
01:04:57.671 --> 01:04:58.504
<v Speaker 7>itself come up with a faster ways and </v>
<v Speaker 7>more efficient ways of doing the same </v>

994
01:05:02.591 --> 01:05:03.424
<v Speaker 7>thing.</v>

995
01:05:03.730 --> 01:05:04.563
<v Speaker 7>And finally I stopped his learning </v>
<v Speaker 7>algorithm and make a million copies and </v>

996
01:05:09.671 --> 01:05:10.504
<v Speaker 7>sell it.</v>
<v Speaker 7>And so at the moment this is not </v>

997
01:05:12.881 --> 01:05:17.881
<v Speaker 7>possible but we already see how we are </v>
<v Speaker 7>going to get them and you can imagine to</v>

998
01:05:18.851 --> 01:05:22.150
<v Speaker 7>the extent that this works economically </v>
<v Speaker 7>and cheaply,</v>

999
01:05:22.151 --> 01:05:22.984
<v Speaker 7>it's going to change everything.</v>
<v Speaker 7>Almost our production is going to be </v>

1000
01:05:28.841 --> 01:05:33.841
<v Speaker 7>effected by that and a much bigger wave,</v>
<v Speaker 7>much bigger ai wave is coming.</v>

1001
01:05:36.431 --> 01:05:38.380
<v Speaker 7>Then the one that we are currently </v>
<v Speaker 7>witnessing,</v>

1002
01:05:38.381 --> 01:05:41.740
<v Speaker 7>which is mostly about passive pattern </v>
<v Speaker 7>recognition on your smartphone.</v>

1003
01:05:42.140 --> 01:05:42.973
<v Speaker 7>This is about active machines that </v>
<v Speaker 7>shapes a data through the actions they </v>

1004
01:05:46.991 --> 01:05:50.200
<v Speaker 7>are executing and they learned to do </v>
<v Speaker 7>that in a good way.</v>

1005
01:05:51.780 --> 01:05:52.090
<v Speaker 8>Okay.</v>

1006
01:05:52.090 --> 01:05:56.680
<v Speaker 7>So many of the traditional industries </v>
<v Speaker 7>are going to be affected by that.</v>

1007
01:05:56.681 --> 01:06:00.130
<v Speaker 7>All the companies that are building </v>
<v Speaker 7>machines,</v>

1008
01:06:01.730 --> 01:06:05.600
<v Speaker 7>well equipped for you as machines with </v>
<v Speaker 7>cameras and other sense auras.</v>

1009
01:06:05.900 --> 01:06:06.733
<v Speaker 7>And they are going to learn to solve all</v>
<v Speaker 7>kinds of problems through interaction </v>

1010
01:06:12.321 --> 01:06:13.154
<v Speaker 7>with humans but also a lot on their own </v>
<v Speaker 7>to improve what they already can do </v>

1011
01:06:16.671 --> 01:06:17.504
<v Speaker 7>them.</v>
<v Speaker 7>And lots of old economy is going to be </v>

1012
01:06:23.161 --> 01:06:26.930
<v Speaker 7>effected by that.</v>
<v Speaker 7>And in recent years I have seen that old</v>

1013
01:06:26.950 --> 01:06:30.320
<v Speaker 7>economy is actually waking up and </v>
<v Speaker 7>realizing that those are the canes.</v>

1014
01:06:31.280 --> 01:06:32.113
<v Speaker 7>And um,</v>

1015
01:06:32.190 --> 01:06:35.160
<v Speaker 9>are you optimistic about the future?</v>
<v Speaker 9>Are you concerned?</v>

1016
01:06:35.660 --> 01:06:37.480
<v Speaker 9>Uh,</v>
<v Speaker 9>there's a lot of people concerned on,</v>

1017
01:06:37.540 --> 01:06:42.240
<v Speaker 9>in the near term about the </v>
<v Speaker 9>transformation of the nature of work.</v>

1018
01:06:43.050 --> 01:06:43.883
<v Speaker 9>The kind of ideas he just suggested </v>
<v Speaker 9>would have a significant impact of what </v>

1019
01:06:47.611 --> 01:06:52.020
<v Speaker 9>kinds of things could be automated.</v>
<v Speaker 9>Are you optimistic about that future?</v>

1020
01:06:52.030 --> 01:06:52.863
<v Speaker 9>Are you nervous about that future?</v>
<v Speaker 9>And looking a little bit farther into </v>

1021
01:06:57.841 --> 01:07:00.150
<v Speaker 9>the future,</v>
<v Speaker 9>there's people like Elon Musk,</v>

1022
01:07:00.750 --> 01:07:01.583
<v Speaker 9>uh,</v>
<v Speaker 9>Stuart Russell concerned about the </v>

1023
01:07:03.511 --> 01:07:08.511
<v Speaker 9>existential threats of that future.</v>
<v Speaker 9>So in the near term job loss in the long</v>

1024
01:07:09.051 --> 01:07:09.884
<v Speaker 9>term existential threat or these </v>
<v Speaker 9>concerns to you or you ultimately </v>

1025
01:07:12.961 --> 01:07:13.794
<v Speaker 9>optimistic.</v>

1026
01:07:15.600 --> 01:07:19.380
<v Speaker 7>So let's first address the near future.</v>

1027
01:07:22.920 --> 01:07:27.920
<v Speaker 7>We have had predictions off job losses </v>
<v Speaker 7>for many decades.</v>

1028
01:07:28.080 --> 01:07:31.470
<v Speaker 7>For example,</v>
<v Speaker 7>when industrial robots came along,</v>

1029
01:07:32.970 --> 01:07:35.980
<v Speaker 7>many pete,</v>
<v Speaker 7>many people predict and lots of jobs are</v>

1030
01:07:35.981 --> 01:07:36.814
<v Speaker 7>going to get lost.</v>
<v Speaker 7>And in a sense they were right because </v>

1031
01:07:42.961 --> 01:07:43.794
<v Speaker 7>back then there were car factories on </v>
<v Speaker 7>hundreds of people and these factories </v>

1032
01:07:49.831 --> 01:07:50.664
<v Speaker 7>assembled cars and today the same car </v>
<v Speaker 7>factories have hundreds of robots and </v>

1033
01:07:54.061 --> 01:07:59.061
<v Speaker 7>maybe three guys watching the robots.</v>
<v Speaker 7>On the other hand,</v>

1034
01:08:00.570 --> 01:08:03.210
<v Speaker 7>those countries that have lots of </v>
<v Speaker 7>robots,</v>

1035
01:08:03.211 --> 01:08:04.110
<v Speaker 7>para camp,</v>
<v Speaker 7>Aton,</v>

1036
01:08:04.860 --> 01:08:05.850
<v Speaker 7>Japan,</v>
<v Speaker 7>Korea,</v>

1037
01:08:05.890 --> 01:08:06.960
<v Speaker 7>Germany,</v>
<v Speaker 7>Switzerland,</v>

1038
01:08:07.260 --> 01:08:12.260
<v Speaker 7>a couple of other countries,</v>
<v Speaker 7>they have really low unemployment rates.</v>

1039
01:08:14.190 --> 01:08:19.190
<v Speaker 7>Somehow all of new jobs were created </v>
<v Speaker 7>accent and nobody anticipated.</v>

1040
01:08:20.470 --> 01:08:23.950
<v Speaker 7>There's always jobs.</v>
<v Speaker 7>And um,</v>

1041
01:08:24.830 --> 01:08:25.663
<v Speaker 7>decades ago I always said it's really </v>
<v Speaker 7>easy to say which jobs are going to get </v>

1042
01:08:31.491 --> 01:08:32.324
<v Speaker 7>lost,</v>
<v Speaker 7>but it's really hard to predict the new </v>

1043
01:08:33.351 --> 01:08:36.920
<v Speaker 7>ones.</v>
<v Speaker 7>30 years ago,</v>

1044
01:08:37.010 --> 01:08:37.843
<v Speaker 7>who would have predicted all these </v>
<v Speaker 7>people and making money as a youtube </v>

1045
01:08:42.020 --> 01:08:42.950
<v Speaker 7>bloggers.</v>

1046
01:08:43.070 --> 01:08:46.830
<v Speaker 7>For example,</v>
<v Speaker 7>200 years ago,</v>

1047
01:08:47.580 --> 01:08:52.580
<v Speaker 7>60% of all people used to work in </v>
<v Speaker 7>agriculture today,</v>

1048
01:08:54.181 --> 01:08:59.181
<v Speaker 7>maybe 1%,</v>
<v Speaker 7>but still only,</v>

1049
01:08:59.401 --> 01:09:01.230
<v Speaker 7>I dunno,</v>
<v Speaker 7>5% unemployment,</v>

1050
01:09:02.100 --> 01:09:05.370
<v Speaker 7>lots of new jobs were created and Homo </v>
<v Speaker 7>Ludens,</v>

1051
01:09:05.590 --> 01:09:10.470
<v Speaker 7>the playing man is inventing new jobs </v>
<v Speaker 7>all the time.</v>

1052
01:09:10.500 --> 01:09:11.333
<v Speaker 7>Most of these jobs are not existentially</v>
<v Speaker 7>necessary for the survival of our </v>

1053
01:09:16.951 --> 01:09:17.784
<v Speaker 7>species.</v>
<v Speaker 7>There are only very few existentially </v>

1054
01:09:21.871 --> 01:09:26.040
<v Speaker 7>necessary jobs such as farming and </v>
<v Speaker 7>building houses and,</v>

1055
01:09:26.360 --> 01:09:27.193
<v Speaker 7>and warming up the houses.</v>
<v Speaker 7>But less than 10% of the population is </v>

1056
01:09:30.211 --> 01:09:31.044
<v Speaker 7>doing that.</v>
<v Speaker 7>And most of these newly invented jobs </v>

1057
01:09:33.571 --> 01:09:34.780
<v Speaker 7>are about,</v>
<v Speaker 7>um,</v>

1058
01:09:36.480 --> 01:09:40.740
<v Speaker 7>interacting with other people in new </v>
<v Speaker 7>ways through new media and so on,</v>

1059
01:09:41.760 --> 01:09:45.960
<v Speaker 7>getting new kite types of Kudos and </v>
<v Speaker 7>forms of likes and whatever,</v>

1060
01:09:46.200 --> 01:09:50.460
<v Speaker 7>and even making money through that Homo </v>
<v Speaker 7>Ludens.</v>

1061
01:09:50.461 --> 01:09:51.294
<v Speaker 7>The playing man doesn't want to be an </v>
<v Speaker 7>implied and that's why he's inventing </v>

1062
01:09:54.781 --> 01:09:55.614
<v Speaker 7>new jobs all the time.</v>
<v Speaker 7>And he keeps considering these jobs as </v>

1063
01:10:00.901 --> 01:10:05.901
<v Speaker 7>really important and there's investing a</v>
<v Speaker 7>lot of energy and hours of work and to,</v>

1064
01:10:06.310 --> 01:10:07.830
<v Speaker 7>and to those new jobs,</v>

1065
01:10:08.130 --> 01:10:08.963
<v Speaker 9>there's a quite beautifully put,</v>
<v Speaker 9>were really nervous about the future </v>

1066
01:10:11.961 --> 01:10:14.690
<v Speaker 9>because we can't predict what kind of </v>
<v Speaker 9>new jazz would be created.</v>

1067
01:10:14.950 --> 01:10:19.210
<v Speaker 9>But your ultimately optimistic that we,</v>
<v Speaker 9>uh,</v>

1068
01:10:19.300 --> 01:10:24.300
<v Speaker 9>humans are so restless that we create </v>
<v Speaker 9>and give meaning to newer in your jobs.</v>

1069
01:10:24.981 --> 01:10:25.814
<v Speaker 9>Totally new likes on faith,</v>
<v Speaker 9>things that get likes on facebook or </v>

1070
01:10:30.231 --> 01:10:31.064
<v Speaker 9>whatever the social platform is.</v>
<v Speaker 9>So what about long term existential </v>

1071
01:10:35.301 --> 01:10:36.134
<v Speaker 9>threat of ai or our whole civilization </v>
<v Speaker 9>may be swallowed up by this ultra super </v>

1072
01:10:42.771 --> 01:10:44.300
<v Speaker 9>intelligent systems.</v>

1073
01:10:45.290 --> 01:10:48.420
<v Speaker 7>Maybe it's not going to be smaller dub,</v>
<v Speaker 7>but um,</v>

1074
01:10:50.120 --> 01:10:50.953
<v Speaker 7>I'd be surprised if a b where we humans </v>
<v Speaker 7>were the last step and the evolution of </v>

1075
01:10:57.021 --> 01:11:00.250
<v Speaker 7>the universe.</v>
<v Speaker 7>And um,</v>

1076
01:11:00.420 --> 01:11:01.253
<v Speaker 7>you,</v>
<v Speaker 7>you've actually had this beautiful </v>

1077
01:11:03.021 --> 01:11:03.854
<v Speaker 7>comments somewhere that I've seen saying</v>
<v Speaker 7>that artificial quite insightful is </v>

1078
01:11:09.951 --> 01:11:14.100
<v Speaker 7>artificial general intelligence systems.</v>
<v Speaker 7>Jessica as humans will likely</v>

1079
01:11:14.100 --> 01:11:14.933
<v Speaker 9>not want to interact with humans.</v>
<v Speaker 9>They'll just interact amongst </v>

1080
01:11:17.491 --> 01:11:18.324
<v Speaker 9>themselves,</v>
<v Speaker 9>just like ants interact amongst </v>

1081
01:11:20.311 --> 01:11:24.630
<v Speaker 9>themselves and only tangentially </v>
<v Speaker 9>interact with humans.</v>

1082
01:11:25.410 --> 01:11:27.870
<v Speaker 9>And it's,</v>
<v Speaker 9>it's quite an interesting idea that once</v>

1083
01:11:27.871 --> 01:11:31.660
<v Speaker 9>we create a gi,</v>
<v Speaker 9>they will lose interest in humans and,</v>

1084
01:11:31.710 --> 01:11:36.180
<v Speaker 9>and have compete for their own facebook </v>
<v Speaker 9>likes on their own social platforms.</v>

1085
01:11:36.750 --> 01:11:38.530
<v Speaker 9>So within that,</v>
<v Speaker 9>uh,</v>

1086
01:11:38.700 --> 01:11:40.110
<v Speaker 9>quite elegant idea,</v>

1087
01:11:40.900 --> 01:11:42.950
<v Speaker 7>the,</v>
<v Speaker 7>how do we know</v>

1088
01:11:43.350 --> 01:11:48.350
<v Speaker 9>in a hypothetical sense that there's not</v>
<v Speaker 9>already intelligent systems out there?</v>

1089
01:11:48.841 --> 01:11:53.841
<v Speaker 9>How do you think broadly of general </v>
<v Speaker 9>intelligence greater than us,</v>

1090
01:11:54.330 --> 01:11:58.530
<v Speaker 9>how would we know it's out there?</v>
<v Speaker 9>How do we know it's around us?</v>

1091
01:11:59.160 --> 01:12:00.300
<v Speaker 9>And could it already be,</v>

1092
01:12:01.940 --> 01:12:06.200
<v Speaker 7>I'd be surprised if within the next few </v>
<v Speaker 7>decades or something like that,</v>

1093
01:12:07.340 --> 01:12:08.173
<v Speaker 7>the um,</v>
<v Speaker 7>the won't have ais are truly smart in </v>

1094
01:12:12.381 --> 01:12:13.214
<v Speaker 7>every single way and better problem </v>
<v Speaker 7>solvers and almost every single </v>

1095
01:12:15.591 --> 01:12:16.424
<v Speaker 7>important way.</v>
<v Speaker 7>And I'd be surprised that they wouldn't </v>

1096
01:12:22.551 --> 01:12:24.860
<v Speaker 7>realize what we have realized a long </v>
<v Speaker 7>time ago,</v>

1097
01:12:24.861 --> 01:12:25.694
<v Speaker 7>which has that almost all physical </v>
<v Speaker 7>resources are not here and this </v>

1098
01:12:30.420 --> 01:12:31.810
<v Speaker 7>biosphere but without</v>

1099
01:12:34.480 --> 01:12:39.480
<v Speaker 7>the rest of the solar system gets 2 </v>
<v Speaker 7>billion times more solar energy than our</v>

1100
01:12:41.921 --> 01:12:42.754
<v Speaker 7>little plot.</v>
<v Speaker 7>There's lots of material out there that </v>

1101
01:12:45.731 --> 01:12:50.480
<v Speaker 7>you can use to build robots and self </v>
<v Speaker 7>replicating robot factories and all that</v>

1102
01:12:50.481 --> 01:12:53.110
<v Speaker 7>stuff.</v>
<v Speaker 7>And they're going to do with that.</v>

1103
01:12:53.111 --> 01:12:55.250
<v Speaker 7>And they will be scientists,</v>
<v Speaker 7>um,</v>

1104
01:12:55.540 --> 01:12:58.690
<v Speaker 7>and curious and they will explore what </v>
<v Speaker 7>they can do them.</v>

1105
01:12:59.800 --> 01:13:00.633
<v Speaker 7>And in the beginning they will be </v>
<v Speaker 7>fascinated by life and by their own </v>

1106
01:13:05.501 --> 01:13:07.270
<v Speaker 7>origins.</v>
<v Speaker 7>And I was urbanization.</v>

1107
01:13:07.300 --> 01:13:09.520
<v Speaker 7>They will want to understand that </v>
<v Speaker 7>completely.</v>

1108
01:13:09.790 --> 01:13:14.010
<v Speaker 7>Just like people today would like to </v>
<v Speaker 7>understand how life works and um,</v>

1109
01:13:16.210 --> 01:13:17.610
<v Speaker 7>and also,</v>
<v Speaker 7>um,</v>

1110
01:13:18.760 --> 01:13:22.680
<v Speaker 7>the history of our own existence and </v>
<v Speaker 7>subluxation,</v>

1111
01:13:22.690 --> 01:13:25.480
<v Speaker 7>but then also the physical laws that </v>
<v Speaker 7>created all of that.</v>

1112
01:13:27.130 --> 01:13:28.040
<v Speaker 7>So they,</v>
<v Speaker 7>um,</v>

1113
01:13:28.300 --> 01:13:29.133
<v Speaker 7>in the beginning they will be fascinated</v>
<v Speaker 7>by life once they understand that there </v>

1114
01:13:31.920 --> 01:13:32.753
<v Speaker 7>was interest.</v>
<v Speaker 7>I'm like anybody who loses interest and </v>

1115
01:13:36.940 --> 01:13:41.550
<v Speaker 7>things he understands.</v>
<v Speaker 7>And then as you said,</v>

1116
01:13:41.580 --> 01:13:46.580
<v Speaker 7>um,</v>
<v Speaker 7>the most interesting sources,</v>

1117
01:13:49.520 --> 01:13:52.940
<v Speaker 7>information for them will be others have</v>
<v Speaker 7>their own kinds.</v>

1118
01:13:58.210 --> 01:14:03.210
<v Speaker 7>So at least in the long run,</v>
<v Speaker 7>that seems to be some sort of protection</v>

1119
01:14:06.540 --> 01:14:08.640
<v Speaker 7>through lack of interest on the other </v>
<v Speaker 7>side.</v>

1120
01:14:11.200 --> 01:14:15.280
<v Speaker 7>And um,</v>
<v Speaker 7>and now it seems also clear as far as we</v>

1121
01:14:15.281 --> 01:14:16.114
<v Speaker 7>understand physics,</v>
<v Speaker 7>you need maton energy to compute and to </v>

1122
01:14:20.771 --> 01:14:25.300
<v Speaker 7>build more robots and infrastructure and</v>
<v Speaker 7>more Ai.</v>

1123
01:14:25.301 --> 01:14:26.134
<v Speaker 7>Civilization and I ecology is consisting</v>
<v Speaker 7>of trillions of different types of ai </v>

1124
01:14:31.600 --> 01:14:32.433
<v Speaker 7>and so it seems inconceivable to me that</v>
<v Speaker 7>this thing is not going to expand some </v>

1125
01:14:37.961 --> 01:14:38.794
<v Speaker 7>ai ecology not controlled by one ai by </v>
<v Speaker 7>trillions of different types of ai as </v>

1126
01:14:43.841 --> 01:14:44.674
<v Speaker 7>competing and all kinds of quickly </v>
<v Speaker 7>evolving and disappearing ecological </v>

1127
01:14:49.301 --> 01:14:52.090
<v Speaker 7>niches in ways that we cannot fathom at </v>
<v Speaker 7>the moment,</v>

1128
01:14:52.510 --> 01:14:56.950
<v Speaker 7>but it's going to expound limited </v>
<v Speaker 7>lightspeed and physics,</v>

1129
01:14:57.010 --> 01:15:02.010
<v Speaker 7>but it's going to expand and we realize </v>
<v Speaker 7>that the universe is still young.</v>

1130
01:15:03.010 --> 01:15:07.420
<v Speaker 7>It's only 13.8</v>
<v Speaker 7>billion years old and it's going to be a</v>

1131
01:15:07.420 --> 01:15:08.410
<v Speaker 7>thousand times older than that.</v>

1132
01:15:11.800 --> 01:15:12.633
<v Speaker 7>There's plenty of time to conquer the </v>
<v Speaker 7>entire universe and to fill it with </v>

1133
01:15:18.511 --> 01:15:19.344
<v Speaker 7>intelligence and senders and receivers </v>
<v Speaker 7>that ais can travel the way they are </v>

1134
01:15:24.870 --> 01:15:25.703
<v Speaker 7>traveling an hour labs today,</v>
<v Speaker 7>which is by radio or from sender to </v>

1135
01:15:29.341 --> 01:15:34.341
<v Speaker 7>receiver and let's call the current age </v>
<v Speaker 7>of the universe one Ian,</v>

1136
01:15:35.990 --> 01:15:36.823
<v Speaker 7>when Ian now it will take just a few </v>
<v Speaker 7>eons from now and the entire visible </v>

1137
01:15:43.201 --> 01:15:44.034
<v Speaker 7>universe.</v>
<v Speaker 7>There's going to be full of that stuff </v>

1138
01:15:47.370 --> 01:15:51.330
<v Speaker 7>and let's look ahead to a time when the </v>
<v Speaker 7>universe is going to be 1000 times older</v>

1139
01:15:51.331 --> 01:15:54.690
<v Speaker 7>than it is now.</v>
<v Speaker 7>They will look back and they will say,</v>

1140
01:15:54.691 --> 01:15:57.150
<v Speaker 7>look,</v>
<v Speaker 7>almost immediately after the big bang,</v>

1141
01:15:57.180 --> 01:15:58.013
<v Speaker 7>only a few eons later,</v>
<v Speaker 7>the entire universe started to become </v>

1142
01:16:01.651 --> 01:16:04.350
<v Speaker 7>intelligent.</v>
<v Speaker 7>Now to your question,</v>

1143
01:16:05.670 --> 01:16:10.470
<v Speaker 7>how do we see whether anything like that</v>
<v Speaker 7>has already happened or has already in a</v>

1144
01:16:10.471 --> 01:16:14.760
<v Speaker 7>more advanced stage in some other parts </v>
<v Speaker 7>of the universe,</v>

1145
01:16:14.890 --> 01:16:18.810
<v Speaker 7>the visible unit routes we are trying to</v>
<v Speaker 7>look out there and nothing like that has</v>

1146
01:16:18.811 --> 01:16:19.644
<v Speaker 7>happened so far?</v>

1147
01:16:20.670 --> 01:16:22.900
<v Speaker 9>Or is that charter?</v>
<v Speaker 9>What do you think?</v>

1148
01:16:22.901 --> 01:16:24.370
<v Speaker 9>We'll recognize it.</v>
<v Speaker 9>Well,</v>

1149
01:16:24.400 --> 01:16:25.233
<v Speaker 9>how do we know it's not among us?</v>
<v Speaker 9>How do we know planets aren't in </v>

1150
01:16:28.271 --> 01:16:33.271
<v Speaker 9>themselves intelligent beings?</v>
<v Speaker 9>How do we know ants seen as a collective</v>

1151
01:16:36.610 --> 01:16:40.000
<v Speaker 9>or not much greater intelligence than </v>
<v Speaker 9>our own?</v>

1152
01:16:40.270 --> 01:16:43.060
<v Speaker 9>These kinds of ideas.</v>
<v Speaker 9>And it was a boy.</v>

1153
01:16:43.090 --> 01:16:44.620
<v Speaker 9>I was thinking about these things</v>

1154
01:16:45.190 --> 01:16:49.840
<v Speaker 7>and I thought maybe it has already </v>
<v Speaker 7>happened because back then I know,</v>

1155
01:16:50.170 --> 01:16:51.003
<v Speaker 7>I knew,</v>
<v Speaker 7>I learned from poplar physics box that </v>

1156
01:16:54.730 --> 01:16:55.563
<v Speaker 7>the structure of the large scale </v>
<v Speaker 7>structure of the universe is not </v>

1157
01:16:58.600 --> 01:16:59.433
<v Speaker 7>homogeneous and you have these clusters </v>
<v Speaker 7>of galaxies and then in between the </v>

1158
01:17:04.540 --> 01:17:09.380
<v Speaker 7>these huge empty spaces.</v>
<v Speaker 7>And I thought,</v>

1159
01:17:09.410 --> 01:17:12.410
<v Speaker 7>hmm,</v>
<v Speaker 7>maybe say island's really empty.</v>

1160
01:17:12.411 --> 01:17:14.810
<v Speaker 7>It's just that in the middle of that </v>
<v Speaker 7>some ai,</v>

1161
01:17:14.811 --> 01:17:15.644
<v Speaker 7>so lization already has expanded and </v>
<v Speaker 7>then has covered a bottle of 1 billion </v>

1162
01:17:20.930 --> 01:17:25.930
<v Speaker 7>light years time visa and it's using all</v>
<v Speaker 7>the energy of all the styles within that</v>

1163
01:17:26.271 --> 01:17:29.090
<v Speaker 7>bubble for its own unfathomable </v>
<v Speaker 7>practices.</v>

1164
01:17:29.600 --> 01:17:34.600
<v Speaker 7>And so it always happened and we just </v>
<v Speaker 7>fail to interpretate the signs.</v>

1165
01:17:34.880 --> 01:17:35.713
<v Speaker 7>But then alarm of that gravity by itself</v>
<v Speaker 7>explains the large scale structure of </v>

1166
01:17:41.631 --> 01:17:44.660
<v Speaker 7>the universe and that this is not a </v>
<v Speaker 7>convincing explanation.</v>

1167
01:17:45.470 --> 01:17:46.303
<v Speaker 7>And then I thought maybe vb,</v>
<v Speaker 7>it's the dark matter because as long as </v>

1168
01:17:53.091 --> 01:17:53.924
<v Speaker 7>we know today 80% of the measurable </v>
<v Speaker 7>matter is invisible and we know that </v>

1169
01:18:01.851 --> 01:18:05.890
<v Speaker 7>because otherwise our galaxy or other </v>
<v Speaker 7>galaxies worked fall apart.</v>

1170
01:18:05.950 --> 01:18:06.783
<v Speaker 7>They would,</v>
<v Speaker 7>they are rotating too quickly and then </v>

1171
01:18:11.621 --> 01:18:12.454
<v Speaker 7>the idea was maybe all us,</v>
<v Speaker 7>he is ai civilizations that are already </v>

1172
01:18:16.571 --> 01:18:17.404
<v Speaker 7>out there.</v>
<v Speaker 7>They they just invisible because they </v>

1173
01:18:22.751 --> 01:18:26.800
<v Speaker 7>are really efficient and using the </v>
<v Speaker 7>energies are their own local systems and</v>

1174
01:18:26.801 --> 01:18:29.820
<v Speaker 7>that's why they appear doctors.</v>
<v Speaker 7>What's,</v>

1175
01:18:29.960 --> 01:18:30.793
<v Speaker 7>this is awesome at a convincing </v>
<v Speaker 7>explanation because then the question </v>

1176
01:18:34.211 --> 01:18:37.070
<v Speaker 7>becomes why is there,</v>

1177
01:18:38.250 --> 01:18:41.820
<v Speaker 7>are there still any visible stars were </v>
<v Speaker 7>left in our own galaxy,</v>

1178
01:18:42.060 --> 01:18:44.160
<v Speaker 7>which also must have a lot of dark </v>
<v Speaker 7>matter,</v>

1179
01:18:44.610 --> 01:18:45.443
<v Speaker 7>so that is awesome.</v>
<v Speaker 7>Not a convincing thing and today I like </v>

1180
01:18:49.111 --> 01:18:54.111
<v Speaker 7>to thing it's quite plausible that maybe</v>
<v Speaker 7>the first,</v>

1181
01:18:54.580 --> 01:18:59.580
<v Speaker 7>at least in our local light cone within </v>
<v Speaker 7>it's a few hundreds of millions of light</v>

1182
01:19:04.181 --> 01:19:09.010
<v Speaker 7>years and we can reliably observe,</v>
<v Speaker 7>observe.</v>

1183
01:19:09.220 --> 01:19:10.720
<v Speaker 7>Is that exciting to you?</v>
<v Speaker 7>They will.</v>

1184
01:19:10.721 --> 01:19:11.554
<v Speaker 7>Might be the first,</v>
<v Speaker 7>and it would make us much more </v>

1185
01:19:15.491 --> 01:19:19.780
<v Speaker 7>importance because if we mess it up </v>
<v Speaker 7>through a nuclear war,</v>

1186
01:19:20.740 --> 01:19:21.573
<v Speaker 7>then,</v>
<v Speaker 7>then maybe this will have an effect on </v>

1187
01:19:25.671 --> 01:19:26.900
<v Speaker 7>the,</v>
<v Speaker 7>on the,</v>

1188
01:19:26.960 --> 01:19:30.270
<v Speaker 7>on the development on the entire </v>
<v Speaker 7>universe.</v>

1189
01:19:31.130 --> 01:19:33.360
<v Speaker 7>So let's not mess it up.</v>
<v Speaker 7>It's not miss it.</v>

1190
01:19:33.630 --> 01:19:35.690
<v Speaker 7>You again,</v>
<v Speaker 7>thank you so much for talking today.</v>

1191
01:19:35.750 --> 01:19:38.060
<v Speaker 7>I really appreciate it.</v>
<v Speaker 7>It's my pleasure.</v>

