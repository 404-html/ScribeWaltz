Speaker 1:          00:00:05       Hi everyone. Welcome to lecture number seven. So up to now, I believe, can you hear me in the back? Is it easy? Okay. So in the last set of modules that you've seen, you've learned about convolutional neural networks and how they can be applied to imaging, no Tivoli, uh, you've played with different types of layers including pooling, Max pooling, average pooling and convolutional layers. You've also seen some classification with the most classic Algorithms, uh, all the way up to inception and resonance. And then you jumped into advanced application like object detection with Yolo, uh, and the fast RCN and foster or CNN series a with an optional video. And finally a face rekognition and neural psych transferred. If we talked a little bit about in the past lectures. So today we're going to build on top of everything you've seen in these set of modules to try to delve into the neural networks and interpret them because you, you, you're Nazis.

Speaker 1:          00:01:06       After seeing, uh, the set of modules up to now, that's a lot of improvements of the neural networks are based on trial and error. So we try something, we do hyper parameter search. Sometimes the model improves, sometimes it doesn't. We use a validation set to find the right set of methods that would make our model improve. It's not satisfactory from a scientific standpoint. So people are also searching how can we find a new effective way to improve our neural networks? Not only we try it in there, but we'd theory that goes into the network and visualizations. So today we focused on that. We first, uh, we'll see three methods, saliency maps or occlusion sensitivity and class activation maps, which are used to kind of understand what was the decision process of the network given this output, how can we map back the output decision on the input space to see which part of the inputs were discriminated for this output.

Speaker 1:          00:02:08       And later on we will delve even more in details into the network by looking at intermediate layers. What happens at an activation level, uh, to lay your level and at a network level with another set of methods, gradient essence, class model, visualization, Dataset set, search and deconvolution. We will spend some times under the convolution because it's so cool. It's a cool type of mathematical operation to know and it will give you more intuition on how the convolution works from a mathematical perspective. Uh, if we have time, we go over a phone application called deep dream, which is super cool visuals for some of you who know it. Okay, let's go. Mentee code is on the board if you guys need to to sign up. So, uh, as usual we go over some context, the information and and small case studies. So don't hesitate to participate.

Speaker 1:          00:02:59       So you've built an animal classifier for a pet shop and you gave it to them. It's, it's super good. It's been trained on image net plus some other data. And what, what is a little worrying is that the pet shop is a little reluctant to use your network because they don't understand the decision process of the model. So how can you quickly show that the model is actually looking at a specific animal? Let's say your cat, if I give it an input that is a cat, we've seen that together one time. Everybody remembers. So I go quickly. You have a network. Here's a dog given as an input to a CNN, the CNN, assuming the constraint is that there is one animal page was trained with a soft Max output layer and we get a probability distribution over all animals, Iguanas, dog car cats and in crap.

Speaker 1:          00:03:53       And what we want is to take the derivative of the score of dog and bark propagated to the inputs to know which parts of the inputs where discriminative for this score of dog. Does that make sense? Everybody remembers this and so the interesting part is that this value is the same shape as x. So it's the size of the input. It's a matrix of numbers. If the numbers are large in absolute value, it means the pixels corresponding to these locations had an impact on the score of duck. Okay. What do you think the score of dog is? Easy. The output probability or no? What? What? What? What do I mean by [inaudible] dog?

Speaker 2:          00:04:41       Yep.

Speaker 3:          00:04:43       It's a score of the dog yet, but it's a point 85 that's what I need. Actual formula is used to compute the funding going through the soft Max factor that when you're supposed to be until yes, it's the, it's the scored Eddie's

Speaker 1:          00:04:56       pre soft Max is a score that comes before the softmax. So as a reminder, here's a softmax layer and this is how it could be presented. So you get us a vector that is a set of scores that are not necessarily probabilities. They're just scores between minus infinity to plus infinity. You give them to the soft Max and the softmax when he's going to do is that he's going to output a vector where the sum of all the properties in this vector or going to sum up to one. Okay. And so the issue is if instead of using the derivative of what we called white hat last time, we use the score of Doug where we get a better representation here. The reason is in order to maximize this number score of dog divided by the sum of the score of Al all animals, or like maybe I should write exponential of score of dog divided by some of the exponential of the score of all animals.

Speaker 1:          00:05:50       One way is to minimize does so the scores of all the other animals rather than maximizing score of dog. So you see, so maybe moving a certain peaks so that we minimize the score a fish. And so this speaks that we'll have a high influence on white hats, the general output of the network, but you actually doesn't have an influence on the score of dug one layer before. Does it make sense? So that's why we would use, uh, the scores pre softmax instead of using the scores plus soft Max Authority properties. Okay. And what's fun is it here, you cannot see there's this slides online if you want to, if you want to look at it on your computers, but you have some of the pixels that are roughly the same positions as the dog is on the input image that are stronger. So we see some white pixels here and these can be used to segment the dog probably.

Speaker 1:          00:06:44       So you could use a simple trash shoulding to find where the dog was based on this pixel. A Pixel there with the big score map doesn't work too well in practice. So we have better methods to do segmentation, but this can be done as well. So this is what it's called saliency maps and it's a common technique to quickly visualize what the network is looking at. In practice, we will use other methods. So here's another contextual story. Now you've built the animal classifier. They're still a little scared, but you want to prove that the model is actually looking at the inputs. He major the right position. You don't need to be quick, but you have to be very precise. Yeah, no, the saliency map is literally distinct. Here is the values of the derivation.

Speaker 1:          00:07:46       So you, you, you take the score of dog, you back propagate the grade in all the way to the inputs. It gives you a matrix that is exactly the same size as the x and you use, you use like a specific color scheme to see which speaks. Those are the strongest. Okay, so here we have our CNN, the dog is for propagated and you get a score of a probability score for the dog. Now you want a method that is more precise than the previous one but not necessarily too fast. And this one, we've talked about it a little bit, it's occlusion sensitivity. So the idea here is to put a gray square on the dog here and we propagate this image with the gray square at this position through the CNN. What we get is another property distribution that is probably similar to the one we had before because the grade score doesn't seem to impact too much.

Speaker 1:          00:08:36       The image, at least from a human perspective, we still see a dog, right? So the score of dot might be high, 83% probably what we can say is that we can build a probability map corresponding to the class dog and ha and we will write down on this map how confident is the network. If the gray square is that as best finger location so far our first location, it seems that the network is very confident. So let's put the Red Square here. Now I'm going to move the gray square a little bit and shifting it just as we do for convolution. And I'm going to send a gain. This new image in the network is going to give me a new probably t distribution output and the score of dot might change. So looking at the score of dog, I'm going to say, okay, the network is still very confident that there is a dog here and I continue, I shifted to gain here.

Speaker 1:          00:09:28       Same networks, still very confident that there is a dog. Now I shifted the square, uh, vertically down and I see that part. Sure that the face of the dog is partially occluded. Probably tee off dog will probably go down because the network cannot see one I have the dog is not confident that there's a dog anymore. So probably the, the confidence of the network went down. I'm going to put a square that is tending to be blue and I continue, I shifted to gain and here we don't see the dog face anymore. So probably the network Mites might classify this as a chair rights because the chair is more obvious than the dog now. And so they're probably, the score of dog might go down. So I'm going to put the Blue Square here and we're going to continue here. We don't see the tail of the dog.

Speaker 1:          00:10:18       It's still fine. The network is pretty confident and so on. And what that we look at now is this probably team up, which tells me roughly where the dog is. So here we used a pretty big filter compared to the size of the image. The smaller the, sorry, the pretty big gray square. The smaller the gray square, the more precise this probably team up is going to be. Does that make sense? So this is if you have time, if you can, you can take your time with the pet chart to explain them what's happening. You will do that. Yeah, we'll, we'll see that in the next light. That's correct. So let's see more examples here. We have three classes in these. These, these images has been have been generated by my dealer and Rob Fergus. These paper visualizing and understanding convolutional networks is uh, one of the seminal paper that has led the research in, in visualizing and interpreting your own networks.

Speaker 1:          00:11:20       So I advise you to take a look at it and we will refer to it a lot of time in this lecture. So now we have three examples. One is a Pomeranian, which is this type of cute dog, a car wheel, which is a true class of the second image. And, uh, an Afghan hound, which is this type of dog here, uh, on the last image. So if you do the same thing as we did before, that's what you would see. So just to clarify, here we see a blue color. It means when the gray square was positioned here or centered at this, the network was less confidence. That's the true class was Pomeranian. And in fact, if you look at the paper, they explained that when the gray square was here, their confidence of Pomeranian went down because the conference, because the confidence of tennis ball went up.

Speaker 1:          00:12:11       And in fact the Pomeranian dog has a tennis ball in the mouth. And another interesting thing to notice is on the last picture here, you see that there's a red color on the top left of the image. And this is you exactly at what as what you mentioned at him is that when the square was on the face of the human, the network was much more confidence than the true that the true class was the dog because you removed a lot of meaningful information for the network, which was the face of the human. And similarly, if you put the square on the dog, do a true class that the network was out putting was human problem. Does that make sense?

Speaker 1:          00:12:53       Okay. So DC's called occlusion sensitivity and it's the second method that's uh, you now have seen for interpreting where the network Luke sites on an input. So let's move to class activation maps. So I know if you remember, but two weeks ago, uh, print off when he discussed, uh, the techniques that he has used in healthcare, he explained that you get, uh, he get a chest x ray and he manages to to tell the doctor where the network is looking at when predicting a certain disease based on these checks. X Ray, right? You remember that? So this was done through class activation maps and that's what we're going to see now. So one important thing to notice is that we discussed that classification networks seem to have a very good localization ability and we can see it with the two methods that we previously discussed. Same thing for those of you who have read the Yellow paper that you've studied in these set of modules, you low V two algorithm has first been trained on classification because classification has a lot of data, a lot more than object detection has been trained on classification.

Speaker 1:          00:14:08       Built a very good localization ability and then has been fine tuned and retrained on object detection data sets. Okay. And so the core idea of cloth activation map is to show that uh, CNN have a very good localization ability even if they were trained only on image level labels. So we have this network that is a very classic network use for classification. We give it a kid and a dog, uh, discuss activation map is coming from MIT, the MIT lab with bullied you at all in 2016 and you for propagate this image of a kid with a dog through the network, which has some calm, really Max pool classic series of layers, several of them. And at the end usually Slaton the last output volume of the comp and Ronnie to several fully connected layer, which are going to play the role of the classifier and send it to a softmax and get the property to output.

Speaker 1:          00:15:06       Now what we're going to do is that we're going to prove that this CNN is generalizing to localization. So we're going to convert this same network in another network and the part which is going to change, it's only the last part. The downside of using flatten plus fully connected is that you lose all spacial information, right? You have a volume that has spatial information, although it's been gone through some Max pooling, so it's been down sample. Then you lost some part of the special localization, flattening kills it, you flatten it, you run it through a fully connected layer and then it's over you. It's super hard to find out where the activation was corresponds to on the boot space. So instead of using flatten plus fully connected, we're going to use global average pooling. We're going to explain what it is, a fully connected softmax layer and get the property to output and we're going to show that now this network can be trained very quickly because we just need to train one layer, the fully connected here and can show where the network looks at the same as the previous network.

Speaker 1:          00:16:13       So let's, let's talk about it more in detail. I assume this was the last comp layer of our network and it outputs a volume, a volume that is size to simplify four by four by six. So six filters were used in the last comp. And so we have six feature maps now that makes sense. I'm going to convert this using your glove global average pooling to just a vector of six values. What is global average pooling is just taking this feature maps, each of them averaging them into one number. So now instead of having a four by four by six volume, I have a one by one by six volume, but we can call it a vector. Doesn't make sense. So what's interesting is that this number actually holds the formation of the whole feature map that came before in one number being average over it.

Speaker 1:          00:17:05       I'm going to put these in a vector and I'm going to call them activations as usual. A one, a two, a three, a four, a five, a six. As I said, I'm willing to train a fully connected layer here with a soft max activation. And the outputs are going to be the probabilities. So what is interesting about that is that the feature maps here, as you know, we contain some visual patterns. So if I look at the first feature map, I can plot it here. So these are the values. And of course this one is much more granular than four by four it's not a four by four it's much more numbers. But this, you can say that this is the feature map and it seems that the activations have found something here. There was a visual pattern in the inputs that activated the the seizure mop and to seem tourism, which generated this feature map here in this location.

Speaker 1:          00:17:57       Same for the second one. There's probably two objects or two patterns that's activated, the filters that generated these feature map and so on. So we have six of those and after I've trained my fully connected layers here, my fully connected layer, I look at the score of dog score of dog is 91% what I can do is to know this 91% how much did it come from these feature maps and how can I know it is because now I have a direct mapping using the weights. I knew that the weight number one here, this edge you see it is how much the score was dependent on the orange feature map.

Speaker 1:          00:18:44       Does it make sense? The second weight, if you look at the green edge is the weights that has multiplied this feature map to give birth to the outputs of a dog. So this way it is telling me how much this feature map the green one has influence on the output. Does that make sense? So now what I can do is do some, all of these are weighted sum of all these feature maps. And if I just do this way, did some I, we get to another feature map, something like that. And you notice that this one seems to be highly influenced by the green one, the green feature, ma? Yeah, it means probably the weight here was higher. It probably means that the second filter of the last comp was the one that was looking at the dog. That makes sense. Yeah.

Speaker 1:          00:19:43       Okay. And then once I get these feature mop, this feature map is not the size of the input image, right? It's the size of the height and width of the output of the last [inaudible]. So the only thing I'm going to do is like, I'm going to sample it back simply so that it fits the size of the input image. And I'm going to overlay it on the input image to get my class activation map. The reason it's called class activation map is because this feature map is dependent on the class you were talking about. If I was using, uh, they'd say I was using car here that was using car, the weights would have been different, right? Look at the edge that connect the first activation to the activation of the previous layer. These weights are different. So if I sum all of these feature maps, I'm going to get something else. Does that make sense? So this is class activation maps and in fact there is a dog here and there's a human there. And what you can notice is probably, if I look at the class of human do weights number one might be very high because it seems that this visual pattern that activated the first teacher map was the face of the kid.

Speaker 4:          00:20:59       Yeah.

Speaker 1:          00:20:59       Okay. So what are you super cool is that you can get your network and just change the last few layers into global average schooling plus a softmax fully connected layer and you can do that and visualize very well. It requires a small fine tuning. Yeah. So were these like saliency map?

Speaker 5:          00:21:16       Oh for the activation though. So it's a different vocabulary. I would use saliency maps for the backpropagation up to the pixels and class activation maps related to one class. It's not the back propagation at all, it's just a nut sampling through those to the input space based on the feature maps of the last couple of days. So it's mostly just examining the weights and sort of doing like a max operation on the, not so much if about backpropagation. Yes. Any other questions on costs? Activation? Maps kill the, yeah, that's a good question. So taking the average, does it kill the spatial information? So let me, let me write down a formula here. This is the score that's we're interested in. Let's say dog Class C once you could say is that this court is the sum of key equal one to six of Dama UK, which is the weight that that connects. You have to put activation to the previous layer times. What's times a

Speaker 1:          00:22:21       of the previous layer? Um, let's say we, we, we use a notation that he's like, Kay is the chase feature map and I, Jay is the location and I summed that over the locations. Can you seem to bag coffee? So what I'm saying is that here I have my global average pooling that happened here and I can divided by a certain number, so divided by 16, four by four. Okay. I can switch the two songs. So I can say that this thing is a sum over Ij. The locations times some over a t equals one two, six of what? W K Times H j. So the activations of the case teacher map in position a I J and Times the normalization one 16 does it make sense?

Speaker 1:          00:23:27       Does this make sense? So I, I still have the Duluth, the location, I still moved, I see moved to some around. And what I could do is to say that these things is the score in location Ij of your class activation map? Is it a class score for dislocation? Ij and I'm somebody needs overall locations. So just by flipping what the average pooling was doing over the locations, I can say that my waiting, using my weights, all the activation in a specific location for all the feature maps, I can get the score of this position in regards to the final output. Does that make sense? So we were not losing the this patient information.

Speaker 3:          00:24:24       The reason we're not

Speaker 1:          00:24:24       losing it is because we know we know what the feature maps are, right? We know what they are and we know that day's been averaged. Exactly. So we exactly can map it back.

Speaker 3:          00:24:42       Yeah. Because we assume that each tilter

Speaker 1:          00:24:45       that generated these feature maps, the TX one one specific thing.

Speaker 4:          00:24:50       Okay.

Speaker 1:          00:24:50       So like if, if this is the feature map, it means assuming the filter was detecting dog, that's we're going to see just, just something here. Meaning that there's a dog here and if there was a dog on the lower part of the image, we would also have strong activations in these parts.

Speaker 3:          00:25:13       I would say if you want to see more of the math behind it, check the papers, but, uh, [inaudible]

Speaker 1:          00:25:20       we shouldn't behind it. You can flip the summations using the global average pooling and showed that you keep the, the spatial information. The thing is you do the global average pooling, but you don't lose the feature maps because you know where they were from the output of their comp. Right. So you're not, you're not deleting this inflammation. That makes sense. Yep.

Speaker 3:          00:25:43       The occupations case, right. It by 16 is it started with taking the average. Great. Okay, let's move on and watch a Pulido on how acs class activation not work. If you do. It was from Kelly MacDonald.

Speaker 1:          00:26:02       They, it's a, it's live. So it's very quick. So you can see that the network is looking at this speed boat. Okay.

Speaker 1:          00:26:29       So now the three methods we've seen or methods that are roughly mapping back the output to the input space and how of visualize, which parts of the inputs were the most discriminative to lead to these outputs and the district of the network. Now we're going to try to delve more into details in the, in the, in the intermediate layers of the network and try to interpret how does the network see our world. Not necessarily related to a specific input but in general. Okay, so the pet shop now trust your model because you've used the occlusion sensitivity, saliency map and cass activation maps to show that the model is looking at the right place. Uh, but they got a little scared when you did that and they ask you to explain what the model thinks a dog is. So you have these trained convolutional neural network and you have an output probably t oh yeah. Let me take one in the back. Yeah.

Speaker 5:          00:27:31       Good ways to visualize like not image data, image data. That's a, that's a good question. It's actually sort the reason we were seeing images. What's most of the research has been focusing on images. Um, if you look at let's say time series data. So either speech or not your language domain way to visualize those. Is we the attention method, are you familiar with that? So in the next set of modules that you're going to start this week and you're going to study in the next two weeks, you will see a visualization method called attention models, which will tell you which part of a sentence was important. Let's say cloud put a number, like assuming you're doing machine translation, you know, some languages they don't have the direct one to one mapping. It means, I might say, uh, I love cats, but in another language may be the same sentence would be chats I log or something like that. It's flipped. And you want an attention while though to see to show you that the cat was referring to the second. I think it's, it's, it's, it's, okay. Sorry guys. So going back to the presentation now we're going to delve into inside the network. And so the new thing is

Speaker 1:          00:28:46       the pet shop is little scared and ask you to explain what the network thing could Doug is, what's a representation of doc for the network? So here we're going to use a method that we've already seen together called gradient essence, which is the finding an objective that is technically the score of the dog minus a regularization term. What the regularization term is doing is it's saying that x should look natural, it's not necessarily held to regularization can be something else and we will discuss it in the next slide. But don't think about it right now. What we will do is we will compute the backpropagation of the subjective function all the way back to the inputs and perform gradient assent to find the image that maximizes the score of the dog. So it's an iterative process. It takes longer than the class activation map. And we repeat the process for what propagate x, compute the objective back propagates and update pixels.

Speaker 1:          00:29:41       And so you guys are familiar with that. So let's see what, what, what we can visualize doing that. So actually if you take an image nets classification network and you perform this underclasses of goose or ostrich or Kit Fox, Husky dot machines and can see what the network is looking at or what the network thinks [inaudible] is. So [inaudible] you can see some some black dots on a white background somehow, but these are are still quite hard to interpret. It's not super easy to see. And even worse here on the screen, better on your computers. But you can see a fox, some here, you can see orange color for the Fox. It means that pushing the pixels to an orange color would actually lead to a higher score of the Kit Fox in the output. If you use a better regularization than l two you might get better pictures. So this is for Flamingo, this is for Pelican, and this is for heartbeat.

Speaker 1:          00:30:38       So a few things that are interesting to see is that in order to maximize the score of Flamingo, what the network visualized is many flamingos, it means that 10 flamingo leads to a higher score of the class [inaudible]. Then one flamingo for the network. Talking about regularization. What does Altura musicians say? It says that for visualizing we don't want to have extreme values of pixel. It doesn't help much to have one pixel with an extreme value, one pixel with the low value and so on, so we're going to regularize all the pixels so that all the values are around each other and then we can rescale it between zero and 2,255 if you want. One thing to notice is that the gradient ascent process doesn't constrain the inputs to be between zero and 255 you can go to plus infinity potentially while an image is stored with numbers between zero and two 55 so we might want to keep that as well.

Speaker 1:          00:31:36       This is another type of regularization. One thing that led to beautiful pictures was what Jason, you're Sinskey and his team did is they for propagates it an image computed the score competent, the objective function back propagated, updated the pixels and blurred them, blurred the picture. Cause what what is not useful for visualizing is if you have high frequency variation between pixels, it doesn't help to visualize if you have many pixels close to each other that have many different values. Instead you want to have a smooth transition among pixels. And this is another type of regularization called Goshen blurring. Okay. So this method actually makes a lot of sense in, in in scientific terms you're, you're maximizing an objective function that gives you what the network sees as Flamingo, which would maximize the score a flamingo. So we call it also class model visualization. Yes. To a more accurate,

Speaker 4:          00:32:40       um, but more relaxed.

Speaker 1:          00:32:44       The classic model digitalization correspond to a more accurate, so it's hard to map the accuracy of the model based on these visualization. It's a good way to validate that the network is looking at the right thing. Yeah. We're going to see more of these later. I think the most interesting part is actually on this slide is we're, we did it for the class score, but we could have done it with any activation. So let's say I stopped in the middle of the network and I defined my objective function to be this activation, I'm going to back propagate and find the input that we maximize this activation. It will tell me what is this activation? What does this activation fire for? So that's even more interesting. I think they're looking at the inputs and then, yeah. Does that make sense that we could do it on any activation?

Speaker 4:          00:33:36       Yep. Any questions on that? Okay. So now are

Speaker 1:          00:33:48       going to do another shake, which is debt to set search. It's actually one of the most useful, I think, uh, not fast but very useful. So the patch off loved the previous technique and asks if there are other alternatives to, to show what, what an activation in the middle of a network is thinking. Uh, you take an image for propagated through the network, gets your output. Now what you're going to do is select a feature map. Let's say this one, we're at this layer and the feature map is offsites five by five by 256 it means that the comp layer here had 256 filters, right? You are going to look at these feature maps and select probably uh yeah. What you're going to do, select one of the feature maps. Okay. We select one out of 250 60 feature map and we're going to learn a lot of data for propagated to the network and look which data points have had the maximum activation of this feature map.

Speaker 1:          00:34:55       So let's say we do it with the first feature map. We notice that these are the top five images that really fired this feature map, like high activations on the feature. Ma'Am, what it tells us is there's probably this feature map is detecting shirts could do the same thing. Let's say we take the second feature map and we look which data points have maximized the activations of this feature map out of a lot of data and we see that this is what we got. The top five images probably means that the other feature map seems to be activated when seeing edges. So the second one is more likely to appear earlier in their network, obviously then later on. So one thing that you may ask is these images seem crop, like I don't think that this was an image in the data set is probably a sub part of the image. What do you think this crop corresponds to? Any idea how we crops the image and why these are crops? Like what? Why didn't I show you the full images? How was I able to show you the crop?

Speaker 6:          00:36:29       Anything outside? It's not important.

Speaker 1:          00:36:33       That's correct. So let's say we pick an activation, an activation into network. This activation for a combination or your network oftentimes doesn't see the entire input image, right? Doesn't see it. What it sees is a subspace of the inputs image.

Speaker 4:          00:36:53       Okay,

Speaker 1:          00:36:54       that makes sense. So let's look at another slide here. We have a picture of Eunice 64 by 64 by three it's our inputs. We run it through a five layer continence and now we get an encoding volume that is much smaller in height and width but bigger in depth. If I tell you what this activation is seeing, if you might be back, you look at the stride and the filter size you've used, you could say that this is the part that this feature is sync the this, this, uh, this activation is sick. It means the pixel that was up there had no influence on this activation and it makes sense when you think of it, you're, you're, the easiest way to think about it is looking at the, the top picks, the topic entry on the encoding volume, top left entry. You have the input image, you put a filter here, these filter, it gives you one number, right?

Speaker 1:          00:37:47       This number, this activation only depends on this part of the image, but then if you add a convolution after it, it will take more filters. And so the deeper you go, the more part of the image, the activation we'll see. So if you look at an activation in layer 10 it will see much a much larger part of the inputs. Then an activation in layer one. That makes sense. So that's why, that's why probably the pictures that I showed here, these ones are very small part truck crops, small crops of the image, which means the activation I was talking about here is probably earlier in their network. It sees a much smaller part of the input.

Speaker 3:          00:38:37       It's going to respond to one the image. Yeah. Yeah. So what you look at is which activation was maximum. You look at this one and then you map this one back to crop. It makes sense. Okay.

Speaker 1:          00:38:56       So here's UNESCO gain up and saying this one would correspond more in the center of the image is intuition. Make sense?

Speaker 2:          00:39:06       Okay.

Speaker 1:          00:39:07       Okay, cool. So let's talk about deconvolution. Now there's going to be the hardest part of the lecture, but probably helping with with more intuition on deconvolution. You remember that that was the generative adversarial networks scheme and we said that giving a code to the generator, the generator is able to output an image. So there's something happening here that we didn't talk about is how can we start with a 100 dimensional vector and outputs a 64 by 64 by three image? That seems weird. We could use, you might say a fully connected layer with a lot of neurons right to up sample in practice. This is one method and other one is to use a d convolution network. So convolutions will encode the information in a smaller volume in heightened with deeper in in depth while the deconvolution. We'll do the reverse. It will up sample the height and width of an image, so that would be useful in this case, another chase where it would be usefully segmentation. You remember our case studies for segmentation, life, lifestyle, microscopic images of sales. Give it to a convolution network. It's going to encode it so it's going to lower the heightened with. The interesting thing about this encoding in the middle is that it holds a lot of meaningful information, but what we want ultimately, it's to get a segmentation mask and the segmentation mosque in height and width has to be the same size as the big sell limit. So we need a deconvolution network to add sample it.

Speaker 2:          00:40:47       Yeah,

Speaker 1:          00:40:48       so the competition are used in these cases. Today the case we're going to talk about is visualization. Remember the gradient assence method we talked about. We did find an objective function by choosing an activation in the middle of the network, and we want the objective to be called to this activation to find the input image that maximizes his activation through an iterative process. Now, we don't want to use any strategy process. We want to use a reconstruction of this activation directly in the input space by one backward pass. So let's say I select this feature map out of the 40 to 55 sorry, five by five by two 56 what I'm going to do is I'm going to identify the Max of these feature map. Here it is. It's this one,

Speaker 1:          00:41:38       third column. Second row, I'm going to set all the others to zero. Just this one. I keep it because it seems that this one has detected something. Don't want to talk about the others. I'm going to try to reconstruct in the input space what this activation has fired for. So I'm willing to come to the reverse mathematical operation of pooling, Relo and convolution. I will pool, I will unrelevant. Let's say it doesn't like these word doesn't exist. We don't use it with unreal and ECON. And I will do it several times because these activation went through several of them. So I do it again and again until I see, oh, this specific activation that I selected in the feature map fired because it's so the ears of the dog and as you see, this image is cropped. Again, it's not the entire image, it's just the part that the activation has seen. And if you look at where the activation is located on the feature map, it makes sense that this is the part that corresponds to it. So now the higher level intuition is this. We're going to delve into it and see what do we mean by an pull? What do we mean by unreliable and what do we mean by decomp? Okay, yes,

Speaker 5:          00:42:59       you're at the restaurant. What do we, a reconstruction of the whole image. So the new phrase, zero out all the activations, he said that these three construction would be messier. Okay. It's going to be more messy. Shit doesn't, doesn't necessarily mean you will not get the full image because probably the other activations probably didn't even fire it means they didn't detect it. Anything else? It's just that it's gonna. It's gonna add some noise to this reconstruction. Okay, so let's talk about the convolution and he'll beat on the board. So to starts with deconvolution.

Speaker 2:          00:43:41       Yeah.

Speaker 1:          00:43:42       And you, you guys can take notes if she wanted. We were going to spend about 20 minutes on the board now to discuss the convolution. Okay. To understand the convolution. We first need to understand the convolution. We've seen it from a computer science perspective, but actually what we're going to do here is we're going to frame the convolution as a simple matrix vector mathematical operation. You're going to see that it's actually possible. So let's start with the one decomp 41 deconvolution. I will take an input x, which is of size 12 x one x two x three x four x five x six x seven x eight so eight plus two padding, which gives me the 12th that I mentioned. So the inputs is a one dimensional vector, which has hardening off to on both sides. I will give it to a layer that will be a one d calm. And this layer we'd have only one filter and the filter size we before we will also use a stride equal to two. So my first question is what's the size of the outputs? Can you guys come to teach on your, on your notepads and, and tell me what's the size of the outputs?

Speaker 5:          00:45:44       Employee size 12 intero size for straight off to hiding off to fight. Yeah, I heard it. Yeah.

Speaker 1:          00:45:54       So you remember you use n x, sorry. And Y equals x minus f Plus Two p divided by stride and you will get five. So what I'm going to get is why one y two y three y four white fife.

Speaker 2:          00:46:18       Yeah.

Speaker 1:          00:46:22       So I'm going to focus on this specific convolution for now and I'm going to show now that we can define it as, as a mathematical operation between the Matrix and a vector. So the way to do it is, I guess the easiest way is to write the system of equation that is underlying here. What is white wine? Why one is,

Speaker 2:          00:46:45       okay,

Speaker 1:          00:46:45       the filter applied to the four first values here. Does it make sense? So he find the find my center as being t y w one w two w three NW four. What I'm going to get is that y one equals w one times zero plus w two times zero plus w three times x one. So it's got the u four times x to you just make sense. Just a convolution element twice operation and then some all of it.

Speaker 1:          00:47:26       Why two is going to be same thing, but we just tried have to going to down. So he's going to give me w one times x, one plus w two times x to close that to you. Three times x, three plus w four times x floor. Correct. Everybody's following no. Same thing. We will do it for all the wise until y five and we know that's why five is element twice operation between the filter and the four last number here, summing them since we give me w one times x seven plus w two times x eight plus zero plus w three times zero plus w four time zero. Okay. Now what we're going to do is to try to write down why as a matrix vector operation between w and x. We need to find what these w matrix is and looking at this system of equation, it seems that it's not impossible. So let's try to do it. I will write my wife Vector here, y one y two y three y 4.5 and I will write my matrix here and my vector x here. So first question is what do you think will be the shape of this w matrix?

Speaker 3:          00:49:18       Five bites way correct. We know that this is five by one this

Speaker 1:          00:49:23       is 12 by one so of course WWE is going to be five by 12th right? So now let's try to fill it in zero zero x one x two x treat, blah blah blah, x eight zero zero can you guys seem to back or no? Yeah. Okay, cool. Uh, so I'm willing to fill in this matrix regarding this system of equation. I know that the why one would be w one times zero w two times zero w three dynamics one w four times x two. So this vector is willing to multiply the first role here. So I just have to place my W's here. That'd be one. We've come here at Monte plays zero w two we'll come here. W three would come here and w four we'd come here and all the rest would be filled in with Zeros. Right? I don't want any more multiplications. How about the second row of this matrix? I know that why two has to be called to this dot product with this role. And I know that it's to give me w one x one plus w two x two plus there'll be three x three x one is the third input on these vector to turn entry. So I would need to shift what I had in the previs row we just trade off to until it gives me that,

Speaker 2:          00:50:43       oh

Speaker 1:          00:50:48       it doesn't make sense. So if I use the dot product of this row with that, I should get the second equation up there and so on. And you understand what happens, right? This pattern we just shift. We just tried off to on the side. So I would get zeroes here and I would get my w one w two w three w four and then Zeros and all the way down here and all the way down here. What did we get? These w four w three w two w one and Zeros. So the only thing I want to mention here is that the competition operation as you see can be framed as a simple matrix times vector.

Speaker 5:          00:51:33       Yes. Cause that's going to pour the top row. Why are on the right side? Yes. Because I don't want white hat

Speaker 1:          00:51:46       one to be dependent on x three two x eight so I want this to be zero multiplicate pliers.

Speaker 2:          00:52:01       Okay. So

Speaker 5:          00:52:03       why is this important for the inclusion behind Judy convolution in the existence of the convolution is because if we manage to write down why you called w x, we probably can write down x equal

Speaker 1:          00:52:18       w minus one. Why is w is an invertible matrix? And this is going to to be our the convolution. And in fact, what's the, the, what's the shape of this new matrix?

Speaker 2:          00:52:43       Hmm.

Speaker 5:          00:52:45       Yes. Twice by five.

Speaker 1:          00:52:50       We have 12 by one on one site, five by one on the other. It has to be 12 by five. So it's flipped competency w so one thing we going to do here is we're going to make an assumption. First assumption is that w is an invertible matrix. And on top of that, we were going to make us stronger assumption, which is that w is an autobahn all matrix.

Speaker 1:          00:53:29       Without going into the details here, same as when we proved, uh, exactly [inaudible] initialization in sections. We made some assumptions that are not always true. This assumption is not going to be always true. One, one intuition that you can have is if I'm using a filter that is, assume the filter is an edge detector, so like a plus one zero zero minus one in this case, the matrix would be orthogonal. Why a matrix that he's auto knoll means that if I take two of the columns here, I dot product them together, it should give me zero. Same with the rows. You can see it. So what's interesting is that if the stride was for, there will be no overlap between these two rocks. It would give me a nautical matrix here. Let's try this too. But if I replace this w one by minus one zero zero plus one plus one zero zero minus one and minus plus one zero zero minus one you can see that the dot product would be zero.

Speaker 1:          00:54:39       The zero is when we multiply the ones and the ones who were multiplied. The Zeros give me a zero dot. Prague. So this is a case where it works in practice. It doesn't always work. The reason we're making this assumption is because we want to make a reconstruction, right? So we want to be able to have these w minus one, this, this, this invert and the reconstruction is not going to be exact, but at at a first order approximation we can assume that the reconstruction will still be useful to us even if this assumption is not always true. In the case where Wu is auto go, no, I know that's the universe of w w transpose or another way to write it is that for Autobahn or matrices, w transports time w is the identity matrix. So what's he tells me is that x is going to be done the You transpose Tame y times y. So let's see, what do we get from that?

Speaker 2:          00:55:51       Me write down the MNC code. So

Speaker 1:          00:56:06       let's say now we have our x and we want to regenerate our, oh we will have our why and we want to generate our x using this method. So I would once I read rights is to understand the one D D Con. We can use the following illustrations where we have x here, which is zero zero x one x two x three all the way down to x eight okay, and I will have my w matrix here, w transpose and my why you vector y one y two y three y four and why five here and so I know that this matrix will be the transpose of the one I have here. Right? So I can just write down the transport. The transport is will the w one w two w three none that you four. Okay. I we shifted down. We just tried off too

Speaker 2:          00:57:18       and so on

Speaker 1:          00:57:32       and this whole thing will be w transpose.

Speaker 2:          00:57:38       Okay,

Speaker 1:          00:57:41       so do the small issue here is that this in practice is not, it's going to be very similar to a convolution, but because it's going to meet a tiny little different in terms of implementation. Another question I might ask is how can we do the same thing with the same pattern as we have here? It means the stride is going from left to right. Instead of going from up to down. I'm going to introduce that with a technique called sub peak. So convolution and for those of you who read papers in Segmentation, in visualization oftentime this is the type of convolution that is used for reconstruction. So let's see how it works. I just wanted to do the same operation, but instead of doing it, we just try going from up to down. I want to do it from a strike going from left to right.

Speaker 2:          00:58:44       Okay.

Speaker 1:          00:58:46       Oh well one thing you want to, you want to notice here is that uh, the two lines that I wrote here are cropped. And the reason is because we're using a potted inputs here. We would just crop the two top lines and same for the two last lines. Then we'd be corrupt.

Speaker 1:          00:59:15       Okay. That's w one. We might simply, why one and this one we want to buy y two so on. So this dot product we give me w one times y one but I don't want that to happen because I want to get to [inaudible] zero here. So we just crop that's in this matrix is actually going to be smaller than it seems. It's going to generate my x one three x way eight and then I will pad the diff top values in the button values. Okay, so let's look at the sub Pixel convolution. I have my inputs and now we do something quite fun. I would perform a sub pixel operation on why, what does it mean? I will insert Zeros almost everywhere. I would insert them and now we get zero zero y one zero two zero three zero y four zero y five and zero zero zero here. So these victories, just the vector why with some zeros inserted around it and also in the middle between the elements of why. Now, why is that interesting? It's interesting because I can now write down my convolution by flipping my weight. So let me explain a little bit what happened here.

Speaker 1:          01:01:13       What we wanted is in order to be able to efficiency come to, to do deconvolution the same way as we've learned to compute the convolution. We wanted to have the weights scattered from left to right with a stride moving from left to right. What we did is that we use a sub pixel version of y by inserting Zeros in the middle. And we divided the stride by two. So instead of having a straight off to as we had in our convolution, we have a stride of one in order the convolution. So Nazis that I shift my weights from one at every step when I moved from one role to another. Second thing is I flipped my weights, I flipped my ways. So instead of having WWE and WCW, CW four, now I have w four W's to WWF. And what you could see is looking at that first look at this row. The first road that is not cropped the result of the dot product of this row with this vector is going to be y one times w three plus.

Speaker 1:          01:02:26       Why two times w one? Yeah. Now let's look what happened here. I look at my first role here, the dot product of these first room with my why. Here is going to be uh, sorry. Sorry, we these two are crops is one and same here. So looking at my first non cropped role here as a dot product with this vector, what I get is w three times y one plus w two uh, sorry, plus w one times white too. So exactly the same thing as I got there. So these two operations are exactly the same operations. They're just same thing. You get the same results to different way of doing it. One is using a weird operation with strides going from top to bottom. And the second one is exactly a convolution. These are convolution, convolution plus flipped weights, insertion of Zeros for the sub Pixel version of why

Speaker 1:          01:03:41       and on top of that padding here and there. So these ones the hardest parts. Okay. Does it give you more intuition on the convolution here? You know now how it convolution can be framed as a mathematical operation between a matrix and a vector and you know also that under these assumptions, the way we will de convolve is just by flipping our weights, dividing this tried by two and inserting zeroes. If we just do that to where deconvolute deconvoluting for propagates into convolution the following way, you want to deconvolute just flip all the weights, insert zero's, sub Pixel and finally divide the stride. And that's the deconvolution. So super complex thing to understand. But this is the intuition behind it. Now let's try to have an intuition of how it would work in two dimension. Uh, led to me writing down why'd you we use that because in terms of implementation, this is the same as what we've been using here is very similar. What this one is another implementation. So you could do both the same. It's the same operation, but in practice this one is easier to understand because it's exactly the same operation of the convolution with flipped weights, insertion of Zeros and divided strike. That's why I wanted to shoot it.

Speaker 5:          01:05:20       What happens with the assumption assumption doesn't hold. So oftentimes you assumption doesn't hold. But what we want is to be able to see our construction and if we use this method, we will still see your construction practice. If we had really w minus one, the reconstruction would be much better. But we don't. So, uh, let me go over to, to the, uh, the two, the example. We're going to go a little overtime because we have two hours technically for one hour and 50 minutes. And, uh, and let me go over the two d example and then we will answer this question on why we need to make this assumption here is the interpretation of the two D de convolution and me writing down here. Right?

Speaker 4:          01:06:10       Okay.

Speaker 1:          01:06:18       The intuition behind the two D D Con is I get my input, which is five by five and this I call it X. I for propagates. It's using a filter of size two by two in a comp layer and astride off too. This is my convolution, what I get. So if you do five minus two plus the padding, which is zero divided by two plus one plus one plus one, and you ignore it. So, so five minus two divided by two gives you a three divided by two plus one. No, actually we'll give you three by three. Yeah, three by three. Oh. Why have two by three? That's what you get. And now, um, these, you call it, why, what's you're going to do here is you're going to de convolve why in order to decompose, why in order to de convolve it, you're going to use a stride one.

Speaker 1:          01:07:31       And what we said is that we need to divide the stride by two, right? So we need to strike of one and the filter will be the same two by two. And you remember that's what we've seen is that the future is the same. It's just that he's going to be flipped. So you will use a filter of Dubai to but flipped and now what do we get? We hope to get a five by five inputs, which is going to be our reconstructed x five by five inputs. And the way we're going to do it is this is the intuition behind it. Yeah.

Speaker 5:          01:08:15       Yeah. It's too late to look it up too late too. Thanks to like to um, five by fights here. That's what we hope to reconstruct. The way we will do it is we will take this into s is two by two. We will put it here and we will multiply all the weights of this filter by y one one all the weights would be multiplied by one point.

Speaker 1:          01:08:45       So we get four values here, which are going to be w four y one one w three one one and so on. Now I will shift this with a strike of one and I would put my filter again here and I will multiply all the entries by y one, two and so on. And you'll see that this entry has an overlap. So tweet it will, it will be updated at every step of the convolution. It's not like what happened in the FordPass. So this is the intuition behind the two deconvolution three the same thing. You have uh, a volume here. So your filter is going to be a volume. What you're going to do is you're going to put the volume here multiplied by one, one, one and so on. And then if you have a second filter, you would put it again on top of it and multiply by one, one, one or the weights of the filter and so on. So these little complicated, but this is the intuition behind the convolution. Okay, let's get back to the lecture. I'm going to take one question here. If you guys need clarification,

Speaker 5:          01:10:00       no worries. You don't understand the capabilities and fully the important part is that you get the intuition here and you understand how we do. So let me make a comment. Why do we need to make this assumption and do we need to make, when we want to reconstruct like we're doing here in the visualization, we need to make this assumption because we don't want to retrain waits for the de convolution neural network. What we know is that the activation we selected here on the feature map is has gone through the entire pipeline of the confidence. So to reconstruct, we need to use the weights that we already have in the confidence. We need to pass them to the deconvolution and reconstructs. If we're doing those segmentation like we talked about for the license excel,

Speaker 1:          01:10:45       we don't need to do this assumption. We're just saying that this is a procedure that is a deconvolution and we will train the weights of the deconvolution. So there is no need to make this assumption. He's just, we have a technique that is dividing those tried by one and a inserting zeroes and then B, we were trained to weights and we get an output that is an up sample version of the input that was given to it. So there was two use case, one where you use the weights and one way you don't, in this case, we don't want to retrain. We want to use the weights. So let's see, let's see a version more visual of the upsampling. So we did a [inaudible] image. This is my image, four by four I insert Zeros and IPAD. I get to nine by 90 Mitch. I have my filter like that and these filter will come volv. I will weed controls over the input. So I would place it on my inputs and at every step I would perform a convolution up. I will get a value here. The value is blue because as you can see, the waste that effected the output. We're only the blue weights. I would use this, try to have one beam now the weights that affect my input are the green ones and so on. And I would just come volve as I do usually

Speaker 1:          01:12:02       and so on. And now one step down, I see that the ways that are impacting my input or the purple ones. So I will put the Purple Square here and so on. So I just do the convolution like that. And so, so one thing that is interesting here is that divide use auto are blue. In my out of six by six outputs were generated only using the blue values of the filter. The blue weights in the filter, the ones that are green, we're only used, you were only generated using the green values of my seater. So actually this subsample sub beak. So convolution or deconvolution could have been done with four convolutions with the Blue [inaudible], green weights, uh, purple weights and yellow weights and then just just replaced such that the adjustment would be the output. Just put the output of each of these comp and mix them to give out a six by six output.

Speaker 1:          01:13:04       Only thing you need to know. We have an input four by four and we get to an output six by six. That's what we wanted. We wanted to have sample the image. We can retrain the weights or use the transport version of them. So let's see what happens. Now we understood what, uh, what did you come voice doing? So we're able to decomp what we need to do is also too, I'm pool and to unreal. Fortunately it's easier than the decomp so we're not going to do board work anymore. So let's see how uncool it works. If I give you this, uh, inputs to the pooling to a max pooling layer, the output is obviously going to be this one 42 is the maximum of these four numbers. Assuming we're using a two by two center, which right off to vertically and horizontally, 12 is the maximum of the green numbers. Six is the maximum of the red numbers and seven to your engines. No question. I give you back the outputs and I tell you he's made the input. Can you give me the input or no? No. Why? Why do you need, you need, you only achieved the maximum so you, you, you lost all the other

Speaker 5:          01:14:12       numbers. I don't know anymore the zero one and minus one. That's where the red numbers, because they get passed to the maximum, so max pool is not invertible from a mathematical perspective. What we can do is approximate. It's invert. How can we do that? Spread it out. That's a good point. We could spread out the six among the four values. That would be an approximation. A better way if we manage to cash from that I use is to catch something. We called the switches. We cashed the values of the maximum using a matrix that is very easy to store of Zeros and ones and we pass it to the and pooling and now we can approximate the inverts because we know where six was. We know we're 12 was we know where 42 and seven it was, but it's still not invertible because we, we lost all the other numbers.

Speaker 5:          01:15:11       Think about Max boot backpropagation it's exactly the same thing. These numbers zero one minus one the had no impact in the loss function at the end because they didn't pass the two for propagation. So actually with the switches, you can have the exact backpropagation. We know that the other values are going to be Zeros because they did an affected the loss during the for propagation that that makes sense. Okay, so this is Max pooling, pooling, earn Max pooling, and we can use it with the switches. You can approximate cash. The whole original matrix. Yeah. Why don't we just catch the whole Oregon electric could, could catch the entire thing. But in terms of back for backpropagation in terms of efficiency, we would just use the switches because it's enough. Yeah, yeah, yeah. For on pulling your right, we could catch everything, but then it's cheating like you, you kept it. So just give it back. Okay, so now we know how I'm pulling works. Let's look at the relative. So what we need to do in fact is to pass the switches and the filters back to the ampoule in the account in order to reconstruct switches are the matrix of Zeros and ones indicating where the maximum yeah

Speaker 1:          01:16:20       is where and filters are the filters that we transpose under this assumption under board. Okay, and so on and so on, and I get my reconstruction. I just need to explain the relevant. Now I give you this input to Relo and I forward propagated. What do we get? All the negatives. I'm PR numbers are going to be equalized to zero and the others are going to be kept. Now let's say I'm doing a backpropagation to Relo. What do I get if I give you that? This is the gradients that are coming back and I'm asking you what are the gradients after the Relo, during the backpropagation, how does the Relu behave in backdrop zeros?

Speaker 5:          01:17:09       Which ones or zeroes there negatives are zeroes. You agree the negative

Speaker 1:          01:17:17       she's in this yellow matrix are going to be Zeros during the backdrop.

Speaker 4:          01:17:22       Okay.

Speaker 1:          01:17:23       I guess. Sure.

Speaker 4:          01:17:28       Okay.

Speaker 1:          01:17:29       Think always about what was the influence of the input on the loss function.

Speaker 4:          01:17:34       Okay?

Speaker 1:          01:17:34       And you will find out what was the backpropagation. Look at this number, this number here minus two did this number have the fact that it was minus two did it have any influence on the loss function? No, we could have been minus 10 it could have been minus 20 it's not going to impact the loss function. So what do you think should be the number here? Zero. Even if the number that is coming back, the gradient is 10 so what do you think should be the revenue? Backward output? Same idea as Max. What we need to do is to remember the switches. You remember which of these values had an impact on the loss.

Speaker 4:          01:18:27       Okay?

Speaker 1:          01:18:27       We pass the switches. All of these values here that are kind of the why. You know this is a why all of these ones had no impact on the loss function. So when you back propagate, their gradients should be set to zero. It doesn't matter to update them, it's not going to make the loss go down. So these are all Zeros and the rest they just pass. Why do they pass with the same value? Because rare relo for positive numbers was one. So this number one here that passed the revenue during the fort propagation, it was not modified. It's gradient is going to be one that make sense. So this is really backward. Now in this reconstruction method, we're not going to use rail backward. We're going to use something we call a Relo de confident. Let's say the reason we're not dean tuition between why we're not using rarely backward is because what we're interested in is to know which pixels of the impact positively affected the activation that we are talking up. So what we're going to do is that we're just going to do a relo. We're just going to do a really backward. And another reason is when we reconstruct, we want to have the minimum influence from the for propagation because we don't really want our reconstruction to depend on the, for propagation. We would like our reconstruction to be unbiased and just look at this activation, reconstruct what happened.

Speaker 1:          01:19:47       So that's what you're going to use. Again, this is a hatch that has been found through trial and error and it's not going to be scientifically viable all the time. Okay, so now we can do everything and we can reconstruct and find out what was this activation corresponds to. It took time to understand, but it's super fast to do. Now is just one path, not iterative. We could do it with every layer. So let's say we do it with the first block of [inaudible] Max Spoon. I go here, I choose an activation. I, I, I find the maximum activation. I said all the others, two zero I and pull relative the convent. I find out the reconstruction, these specifi activation was looking at edges like that.

Speaker 1:          01:20:31       So let's delve into the phone and see how we can visualize insight, what's happening inside the network. So all the visualization we're going to see now can be found in much use dealers in rob Ferris uses paper, visualizing, understanding convulsion networks. I'm going to explain what they correspond to, but check, check out their papers if you want to understand more and to be dictates. So what's happens here is that on the top left you have nine pictures. These are the crop pictures of the Dataset that activated the first filter of the first layer maximum. So we have a first feature on the first layer and we run all the data sets and we recorded what are the main pictures that activate these filter, these words, the main ones, and we did the same thing for all of the filters of the first layer and there are nine times nine of them.

Speaker 1:          01:21:24       There are a lot of them. I think in the bottom here you have the filters, which are the weights that were plotted. Just take the filter, plot the whites. This is, this is important only for the first layer. When you go deeper into the network, the filter itself cannot be interpreted. It's super hard to understand it here because the weights are directly multiplying the pixels. The first lay your weights can be interpretable and in fact you see that the, let's look at the third one, the third filter here on the first row. The third filter has weights that are kind of diagonal. Like one of the diagonals and in fact if you look at the Datas that maximize these filters, activation in feature map corresponding to this filter, they're all like cropped images that correspond to diagonals. That's what happens now. The deeper we go, the more fun we have.

Speaker 1:          01:22:19       So let's go results on a vibration set of 50,000 images. What's happened here is they took 50,000 images, therefore propagated to the network they recorded which image is the maximum, the one that maximized the activation of the feature map corresponding to the first filter of layer two, second filter and so on for all the filters. Let's look at one of them. We can see that. Okay, we have a circle on this one. It means that this, the filter gender which generated the feature map corresponding to this has been activated through probably a wheel or something like that, so the, the image of the wheel was the one that maximizes the activation of this one and then we use the deacons method to reconstruct it. Any questions on that? Yeah,

Speaker 3:          01:23:11       face not give you the lord the question. What if do activation function is not really

Speaker 1:          01:23:18       in practice, you would just use a backward to reconstruct if it's Dinesh would use the same, the same type of method and you will try to approximate the reconstruction. Okay, let's go a little deeper. So now same layer two four propagates all the images of the Dataset. Find the nine images that are the maximum activity that lead to the maximum activation of the first filter. These are plotted on top here. What you can see is like for this filter that is the sixth row first filter features are more inviting to small changes. So this filter actually was activated to many different types of circles, spirels wheels, and so it's, it's still activated, although the circles where different sites,

Speaker 4:          01:24:04       okay,

Speaker 1:          01:24:05       can go even deeper up third layer. What's interesting is that the deeper you go, the more complexity you see. So at the beginning we were seeing on the edges and now we see much more complex figures. You can see a face here in this, in this entry. It means that this filter activated for when it's cds, when it has seen a data point that had this face that we reconstructed, it cropped it on the face. The face is kind of red. It means that the more red it was doing more activation, it led to

Speaker 4:          01:24:37       okay

Speaker 1:          01:24:37       and same top nine four layer tree. So these are the nine images that actually led to the face. These are the nine images that maximize the act, the activation of the feature map corresponding to that filter and so on. So here's a,

Speaker 4:          01:25:06       okay. Okay.

Speaker 3:          01:25:59       We can switch back and forth between showing the actual activations and showing images, synthesize

Speaker 7:          01:26:04       to produce high activity.

Speaker 6:          01:26:05       He's giving his own. You mentioned the network right now

Speaker 7:          01:26:09       at the time we get to the fifth convolutional layer. The features being computed represent abstract concepts. So these are the greatest as for example, this neuron seems to respond to faces. We can further investigate this neuron by showing a few different types of information. First, we can artificially create optimized images using new regularization techniques. The one we got this new thing they're on fire is in response to her face and she'll just, one is that they also thought the image search training set the activate this neuron the most as well as pixels from those images. Most responsible for the high activations computer via the de convolution convolution. Rick's feature response to multiple faces in different locations and by looking at the [inaudible].

Speaker 4:          01:26:49       Okay,

Speaker 7:          01:26:50       we can see that it would respond more strongly if we had even darker eyes and Rosier Lips. We can also confirm that it cares about the head and shoulders that ignores the arms and torso.

Speaker 4:          01:27:00       Okay.

Speaker 7:          01:27:00       We can even see that it fires to some extent for cat faces using backdrop or di come. We can see that this unit depends most strongly on a couple of units and the previous layer kind of form and not about a dozen or so. In contrast, let's look at another nurse on your own lead. So what is this unit doing from the top nine images? We may conclude that at fires for different types of clothing, but examining this synthetic images. So it's did, it may be detecting, not clothing per se, but wrinkles in the lifetime. We can see that it's activated by my shirt and smoothing out half of my shirt causes that hack of the activations to decrease. Finally, here's another interesting though.

Speaker 7:          01:27:42       This one has learned to look for printed text in a variety of sizes, colors and fonts. This is pretty cool because we never asked the network to look for wrinkles or text or faces. The only labels we provided the were at the very last leg, so the only reason that network learned features like texts and faces in the middle was to support final decisions at that last layer. For example, the text detector may provide good evidence that a rectangle is in fact it booked, seen on edge and detecting many books next to each other might be a good way of detecting a bookcase, which was one of the categories we trained the net to recognize.

Speaker 4:          01:28:17       Yeah.

Speaker 7:          01:28:18       In this video we've shown some of the features of the deep this toolbox and a few of the things we've learned by using it. You can download it.

Speaker 6:          01:28:24       Yup. So they have a toolbox, which is exactly what you need. Your lights here and you could test the two bucks on your model. It takes time to, to get, get it to run. But, but if you want to visualize all the neurons, it's very helpful. Okay. So, uh, let's go quickly. We spend about three minutes on the optional, the dream 100 fun and uh, yeah, feel free. Feel free to jump in and ask questions. So did the dream one is like Google and uh, the p the, the blog post is by Alexandre more sef. The idea here is to generate parts using these knowledge of digitalization and how would they do that is quite interesting. Now we'll take any input for propagated to the network and at a specific layer that we call the dream layer. Then we'll take the activation and sets the gradient to be called to this activation, the gradient, that layer and they would back propagate integrations to Naples.

Speaker 6:          01:29:28       So earlier what we need is that we defined the new objective function that was equal to an activation and we tried to maximize this objective function. Who would be there doing it even stronger. They take the activations and they said the gradients to be called to the activations and so the stronger the activation, the stronger it's going to become later on and so on and so on and so on. So they're trying to see what the network is activating for and increase even this activation. So for probably get DMH said the gradient of the dreaming layer to be called to exaggeration, but light propagates all the way back to the inputs and update data, Pixel of the image. Do that several times and every time the activation, good change. So you have to set again the new activations to be the the, the gradients of the green layer and by propagating and also makes it, you would see things happening, so it's hard to see here on the screen, but you would have a pig appearing here.

Speaker 6:          01:30:22       You'd have like a tree somewhere there and some animals and a lot of animals are going to start appearing in this cloud. It's interesting because it means, let's say you see this cloud here. If the network thoughts that this cloud looked a little bit like a dog. So one of the, the, the, the feature maps was which would be generated by the feature that detects dog would activate itself a little bit because we said the gradient to equal to the activation is going to increase the appearance of the dog in the image and so on. And then you would see a dog appearing after a few generations. It's quite fine and issues zoom, you'll see that type of thing. So you see a peak snail, it's kind of a big, uh, with this snail, uh, CarePass Cameron bird, dog, dog, fish. I advise you to like look at these on the slides or rather than on the screen, but it's quite fine.

Speaker 6:          01:31:15       And uh, same like if you give that type of image, you would see that because the network thought there was like a tower earlier bits, you will increase the network's confidence in the fact that there is a tower by changing the image and the tower would come out and so on. It's quite a cool. Uh, yeah. And if you dream in lower layers, obviously you will see edges happening or patterns coming because the, the lower layers seem to detect an edge and then you will increase his confidence and his edge. So equally it would create an edge on the image. These are fun.

Speaker 8:          01:31:53       Deep dream on a video

Speaker 6:          01:32:33       gets to the tricky, I'm going to stop. So what one insight that he's fun about it is if the network, and this is not only for deep dream, it's also for, it's mostly for graded assets. Let's say we have an awkward score offered Dumbbell and we define your objective function can be a dumbbell score. And we tried to find images that maximizes the dumbbell when we'd see something like that. It's interesting is that the network thinks that the dumbbell is a hand with a Dumbo, not only to Dumbo. And you could see it too. You see the hands and the reason he has never seen a gun bill alone. So probably image editor who's, they'll beat you up, you don't feel alone in a corner and labeled as number. But he said, uh, it's usually a human trying to, we've hired, okay. So just to summarize what we've learned today, we are now able to answer all the following questions.

Speaker 6:          01:33:32       What part of the employee's responsible for 40 hours goods beam, occlusion sensitivity, class activation map seem to be the best way to go. What is there all of a, given your own feature layer he called involve, reconstruct, searching the data set. What are the top images and who radiant sense checked? Can we check what the number of focuses on [inaudible] intensity saliency, map class activation maps, how does the network cr world, I would say great in the sense maybe deep dreams of cool stuff. And then what are the, the implication and use cases of these visualizations. You can use Saint Lynsey map to segments. It's not very useful given the new methods we have, but the deconvolution that would sing together is widely used for segmentation and reconstruction. Uh, also for generative adversarial networks to generate images and art. Sometimes these visualizations or also helpful to detect if some of the neurons in your network are dead. So let's say you have a network and you use the toolbox and you see that whatever the input, you may give some feature maps or always like it means that the feature that generated these feature map icon building over the inputs probably never detected anything. So it's not even trained. That's a type of each site you can get. Okay. Thanks guys. Sorry we went over time.