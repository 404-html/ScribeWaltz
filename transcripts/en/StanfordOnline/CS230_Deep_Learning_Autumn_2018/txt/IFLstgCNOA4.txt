Speaker 1:          00:05          So hello everyone and welcome for the last lecture of cs two 30 deep learning. So He's been 10 weeks and you've been, you've been studying deep learning all around, starting with fully connected networks, uh, understanding how to boost these networks and make them better. And then, uh, using record neural networks in the last part then is and convolutional neural networks in the fourth part to build models for imaging and texts and other applications. So today's the costs wrap up and uh, the lecture might be a slightly shorter than usual, which we're going to go over a small case study on conversational assistance to start with, which is a, an industrial topic. Um, we will do a small quiz competition with mentee and the fastest Uiux person who has the best answer would win a 400 hours of GPU credits on Amazon.

Speaker 1:          01:08          So you guys can, can start, can start working on it. Um, we will see some class projects advice because you guys have about two weeks, less than two weeks before the, the poster presentation and to find no a project due date. We'd also go over some of the next steps after cs two 30. What have our students done over the past year and what we think are good. Next steps and closing remarks to finish. I'll buy you one if you have a clicker, uh, with, with battery please. Can you bring it to me? Yep. Um, okay. So let's get started with how to build a chat bot to help students find ore and enroll in the right course. So he's going to be a pretty simple case of a chat bot because chatbots and conversational conversational assistance in general have been very hard to be then having a neutral topic.

Speaker 1:          02:07          There is some places where academia has helped, uh, the chatbots improvements. And here we're going to see how we can take all our algorithms, what we've learned in discuss and plug it in in a conversational setting. That sounds good. So let me give you an example. The students might write to the Chat Bot high. I went to enroll in cs one six, eight four winter 2019 to learn coding. Your Chat Bot cannot answer for sure. I just enrolled you. So that would be one goal of the Chat Bot. A second example might be finding information about classes. Hi, what are the undergraduate level history classes offered in spring 2019 then the chat Bot can get back to the students and said, here's the least of history classes offered in spring 2008. So we're making a smarter assumption here. We're building a chat bot for a very restricted area in general.

Speaker 1:          03:09          And a lot of time chatbots, which work very well, are super goal oriented or transactional. And the state of possible, uh, archer and or requests from users is small, smaller than what you could expect in other industrial settings. So here we're making the assumption that the students will only try to find information about a course or we try to enroll in the course. So I want you guys to, to pair in groups of two or three and uh, tried to come up with ideas of what methods that we've seen together. It can be used in order to implement such a chatbox. Okay. So take a minute, introduce yourself to your mates and, and tried to figure out which methods can be leveraged in this case.

Speaker 1:          04:01          Okay. Let's see what we have here. RNS for natural language processing yet transfer learning and it seemed to pick out important words from inputs based on those input triggers. Output, some predefined inflammation from storage. Yeah. So this seems to to say that there's going to be one learning parts where we need to have probably recurrent neural networks helping out and one other knowledge base or storage part where we can retrieve some information. We're going to see that some of the tension models, it's true that today a lot of natural language processing models are built with attention models.

Speaker 2:          04:48          Yeah.

Speaker 1:          04:49          RNN forced speech recognition and speech generation four. So we didn't talk about the speech parts so far. We assume that uh, the conversational assistant is tech space. Uh, but later on we will see what happens if we want to add speech to it.

Speaker 2:          05:06          Okay.

Speaker 1:          05:08          Fancy methods. Oh, reinforcement learning for making this students about responses. That's interesting. So why do you guys think we would need reinforcement learning? Yes.

Speaker 3:          05:25          Contexts. You have different states and you also have like our value. And so she wouldn't be said it was very goal oriented and so you could sort of have a progressive that fashion. Yeah, that's good.

Speaker 1:          05:35          Just to repeat, uh, it's important to keep a notion of context and also we have a sequence off our truancies from the user and uh, the commercial assistance and probably the outcome of the conversation would come far along the way and not that every step. So that's true. Uh, reinforcement learning has been, uh, uh, research, Xapi, commercial assistance as well. And oftentimes we will try to learn a policy for the Chatbot, which given the state will tell us what action to take next. This can be done using Cuellar and ink, which is the method we've seen together. Or sometime we'd policy grievance.

Speaker 2:          06:13          Okay.

Speaker 1:          06:15          Word and coding. So word embedding probably.

Speaker 2:          06:21          Okay,

Speaker 1:          06:22          cool. So it would be, there's many ways to, to plug in a deep learning algorithm in, in this box setting. We're going to see a few of them.

Speaker 2:          06:32          Oh,

Speaker 1:          06:37          uh, first I'd like to introduce some vocabulary, uh, which is commonly use when talking about commercial assistance, conversational assistance. Uh, not Terrance is, you can think of it as a user inputs. So if I say the student utterance, it's the sentence that was written by the students for the Chat Bot. Uh, the assistant utterance is the one coming from the chatbots, like the intended notes, the intention of the user. So in our case we will have two intense, which is very limited. The user either wants to find information from for a course or the user wants to, uh, enroll in a class. These are two different intentions that are probably to be detected early on the conversation. And then you have something called slots. Slots, uh, are used together multiple information from the user on a specific intense that you use your hands. So let's say the students wants to enroll in your class.

Speaker 1:          07:35          In order to enroll the students in your class, you need to fill in several slots. You need to understand probably which class the student is talking about, which quarter the student wants to enroll in the class, which year is the student talking about? And eventually you want to know this shoot suid of the students. But probably we can assume that the MSU ID is already included in the conversation on the environment we're in. So these are three vocabulary and we're also going to talk about turns for commercialization assistance. So so single turn a conversation is when there is just an user returns. Any response and multi turn is when there's several user authoring Cs and a conversational assistant utterances and you understand that Malta multirotor utterance conversations are harder to understand because we need to track context or assumption today will be that we work in an environment with remitted intense and slots. It means we can define too intense and for each of these two intense, there are several slots that we want to fill in is going to make our life easier. Of course, in practice you can have multi myriads off, intense in slots and you did. The task becomes more complicated when you have more of those. So my first question would be how to detect the intense based on, uh, the user utterance. Can you talk about what kind of data set you need to build in order to train a model to detect the intense?

Speaker 2:          09:24          Okay.

Speaker 1:          09:26          Or what type of network do you want to use?

Speaker 1:          09:37          There's not a single good answer, so go for it. Him brainstorm. So I think there's, there's going to be two options obviously because we have a, we have a sequence coming in, which is the user inputs. We might want to use a recurrent neural network to encode long term dependencies, or we might want to use a convolutional network. Actually, a convolutional networks have some benefits that's recurrent neural networks don't have, and they, they might work better. For example, if the intent we're looking for is always included in a small number of words somewhere, Indian put sequence, because you will have a filter scanning that's in the future. It can detect the entities. So each other filter that was trained in order to detect the intense inform, another feature trained to detect the intense enroll. Then these two filter, we detect the word enroll, Lord, the word I'm looking for and so on in order to take the intent.

Speaker 1:          10:33          Okay. In terms of data, what you probably need is pairs of user utterances along with the intent of the user. So you would need to label the data sets like this one with eggs and input. I want to, so it's padded. I want to enroll in [inaudible] 64 winter 2019 to learn coding and this you will label it as enroll and notice that enroll here is a function. So did the label is actually noted as a function and the reason is because we can call this function in order to retrieve information. And another example is high. What are the undergraduate level history classes offered in spring 2018 and this would be labeled as in four. So he's probably a two class classification or three classes. If you want to add a third class that corresponds to other intense user might want to use these chatbots for another intense that the child wasn't built for.

Speaker 1:          11:29          So these are new classes enrolling in form. And what's interesting is that if we identify that the intent of the user is enroll, we probably want to call an API or to request information from another server. And in this case it might be access because the platform we use to enroll in classes is access and same to retrieve information in order to help the user about their classes. We can probably explore courses assuming that these these services have aps, the surfaces of aps. Does that make sense? And now the interesting part is that the enrollment function might request some inputs that you have to identify. Those will be the slots, same 14 form function. Okay. So we could train a sequence classifier, either convolutional or records. And these were not going to go into the details. You've learned it in the sequence models class. How did they take the slots now?

Speaker 1:          12:32          So in terms of data, it's going to look very similar to the previous one, but we will have a sequence to sequence problem now where the user assurance will be a sequence of words and the slot stag will also be a sequence. So for example, show me the Tuesday 5th of December flights from Paris to Kuala Lumpur. If you were to build a conversational assistance for flights and booking, then uh, the label you want to have is probably something like that. Doesn't have to be exactly this, but why they know zero for some of the words, the sequence is B day I day or be Dep, B r. R what do you think these correspond to and why do we need that? We've probably, you've probably seen that in, in the sections a few weeks back.

Speaker 4:          13:31          So why do we do know these labels? Certain format.

Speaker 2:          13:42          Huh?

Speaker 4:          13:42          It helps you out and find a slot facts and like departure or I won't ramble. And then the other one for day two possible things. Yep. Correct. So, uh, I agree with what you said for day day.

Speaker 1:          13:58          Sure. Arrival arrivals. So these words are encoding day, departure and arrival. How about the B and the I and the o?

Speaker 4:          14:08          Yeah. Someone has an idea beginning, beginning because sometimes these things are more than one word. Yeah, exactly. It's me be the notes beginning.

Speaker 1:          14:18          I they know it's in or inside an o out or output in general. So what happens here is that sometimes you would have a slot which might be filled by several words and not a single work and you want to be able to detect this entire chunk called chunking. Um, so you would use a special encoding in order to identify if this word is the beginning of a word that you want to feel in the slot or is the end or inside or out of the word you want to fill in the slot and then they departure arrival or three possible slots that we want to seal in in order to be able to book the flight. If you don't receive these slots, you might want to have your chatbots request these slots. Itero

Speaker 2:          15:03          okay.

Speaker 1:          15:04          Okay. So another example in classes here can be daily departure or arrival class. Like, do you want to travel in echo or business, a number of passenger that you want to have on your flight? Uh, if we were for our Chad, huge would be high. I want to enrolled in cs one to six today, a four winter, 2019 to learn coding. And we will include it by the beginning of the code of the class, beginning of the quarter and beginning of the year. That would be a possibility in coding and then you will train, uh, using a, probably a recurrent neural network and algorithm to predict all these tax. Does that make sense? So now we have already two models. That's all running on our chat bots. One Daddy's 40 intense and one that is for the tax. What'd you think about joint training? Do you think it's something we could do

Speaker 2:          16:01          here

Speaker 1:          16:04          and what do I mean by joint training?

Speaker 2:          16:16          Yup.

Speaker 4:          16:16          Pruning on all the different codes like trading order here and class rather than training and separate network for each of them. Settled like the drag element of the training. Not Training for different codes. No, I was talking more about training for different tasks. So intense and intense for enrolling in 10 from the intention and a and slots tagging is here. We have one intense classifier, which takes any input, sequence and outputs a single class. And we have started tiger, which takes the same inputs, exactly the same inputs and tags every single word in the sequence. So probably we can use join trainee in order to train one network that might be able to do both. And these would be jointly trained with two different loss functions, one, four d intense. And in one photo as loss, it's usually had fallen to join key train two networks, especially in the earlier layers because you end up learning the same type of features. That's, that's interesting. For natural language processing. There's a yes. Have you do the trek loss function for them? Is it calculate both losses and had been deleted and some of them together, or is there a trade off between findings versus finding spots? So the question is, how would you describe the loss function in this joint training? He was actually some to loss functions. The toolers functions you were using, using

Speaker 1:          17:42          it with just some them and hope that's the backpropagation we train actually both networks and the networks will probably have a common base and then we'd be separated after. So let's say you have a first LSTM layer that encode some information about your user utterance. Then this will give a, we give its output to two different networks, which bill will be trained separately. Okay. And class says here our codes for the class quarter, you're and suid assuming suid is already in the environment, we will not need to request it. So can you tell me how to acquire this data now that we've seen it? So take, take about two minutes to discuss with your mates how to acquire that type of data. And then on Sir on mentee. Okay. So let's go over

Speaker 4:          18:34          some of the answers. Mechanical Turk, have people manually collect, annotate the data? That's true. So as we discussed earlier in the quarter, this would be the method which is probably the more rigorous, uh, when it's applied with a specific labeling process and data collection process. Uh, it will take more time. So you would have to build a Ui, a user interface for them to be able to label all these data, which is not trivial in general.

Speaker 1:          19:06          Amazon Mechanical Turk pay large number of Stanford students at works. Uh, have a human chat assistant service user and entered the data in hand labeled data. Yeah, it, you can start with a hand labeling, probably can auto generate some data by substituting dead courses quarter and other types of Oh, that's a good idea. So who wrote that? Someone wants to comment. Yeah.

Speaker 4:          19:41          Yeah, that's a good idea. So I repeat for the CBD students,

Speaker 1:          19:47          um, we already have a bunch of possible dates. We can easily find a list of dates. You've done it in one assignment rights, uh, where you were using the neural machine translation to transfer for human readable dates to machine readable dates. So we have data sets of dates so we could use that. We also have a list of course is that we can probably find on explore courses. Uh, we know that there are not too many quarters and, and we are, we have probably databases for any other tag like least of possible Su ids or like seven figures, something like that. So all numbers of selling, two years hopefully. Um, and then we can have sentences. We'd like blank spots where we insert these and we can generate a lot of data using these insertions scheme automated. And every time we insert we can label.

Speaker 1:          20:38          We're going to see that. Um, I like these ideas. Well, user part of speech Tagger I did three commission to identify examples, requests that are found elsewhere. So, uh, one thing we discussed in section is that you have available models to do part of speech tagging, right? So why don't we use them. These are trained really well and we could give our user Altran sees that we collected online, uh, and tag them automatically using these good models. Of course he's not going to be perfect, but we can at least get started with dots and leverage a model that someone else has built to tag and label our data set. Okay. Good ideas here.

Speaker 1:          21:29          So let's see the data generation process, which is the most strategy to start with. I would say, uh, we would have talking about the, the flight booking, a virtual assistance, we would have a database of all the departure locations, so whatever, Paris, London, uh, Kuala Lumpur and a lot of our eyeballs as well. So these are list of cities that have airports probably in the world. And we will have a list of way to right days and also class business Eiko Eiko plus premium, I don't know, whatever you want, uh, and user utterances. And then what we will do is that we will pool a user, a trans from the database such as this one. I would like to book a flight from depth to our Ivo for, uh, in, in, in business class, let's say in class for this date. And then we can plug in from the to set randomly the slots. Does that make sense? We can generate a lot of data using this process. So this user attributes can be augmented in virtually tens or hundreds of different combinations. So that's one way to augment your data set automatically. Label it, but you also need hand labeled data because you don't want your model to over feet to this specific type of user utterances. Okay. And so, so same for our virtual assistant for the, for, for the university. Hi. I want to enroll in code for quarter year and then we can insert from the database the quarter, the year, the code of different classes so that we can train our network on that. Those, the state augmentation. Makes Sense.

Speaker 1:          23:28          So these are common tricks you would see in invoice papers. And this is an example of one of them. Okay. So we can label automatically when inserting and we can train a sequence to sequence model in order to fill in the slots. Okay. So let's go on mentee and start the competition, which is the the most fun. Okay. So let's get back to to to where we were. We have a chat bot that he's able to answer for sure. I just enrolled you. The way he does that is that it receives the user a trends. I want to enroll in cs one six eight winter 2019 to learn coding. It identifies the intent of the user using a sequence classifier, same type of network as you've built for the Mog fi assignment. And then it also runs another algorithm which will fill in the slots.

Speaker 1:          24:22          And here we have all the slots need. We have the code for the class, we have the quarter, and we have the year. Those tonight ID is implicitly given. So we able to enroll two, enroll the students by calling access with all these slots. Dot. Now let's make it a little more complicated. Let's say the students say, hi, I want to enroll in cs one oh six eight two to learn coding. So the difference between these assurance and the previous one example one is that you don't have all the slots you identify, uh, with your slot stagger. That's [inaudible] is Dakota of a class, but you don't know the quarter, you don't know the year. So you probably want your chat Bot to get back to the, to the student and say for which quarter would you like to enroll? Right? And then the student would hopefully say winter 2000, 19 or winter.

Speaker 1:          25:11          And then you'd have to ask for the year 2019 and finally you can say for sure I just enrolled you. So we're not making any assumption here on natural language generation. You've worked on a Shakespeare assignment where you generate Shakespeare like sentences. In fact a good chat Bot would have this feature of generating language, but for our purposes, which can just hard code that when you're able to enroll the students you just say, I just enrolled you. When you were able to retrieve information from the students, you would just write, here is some information and you would plug in whatever the explore courses API sent back in a Jason. Okay, so here the idea is these students archer and cannot be understood without context. There is no way to understand winter 2019 if you don't have a context management system. Does it make sense? So we want to build that context management system and then the question is how to handle context.

Speaker 1:          26:09          So there is a, there is many, there are many ways to do that and people are still searching for the best ways. One way is to handle it with reinforcement learning. As we mentioned earlier, another way, which is quite intuitive and, and closer to what we've seen together in sequence model. Uh, in the module in the module five is, uh, these type of architectures, which is, which is taken from channels all entwined memory networks with knowledge carryover for multiterm spoken language understanding. So now you're able to understand what multi-term means and twin memory networks. So what happens here just to it is we will save all the history of trances. It means from the beginning of the conversation, we will record all the utterances and messages exchanged between the user and the, the assistant will keep eating the storage that we recall. History, our transits c is the current insurance.

Speaker 1:          27:03          So let's say the students says winter 2019, this is the utterance of the, the student. At this point we will run this Si, uh, and of course like it's, it's, this entrance would be around into an RNN and we will get back to an encoding of the sentence. So there is all the like word embedding stuff that I don't describe what you guys are used to it. So we use word embeddings, we were running to uh, we run into an RNN and we get back the encoding of the user attributes and these and CUNY will then be compared to what we have in memory. So all of the user, our truancy is that we had in memory are also going to be running an RNN that will encode their information in vectors. These vectors are going to be put in a memory representation and are you will be directly inner product. We will have an inner product from are you with all the memories and this pooled into a softmax will give us a vector of attention that you guys should be used to. Now, knowledge, attention, distribution, telling us what the relation, where should we put our attention in the memory for this specific, does that make sense? So simple in our product. Softmax gives us a series of weights here.

Speaker 1:          28:28          Okay. Then we get a weighted sum of all these attention weights multiplied by your memory and it gives us a vector that encodes the relevance of the memory regarding our current utterance. This is then psalms and run into a simple matrix multiplication to get an output vector, which would be around in a slot stag in sequence. And usually it's experimental but they pass also the current utterance to the RNN tiger and the RNN Togare comes up with a slot tagging. So using that, you can understand that winter 2019 is actually the tag for the slots quarter and year because you have this memory network. Does it make sense?

Speaker 1:          29:14          So this is another type of attention models you want to use and these memory networks, it can be used to manage some context for the slot Steiger. Okay, so just to recap, we have our example. Hi, I want to enroll in a class and we detect the intense which is enrolled. We also detect that there is some slots missing because we know, we know that the enrollment function needs the quarter, the year end, the class in order to be able to be called. So we have to ask for those. So we probably hard good in the fact that if you don't have the quarter, the year end, the class you probably want to first ask for the class or the quarter or the year, then you can, you can get back to the person by asking which class do you want to enroll in? The person would get back to you. You will use your memory network to understand that cs two 30 is a slots for the enroll intense. You would fill it in. So now we have our intent with the class equals yes, two 30 and we have our slots quarter and year, which are to be filled. The chatbot get bags for each quarter and hopefully the student gives you the year at the same time and you can fill in the slots. And then you are enrolled in cs two 34 winter 2019

Speaker 1:          30:33          yeah, she'd be spring. Yeah, he's shy, but he's not trained very way. Okay. Any questions on that? So these are very simple case of a, of a conversational assistant. Just to give you some ideas. There's some paper listed in the presentation that you can go to in order to get more advanced, uh, research insights. Uh, but the idea here is that we're limited to a specific intense to two specific intense and a few slots. What do you think we would need if we didn't restrict ourselves to specific intense and slots?

Speaker 4:          31:25          It's a very complicated, one industrial way to do it is to use a knowledge graph. What do you mean? Let's say you were an ecommerce platform. You probably have from your platform or knowledge draft oil of all the items on the platform. We've connections among them. Like let's say color of, let's say you have a shoe, a shoe is lost. That might be the objective for the intense, I want to buy something,

Speaker 1:          31:57          right? The shoe can have several attributes like color or size or men or women like gender and all these are connected together in a gen, in a, in a, in a, in a gigantic knowledge graph. And you will follow the path of this knowledge graph following some probabilities, probabilities. So when we detect the intent of the user, which is buy something, we could identify the object, I want to buy a shoe. And then based on our knowledge graph, it says that the next question that we should ask, or the next slots that we need to feel is a which brand you want your shoe to be. And so the knowledge graph is going to tell you we'd 60% probability go to brand and ask about the brand once you're there, what other information you need in order to be able to retrieve five results for the user to review and so on. So the knowledge graph is something industrial. It can be used in order to have multiple intense multiple slots for every intense. Okay. And at the end we can make an APA call hair we see as two 30 quarter winter 2019 quarter winter year 2019. And the suid. Okay. Another question I had for you, I, I've had for you, I have for you is how to evaluate the performance of the Chat Bot. What do you think of that?

Speaker 1:          33:33          So there are common ways to, to, to evaluate several parts of your pipeline. Like how is your slot tiger doing? How is your intent classifier? Duke, you can use metrics such as precision and recall f one score does a mix of both, uh, and report those in order to compare how this module is doing for the Chat Bot. But ultimately you want to understand how good is your chat bot overall. So some experiments are done and this is a paper of a deeper enforcement learning chatbots built in 2017 by the Miller, uh, uh, on, at all. And what they did is that they used mechanical Turk in order to evaluate their chat Bot and also build a scoring system for their reinforcement learning chat Bot. So I'm reading for you the instructions. Uh, you will be presented with a conversation between two speakers, speaker a and B.

Speaker 1:          34:26          You will also be presented with four potential responses from one of the speakers for this dialogue. And the task is for you to reach each of the responses between one in appropriate. It doesn't make sense to five highly appropriate and interesting based on how appropriate the response is to continue the conversation. Three is neutral. And uh, if two responses are equally appropriate, you should give them the same score. And if you see response that is not in English, please give a one score. So here's what happens from a user perspective, you would have a conversation, you need to work on your English. Why do you say that? That's about me. Well, your English is very poor. So this is a conversation. And then the response one is, but English is my native language. Response to is. What other reasons come to mind responds? Three is here is a funny facts.

Speaker 1:          35:24          Go is the shortest complete sentence in the English language. And then the fourth, the responses by doggy. Yeah. So if you see you have to, you have to score, uh, you have to score these, uh, these responses according to what you think, how relevant they are. And then, uh, and then these scores will be used either for the scoring system of the deeper enforcement learning chatbots or it can be used to evaluate how good is your chat Bot compared to other chatbots. So maybe each of these responses come from a different model. Does that make sense?

Speaker 1:          36:03          So these are a few ways. They are not under way, which is asking for the opinion of the user on a different uh, responses. So let's say you are a user and um, you are, you are comparing to chatbots. You can give your opinion on which one you think is more natural. And you would ask a lot of users to do that, to compare two or three chatbots together and also compare them to natural language from human. And then by doing a lot of uh, mean opinion score, uh, experiments, you can evaluate which chatbots are better than the others. Just comparing them one on one. Okay. Now getting back to one thing that a student mentioned earlier is what if we want to have a vocal assistance? So right now, or as you said is not vocal, it's just text. What other things do we need to build in order to make it a vocal assistance?

Speaker 1:          37:04          We're not going to go into in the details, but roughly you would need a uh, a speech to text system, which will take the voice of the user converted into a text. And these ads you've seen in the sequence model class has different step in the pipeline, uh, and the speech to text and the text to speech that takes the text from the chatbots and converted into a voice. So that's how you have like virtual assistants talking to us is because they have a text to speech system running. And these are three papers. The first one is the speech to from Baidu seem, uh, which built an end to end speech recognition in English and Mandarin. And the two others are text to speech synthesis. So one came up in February, 2018, which is the TACO truck two. And the second one is wavenet, which is a very popular generative models.

Speaker 1:          37:54          And these are, these are far beyond the scope of the class. Uh, but uh, you can study them in other classes at Stanford, which are more specific to speech. Okay. Cut Class project advice. So this Friday we're going to go over, uh, again the rubrics of what we look at when we, when we grade projects. And here is the list of things we would look at. Uh, so make sure you have a very good problem description. When you read papers, you see that there is a very good abstract. We expect you to give us a very good abstract so that when we read it, we get a good understanding of the paper, a hyper parameter tuning, always report what you do. You don't need to to be very exhaustive, but what you can just tell us what hyper parameters you've been choosing and which ones you've been testing and why they didn't work.

Speaker 1:          38:43          Um, the writing, uh, we look for typos. This is common in integrating scheme typos, a clear language. Uh, so review it, uh, peer review your paper, uh, explanation of choice in this year. And this is a very important part. We expect you to explain, uh, the decisions you're making. So we don't want you to, to tell us I've taken, I've made that decision just without explaining, but rather tell us there is this paper that mentioned that this architecture worked well on that specific task. Uh, I've tried three architectures. Here are my hyper parameters and results. That's why I'm going to, I'm going to dig more into that one. And so on a data cleaning and preprocessing if applicable to your pro project, explain it, uh, how much code you wrote on your own. It's important to us and please submit your guitar or privately to the Tas when you submit your is going to make it easier for us to review the code.

Speaker 1:          39:40          Um, insights and discussions include the next steps. What would you have done if you had more time? Uh, and also interpret your results. Don't just give results without explanation, but rather tried to extract information from these results. And you can also drive your next steps. Explanation, uh, residents. So important. But if you don't have the results you expected, it's fine. We will look at how much work you've done and some tasks are very complicated. We don't expect you to beat state of the art on every single task. Some of you are going to meet state of the art, hopefully, uh, but those of you who didn't steal, report all your results and explain why it didn't work. Uh, give references and also penalty for more than five pages. So if you're working on a, on a theoretical project, you can add additional pages as appendix a.

Speaker 1:          40:32          You can also add an appendix for your project, but the core has to be five pages. Uh, and for the final poster presentation, which will happen not this Friday. Next one, uh, we will ask you to pitch your project in three minutes. So not everyone in the group has to talk, but at least one person has to talk. And, and we prefer if several of you talk in the project, but you have three minutes to pitch your project. So prepared the pitch in advance and you will have two minutes of questions from the ta, which are also part of the grading. Okay. Finally, what's next after cs two 30. So there's a ton of class at Stanford. We're in a good learning environment, which is just super, uh, next steps can be in the university classes you can take in natural language processing and computer vision, but also classes from different departments.

Speaker 1:          41:25          Uh, deep generative models is a, a good way to learn about text to speech for example or Ganz. Uh, probably see graphical models is also a very important class in the, in the CS department. Of course if you haven't taken it yet, cs two to nine machine learning or cs two tonight, applied machine learning or uh, do go to, to learn machine learning. Reinforcement learning is a class where you can, you can delve more into a cue learning policy gradients and all these methods that sometime use deep learning. So we're going to publish that list in case you want to check it. But these are examples of classes you can take an of course there are other classes that tournament not mentioned here that might be relevant to pursue. Uh, you're learning in, in deep deep learning and machine learning. Okay. That said, uh, I'm willing to, to give the microphone to Andrew for closing remarks and a, and yeah, good luck on your projects. Uh, so we'll see you on Friday for the discussion sections and next week for the final project. Do you have your microphone? Sure.

Speaker 5:          42:37          Yeah. So all right, here we are at the end of this class. Oh yeah. The, at the end of this class, um, you know, dia new reps conference, um, uh, is taking place right now. Formerly the nips conference up, I renamed to new ropes and I remember it was a 10 years ago that, um, at that time a phd student in the Diet or ratio Rainer presents the paper workshop paper in Nips, uh, telling people, hey, cause they're using gps and crew there, which is a new thing that Nvidia just publish, um, to train your networks. And we've done that work on a GPU server that Ian Goodfellow, the creative gans how built in his dorm room, um, when he was an Undergrad at Stanford. So our first few few serve was built into Stanford undergrads dorm room. Um, and, um, uh, I remember sitting down with Jeff Hinton and a food court and saying, hey, check out this crew the thing.

Speaker 5:          43:32          And Jeff said, ah, but GPU program is really hot. But then, but then, but, but oh, maybe this glue, the thing looks promising. Um, and I tell this story because I want you to know as Stanford students that your work can Matta, right. When Ian Goodfellow, um, build that GPU server in his dorm room. Um, I had no idea if you realize that a decade later, you know, someone would be winning several hundred hours of AWS credits, uh, uh, to try and pick it up. Deep Learning Algorithms. But, um, I think as Stanford here at Stanford University, but very much at the heart of the technology world, I think Silicon Valley is here to a large pot because Stanford University is here. And, um, we live in a world where with the superpowers that you now have, um, you have a lot of opportunities to do new and exciting world, which may or may not seem like a match in the short run, uh, maybe even seen, um, consequential in the short run be concerns that you have a huge impact in the long run.

Speaker 5:          44:35          Um, actually a couple of weekends ago, so, um, my wife, uh, we roast coffee beans at home, right? My wife buys raw coffee beans and then we actually roast them and Carol, my wife tends to roast them and this is really cheap popcorn popper that we have. Right. You know, so I don't have, I don't know how much coffee you guys drink. I drink a lot of coffee and so, um, you know, so carer bases being coffee beans, she puts them in this like cheap popcorn popper, which me for popping popcorn, not me for roasting coffee beans is one of the standard cheap ways to roast coffee regions and, and alumni way. I drink the coffee, she makes her, sometimes she burns the coffee views. Um, so, uh, I found this article on the Internet from a former student that had written an article and how they use machine learning to rose to, to, to optimize the roasting our coffee beans.

Speaker 5:          45:23          Um, and say Ford the did the Carol, she wasn't very happy about that, but that I raise, this is another example of how, um, uh, all of you, um, you know, I would never have thought of applying machine learning of the roasting coffee views. Uh, it's just, I mean, you know, I like my coffee but that it had never occurred to me to do that. That someone taking a machine learning class, um, like you guys are, go ahead and come up with a better, we're roasting coffee beans using learning our ribbons. Um, and again, I think you would, I don't know if for compressing the road is or was thinking of building a business, all of it, I don't know. There might be a business there. They might not or it might be just a fun personal hobby actually. Don't know. Um, but all of you with these skills have that opportunity.

Speaker 5:          46:10          And then, um, again, earlier this week, was it Monday night, um, a group of us, uh, we were actually in the gates building, um, where a bunch of students actually from there, yeah. For Healthcare bootcamp that Ken alluded to. Yeah. We're going over some of the final projects for the, for the students and that you have to healthcare bootcamp. Um, we're, we're, we're working on and I think, and I think I actually met several people including our ti right when she first participated in much earlier version of that Ui. Healthcare. We can see it, you can ask rt of others lives interested. But there, um, one of the, uh, masters students who's working with pcs in print of Raj broker, they think you guys been in this class. He was demoing an app where you could pull up an x ray film, uh, and took a picture with your cell phone.

Speaker 5:          47:00          Um, upload the picture to a website and have a website, you know, read the x ray and suggest a diagnosis for, uh, for our patients. Uh, most of the planets today has insufficient access to radiology services. There are many countries where it costs you three months of salary, um, to go and get an x ray taken and then maybe try to find the radiologist to read it. But most of the planet, um, billions of people on this planet do not have sufficient services or radiology services. And, um, while the statuses and the AFA healthcare bootcamp is still a research project, actually you recall Arthur on the checks and that people weren't sure it yeah, right. Yes, I'll do, is share a coauthor on, on, on, on when these papers, um, it is a game, maybe work done here at Stanford that, you know, is taking the first steps to what maybe if we can improve the deep learning algorithms, past rectory hurdles, you know, proof safety, maybe that type of work.

Speaker 5:          47:59          Tapping, you're a Stanford, I'm doing half the healthcare. Maybe that will have a transformative effect on how healthcare is run, um, around the world. So, um, the skills that you guys now have, uh, uh, are very unique set of skills. They're not that many people on the planet today that can apply learning algorithms and deep learning algorithms the way that you can. And you can tell a lot of the ideas you learned in this course where you know, invented in the last year or two. So this is just not yet been time for these ideas even come widespread. And if I look at a lot of the most pressing problems facing society be a lack of access to health care or um, scientists spent a lot of times think about climate change. Um, uh, uh, and I think if we look at the, the, can we improve access to education?

Speaker 5:          48:50          Can we just make whole society run more efficiently? Um, I think that all of you have the skills to do very unique projects. Um, and I hope that as you graduate from this class, I'm sure some of you are, we'll great businesses mean all of the money. That's great. And I hope that all of you will also take the unique skills you have to work on projects that, not to the most to other people that, that, that hope other people. Um, because if one of you does not take your skills to do something meaningful, then there's probably some very meaningful project that just no one is working on because I think the number of meaningful projects, um, I think actually greatly exceeds the number of people in the world today. That a skill, that deep learning, which is why all of you have a unique opportunity to take these algorithms and you now know about to apply to anything from developing novel chatbots, um, uh, to improving health care too.

Speaker 5:          49:44          I guess my team are landing ais, improving manufacturing, agriculture, also some health care, um, to maybe helping with climate change, um, to helping with global education. Uh, and, and, and the other problems that, that really matter. So I hope, I hope, I hope that all of you go on, um, to, to do work that matters. Um, and then one last story. Um, you know, a few, few months ago now, um, I got to drive a tractor, right? It was very vague. Lovin scary. If he was like a big a machine, then I should be qualified to drive. Um, is, is a huge tractor and it turns out that when you drive a tractor, so it turns out when you drive a normal car, you know, it's really clear which way is up by a steering wheel, right? Yeah. You point us to ring up and heal your car drives forward, uh, for the tractor that I got to drive this huge tractor.

Speaker 5:          50:37          It turns out there is this giant steering wheel. And to drive straight, the giant steering wheel was just oriented. That's a weird angle. And to turn right, you turn it clockwise to turn it up your turn. Anticlockwise and Dell, is that right? So there's a lot of fun. Um, and maybe in addition to, uh, uh, and, and it was just fun. You know, I drove a tractor, made a uterine, drove back to where I started, did not hit anyone, no accident. And then I climbed down off this giant tractor. Um, and maybe I tell that story because, uh, uh, I hope that even while you are doing this important, uh, uh, maybe beneficial to other people sense of work, um, I hope, I hope you also have fun. I think that I feel really privileged that as a machine learning engineer, um, I, some days I get to go drive a tractor.

Speaker 5:          51:28          Right. Uh, and, and I hope that, um, and one of the most exciting things, um, you know, I feel like, um, uh, a lot of the best, a lot of the biggest untapped opportunities for AI like old side, the software industry. Um, I'm very proud of the work that help do, you know, leading the group rain team Vdi. I do. And I think more people should do that type of work. Um, and I think that, um, here in silicon valley, many of you will get jobs in the tech sector and that's great. We need more people to do that. And I also think that if you look at all of human activity, the majority of human activity is actually outside the software industry. The majority of global GDP growth or global GDP is actually outside the software industry. And I would just urge you as you're considering what is the most meaningful work, so consider the software industry, but also look outside the software industry.

Speaker 5:          52:22          Because I think really the biggest untapped opportunities for AI, like outside, I think light outside the software industry and um, and we can't have everyone doing the same thing, right? It's actually not a healthy planet. If everyone you know, works on the improve web search or improve or, or, or, or even improved healthcare. I think we need a world where all of you have these skills, share these skills, teach other people what you've learned and go out to do this work that hopefully affects the software industry, affects other industries, affects profit, nonprofit affects governments, um, but uses these AI capabilities to lift up the whole human race. Okay. Um, and then finally, um, uh, the last thing to say on behalf of Ken and me and the whole teaching team is, um, I wanted to thank you for your hard work in this class. I know that, you know, watching the videos are, uh, doing the homeworks and the website, uh, and the TA's going to the section.

Speaker 5:          53:19          Um, uh, you know, that many of you have put a lot of work in this class and it wasn't so long ago. I guess when I was a student, uh, you know, staying at home, doing this homework, like trying to derive that math thing, I also take some online courses myself. So it's actually not so long ago that, you know, I was sitting in a computer mice that you kind of watch some cool Sarah videos and they click on this click on dad and also things online. Uh, and, and, and I, I appreciate, uh, Jen and I, the whole teaching team appreciate all the hard work you've put into this. Um, and I hope also that, um, you called the law all of your hard work and that you will take these rare and unique skills you now have to go on and, and when you graduate from Stanford's a offer, the Oh, oh, for the home viewers, I guess a whole viewers as it was in costume Vus that you take these risks, those do not happen.

Speaker 5:          54:10          And he'd go on to do work, then maths isn't going to do record calls on the people. So if that's, um, I look forward to seeing all of your projects at the poster session, uh, uh, and apologize in advance. We won't be there. Really get a deep understanding of three minutes, but don't worry, we do reach your pressure roof once. Uh, uh, but I look forward to seeing, uh, hope you are looking for also to seeing everyone else's work or the poster session that, let me just say on behalf of the, and me and the whole teaching your team. Thank you all very much. Thank you.

Speaker 2:          54:41          [inaudible].