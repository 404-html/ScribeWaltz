Speaker 1:          00:00:06       All right here. He [inaudible]. Okay. I guess what life, uh, as as Arthur was saying, please enter your son. It's ID. Uh, we can bring this up again at the end of class today. We're just take another like what, 20 seconds and then we'll, we'll go into the main discussion.

Speaker 2:          00:00:30       All right.

Speaker 1:          00:00:34       So, um, what I want to discuss with you today is, um, uh, may, why were they called full cycle deep learning applications, right? Um,

Speaker 1:          00:00:53       and so, um, I think this Sunday, uh, you'll be submitting your proposals for the class projects you do this quarter. And, um, in most of the, uh, in, in a lot of the West you learn about the machine learning projects. You learn how to build machine learning models. Um, one of the one to do today is share with you the bigger context of how a machine learning model, how a neural network by train, uh, fits in the context of a bigger project. Uh, so what are all the steps, right? Just as if you're writing a software product. Yeah. You take other classes and learn you, oh, what happened there that teach you how to build a website, for example? What does that, um, but to build a product requires more than just building a website. Right? So what are the, what are the other things you need to do to actually do a successful software project? And in this case to do a successful machine learning application? Um, and so, uh, let's see. So to Oh, Yep. Oh, test, test is the audio on test. Could you turn off the audio? How's this? Yup. Can't hear me. Hello. Hi. Oh, I think I'm broadcasting. I hear myself great.

Speaker 1:          00:02:13       Okay. You can hear me now. Great. Thank you. Alright, thank you. Alright, so one, the one that did his share of you, um, full cycle machine learning, not just how to, uh, you learn a lot about how the built deep learning models, but how does that fit in a bigger project, right? Just as if you're taking the clause on building a website, then great. You didn't know how the code, they have a website that really valuable, but whether all the things you need to do to make us successful website to build their, build a project that involves launching a website or a mobile app or whatever. Um, so as, as you plan for your class project proposals due to Sunday, uh, if you're doing an application project that fits in the context of a bigger application also keeps on with these steps in mind. Right?

Speaker 1:          00:02:57       So, um, you know, these are what I think of as the steps of an ml project or really maybe maybe not fast project, but maybe are serious machine learning application. Right? And I think, I'll know I've built a lot of machine learning products over several years. So some of these are also things that I wish I had known like, you know, many years ago. Um, one, this was kind of maybe kind of obvious, but you know, a problem. And let's say for the sake of simplicity data, you use supervised learning, right? It turns out for the CSU 30 costs, Rajai eggs, I think more than 50% of the class projects tend to use supervisor. And then there are also other projects they use. And I've using gans we should talk about later this quarter or other things. But I think, you know, let's say you supervise there anything to take build that you're seeing application.

Speaker 1:          00:03:54       Um, and, and I think for today I'm going to use as a running example, building a, um, uh, building a voice activated device. Right? So, you know, uh, I don't know actually how many of you have like a smart speaker in your home, like a voice activated device in your home, you know, in the US? Well, not that many of you are interesting. Okay, cool. Yeah, so I think, uh, uh, you know, the Amazon Echos Google homes, that apple series or the, the in, in, in China, my one of my former team was built by two zero s uh, but let's say for the sake of argument that you want to build a voice activated device and I'm going to use it as a running example. Um, and so in order to build a voice activated device, and again, I'm not going to use any of the commercial brands like Alexa or okay Google or hey Siri or I guess in China was a hello sal duty while the south do anyhow, which means kind of roughly, hello little do.

Speaker 1:          00:04:50       Um, but let's use a more neutral word, which is he wanted to build a device that your response there where it activates and you're actually going to implement it as a problem set later this quarter. Um, but so you want to build a yeah, nope. Volume. Uh, uh, let's see how that, okay. Is this better now? Yes. No, this is better. Okay, cool. Thank you. Logan. Ironic talk about speech recognition and the volume is higher. Okay. Um, so let's say you want, wow, let's do that. Let me know if they've come software gave it. Thank you. Um, so let's, you want to build a voice activated device. So the key components, the key machine learning and deep learning components is going to be a learning algorithm that takes us input and audio clip and outputs. Um, did it detect what's sometimes called a trigger word.

Speaker 1:          00:05:53       Now did I go software game? Okay, this is okay, great. All right. And, and I'll plus y zero one digit to check the trigger words such as Alexa or okay Google or hey Siri or a hello little do or, um, uh, or activate or whatever wake where they'll trigger word, right? Um, and so step one is a select a problem. Um, and then in order the trainer there learning algorithm, you need to get they both data. If you apply supervised learning and then you design a model, use back prof or some of the other albums you've learned about momentum, Adam, you know, various optimization algorithms, gradient descent to train the model.

Speaker 1:          00:06:50       And then maybe you testing all your test that and then you deploy it. Meaning just start selling these smart speakers and you know, putting them into hopefully until your uses homes. Um, and then you have to maintain the system. They'll talk about this later as well. Uh, and, and this is not chronological beds. Uh, one thing that is often done but I want to talk about today at the end is dead. It's not really, step eight is a Qa, which is a quality assurance, which is an ongoing process. Right? And so, um, one, uh, let's see. So as you said, if you want to build a product, everyone selling machine there any product, these are maybe some of the key steps you need to work on. Um, some observations when you train them all though training them all the is often a very iterative process.

Speaker 1:          00:07:45       So every time we train the machine learning model, you find that, you know, I can almost guarantee whatever you do, it will not work, at least not the first time. Right? And so you find that even though I've written it as a sequence of steps, when you train them all though young ago, know that neural network architecture, it didn't work. I need to increase the number of hidden units or change the realization or such. They're RNN or switch to a totally different architecture. And sometimes you train them all day and go, nope, that didn't work. Um, I need to get more data. Right? And so this is often a very iterative process where you're cycling through, um, oh to several different steps here. Um, and then I think, uh, one distinction that you have not yet during the ball in the Coursera and the deep learning.ai Coursera videos is how to split up the data into train death and tests.

Speaker 1:          00:08:34       So I'm going to simplify those details for now, but just as a foreshadowing, I guess you learn later in the, in the, uh, deeply into AI, Coursera videos is how to take a data set. You have training to excuse me, the entire training set, um, uh, into a set that you actually test, cross validate using during development called the deaf center development sets, or hold our cross validation set as soon as a separate test set. So you learn about this later, but I'm just simplifying a little bit for today. Okay. So, um, uh, so I think, um, the first thing I want to do is ask you a question, right? So we're going to talk through many of these steps. Oh. And it turns out that, um, what a lot of machine learning classes do and do a good job to change is focusing on maybe these three steps.

Speaker 1:          00:09:28       So maybe these four steps, right. And one of the ones that do today is spend more time. So this is the hearts and machine learning. How do you build a great model? A and one other one that do today is spend more time talking about step one and six and seven and then just a little bit of time talking about the call this because you kind of need to do the steps was well you want to go with deep learning product. I'll go on the machine learning application. Okay. Um, so let's start the discussion question. Um, I'm actually curious, uh, if you are selecting a project to work on, uh, uh, what are the actually, so I don't, don't answer this yet. I'll tell you what the question was going to ask is, which is, all right, uh, what properties make for a good candidate deep learning project.

Speaker 1:          00:10:20       But don't answer yet right though. I want to say a few more things before I invite you to answer, which is that, um, all of you for the last few days I hope have been thinking about what pressure you want to do for this cause. And what I want to do is just discuss some properties of what are good projects to work on and what are maybe not good practice and work on. Okay. And, and think of this as your chance to give your classmates advice, right. One of the things you're consummation should think about, the shiny decides this is a good price, the work on. Okay. Um, and so what I want to do for today is, uh, use, um, this voice activated thing as, as a, as a motivating example. And you know, there's actually one project I was working on. Uh, the, there's actually a thought that we're actually, there was one project I thought that working on with decided not to work on, uh, and that, that there's a voice activated device.

Speaker 1:          00:11:08       So it turns out that, um, these voice activated devices and Echo Google homes and so on, they are taking off quite rapidly. In the U s and around the world. Um, it turns out that one of the, you know, significant pain points of these devices is the need to configure it, right. To set that up for Wifi. So I've done a lot of work on speech recognition, you know, a hotel dialogue work and Google speech system. I let the buy to speech system. So I've been published papers and speech recognition and I have a, I have one of these devices in my home, right? Uh, actually I was, I have the Amazon Echo in my living room. Um, but even to this day I have configured exactly one light bulb to be hooked up to be controlled by my echo because the setup process, not blaming any country, it's just difficult to hook up, you know, it Wifi enabled light bulb and then to set it up so that your smart speaker or whatever, I was going to say, you know, smart device turned off to the lab.

Speaker 1:          00:12:04       So I have one light bulb in my living room where I can turn on and off and that's it, right. Even as a speech researcher. So I'm going to say a bad example. Um, so one, one, one application that I think dead I was actually seriously cause were working on is to build a embedded device that you can sell to lamp makers so that, I don't know where you buy your downstroke and you'll have a few labs or my career or a few labs or wherever, but you can buy a desk lamp so that when you buy the desk lamp, there's already a built in microphone so that without needing to connect this thing to Wifi, you know as a, Hey, here's a $20 a desk lamp. Um, but then on your desk and you can go home and say desk lamp, turn on or turn off a.

Speaker 1:          00:12:53       Then I think that will help a lot more users get voice activated devices into their home and it's actually not clear to me. If you want to turn on a desk lamp is actually not clear to me that you want to turn to a smart speaker and say, Hey smart speaker, please turn on that lab over there. It may be a fuse one, natural it just talk directly to a desk lamp and tell it to turn on a term. Um, and so, uh, also for wellness where if someone were friends, now we evaluated this, we actually thought that this could be a reasonable business to build embedded devices to sell to lamp makers or other device makers so that they can sell their own voice activated devices without needing this complicated wifi setup process. Um, and so to do this, you would need to build a learning algorithm and have it run in an embedded device.

Speaker 1:          00:13:39       They just impose an audio clip and I'll quiz, you know, whenever it detects the, the wake word and instead of a wake where being activated the week where it would be a lamp turn on or turn off, you need to wake words or trigger words one to turn it on, when to turn it off. Right. Oh. And, and, and, and I think just the other thing that, um, I think would make this work, uh, is, um, uh, uh, to, uh, to give these devices names. So if you have five lamps or two lambs, you you need an way to index into these different desk lamps. So, um, let's see, you decide for your project, you know, to have a little switch here. So this lab could be called John or Mary or Bob or hours, like a four way switch. So that's depending on where you said this before we switch, you can see, you know, John very term on or is it if you decide to call this lamb John, like it was a goodness, some of the names so you don't have every land by the same name.

Speaker 1:          00:14:33       Okay. Um, so what I'm going to do is use as a, a motivating example, um, this as a possible project. Oh. And I'm not working on this. If any of you want to build a start up doing this, go for it. I, I, this is not, I felt my teams and I had better ideas that we wanted to do other things in this, but I should don't see anything wrong with this. I think this actually could be a reasonable thing to come see us for help. And I'm not doing it. So you are very welcome to if you want. Okay. Um, so now the question I want to post you is a, when you're brainstorming project ideas, you know, like this idea, some other idea, um, what are the things you would want to watch out for? What, what are the properties that you would want to be true in order for you to few good proposing this as a, as a CSU 30 project, right? So why should take a minute and write this down? I think, uh, uh, uh, yeah. What if you're asking a friend, if a friend is asking you, what are the things I should look at to see if something has a big project, what would you, what is your recommended them? So feel free, just write down a few keywords and then we'll see what people say. And then, and then I'll tell you what I tend to look out for when I'm selecting projects and they have lists of a five points.

Speaker 2:          00:15:50       Okay.

Speaker 1:          00:15:52       To take late, I don't know, like two minutes to, oh, sorry, this is not activate it.

Speaker 2:          00:16:00       MMM.

Speaker 1:          00:16:02       I do not ever, the answer is up and to answer this. Okay. Let me test the Internet says just checking it on. Yup. I am connected to the Internet. Uh, it, any ideas? Oh, I see. Okay. All right. Let me try that. Okay. Thank you.

Speaker 2:          00:16:34       Oh yes, thank you. Thanks.

Speaker 1:          00:17:11       So can you take like two minutes to enter? I think, I think I can think of this and let you enter multiple answers. Let me stick tunes. All right, another one minute.

Speaker 2:          00:18:18       Okay. Yeah. Hi,

Speaker 1:          00:18:37       Miss 30 seconds.

Speaker 2:          00:18:47       Okay. Yeah. Okay. Okay. Sweet to one. Well,

Speaker 1:          00:19:12       maybe in hindsight that wasn't the best visualization. Can people see this?

Speaker 2:          00:19:32       MMM,

Speaker 1:          00:19:39       well the line, trying to see if, all right, so, uh, data novels, he lost the data. Some of these really small, he wouldn't doable number of examples. Do you have one, two months? No. Office salvo. You industry a fields a clear objective. Practical. Useful.

Speaker 2:          00:19:57       Yeah.

Speaker 1:          00:19:57       Huh. Oh, can we finish in time? Uh, host real life problem. Useful. Hasn't been done computationally tractable. Yeah. Generalization. I see. Cool. Great. Um, let me make some comments on fees. I think I, this is, this is pretty good. I had a list of five bullet points that maybe I just share with you my, this a five. Ah, um, which is I think just some things I encourage you to pay attention to. Um, you know, this, this may or may not be the best criteria but interests, interests, just, oh no, it doesn't. Hopefully you can work on something that you're actually interested in. Um, and then I think, uh, uh, data availability, which many of you cited is a good criteria or one of the ways that, um, Stanford cost projects sometimes do not go well is if students spend a month to try to collect data and after a monk have not yet found the Datatel and then, and then, you know, and then this and then there's a lot of waste of time.

Speaker 1:          00:21:04       Um, one thing that I would encourage you to consider as well is a domain knowledge. Um, and I think that if you are a biologist and have unique knowledge into some aspect of biology to which you want to apply machine learning, that will actually let you use very interesting project, right? That is actually difficult for others to do. Um, and I think more generally as, as advice for navigating your careers. Right? So you a shame because AI, machine learning, deep learning, there's so much, there's so many people wanting to jump into machine learning and deep learning. Um, actually give an example. So I sometimes talk to doctors near Radiology students, uh, including Stanford and other universities realize you students that want to learn about machine learning, right? Because they hear about, you know, deep learning, maybe someday affecting radiologists as jobs. And so they wanted to be politic learning.

Speaker 1:          00:22:02       And so my career advice to them is usually to not forget everything they learned as a doctor and try to, you know, do machine learning one on one from scratch and just forget everything they learned as a doctor and just become a CS major. I think that that, that path can work, but I think we're radiologists could do the most unique work, uh, that, that allows them to make the most union contribution is that they use their domain knowledge of healthcare, radiology and do something in machine learning applied to radiology rate. Uh, and so, all right. How, how, how many, how many millennials are there in this class?

Speaker 1:          00:22:42       What does that mean? Me, me, me, me thing. All right. This is really wrong. I think it's because of the word cloud. So very council where it frequency, right? The money thing. I don't know. I have very mixed feelings about that. All right. Um, but then as you for, I actually know that some of you are taking your deep learning because you work in a different discipline and you want to do something in this hot, new, exciting thing of machine learning and they think whatever this summit is you're in. If your domain knowledge about some of the area, you know, education, civil engineering, biology, law, um, taking deep learning allows you to do very unique work, applying machine learning to your domain. Right? Oh, let's see. Um, I think that, uh, uh, um, I think what I call the utility, but several of you mentioned as well, something that has a positive impact that I should helps other people, uh, uh, uh, I don't have money.

Speaker 1:          00:23:47       It could be an aspect of utility, but maybe not the most inspiring one. Uh, and then I think, um, I think one of the biggest challenges we faced in the industry today is, so frankly there's actually a good judgment on feasibility. Um, so today I still see too many leaders are sometimes CEOs of large companies that stand on stage and announced to the whole world, you know, we're going to do this machine learning project to do this by this deadline. And then 20 minutes later I talked to their engineers and the engineers say, nope, no way not happening. Where the CEO just farming this age, Ho Ng modelization, there's not doing it. And those is impossible. So I think one of the biggest challenges is actually feasibility, um, in, in fact, I actually know that a, you know, that's a chatter of rt, about, uh, the, the um, uh, ta office hours.

Speaker 1:          00:24:39       And I know that, uh, uh, have been a lot of, you know, long of you have been thinking about applying a end to end deep learning. Right. You know, can you input any acts and output any why and, and do the Acura the, and sometimes it's possible and sometimes it's not. And it still takes a relatively deep judgment about what new nether us can and cannot do with a certain amount of data that you may or may not be or April to acquire in order to do some of these things. Right. Um, so, so I think throughout this quarter you've gained much deeper judgment as well on what is feasible. I guess it was pretty interesting. I once, no, uh, I, I knew a CEO of a very large company that once told his team, um, uh, he actually gave us seem decent structure. It's, he said, I wish the assume that AI can do anything. Uh, and, and, and it, it, I think that had an interesting effect, I guess. Uh, uh, uh, yeah. Cool. All right. So I think step one was selected project. I hope there's this thing projects chose. Keep some of those things in mind. Um, step two is get data.

Speaker 1:          00:25:51       Um, and so, uh, what I want you to do, and I'm going to pose a second question and then have some to discuss this. Let's say that you're actually working on this, you know, smarts, a voice activated embedded device thing, right? So let's say that you and your friends want to build a startup. So train the deep burning our river to detect you there. Phrases like John turned on will marry you, turnoff or Bob turned off or whatever to sell to a device makers so that they can a low voice embedded voice detection chip that doesn't require a complicated wifi set up process, right? So let's see when, uh, let's see, I actually want to do this. So you need to collect some data in order to site training or learning our revenue. So, um, the second question that I pose to you is, uh, uh, uh, to, uh, question in two parts, but I'll have you answer it all at the same time, which is I'm in how many, how many days?

Speaker 1:          00:26:45       Let's say you actually propose this for your CSU 30 project this Sunday, and then you start work on it, you know, like on Monday, are you going to start work on it today before the proposal, but, uh, how many days would you spend collecting data? Uh, and how would you collected data? Okay. And I think, um, I actually, how many of you have participated in engineering scrum? If you know what that means. Oh, okay. A few of you. Those who have an industry. Okay. All right. So engineering estimation, when you estimate how long a project takes, one of the common practices is use a Fibonacci sequence to estimate how long a project will take. Right? And so people now she sequence one, one, two, three, five, eight, 13 and so on. And there's roughly powers of two, but doesn't grow as fast as pilots too. And FIBONACCI numbers are cool. Right? So, uh, so, so whether one should they do actually the me just finish over the configuration. Right.

Speaker 2:          00:27:45       Okay. When I would, um, speech bubbles. Okay. Yeah, that's good.

Speaker 1:          00:27:56       All right. So what I'd like you to do is in the text answer, I really write two things. One is write a number. How many days do you think you spend on collecting data union teammates if you're actually doing this project? Uh, and then how, how would you go about collecting the data?

Speaker 2:          00:28:10       Okay. So why don't you take like another two minutes to write in an answer. Oh, I'm sorry. Let me say reload now. Still not activated Sarah down. I'm trying to hit what we're just saying. That is not helpful. Okay. All right, Dennis. Definitely not helpful. Um hmm.

Speaker 1:          00:29:04       All right, let's do this. Write down your answer on a piece of paper first and take two. And this is, yeah, so the two questions off or how many days, um, pick a number for the people Nachi sequence and uh, or are you going to use that all time? Oh, okay. Let's swap out my computer for rts. Oh, actually, yeah. Oh, it hotties computers working.

Speaker 2:          00:29:25       Yeah, sure. Go ahead.

Speaker 1:          00:29:28       Oh yeah, I can just present. Let's plug in your laptop. Just use your laptop.

Speaker 2:          00:29:37       Sure. Yeah, yeah.

Speaker 1:          00:29:43       Doesn't it say, I wonder if it's a death where problem a web browser problem.

Speaker 2:          00:29:46       MMM.

Speaker 1:          00:29:47       I started that using a Firefox recently in addition to chrome and Safari and Dallas fire falls. I tried with other web browsers. Liter.

Speaker 2:          00:29:59       Great. All right, cool. Thanks. Awesome. All right. Maybe we have maybe people that take another minute from now. Just extend the time a bit. All right. 10 seconds. Yeah. All right, cool. Let's see answers. Okay. All right.

Speaker 1:          00:31:25       Well, 365 does, uh, does uh, does a lot of variance in the answer is right.

Speaker 2:          00:31:37       MMM.

Speaker 1:          00:31:43       I know. Download from online depends on what data you want. It turns out well. So if you're trying to find data or phrases like John turned on that that data doesn't exist online. Uh, it turns out that you're trying to find audio clips of the wet activate. There are some websites with a single worst pronouns, but those, but I'm not a lot of audio clips actually. You said they tried to word or the wake word is the word activate a derail. Some websites we can download like maybe 10 audio clips of a few people saying activate, but it's quite hard to find hundreds of examples of different people saying that we're activate.

Speaker 2:          00:32:16       MMM.

Speaker 1:          00:32:24       Five days, it falls from the sky.

Speaker 2:          00:32:31       All right. So let me suggest, um, uh, let me suggest that you guys discuss

Speaker 1:          00:32:40       with each other in small groups, uh, what you think would be the best strategy. How many days would you find collecting the data and how was your cycling? Because anytime you try to convince people next to you on that, um, and, and before I asked you to start discussing, I want to leave you with one thought, which is, um, how long do you think it'll take you to train your first model? Right? And so it will take you a day to train your first Waldo or two days. Uh, do you want to spend x time collecting data and then spend, let's say, you know, oh no, it's a seventh deep learning thing and train them all though it might take a couple of days, right? Especially if you download open source packages. So, so if the amount of time needed to collect data as x followed by two days to train your first model, what do you think? Extra beat the amount of time. Why don't you guys spend like two minutes to discuss with each other and see if you can cut their, their, their answers are, there's a very large areas, right? Why don't you guys to discuss if you actually, if the people sitting next to you or your project partners, why should discuss with them how many days do you think you should spank collecting data and how you collected data? Okay, let's take two minutes to discuss an yeah.

Speaker 3:          00:33:43       Okay. Yes. All right guys. So, all right guys. Hey guys. So all right,

Speaker 1:          00:36:06       mother of exciting discussion. Um, uh, so actually how many of you helped me up? The groove swells up on the, on the low end. How many of you, you know, convince each other that maybe it should be like three days or less? Just a few of you. How come some assault someone, someone to say, why, why is it, why wife?

Speaker 4:          00:36:29       Because you're welcome to just to see if that algorithm works first. So you need some data to just test to see a job were, was even reaching sort of some sort of good bench mark before you then go and collect a massive dataset.

Speaker 1:          00:36:42       Cool. Yeah, I guess a little bit of the data to test how the average horse before you even go into like a massive data set. Okay, cool. Yeah. And did anyone has had a high end, like a 13 days or more? Very few. How come? Anyone edgy. Anyone, anyone with insights you want to share with the whole cloth as you, what, what were you all discussing? So excited. Yeah.

Speaker 2:          00:37:06       Okay. So, um, depending on your domain knowledge, um, data collection, you can't take a long time, especially with this problem, like based on the one I get to the system last year thinking like, could we use like movie clips and like sometimes it was too late, generates on August minutes as far as he was since you won. And that would take like a thing to like mine data from movies. Good. Yeah. Yeah.

Speaker 1:          00:37:40       Right. Yeah. And so the complicated systems and look at it, a subtitle, videos, right? Uh, like a youtube videos have captions or something. And if there's a the right creative Commons day to day, I think it use. Yeah. So let me, let me tell you my bias. [inaudible] I just tell you what I would do if I was working on this project. Uh, what, well, one caveat, if I haven't done so much work in speech recognition previously fragments was my first project. Um, I would probably spend one to two days collecting days Hara kind of on the short end. Right? And I think that's, um, you know, one of the, and, and, and one of the reasons is that machine learning kind of that circle I drew up there is actually a very iterative process where, um, until you try it, you, you almost never know what's actually going to be hard about the problem.

Speaker 1:          00:38:29       Right? And so, um, so if I was seeing this project just so you all to see what, what I would do, they like it. I've actually thought about this project a bunch, right? Including, you know, trying to validate market acceptance and so on. But um, which is that, um, I would get a cheap microphone, a user or use a built in that top microphone or buy a microphone off, you know, buy a microphone off Amazon or something and go around, say go around Stanford campus and go to your friends and have them just say, Hey, do you mind saying to this microphone there word activate or John Turner or whatever, and collected a bunch of data that way. Um, and then, uh, uh, and with one or two days, um, you should be able to collect at least hundreds of examples. Uh, and that might be enough of a Dataset to start training a rudimentary learning algorithm to get going.

Speaker 1:          00:39:19       Because if you have not yet worked on this problem before, it turns out to be very difficult to know what's going to be hard about the problem. So is what's going to be hard, um, highly accent of speakers, right? Uh, always what's going to be hard background noise or it's what's going to be hard, you know, confusing turned on. We've turned off, he's year. John turned. And then, uh, but when you build a new machine, learning any system is very difficult to know what's hard and what's easy about the problem or it was what's going to be difficult that a far few, which is um, the technical term for if the microphone is very far away. Right? So it turns out that if we turn on the microphone on my laptop now, for example, um, the, the laptop, which is what, like three meters away from me, uh, we'll be hearing voice directly from my mouth as well as voice bouncing off the walls.

Speaker 1:          00:40:10       So there's lot of reverberation in this room. And so that makes me free condition harder. Humie are so good at processing our reverberant sounds reverberations that you almost don't notice it, but it actually, the learning room we'll have sometimes has problems with reverberations, echoes bouncing off the hard walls of this room. Um, and so depending on what you're learning, Arbonne has trouble with. Um, you will then want to go back to collect very different types of data or explore very different types of algorithms. What was the problem that sometimes the speaker, that's just the volume is just too soft in which case, you know, maybe we need to do something else and normalize all of your volumes of buying more sensitive microphone or something. So it turns out they weren't building most machine learning applications unless you've experienced working on it. And so I've actually worked on this problem before so I have a sense of what's hot and it was easy, but they work on the new project for the first time.

Speaker 1:          00:40:58       It's very difficult to know. It was hard, it was easy. And so my advice to most teams is rather than spending say 20 days to collect data and then two days to collect model to train the model and is often by training a model and then seeing whether the examples it gets wrong. When did the average fail that that that's you feedback to either collect more data or redesigned the model, right? Or try something else. Um, and if you can string the data collection period down to be more comparable to how long have you ended up taking to train your model, then you can start iterating much more rapidly on, on actually improving your model. Right. Oh, and um, so maybe one roof I'm actually tend to recommend for most cost projects is oh no. If, if maybe if he needs to spend a week up to a week to collect data, yeah, maybe that's okay.

Speaker 1:          00:41:53       But it didn't get going even will quickly. Uh, I would even maybe more strongly recommend that. Um, and they've been so few examples in my life where the first time I trained the learning algorithm room, it works. Right? It's like pretty much never happens. It happened once about a year ago and I was so surprised. I still remember that one time. Ah, and so what, so, so, uh, machine learning development is often a very iterative process. And by quickly can I have days that and often data sets a collected through sweat and hardware, right? And so I wouldn't literally Yo and as w I bet she thought long world speech and it going quickly, I would probably just um, uh, have myself or my team members run around and find people and asked them to speak into a microphone and record all your clips that way. Um, and then only when you validate that you need a bigger dataset. What'd you go to? More complicated things. I set up an Amazon Mechanical Turk thing, right? To Krauss was, which I've also done Ashley, right? Also had very large DSF collect off Amazon Mechanical Turk, but only in a later stage the project you understand what you really need. All right. Um, so as you, as you start working on your class projects, maybe, maybe keep that, keep that in their minds now. Um,

Speaker 2:          00:43:19       oh,

Speaker 1:          00:43:28       so one other tip that uh, machine learning researchers on average, we tend to be terrible at this. Um, but like if this advice anyway is when you're going through this process, get some data or design a model, a literature search would be very helpful. You also see what others see what our rooms others are using. For this problem. It turns out that literature actually quite immature. There isn't a convergence of, uh, like a well standard said that standed out for him. As for trigger words detection, then lift your shirt. Right now I should be boss still making up algorithms. So if you, if you do the survey, you find that to be case, but he didn't train the initial model. Um, and in most machine learning applications who go through this process multiple times. So one tip that I would recommend you do is keep clear notes.

Speaker 2:          00:44:12       Okay.

Speaker 1:          00:44:13       Um, on the experiments you've run,

Speaker 2:          00:44:18       right? Because

Speaker 1:          00:44:19       so often be, uh, as he trade them all though, you see, oh, this model where it's a great on the American accent of speakers but not on British accent to speakers, right. I was born in the UK, so I'm just gonna use British accents, right? Example, if a, for a different part of the world, you have to think of different global access descends down from the UK. I'm just gonna pick on British accents, I guess. Um, keep clearing those on the experiments run. Because what happens in every machine learning project is after a while you have trades 30 models and then you and your team members a good, oh yeah, we tried that idea two weeks ago, did it work? And if you have clear notes from when you actually did that work two weeks ago, then you can refer back route. Didn't have to be run experiments.

Speaker 1:          00:44:55       Oh, the other thing that some groups do is uh, have a spreadsheet that keeps track of what's the learning rate you use, what's the number of head and unions was this was this was this or, or, or, or cheaper than a text documents. So that, which will make it easier to refer back to it, to know something you try earlier. Um, this is one piece of comedy given advice. And this is one of those things that every machine learning person knows we should do this, but on average we're very bad at doing this. But that, that you could, I don't know. Uh, but at the Times I managed to keep good notes. It actually saved them all the time. Right. To try. Remember what exact view. Tried two weeks ago. Okay. So, um, a lot of this class will be on this process of how they get data, develop the chain Dev, test, the design, the model to train the model, eventually test them all the innovate.

Speaker 1:          00:45:46       So a lot of this causes on this, so when they jump ahead to when you have a good enough model and you wanted to deploy it. Okay. So step six, I guess since deployment now, um, uh, uh, this is uh, oh, um, one of the reasons I want to step through this example going through a concrete example is I find that when you're learning about machine learning for the first time is often seeing, you know, what, what my team sends it called war stories, kind of stories of projects that, that, that others have built before that often provides the best learning experience. So I think like, I have built speech recognition systems, it tells me like a year or two years and so we need to do it. So I'm trying to, so rather than, you know, having you spend two years of your life building speech, the sims if can summarize a war story, right?

Speaker 1:          00:46:35       To tell you what the process is like. I'm hoping that these concrete examples of what building these systems, our life in large corporations that that can help you a salary of learnings without needing to get two years of on the job experience. You can just hear the salient points. Okay. Now, if you're deploying a system like this, one of the things, and this is actually true, there's actually a real phenomenon for deploys speech systems is you have the audio clip, you have a neuro network, and then, you know, this will all put zero one. And, um, the neural networks that work well, we'll tend to be relatively large, relatively large model, the Laotian or hidden Eunice, relatively high complexity. And, um, if you have some of the smart speakers in your home, um, you recognize that a lot of them are h devices as opposed to a purely cloud computation, right?

Speaker 1:          00:47:27       So we all know what the cloud is. Um, uh, and what an edge devices, edge devices, the smart speaker that's in your home or the cell phone and your wallet. So a edge devices are, you know, the things that are close to the data, I suppose in the cloud, which is a giant surface we have in our data centers, right? So, um, because of network latency, uh, uh, and uh, uh, and, and, and because of privacy, a lot of these computations are done on edge devices like a smart speaker in your home or, uh, like a, I guess, Hey Siri or, okay, Google can wake up your cell phone, right? And so edge devices have much lower computational budgets and much lower power budgets are limited battery life, much less powerful processes than we have in our cloud data centers. And so it turns all that salt, salt serving up a very large neural network is, it's quite difficult. It's very difficult for, you know, a low power, inexpensive microprocessor sitting in a smart speaker in your living room to run a very large neural network with a lot of hidden units and with all the parameters. And so what is often done

Speaker 2:          00:48:38       is to actually do this, which is, um, to input an audio clip

Speaker 1:          00:48:53       and then have a much simpler algorithm, uh, figure out if you know anyone who has even talking, right? Because, uh, oh, so the smart speaker in my living room, he was silence most of the day, right? Because usually just no one at home, right? There's no, no, no voice. And then only if it hears, you know, someone's talking then feed it to the big neural network that you've trained and GRANDPA use a larger part budget. Um, uh, in order to classify zero one. Okay. Um, just component goes by many different names, uh, um, in, in reasonably standard terminology, but not totally standard terminology in the literature. I'm going to call this VA, um, for voice activity detection,

Speaker 2:          00:49:41       right?

Speaker 1:          00:49:42       Oh, it turns out that voice activity, it's actually, there's a standard component is in, in many different speech recognition systems. If you are using a cell phone, for example, a VAT is a component that tries to figure that hands even talking. Because if it thinks no one is talking, then there's no need to encode the audio and tried to transmit the audio right onto cause, you know? Um, and so, uh, so the next question I want to ask you, and I thought this is timely because, um, uh, uh,

Speaker 2:          00:50:17       wow

Speaker 1:          00:50:20       is, um, a couple of options, right? Option one is to build a non machine learning VAT system, voice activity detection system, which is just, you know, see,

Speaker 2:          00:50:32       okay,

Speaker 1:          00:50:36       if the volume of the audio, your spa speakers recording has greater than epsilon. So the side is just to get it. And option two is a train a small neuronetwork, um, uh, to recommend on, on, on human speech.

Speaker 2:          00:50:59       Right.

Speaker 1:          00:51:00       Um, and so, uh, my next question to you is if you're working on this project, which you pick option one or what'd you pick options? Who? Great. Uh, as you, as you, as you move to what, oh, sorry. And I think, um, a small, newer network, a small network or in some cases I've seen people use this small support vector machine as well. For those. He didn't know what that is. A small wall that it can be wrong with a low computational budget. This is a much simpler problem to detect that someone is talking then to recognize the word they said. So you could actually do this. You don't know what reasonable accuracy was. Small, newer network. But if you actually work on this project, uh, for CSU 30, which would you try for us? So Michelle, can we go onto the next question? Yes. Okay, cool. Figure out how to do that. Sure. Yeah. We can let them start answering I guess. And then why you figured out the projection.

Speaker 2:          00:51:56       Cool. I'm just keep unlocking it periodically.

Speaker 1:          00:52:03       Are People able to vote? No. The no votes yet. Well, I see. I guess you write so much code, you have a shortcut to go to your coding environment or your laptop

Speaker 2:          00:52:23       on the whole. Great. All right, cool. Great. Thank you.

Speaker 1:          00:52:48       Hello. All right. Yvonne, him quickly and now they're like 20 seconds, if that's enough time to give you answers.

Speaker 2:          00:53:08       Oh, cool.

Speaker 1:          00:53:21       All right, cool. Um,

Speaker 2:          00:53:28       okay,

Speaker 1:          00:53:29       that's fascinating. There's a lot of disagreement in this Hos, um, uh, people want to say why, why would you choose option one? Why would you choose often to, and, and I, I have a very strong point of view on what I would do. Right. Uh, but, but I'm curious why, uh, why option one and why two

Speaker 2:          00:53:46       go ahead. Easy to debug issues either. I was option one officer, actually simple options. Who's not the harder dog in your house and carts and pros, they're activated. You can probably out already like simplify the problem that knowing if a noise, I mean activates the machine. But that's why I picked up there may be people have like three options, noisy place and I think it will pick up the background noise. You have a friend who's a train station, right? So option one, we'll pick up a lot. The pain has to be running constantly, very cheap. So it seems like option one is better because no power, no country. So let me show you some of the pros and cons. Uh, so I think there are pros and cons of option one. Option two is why

Speaker 1:          00:55:50       so many volts, but both options I proceed with choose option one. Um, but, but let me just, let's just discuss the pros and cons. Right? I think that um, uh, option one first is just a few lines of code is yes, maybe option two isn't that complicated, but option one is even simpler. And I think that, um, uh, maybe I would say if I hadn't worked on this problem before, I would choose option one. Uh, but since I have experienced as feet recognition eventually I know you need option too. But that's because I, because I've worked on this problem before, but there's your first time working on the speech application problem. I would encourage you on average to try to really simple, quick and dirty solutions and go ahead. And, um, so let's see, how long would it take to implement this? Right? I would say like 10 minutes or five minutes.

Speaker 1:          00:56:39       I Dunno. Right? Hollywood thinking to implement that. Oh hell for all of us one day or I don't really know. Actually right now, let me just write one day and then I'm not quite sure. Great. But if I'm often went to BMC in 10 minutes, then I will encourage you to do that and go ahead and put the smart speaker in your home or in your potential users homes. And only when you find out that the dog barking is a problem or the train on their airways, seizure, no, whatever is a problem, then go back and invest more in the fixing it. Right. And in fact, um, it's true that maybe it's annoying if the dog barking and keeps on waking up the system. But maybe that's okay because if the launch neural network, then screens are all the dog barking then the overall performance systems as you just fine and, uh, and, and you now have a much simpler system.

Speaker 1:          00:57:32       Right? But, uh, but, but it turns out that the reason you might need to go to option to eventually is because they're awesome homes in noisy environments. Uh, you know, this constant background noise. And so that will keep the large neural nets were running a little bit too frequently. So, so if you have a large engineering budget, you know, so some of the smart speaker teams are like hundreds of engineers working on it so they have hundreds of injuries and work on it. Totally. Option two will perform better. But if you're strapped startup team is scrappy startup team lift fee of you working on a class project, you know, the evidence that you need, that level of complexity is not that high. And I would really do that first and use that to gather evidence that you really should make the investment to build a more complex system before actually making the investments of days off.

Speaker 1:          00:58:21       And eventually, I think this is one day to pull your first photo. All right. And then eventually you'll be, I'll be more complicated. Um, it turns out that, um, did other reason, um, the other huge advantage of the simple method is the following. Um, and this is one of the faculty. This is one of the, there's actually one of the big problems and big weaknesses of machine learning algorithms and deep learning algorithms, which is what happens is, uh, um, when you build a system and you should ship a product, the data will change, right? And so, um, I'm going to simplify the example a little bit, but you know, I know Stanford is very cosmopolitan. There's Powells is very hospital. See, we collect data in this region. You get access from people all over the world, right? Because, because that's Stanford, that's Palo Alto. But, but just to simplify these apple orbit, um, let's say that you train on a u s accents, right? Uh, but you know, for some reason, uh, uh, when you're ship a product, maybe it sells really well in the UK and you start getting data

Speaker 2:          00:59:35       okay.

Speaker 1:          00:59:37       With a UK or with British accents. All right, so one of the biggest problems you face in practical deployment of machine learning systems is that the day to train on is not going to be the day you need to perform well on. Um, and, and I'm gonna share with you some practical ideas for how to solve this, but this is one of those practical realities and practical weaknesses is machine learning that is actually not talked about much in academia. Uh, uh, because it turns out that the data says we have in academia are not set up well for researchers to study and published papers on this. I think we could sell a new machine there, any benchmarks in the future, but this is one of those problems as it's actually kind of underappreciated in academic literature. But that is a problem facing many, many practical deployments are machine learning algorithms. Um, and uh, and so more general, the problem is one of data changing, right? And, uh, you might have new houses of users with new accidents or you might train a lot on, uh, the maybe get data from even Stanford users and maybe Stanford. It's not too noisy. All staff are there certain types of cars in the states where you ship it to another city, another country. There's much more noisy, uh, you know, different background noise.

Speaker 2:          01:01:01       Okay.

Speaker 1:          01:01:02       Right? Or you start manufacturing the smart speaker and to lower the costs of the speaker, they swap it out. They swap out the high end microphones that you use from your laptop to collect the data for lower and microphone. It's a very common thing done in, yeah, well done in manufacturing, right? If you could use a cheaper microphone, why not? Right. And often to a human eras, the sound sounds just fine on the cheaper microphone. But if you change your learning algorithm using your, you know, I guess, yeah, well I use a Mac, but the Mac is a pretty decent microphone. So if you train the data using all collateral Mac and then eventually as a different microphone, it may not generalize well. So one of the challenges of, um, machine learning is that you often develop a system on one dataset and then when you ship a proud out, something about the world changes, uh, and, and, and your system needs to perform on a very different type of data than what you've had training.

Speaker 1:          01:02:01       Um, and so, um, and so what will happened is after you deployed a model, uh, the world may change and you're often end up going back to get more data. We designed the model, right? And, and I guess, sorry, and this is, this is, uh, uh, the maintenance of the machine learning model. Um, I want to give some of those apples a web search, right? This happens all the time and multiple of us search engines, which is, uh, you train a neural network or you train the system to give relevant web search results, but then something about the world changes. You are, for example, there's a major political, then some new person is elected president of some foreign country or does a major scandal or just the Internet changes, right? Or there's a, actually what happens in China is a new word getting invented all the time in, in China, the China.

Speaker 1:          01:02:58       So is that by of I Google and Baidu, but the Chinese languages a more fluid than the English language. And so new worst he invented all the time. And so the language changes. And so whether it be a trade just isn't working as well as it used to. Right. Um, or, or maybe a different company, southern shuts off, you know, their entire website to your search index because we don't want you, uh, indexing their website. And so internet changes and what have you had done doesn't work anymore. Um, or um, uh, self driving. Uh, it turns out that you build a self driving car in California and then you tried to deploy these vehicles in Texas. Um, you know, it turns out traffic lights in Texas look very different than traffic lights in, in, in California. So, um, although I trained on California, Texas on, so a newer network trained to recognize a California traffic ones actually doesn't work very well on Texas traffic leads.

Speaker 1:          01:03:56       Right? Oh, I'm trying to remember which way round than us. But I think California and Texas has a different distribution of horizontal versus vertical traffic lights, for example. It's actually a human's, they'll notice if you go, oh yeah, red, yellow, green for the learning algorithm doesn't actually generalize that well. If you go to a different location and go to a foreign country, again, traffic lights, signage, the lean markers or change, um, or I guess, well one example I was working on earlier this week, right? Uh, manufacturing, right? Learning Ai, working on inspection of parts in factories. Um, and so if you are doing visual inspection in the factory and the factory starts making a new component, you know, they were making this model cell phone, but cell phones turned over quickly. And so, but in a few months later, they're making a different type of cell phone or something weird happens in manufacturing process. So the lighting changes as new type of defect. So the world changes. And um, so I'm knocking again, what I like to do is I'm actually revisit the previous question in light of this, uh, the world changes phenomenon, right? Which is, let's say you've collected a lot of data. We an American accent of speakers. Um, and then, you know, we shut the product in the UK and then, um,

Speaker 1:          01:05:21       and then for some reason you find that you've all these British accents speakers, right? Trying to use your spot. Speaker. So between these two algorithms and our machine learning approach, which is a set the threshold versus train the neural network, which system do you think will be more robust for Vat? Boys activity detection.

Speaker 2:          01:05:37       Okay.

Speaker 1:          01:05:56       All right. I'm particularly another, I'll know 40 seconds.

Speaker 2:          01:06:28       All right.

Speaker 1:          01:06:40       Yeah. Interesting to people when they comment, well, more people voted for this one. Let me explain why.

Speaker 2:          01:06:49       No, go ahead. If we want to detect that and instead, right. So say for the VAT, if you just measure the volume that it doesn't really depend on on the accent, so non ml might be more robust. Anyone else? All right. So,

Speaker 1:          01:07:30       okay. Again, you show you, I thought, so it turns out that if you train a small neuronetwork, uh, to um, uh, you know, American accent, his speech, uh, there's a bigger chance that your neural network, because it's so clever, right? They'll learn to recognize American speech and have a harder time generalizing to British accented speech. Does that make sense? And so one of the things that I've seen a lot of teams are, whereas, so, so one way the non GMO thing could fail to generalize would be a British speakers are systematically, you know, allow there are softer than the American speakers. Right? So, you know, I don't know, I don't have Americans stereotypically allowed, there are less loud than British, but, but you know, but the American and British speakers, one country just as loud a voice as a softer voices, then maybe the threshold you set won't generalize.

Speaker 1:          01:08:21       Well, but that seems unlikely. I don't see that being realistic thing. But um, but they have a training on your own network, a lot of parameters then, uh, is more likely that the neuro network, we're pickup on some idiosyncrasy of American accents to decide the 70s even speaking. Um, and does, maybe that's robust who generalizing to a British accent it speech. Right. And another way to think about the, or imagine to take an even further example, imagine that you're using Va d for a totally different language than they then English, right? Where um, take a different language, you know, Chinese or Hindi or Spanish or something where the sounds of really different. If you create a VAT system to detect, you know, English, it may not at all work for detecting Spanish or Chinese or French or, or some other language. Um, and so if you think of British accents as a, as somewhere on the spectrum, not the foreign language by any means, but just more different than I think the [inaudible] system is more likely to be robust.

Speaker 1:          01:09:23       Right. And so one of the lessons that too many that, that a lot of machine learning teams during the hard way it is, uh, um, if you don't need to use a learning algorithm or something, if you can hand called the simple rule, like if volume greater than 0.01 do this or that, uh, those rules are, can be more robust. And the one of the reasons we use only our rooms, it's where we can't hang caught something, right? I don't know how the handcuffs something to detect the cat or to the car on the road or detective the person. So use learning Alvin's with those. But if there was actually a hand called the rule that actually does pretty well, you find that it is more robust to shifts into data and what often generalized better. Oh, and uh, if any of you take, uh, uh, we, we talk a bit about this a little bit in cs two, three, nine a I think CSC here, 90 talks about this as well.

Speaker 1:          01:10:13       But this book, the observation is backed up by very rigorous learning theory and the learning theory is basically that the fewer parameters you have, uh, if you still do well in your training set, if you kind of model with very few parameters that does well and your training set your generalized better, right? So there's, there's very rigorous machine learning theory that basically says that. And in the case of the non machine learning approach, there's maybe one parameter which is what's the threshold for epsilon and that's worthwhile enough for your training set. Then your odds of a generalizing even when the data changes is much higher right.

Speaker 1:          01:10:48       Now, the last question, um, I want to post with discussion today is, um, when, when discussing deployments, uh, oh and so one of the lessons deployments, that's just the way the world works, you know, the machine learning system and deploy it, the world will usually change and you often end up collecting data and having an elevator and maybe improve the model, right? And then they'll fix them off a previous speakers happen. Um, so we talked about edge deployments as well as cloud deployments, right? And so, um, ignoring issues of user privacy and latency, which is super important. But for the purposes, the question, let's, let's, let's put aside issues of user privacy and network latency. Um, if you need to maintain them all though, sorry. Maintenance means updating them. Haldol, right? Even as the world changes, um, oh, sorry. I miss uh, miss tabby should be, does he cow or h deployment make maintenance easier if not earth. Right? Why don't you, why don't you just enter a one word answer and, and, and why, right? And so managing that is this, when the world changes, something changes. So you need to update the learning model to take advantage, take care of this British accent. So which type of deployment makes it easier?

Speaker 1:          01:12:08       Mystic Lake. Yeah. Another two minutes. Send to your answers.

Speaker 2:          01:12:51       Yeah.

Speaker 1:          01:13:14       All right. Another like 50 seconds. All right, cool. See what people are routes. Wow. Cool, great. All right. Almost everyone in the St Cloud,

Speaker 1:          01:14:16       most people are saying cloud. All right, cool. Great. And then just to summarize, I think they're actually two reasons why most people send, it's easier to push updates. That's part of it. I think the other positive is that if all the data that is at the edge, if all the data is processed yo and it uses home and none of it comes to cloud, then even if you have all these unhappy British accents to users, you may not give him the fine Dell. Right? You're saying the company headquarters, you have all these users and this theory is these, you know, seem to be not using your device maybe cause they're unsatisfied with it. But if the data isn't coming to your servers in the cloud that you may not even find out about it. Now there are serious issues about user privacy, uh, as we as security, right?

Speaker 1:          01:14:55       So, so, so please, if you have a brother product, please be respectful of that. Uh, and then take, take, take care of that in very thoughtful and respectful way of users. But, um, uh, for us, um, so this is the cloud, right? If you have a lot of edge devices and all the data is processed there, you won't even know what your users are doing and they're happy, unhappy, you just don't know. But if some of the data in the stream to your servers of the cow and if the user privacy with really easy as good user consent, tell people what you're doing with the data. But if you take care of that in a, in a, in a, in a, in these moe and sound way, if you're able to examine some of the data that you can at least figure out that gee, looks like analyzing the data.

Speaker 1:          01:15:42       There are these people, if this accident, this background noise that um, uh, is, uh, giving it back. Other days be rinse and you can also maybe have the data so you can gather the data from the edge to feed back to your model, right? So, so that's you detect if something's gone wrong. Um, unless you have the data to retrain the model to solve the British accent problems are going to retrain the model a lot British accent to speech. Um, and if find it, he lets you push them all back home, right? So of course, and that's, you detect what's going on too. It gives you data for training and see, unless you're more easily push the model back up, pushing, pushing the new model to production to deployments. Okay. And does this also why, uh, even if your compensation needs to run on the edge, if you could in a way respectful of user privacy in this transparent about how you use data.

Speaker 1:          01:16:38       If you can get even a small sample of data or have a few volunteer uses, sent you some dates back to the cloud, that will greatly increase your ability to detect if something Kahn wrong as well as maybe give you some data to retrain the model. Uh, so even if you can hold you too. So the push updates, right. This, this will just will help. Creepy. Okay. Um, all right. So finally the one last comment, I think, uh, one, one, one last challenge is a lot of the machine learning systems, you're not done at deployment. There's a constant ongoing maintenance process and I think one of the processes, uh, you know, AI teams are getting better at as well. I set up Qa to make sure that we update the model. You don't break something. So then Qa and large company is quality assurance process.

Speaker 1:          01:17:21       It's kind of testing this and I think the way you test machine or the arb rooms is different than the way you test, which are, there is no software because the performance of machine learning algorithms is often measured the status call way, right? So it doesn't work. And it doesn't work. It either works or doesn't work. Instead that works, you know, 95% of the time or something. And so a lot of companies are evolving the Qa processes, they have this type of statistical testing to make sure that you don't, you changed them all, then you do a push update. It's the works, you know, 95 or 99% of the time or something rather than so, so, so putting in place new Qa test processes as well. Okay. All right. I hope that was helpful. Stepping through what the full arc of a machine learning project will look like, uh, uh, will, will they did this course or any course suite as well as in a later lecture there are present, we'll keep talking about machine learning strategy and how they make decisions. So let's break for today.