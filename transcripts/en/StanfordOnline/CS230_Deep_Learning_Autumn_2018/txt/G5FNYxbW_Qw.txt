Speaker 1:          00:05          All right. Hey everyone, welcome back. This is people hear me okay. All right. So if as usually you can take a second to enter your, uh, id so we know who's here. Um, so today's lecture will be a choose your own adventure lecture. Um, so I think you know, by now you've learned a lot about the technical aspects of building learning algorithms. And then in the third course, in the third set of modules, you saw some of the principles for debugging, learning algorithms and how they, as you use these tools in order to be efficient in how you build a machine learning application. What I want to do today is a step through with you, a moderately complicated machine learning application. And, um, throughout all of today's lecture I'm going to step you through a scenario and then as you to kind of choose your own adventure.

Speaker 1:          01:04          Because if you are working on this project, what are you going to do, right? And to give you more of that practice in the next, um, what are in a bit that we have a on thinking through machine learning strategy. Um, and you know, I've, I've seen in so many projects, uh, they're there sometimes things that a less strategically sophisticated team will take a year to do. But if you're actually very strategic and very sophisticated in deciding what you will do next, very how the drive the project forward. I've seen many times that what a different team will take to do. Maybe you could do it in a month or two and you know, if you are trying to read a research paper or build a business, I've got the product, the ability to drive a machine learning project quickly gives you a huge advantage and just, you know, you're making much more efficient use of your life as well.

Speaker 1:          01:59          Right. Um, so for today I'd like to, uh, uh, I'm going to pose a scenario, post a machine learning application and say, all right, I mean, you are the CEO of this project. What are you going to do next? So, but I'd like to have today's meeting be quite interactive as well. So can they get people to sit in groups of two and ideally three or so, maybe plus minus one. And, um, tried to sit next to someone that you don't work with all the time. Uh, so, so if a Sydney sitting next year, best friend, I'm glad your best friend is in the class review, but go sit through someone else because I think, um, I've done this multiple times and the discussions that he, Richard, you talk to someone that you don't know super well. So as you take a second and introduce yourself and just your neighbor, I guess.

Speaker 1:          02:47          So the example I want to go through today is actually a continuation of the example I described briefly, uh, uh, in, in the last lecture I us a building a speech recognition system, right? So remember I briefly, I'm motivated this a trigger word, wake word or trigger word detection system last time where, you know, uh, right, I, I actually had both an Amazon echo and Google home, uh, but you know, is this a lot of work to configure these things to turn on and off your light bulbs. Um, and so if you can build a chip, uh, to sell, to say, a lamp maker to recognize, uh, phrases like, you know, let's say we call the Lamp Robin, right? Then you can recognize phases like Robin's her in the [inaudible], right? Robin turned off and he kept that little switch to give this thing different names were called robbers or leaner or allies or somethings.

Speaker 1:          03:47          You can also lean air turned on the, turned off his gift to give you a lamp, a name, and just say, Hey, Robert turned on right. So rather than detecting different names and turn on and turn the off, I'm just going to focus on just for the technical discussion, I'm just going to focus on the phrase Robin turned on. Uh, but it's kind of the same problem and we need to solve like four times to give it to names or to turn on and turn off. So I'm going to abbreviate Robert, turning on this Rto rights. If you want to call your name Roberts, and I'm a tell you lamp to turn on. Um, I think it was inspired by, well, Isaac Asimov wrote these alums, robotic novel C's and all this robots name started with r. So maybe our robot turn on. Um, and so, uh, let's see.

Speaker 1:          04:34          So let's see that, um, you are the new CEO of a small startup with fie persons are and you go is the building is to build a circuit. Oh, actually your goal is to build a learning algorithm that can recognize this race. Robert turned on, uh, so that when someone buys this lamp and they say Robert's in the on the lamp can turn on, right? And just focusing on the task of building and then you know, to, to, to be CEO of this thought. They've used to do a lot of things, right? I need to figure out how to do the embedded circuitry. You figure out who the land Meeker's the sales journey. So there's all that stuff. But for today, let's just focus on the machine learning aspect of it. Um, and so my first question to you is very open ended is, but, and this is the life of the CEO, right?

Speaker 1:          05:21          You wake up one day and you just got to decide what to do. Um, but, so my first question to you is, an open ended question is, uh, you're the CEO, you're going to show up at work, uh, you know, tomorrow in your startup office and you want to build a learning algorithm to detect the face Robert turned on for this application, right? So, um, so my question is what are you going to do? Right? So take a take a minute to answer that by yourself first. No, don't, don't discuss your neighbor yet, but you know, you're going to show up in your office and, and you're going to start working on this engineering problem to build a neural network to do this. So, uh, and, and do this as yourself, right? Don't, don't, don't pretend that Ya'll, this hypothetical, whatever, a startup CEO of 10 minute, $10 billion to spend on whether it was just do this.

Speaker 1:          06:08          See, yeah, I, but I, I don't think this is a terrible style of idea. I, I, this is not the best idea, but I think this could work. So you actually welcome to do this, but let's say you decide to do this and you go into your office tomorrow, what do you do? Right? Once you take, um, why don't you take let's say two minutes to enter an answer, then we can do, you can discuss in fact, I think of, yeah. Yes. One thing I really like about answer sheet the readers because the Singlish usher upon, right? Um, in fact, when you're suddenly a new project, um, uh, uh, and I think, um, uh, it's not the only project like that assuming you've not worked in trigger words, it's action before, you know, reading research papers or reading code and get hub or reading blog posts and this problems as you're very good way to quickly level of fuel knowledge.

Speaker 1:          06:56          Um, and I think that, you know, it, it turns out that, um, uh, in terms of your exploration strategy, right? Um, I want to describe to you how I read research papers. Um, uh, which is, so this is not a good way to review the literature, which is if the x axis is time and the vertical axis is research papers, where some people will do is find the first research paper and read that until it's done and then go in and find a second research paper and V. Dot until it's done. And then you can find the third research paper printers for this is very sequential way of um, meeting research papers. And I find it the more strategic way to, to go through these reasonables is everything ranging from blog posts, um, lots of good medium articles and they explain things very, it's our research papers.

Speaker 1:          07:51          Um, right. Good hog is if you use a parallel exploration process where this does actually what it feels like when I'm doing research on where I'm trying to learn about a new few of them, not that expanded, right? So after she's done a lot of work on trigger words detection, but if it hadn't worked on this before then I would probably be fine, you know, three papers. So again, it's classes as time and virtually acids as different papers and um, you know, read a few papers kind of in parallel at a surface level and skimmed them. And based on that you might decide to read that one in greater detail and then to add other papers that you started screaming and maybe finding another one. Do you want to read in great detail and into gradually add new papers to your reading lists? A and B, some to confusion and some not to completion.

Speaker 1:          08:40          Um, you know, I was actually chatting with um, uh, uh, one of my friends, a PDRP former students at Berkeley who mentioned that he was wanting to learn about a new topic and he, he was, uh, he told me he was compiling a reading list of 200 research papers they want to read. That sounded like a lot. You rarely read 200 papers, but I think if you read 10 papers, you have a basic understanding. If you read 50, you have a pretty decent understanding of read like a hundred. I think you were very good at understanding, uh, of of a few but often does this time well spent I guess. Um, and, uh, some other tips, again, this is, I'm really thinking if you really are CEO of this startup and this is what you want to do, what advice would I give you? Um, uh, when you're reading papers are other things to realize?

Speaker 1:          09:30          Uh, one is that, uh, some papers don't make sense, right? And this fine, uh, uh, you know, even ivy some papers I just go, nope, I don't think that makes sense. Uh, and, and it's not uncommon for us to find papers from a decade ago that, and we learned that half of it was free and the other half of it, you know, was really talking about things that were not that important. So it was okay. Uh, authors, you know, usually papers of technically accurate, but often what they thought was important. Like maybe an author thought that using bash them was really important for this problem, but it just turns out not to be the case that that happens a lot. But that happens sometimes. And I think the other tactic that I see Stanford students sometimes not using now is talking to experts, including contacting the authors.

Speaker 1:          10:14          So when I read the paper, um, uh, I don't, I don't bother the authors unless I've actually like tried to figure it out myself. Right? But if you actually spend some time trying to understand the paper and if it really doesn't make sense to you, uh, uh, uh, is, is, is okay to email the authors and see if they respond and, and people are busy. Maybe there's a 50% chance of responding. And that's okay because it takes you five minutes to write an email and there's a 50% chance to get back to you. That could be time pretty well spent. Uh, uh, but, but don't, don't, don't bother people on this. You tried to do your own work. I actually got a lot of emails from, you know, high school students that do not feel like they've done their own work. And I just write and then, Eh, so, so just don't, don't, don't bother people.

Speaker 1:          10:58          And as you've actually tried to, um, cool. So after, um, looking at the literature and having a base, maybe downloading a open source implementation or getting a sense of an avenue where they try, oh, it turns out they trigger words detection literature is actually one literature where there isn't consensus on this is a good algorithm does is a bad algorithm where despite all the trigger words or wake word detection systems that, you know, some of you may use already, uh, there, there, there isn't actually a consensus in the, in, in, in their research me today on like, this is the best average try. Um, but so let's say that, um, you've read some papers, downloads some open source and plantations, and now you want to start training your first system, right? The last time we talked about this, we talked a little bit about how much time you would spend to collect data.

Speaker 1:          11:51          And you know, we said we spend a small amount of time, spend like a day or maybe two days at most. So collect your first data set to start training up a motto. Um, but my next question to you is a, what data would you collect? Right? Um, in particular, what train def test data would you collect? So you've decided on an initial new inotrope architecture and you want to train something to recognize this face. Robert turned on. I think there's a pervy I don't think as possible to download the data set. I don't think anyone has collected a data set with the West. Robert turned on and posted on the Internet. So you have to collect your own data for this particular trigger phrase that you want to use. But it's um, you know, as CEO of this thoughts of trying to build a new and yet to detect the phrase Robert turned on.

Speaker 1:          12:51          What data do you collect? Right? So why don't you take once you again take, Oh know let's say three minutes to write an answer to this. Yeah, I think this is an interesting one. Um, Robert turned on over and over. And then data augmentation, data augmentation is one of those techniques that, um, uh, is a way to reduce, uh, in senior learning our room because you're generating more data and, uh, having worked on this problem, I happen to know data augmentation works, you know, is very useful for this problem. But if you didn't already know that fact, this is one of the things I would probably not do right away because I would train a quick and dirty system, validate that you really have a high clearance problem before investing in the effort and do data augmentation. So they only as well as those techniques that, so, you know, it never hurts her barely hurts, usually hopes, but I don't bother to make that investment unless you have collected the evidence that you actually have a high his problem and that this is actually a good use of your time. Right?

Speaker 1:          14:07          Yeah. I think this one that she does actually nice. So, um, uh, required everyone to start to Saint Robert turned a hundred times that really nice thing about that. You can get that really quickly. Um, uh, when I'm working with teams, um, I actually think in terms of hours in terms of hollow it take us to do something. So this one you could probably do and like 30 minutes, right? So get you, the collected 30 minutes ain't get going or, or have you run around Stanford, they just ask, you know, friends or strangers to speak into your, uh, laptop microphone. You didn't spend a few hours together, much bigger data set then pass with the startups. I apparently do that. Probably actually go to collect data in several hours routing only spend 30 minutes. But this is actually pretty interesting as well because unless you get it done pretty quickly, it makes sense. Right? So, um,

Speaker 1:          15:04          yeah, so let me actually the uh, uh, share some more concrete advice. Right. And I think actually some point sometime back to prepare a homework problem that you see later in this course, Ken and Eunice and I were actually, you know, building this system partially to, to to create the homework, right? That, that, that you see later in this call. So this is, uh, this trigger where thing is a nice run. The example that we're using the few points throughout this course. Um, so here's one thing. You can do it. This does actually what, um, uh, what we did right, which is a collect, I'm simplifying a little bit. Um, collect a hundred examples of uh, uh, ten second audio clips.

Speaker 1:          15:55          Great. And so, uh, it turns out once you grab a hold of someone and ask them to speak into your microphone, you know, you can keep them for three seconds, which is how long it takes to say Robert turned on. Or you can keep them for 10 seconds, which they're actually very willing to spend an extra seven seconds of you. Right? Um, but so if this is 10 seconds of audio data, you know, so this is 10 seconds of audio and audio is just patterns of a little changes in air pressure, right? So if you plot audio, the reason it looks like this way form, it's just the way you're hearing my voice is my voice or the speakers I creating very rapid changes in air pressure and your ear measures, those very rapid changes in the air pressure interprets as a sound. And so a microphone, uh, is a, is a sensitive device for recording these very, very high frequency changes in air pressure.

Speaker 1:          16:44          And this plots there you see an audio is just what is the air pressure at different moments in time, right? But so given a, um, a ten second clip like this, if this is the fee second section where they said Robert turned on, then what you would like to do is to build a desk lamp. Say they can sit here and the lamp is turned off, turned off, turn off, turn off, turn off, turn off. And at the moment they finish saying, Robert turned on, you know, you turn it on. So this is a open label. Why Rooney? Right. And then, and then it's not detecting the free three. So. So, so what you want to do for the trick word system is, um, at, you know, pretty much the moment they finish saying Robert turned on, uh, you want your learning how room to output a one that's your target label.

Speaker 1:          17:38          Why saying Yep, I just heard this trigger word. Uh, and for all other times you want it to operate zero, right? Cause cause the one is when you decide to turn on the lamp, that moment in time, right? So to collected data sets, um, she has something you can do which is collect 100 audio clips of 10 seconds each. And you know, when I'm prioritizing my work whole, my teams who are, I would really look at these numbers and think, okay, let's say let's say she, if y'all doing it, let's see, you are running around Stanford and you want to collect a hundred audio clips. Uh, uh, maybe 10 people tend to cliffs for person or maybe a hundred different people. Um, I would actually estimate, you know, if you go to Stanford cafeteria, uh, how long does it take to get one person? Right? And you could probably get one person every minutes or two if you go to a busy place out on like a staff, a cafeteria, so you could probably get this done in like a 100 to 200 minutes I two or three hours.

Speaker 1:          18:43          Right? It's not that bad. So you get this done quite quickly. Um, and so and and less. He collect hundred audio clips and Ashley for the, for the, for the purposes of today, let's say you collect a hundred audio clips to use for training 25 for your deaf set at zero for the test set, right? It's actually not that uncommon. If you're building a new product, they just not have a test set because you go is to build something that y'all convinces, you know, just early prototyping phases of a project. Sometimes I don't bother with a test that if it goes to publish a paper, then of course you need a rigorous, he collected test that. But if you're just building a product and you don't need a rigorous evaluation, sometimes you can just get started without dealing with a test set. Right? So it was pretty well get started. Um, and then,

Speaker 2:          19:53          all right, so taking that audio clip from above,

Speaker 1:          20:00          um, one thing you can do to turn this into a supervisor, any problem is to take, so the phrase Roberts hair can be said in less than three seconds. So let's see, you take three seconds as the duration of audio. So we can do is a clip out. So let's say if here was when Robin turn on them, I said, so what you can do is I'm the type of paper that says why you can do is then it clip out different audio clips of three seconds. So here's one audio clip. You can take that audio clip, this is x and the target label is zero because Robert turned on was not sad. And you can take on all this audio clip at different band of nature clipped three second clip and that clip also has its of a bugs. Um, and you know, for this one, right, which is a fee second clip that, that, that, that ends at the real, on the last part of the on sound, you would have a toggle label of one, right?

Speaker 1:          21:13          So, and, and, uh, when, when, when you learned about sequence models, the rns, you learn a better method than this explicit clipping. But for now, let's say you take these, um, audio clips and turn it into, so take a ten second clip. And by clipping out ran different windows, you can take your let's say hundred uh clips. And because for each ten second clip, you can take different windows. You could turn this into let's say 3000 training examples, right? So here I took a ten second clip and, and, and show you three different three seconds windows, but you would take 33 seconds windows. Then each ten second audio cook becomes through the examples. And now you've turned the problem into a binary classification problem where you need to train a neural network, the inputs, a three second clip, and they balls it as either zero or one. It doesn't make sense. And so this is an example of uh, uh, the, the, the more complex pipelines you might have if you're building a learning algorithm to take a continuous Yale audio detection problem and turn it into a binary classification problem, which you've learned how to bill. Baer is neural networks for great. And again, we learn about our nose, you learn about other ways to process sequence data or temporal data. Okay. So, um, oh, go ahead.

Speaker 1:          22:45          Oh, uh, is this Mandy leaving? Yes, I would. Yeah. Actually if you have a hundred examples, um, is not that hard to just listen to you on your laptop or some audio playing software to figure out when, when they finish saying Robert turned on and then at that moment to put a one in to target navel. Right. Cause this is really when you want the lab to turn on. Right. Let me see. Cool. So, um, any other questions? Actually a few few that ask clarifying questions. Yeah, go ahead.

Speaker 3:          23:24          Oh sure. Let me get back to that. Anything else? All right. Why do we do three seconds or five seconds? This is cause another hyper pounds. You can test. Oh No. Oh yeah. You had to say it really slowly to take on l three seconds. Is this right? Fizzy Robert Turn

Speaker 1:          23:59          on right? Does it sound okay? Is it is a design choice? Yeah. Yeah. Um, all right. So, so, um, let's say you do this, feed it to supervisor in the algorithm, train the new, and that's where, um, and let's say that when you classify this, uh, when, when you run this algorithm, you ends up with a 99.5% accuracy,

Speaker 2:          24:28          right? Um, uh,

Speaker 1:          24:31          but you find that the algorithm has zero detections.

Speaker 2:          24:44          Great.

Speaker 1:          24:45          Um, and I what that mean is that whether the audio you give it, it just opens zero all the time. So the algorithm just says, nope, I never heard the phrase Robert, her and not, you know, so, so, so, um, so, uh, and so my question to you is, you know, and by the way, the reason I'm going through these scenarios is, um, I found that, uh, a good way to gain good intuitions and, and to become good at making these decisions is these are the decisions that project leader write a tech leader, a CEO needs to make. These are actually like pretty much exactly the design she needs to make. And I find that I'm one of the ways that this type of experience, if you, you know, find a job with a good AI team and work with them for five years, right?

Speaker 1:          25:31          And then you said she lived through this and you see what they do, but instead of needing you to go and spend five years to see 10 examples of this, I'm trying to step you through maybe one example in one hour. So, so instead of, uh, you know, gaining, does experience through work experience, which is great, but texts many, many years, many, many months hoping to, you know, let's just put you in that position and making these decisions, he comes there and from that much faster. Right. Um, so, uh, and, and all the examples I'm giving are actually completely realistic. Right there. You either exactly or very similar to things I have seen in, in actual, you know, very real project. So question is, uh, you're learning our room gives this result out. 95% of assay zero detections. Whether you do, let me mention some of some of the answers I really liked.

Speaker 1:          26:22          Um, I think that, uh, um, you know, I, when I think of building learning algorithms, uh, the process is often specify a depth set and our test set that measure what you care about us and then, um, you don't always have to do it, but it's good hygiene. It, it's, it is, um, uh, Shopkins clarity of your thinking, right? If you have a very clear specification of the problem. And I think when inside all of this is that if your desk set, there's really all the whack, right? Because it's so unbalanced. That actress here, Jeff set doesn't translate to what you actually care about. Uh, because you know, presume it is 99.5% accurate on the deaf set as well. But this performance is terrible. So it's doing great on the dead set, on your accuracy. Mashaikh we're giving terrible performance. So I think of it as good hygiene.

Speaker 1:          27:13          You know, this is kind of good sound practice, uh, to, to just specify, make sure you at least have a just said and the validation metric that corresponds more closely to what you care about. So making the depth set more balance, uh, equal numbers of positive and negative with would be a good step to have that. Um, uh, and then I think, um, uh, you could also, uh, there are a few people that talked about, um, give the higher weights to the positive examples, right? So, you know, uh, uh, one way to do this is the reassemble your training and your Jeff says to make them more proportionate. In terms of maybe closer to a balanced ratio of positive negative examples. That'd be okay. The other way to not do re sampling, we were just give the positive examples a great to await, right? Um, I would probably be re sample.

Speaker 1:          28:01          Um, another thing you could do, uh, uh, uh, you know, in the inches of, um, uh, speed, even if it's not the math, math most most sound thing to do is to change the target labels to be a bunch of ones after that. Um, uh, and this is a hack. This is not formally rigorous, but if you've implemented the rest of this code already, this might be a reasonable, you know, a little bit hacky thing to do. But this is this, this, this might work well enough, right? I, I would, I might not, I don't know if I would want to try to, you know, write an academic research paper with this method. Maybe I can get away with it. But this little thing that I think if you tried to publish the paper with this, academic reviewers might raise their eyebrows and say, maybe, you know, maybe it is okay, but I think of your one something quick and dirty.

Speaker 1:          28:49          They just works. I think, uh, uh, they bring the ones changing a bunch of labels to be one. So that, say a clip here, right? Uh, that ends just a little bit after Robert turned on is still labor one. There'll be pretty reasonable, but it still just be saying that, um, uh, for anywhere within maybe a 0.5 second period off there, Robert turned on finish. It's okay to turn on the light anytime within that period. Then you kind of want to be turning on the light, turning on the lamp, you know, say within half a second right off there. Robert turned on this has been said, and this would be a not, does it be a way to just get more labels of ones in there? Great. Let me say this. Uh,

Speaker 4:          29:42          how does that translate to like, when you deploy this, you're not going to see Robert Turn Os much, right? Like one out of 1000 might be reflective of what you expect to see.

Speaker 1:          29:52          Yeah, this is good. Yeah. Right. So, um, I think that, uh, put it, um, so if you actually, yes, so what I did, this is how bad deaf set and evaluation the I show kind of question, right? So, uh, one of the couple of the metrics that people often use a when actually working on this is when someone says Robert turned on whether it's the chance that she wakes up or the turns on. And then the second is if no one is saying anything to the lamp, you know, how often does it randomly turn on by itself without you having said anything? So those are the two metrics people actually use. And, and, uh, sometimes you could also try the combined in a single now be evaluation metrical something. Uh, uh, but I think that's, um, uh, you could tend to find a data set to measure both of these things.

Speaker 1:          30:39          And then and then and then hopefully finding a way to combine them into a single rule number, which I think, yeah, I think one of the ways we talked about in the, in the videos as well. Great. So it makes sense. Oh yeah. But I think, I think so question is really, um, uh, what is it? The size, size is using the right. Yeah. And Oh and just one, one thing about the straight forward way of rebalancing is that if you don't do this then your whole data set just as very few positive examples. Right. Um, and so if you throw away all the negative examples so that you cut down the number of negative examples until you have exactly equal numbers was a positive and negatives, you've actually thrown away a lot of negative examples. Does it make sense? And so one, one, one problem with the straight forward way of rebalancing is that, you know, and your audio clip and your test ten second clip they were collected by running around Stanford. You have one example of Robert turned on. And so if you want exactly PR perfectly balance, positive and negative, it means that you're allowed to own the clip out. One negative example, all of this, you can say that's a negative and that's a positive and Yukon clip out more negative examples from this, right? So, so, so of you use a he of the perfect rebalance Yara is throwing away a lot of negative examples that that could be helpful for them running off. Great. Um, so

Speaker 4:          32:09          all right, so, um,

Speaker 1:          32:16          you know, a lot of the workflow of building learning algorithms is um, uh, building learning Auburn's feels more light did buggy, right? Because what happens in a typical machine or in your work though is you implement something and it doesn't work. We'll see you figure out whether is a problem. So he fixed that. Ah, AH, like rebalancing. Are we waiting or adding more once and so that fixes the current problem. And then after fixing the current problem, which, which is the one we just solve, say you then come across a new problem and you have to solve that and you to fix that problem somewhere else. And now the new problems, I find that, uh, the workflow of, um, when I'm working in a machine learning project, it often feels more like software debugging, then software development, right? Because you're often trying to figure out what doesn't work and then trying to fix that.

Speaker 1:          33:01          And after you fix that problem, then another bug surfaces and the squash that and you do that and then another, and you kind of keep doing that until the offer of work. So if I keep talking about, you know, your algorithm doesn't work, what do you do, nick? Right? That's kind of the theme of today's presentation, but that, that is what the workflow, that is what your day to day work of developing a learning algorithm. It's usually like, because it's like it doesn't work and you fix it, it still doesn't work. You fix that and he still doesn't work. You fix it. And He'd do that enough times until it works, right? That, that, that is actually what often working on the learning algorithm works look, looks like. Um, all right. So let's say you fix that problem, um, and you conclude, uh, through doing error analysis that you're, our room is over fitting, right? So, you know, you've added a lot more ones, so the Dataset is a little bit more balanced. So let's just add a bunch of ones like I did on that previous board. Let's just add a lot of ones here. So the INSEAD isn't as unbalanced and, um,

Speaker 2:          34:09          let's see.

Speaker 1:          34:18          MMM, right. Okay, good. Um, let's say that,

Speaker 2:          34:31          sorry, two pages of notes here.

Speaker 1:          34:41          Okay, good. So let's say that, um, you find that are the cheese now, 98% accuracy on training and 50% accuracy on the Dev side, right? So very lush gap boutine your training and your, um, deaf set performance. And so a clear sign of over fitting. And so I think one of the earlier questions, someone talked about data augmentation. Uh, and so we have this clear sign of overfitting, um, this is a good time to consider data augmentation, right then. So let's say you go ahead and do data augmentation. So for audio, this is how you could do data augmentation, which is, um, collect a bunch of background, all audio.

Speaker 1:          35:24          So I guess if you're trying to build a lab that might go into people's homes, then you could go into your friend's homes and, uh, you know, with their permission record, right, what the background sounded, their home looks like. You maybe people talking to background, maybe the TV on in the background, whatever it goes on people in people's homes. Um, and then it turns out that if you take a, um, say a one second clip of Robin turned on an Rto and you add that to background clip, then you can synthesize an audio clip of what it sounds like in your friend's house. If someone were to suddenly pop up and say, Robert turned on against the background sound of your friend's house. Right? Um, and, and it turns out that, um, uh, uh, if you want to make the system robust, so actually phrase apple, they have a, Oh no, I actually know someone that lives unfortunately closely to a train station.

Speaker 1:          36:23          And so their holes as she has a lot of translation noise from the Caltrain. Uh, and so when you can do to make your system more robust is also a take a clip of safe train noise, right? Like cow train noise. And if you take that noise and take, uh, in, in this case, let's say one second, one second or three second clip of someone saying Robert's her and on, and you synthesize that on top of the train in the background. Then once you end up with is a ten second clip of someone saying, Robert turned on against the noisy, you know, trained in the background type of debit noise, right? And so in order to do data augmentation or data synthesis, you can take some one second clips that people saying Robert turned on and the quiet background. And then take some one second clip.

Speaker 1:          37:10          But people saying random words, right? And let's say, you know, Cardinal, right, since the staffing and synthesize this against the train noise background. And then you would have, in this case, you would have what sounds like crazy noise train, train on street noise. Robert turned [inaudible], right. And then, uh, you could generate the labels now as zeros there, one's there, and then Zeros there. Right? Because if this is what it actually sounded like in a, in a user's home, then you want the lab to turn on off. Robert turned on. But not after these random words, he can take different random words. Great. Um, so let's see.

Speaker 1:          37:59          Great. So, um, what I'd like you to do is evaluate, um, uh, three different possible ways to collect noisy data, right. Uh, to, to, to collect this type of background data. Right? Um, and so, um, when I like they do for the next question is let's say you and your team, you know, have, uh, uh, uh, brainstormed, um, uh, uh, brainstormed a few different ways, uh, to collect this type of background noise data. Um, and let's say you've decided that you would like to collect 10 hours of background noise data, right? Okay. So I'm going to present to you three options. One is, um, you know, running around Stanford and taste microphones around Stanford or your friend's house. Do this with consent and don't, don't, you know, California or shoes, you're not supposed to. I don't recall people about their knowledge and consent. Uh, second is a

Speaker 2:          39:23          downloads clips online.

Speaker 1:          39:28          Uh, it, it turns out you can go to youtube. There are these like 10 hour long clips of, you know, rain noise or cars driving around. And so you actually, uh, and again if you do that, find something that's creative comments and sort of appropriate with the license. Right? Um, another thing you could do is use a mechanical Turk,

Speaker 2:          39:57          Amazon Mechanical Turk.

Speaker 1:          40:01          We can have people over or around the world, um, be paid, you know, modest amounts of money to submit audio clips. Right? So for the next exercise, what I want you to do, because I'm, and I want you that this exercise of, of, of this discipline, which is why the why should they do is, um, I went to the estimate, let's see what time is it now? Okay. It's 12:30 PM very now whether wants you to do is write down three numbers in the next exercise to estimate. If you went to do this, you know, let's say you were to go do this right now, right? By what time, where you have finished. If you were to do option one, what time would you finish? And we had to do option two. What time would you finish? You were to do option three if you go is a collect 10 hours of data through one of these mechanisms.

Speaker 1:          40:52          Does that make sense? So it's tough though. The PM now. So one of the lecture they do is just write down three numbers. First number is what time is it, what time would it be? By the time you collected 10 hours of data, you know, from around Stanford, what time would it be? Right? And if you could do this in a so, so if you think you would do it by tonight, then write 9:00 PM if you think it'll do, if you think it will take you one the week, then write the date one week from now, right? Whatever it is. Uh, but just write down three numbers. Obesity activity. Okay, let's do this one relatively quickly. You can people do this and like, uh, maybe a minute and a half. All right, cool. This is interesting. Um, what did people think? Actually this is a surprising large variability. I'll mention one thing that surprised me.

Speaker 1:          41:47          Um, I'll give you my own assessment. I think that, uh, you know, w when I'm leading startup teams, we tend to be very scrappy, right? And so I think that, um, if it goes to collect 10 hours of data, if you have three friends who have laptop, you can collect three hours of data per hour cause he goes see recording's going in parallel. So if I were doing this with say two other friends, you know, I bet I bet we could get this done by tonight, right? Cause if you need nine hours of data that each person needs to collect three hours of data and you run around Stanford, the Keith and microphones running, I bet. I Bet I could get this done by 6:00 PM. Right? Maybe, maybe even earlier. I don't know. Download clips online, uh, is actually earlier on. It's actually an interesting one.

Speaker 1:          42:33          Maybe be about the same time. It turns out one tricky thing about downloading clips online is that um, uh, I think a lot of the, you know, there, there are people that have trouble sleeping at night so they listen to highway noise or whatever. And so there are these, you know, 20 hours of highway clips, highway noise on youtube you can find, but I don't know how those clips are generated. And I suspect a lot of them loop right meaning is the same one hour play over and over. So actually think it's harder than than, than one might guess they get 10 hours of non repetitive data. And as one of those things, you know, if I take an hour of how high sound and Loopit you can't tell the difference cause all high res sounds sounds of saying I just can't tell one minute of highway sound from another one.

Speaker 1:          43:21          But if you have one hour of highway sound loop 10 times the learning our room where she performed much less well than if you have 10 hours of fresh highway sounds. So this I will actually have a harder time doing I think our priority. I would probably, if I were doing this I, because of these problems, I were carried by June until sometime tomorrow. Right. Maybe, maybe 9:00 PM or something. Maybe that's doable. I'm not sure. I'm, the one surprise to me was some people thought they could do this by tonight. I, again, I've used Amazon Mechanical Turk is actually a huge process to set up Amazon where Carl's her get people on board and especially they get them microphone. Uh, I don't have your implants something on flash so we can speak in their web browser or an and be supportive is, it's actually, it's actually not that easy to get a lot of the Turkers to do this and the global supply of [inaudible] salsa unlimited.

Speaker 1:          44:13          So I would, if I were doing this, I would probably, I know maybe a week or something, right. How to say natural. Um, but so does specific opinion isn't that important? But I want you to go through this exercise because this is how, um, efficient startup teams either brainstorm a list of things and then you all figure out how long you think it'll take to do these things. And I think, uh, you can have a debate about how high quality the day duress, I think you can get very high quality data from this. And from this, uh, I, I just didn't cuss of those online, all your sources. But if this is really fast and you can get pretty high quality data, I will probably do this, a collective backgrounds how to get going. Great. But I think that part of their work, so I see of, you know, fast moving teams is pretty much exactly what she did, which is why, why is that, that exercise of brainstorming the list of options and then really estimating, oh, what time can we get this done and then use that to pick an option.

Speaker 1:          45:14          Right. Um, and then I want to just mention one last thing, um, which is that these differences matter, right? Um, you know, I've actually put, I put the last piece of simple all of machine learning systems, but, um, oh and, and I think by the way, if you do everything we just described and you see this later in a problem set, uh, you can actually, with this set of ideas, pretty much the set of ideas that we just went through today. You can actually print the bill, the bill, a pretty decent trigger words. It's action system. I'll wake word detection system. And in fact we'll ask you to do pretty much this and the later homework exercise. But now you know, when you get to that whore exercise, when you do RNN stuff, you know how you could come out with this. So the process yourself, if you didn't already know how to make these types of choices.

Speaker 4:          46:11          Oh my, my, my results at the beginning, I could see like it's not too frozen. Like my micro lights is the same as the one that's used. Oh, when I run the run, let's mess that up. That's what we're asked to think about it.

Speaker 1:          46:31          Yeah. So my advice. So what does your microphone affect your results? Right? Yeah. So my advice is put pizza, get something going quick and dirty and then develop a depth set, right with the actual types of days that you think. If you get on your role microphone and then see if it is a problem. And it may be different microphones, do you have different characteristics? And if it is a problem, then go back and think about how you'd collect data. There's more representative of how you test. I want to mention one more quick thing. Do I had a heart surveys. I want us to do something real quick, which is, um, I want to tell you why these things really matter, which is, um, if this is a performance, right? Oh, oh, let's say Ashley era and this is the time, right? And this is today and you had to see all this thoughts. I remember that. That's what we're doing. Just lesson. And this is six months from now and this is 12 months from now. Right? Um, you know, maybe have a competitor actually, maybe, maybe,

Speaker 3:          47:29          I don't know. Maybe it's because we talked about this so much in this class. Maybe two of you in this classical, I thought the sauce, but it's certainly a competitor. But over time, most of the machine learning teams, the Arrow actually goes down over time as you work on problems right there. That means this is what I see in tons of practical projects. You know, you work on the project, improve the system and the era as she goes down over time, as you work on this over the next, next

Speaker 1:          47:57          12 months, say right, if you're really see over started doing this. And it turns out that it's a startups after discipline to constantly be the most efficient. Um, don't do something that takes you two days. If you can get a similar result in one day, the difference is not that your one day slower, the differences that your two x faster, right? And then, then having that mindset it when take this whole chart and compress it on the horizontal axis. Um, then you want to be the startup that makes the same amount, the pros in six months instead of 12 months. Right? Because if you're able to do this, then your startup will actually perform much better in the marketplace. Uh, assuming, you know, accuracy's important, which it seems to be for wake word. And so don't think of this as saving you a day here and there.

Speaker 1:          48:44          Think of this as making your teeth twice as fast. And that's the difference between this level, the form. Isn't that lovely? So that's why when I'm building teams that execute these projects, I tend to be pretty obsessive about making sure we're very efficient in exploring the options and don't wait until tomorrow to collect data of dubious quality when you have a better idea of collecting data by today. Because the difference is not that you wasted 12 hours a different as you had twice as slow as a company. Right? So I think, uh, so hopefully through this example on your ongoing experiences throughout this quarter can help you continue to get better at this. Right. Um, last thing we wanted to do was, uh, we're about halfway through the course. Oh, go ahead. Um, we want to handle the survey and anonymous survey to get some feedback from you about this costs.

Speaker 1:          49:33          And whenever we get these surveys, uh, we ended up, uh, uh, thanks to the previous generations is his feedback. We've already been gradually we can cause better. So I think Ken and I actually read all of these questions, I'll cells and try to find ways to take your feedback to improve the cost. So I can take, you know, five minutes, uh, felt the survey and you can hand it in and just drop it off and on them see up here in front of me. Very grateful for your suggestions. Okay. So, um, I think if you haven't entered your id yet, uh, you could still do so. But, uh, that's it for today. So please start the survey in the anonymous. You just drop that back in front, then we'll wrap up. Okay. Thank you.