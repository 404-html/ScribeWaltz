Speaker 1:          00:00:09       Welcome to CSU 30 deep learning. Um, so many of you know that, um, deep learning these days is the latest how this area of computer science or AI, uh, argue of the deep learning is the latest, hottest area of, you know, all of human activity. Uh, maybe, um, but this is the class CSU 30 deep learning where we hope that we can help you understand the state of the art and become experts at building and applying deep learning systems on. Unlike many Stanford causes, this class will be more interactive than, than others because this has to be offered in the flipped classroom format where we'll ask you to watch a lot of the videos at home. A lot of the deep learning AI contents hosts on Coursera does preserving the classroom and discussion section time for much deeper discussions. Um, so to get started, let me, let me first introduce our teaching team.

Speaker 1:          00:01:08       So the co-instructors I can cut in fruition who had actually, um, one of the cocreators of the, uh, deep learning specialization, the event, our AI content that we're using in this class. Um, and, uh, uh, the rest of the teaching team, uh, Swati do bay is the cost coordinator and she has been working with me and others on coordinating, uh, uh, CSU 30. Also cc [inaudible] to make all of these classes run well and let you have a relatively smooth, you know, uh, experience, um, newness. Maury is the course adviser and he'd also worked closely with ketamine in creating the online contents that you use. And Eunice is also head ta for CCG Eight, which some of you may also be taking. And then, um, we have a two [inaudible] is worked on machine learning research for a long time and the opposition noise, uh, still traveling back I think.

Speaker 1:          00:02:09       And also a large team of tas that I think about half of our tas in CSU 30 had previous the ta discourse. And uh, their expertise spans everything from applying machine learning problems in the whole care, applying machine learning or applying deep learning to problems in, uh, in robotics to problems in computational biology to problems in. Um, so, so I hope that as you work on your projects this quarter as posse as two 30, you be able to, um, get a lot of great advice and help and mentorship from all of the Tas as well. Um, so the plan for today is, uh, I was going to spend maybe the, a little bit of time sharing with you what's happening in deep learning, why, you know, why deep learning is taking off and how this might affect your careers. Uh, and then in the second half have can't go take over and talk a bit more about the projects you work on in this gloss and not just to final term project, but you know, the little machine translation system, you build a face recognition system, you built a iGeneration system, you're built all of the, uh, many pretty cool machine there.

Speaker 1:          00:03:18       Any deep learning applications. I think you'd get to build throughout the course of this quarter. Uh, and, and also share view the detailed logistics for the plan for other class. Okay. Um, so I think that, um, uh, let's see. All right, I'm going to just use the whiteboard for this time.

Speaker 2:          00:03:41       Cool. So, um, you know,

Speaker 1:          00:03:49       learning, right? Yeah. It seems like the media is still con stopped talking about it. Uh, and um, it turns out that a lot of the ideas of deep learning happening around for several decades, right? The, the, the basic ideas of deep learning has been around for decades. So why is deep learning suddenly you're taking off now? They, why's it quote coming out of nowhere on whether whatever people say. Um, I think that, uh, me visa and deep learning has been taking off a and why, you know, suddenly all of you hopefully will be, I do really powerful things with it. Much more effective. Eden two or three years ago is the following on a lot of, over the last couple of decades with the digitization of society, we've just collected more and more data. Uh, so for example, all of us spend a lot more time on our computers and smartphones now, and whenever you do things on the phone, uh, you know, that creates data, right?

Speaker 1:          00:04:44       Uh, and, and, um, and um, uh, and what used to be represented through pieces of paper is now much more like FIFA digital rec world as well. So if he go take an x Ray, uh, as it, at least in the United States, less so than some other kinds in developing harmony has been easy. The United States does as much high Sean's now at that your x Ray in the hospital is a digital image rather than a physical piece of film. Or if you order a new marker, right, there's a much higher chance that the fact that you ordered a marker, you know, off of website is now represented as a digital record compared to a 10 years ago when to stay that the global supply chain, actually if you order, if you order 10,000 markers, um, there's a much higher chance, you know, 10 years ago did the fact that you placed that order was stored on a piece of paper that someone's scribbled saying, Hey, ship 10,000 lockers to Stanford. But now that's much more likely to be a digital record. And so the fact that, um, so many pieces of paper and now digital has created data and for a lot of application areas, the amount of data has, so the, you know, exploded over the last 20 years. But

Speaker 1:          00:05:58       what we found was that, um, if you look at more traditional

Speaker 3:          00:06:03       learning algorithms, traditional machine learning

Speaker 1:          00:06:10       algorithms, the performance of most of them with plateau, uh, even as you feed it more and more data. So by traditional learning our rooms, I mean just the progression support vector machines, you know, maybe decision trees depending influential details. And it was as if our older learning Auburn's didn't know what to do. If all the data you can now feed it. Um, but what we sought to define several years ago was if you train a small neuronetwork

Speaker 3:          00:06:36       okay,

Speaker 1:          00:06:38       it's performance me lots like that. If you train in medium, you know, Annette is per wants me as I'll say that. And if you train in a very large nearing that, you know, the performance kind of keeps on getting better and better, uh, up to some, usually up to some cervical limited called area we should learn about later this course or a bit more performance can never exceed 100%, but sometimes, uh, sometimes there's some seeding and the performance, but we've been able to measure on many, many problems are we've not yet. I think that across machine learning and deep learning broadly, I think we've not yet hit the limits of scale. And by scale I mean, um, the amount of data you can throw the problem that's still useful for the problem as well as the size of the neural networks. And I think, um, you know, GPU computing, uh, uh, was a large part of how we were able to go from training small to medium to now training very largely are networks.

Speaker 1:          00:07:33       And once upon a time, I think, um, you know, the first, actually I think a lot of the early work on a training, you're in the throttles on Gpu as she's done here at Stanford, right? Uh, crew, they're using crew that the training neural networks, but, um, what used to be, you know, one of the things, one of the lessons we've learned over and over and confusing is that a, what yesterday supercomputer is today's, uh, uh, you know, processor on your, on your smartwatch, right? And so what used to be an amount of computation there was accessible only to, you know, large research labs in Stanford. They could spend $100,000 on gps today. You could rent that on a, on a cloud relatively inexpensively. And so the availability of relatively large neural network training capabilities has allowed really, students really know Albany's everyone, many people, not many, many people.

Speaker 1:          00:08:22       Um, to have enough access to computational power, to train what are large enough to drive very high levels of accuracy for a lot of applications. Um, and it turns out that, uh, um, if you look broadly across Ai, you know, I think the mass media, right? And newspapers, you know, reporters use the term Ai. I think, uh, uh, within, within academia, within the industry, you tend to say machine learning and deep learning, uh, uh, that if you look broadly across Ai, it turns out that AI has many, many tools that's beyond machine learning does even beyond deep learning. And if any of you take, you know, see us through 21, the right staff is AI gloss straight costs, um, uh, you learn about a lot of these other tools of AI. But the reason that deep learning is so valuable today is that if you look across many of the tools of AI in that say, you know, there's a deep learning slash machine learning.

Speaker 1:          00:09:24       Um, oh, and, and, and, and, and again, 70 there a neural networks and deep learning mean almost exactly the same thing, right? It's just that, um, as you know, as we start to see deep learning rise of the last several years, we found that deep learning was just a much more attractive brand. And so, you know, and so, so that's the brand that took off. Ah, ah, but, um, if you look at, if you, if you take an AI class, if you look broadly across the portfolio of tools, you have an AI. Um, I think that, you know, I'll often use deep learning and machine learning. Um, I'll sometimes also use probabilistic graphical model, right? We should learn about and see CST journey also a great class. Um, sometimes I use a planning algorithm. You know, when I'm working on a self driving car, you need a motion plan in the room.

Speaker 1:          00:10:11       You need various planning our rhythms. Uh, sometimes I use the search algorithm, sometimes I use knowledge representation. It's very, see this is one of the technologies, uh, specifically knowledge drafts is one of the technologies that is why are you using the industry? But I think often underappreciated in academia. If you do a web search and then with search engine PauseAble hotel and then this room prices and where there's Wifi with a swimming pool, there actually a knowledge graph, a knowledge representation, knowledge graph. But, uh, so it's actually used by many companies, these large databases. But this, this is actually maybe underappreciated and academia. Um, or sometimes even game theory, right? So if you learn about Ai, there is a very large portfolio of many different tools you will see. But what has happened over the last several years is, um, if you go to a conference on probabilistic graphical models, right?

Speaker 1:          00:11:04       If this is time and this is a performance, you'll see that, you know, every year, um, probably see graphical models worked a little bit better than the year before. It goes to the UAI confidence and certainty in the AOE conference. Maybe the one of the leading conferences, maybe DVD in one nostril on PGM. So you'll see there every year and you know, researchers published papers, they're better than the yoga for in the state. The, the, the fetus steadily marching forward. I'm seeing for planning, we've got the triple AI or something and you'll see a few of those advancing social rooms are getting better, uh, nausea, potentially albums getting better again through we are gay better. And so the, the, the field of AI marches forward across all of these different disciplines. But the one that has taken off, you know, incredibly is deep learning machine learning. And I think a lot of this progress was initially driven by scale, scale of data and scale of compensation and the fact that we can now get tons of data thrown into January and etheric and get good performance, but more recently has been also driven by, um, uh, the positive feedback loop of, um, seeing early traction in deep learning does causing a lot more people to do research in deep learning algorithms.

Speaker 1:          00:12:23       And so there's been tons of algorithmic innovation in deep learning and the last several years, and you hear a lot about, uh, algorithms. They were, you know, relatively recently invented in discourse as well. Right. Um, and so really I think the, the initially the twin forces of a scale of data scale computation, but now the triple forces have also a lot of algorithmic innovation and massive investments, um, is continuing to make deep learning, uh, tremendous progress. And so in CSU 30, are we kind of of, um, uh, uh, you know, I think the two main goals, the first is to, um, have you, uh, become expense in the deep learning algorithms. Have you, have you learned the city arts? Have you, have, you have, you have deep technical knowledge on, um, the Steve odds and deep learning, um, and second is to give you the knowhow to apply these algorithms to whatever problems you want to work on.

Speaker 1:          00:13:20       So, uh, one of the things I've learned, so I think actually some of you guys know my history, right? So, you know, we're up to Stanford for a long time then, um, started as leading the Google brain team, which did a lot of projects at Google. And I think the Google brain team to built from scratch was arguably the leading force for helping Google go from what was already a great internet company and today a great AI company. Um, and then, uh, did something similar at Baidu in China or Chinese, which was headquartered in China, which kind of helped by do you go from also what was already a great company into today? You know, many people will say China's greatest Ai Company. Um, and I think through work on many projects at Google and the phrase the Baidu and now leading landing AI, helping many companies on many projects and running around to different companies and see many different machine learning projects they have.

Speaker 1:          00:14:12       I think I've been fortunate to learn a lot of lessons, um, not just about the technical aspects of machine learning, but about the practical know how aspects of machine learning and um, if you, uh, uh, and, and I think that, uh, what you can learn from, um, you know, the internet or from a purely academic sources or from reading research papers. There's a lot of the tactical aspects of machine learning and deep learning. But, uh, there are a lot of other practical aspects of how to get these algorithms to work that, um, I actually do not know of any other academic course that, that kind of goes into great deaf it, there might be one, but I'm, I'm, I'm not sure, but one of the things that, um, uh, uh, we hope to do in this class is to not just give you the two as well as to give you the knowhow on how to make it work.

Speaker 1:          00:15:03       Right. And I think, you know, actually spent a lot of time thinking about, uh, so actually late last night, I actually stayed up very late last night reading this new book by John Holtz on a software architecture. Right. And I think that, um, there's a huge difference between, you know, a junior software engineer and a senior software engineer. Maybe everyone understands the c plus plus and Python and Java Syntax. You know, you can get that from, from, uh, from, you know, you just figured out, hey, this is how c plus this works. This is how job roles is, how python none pay works. But, um, is often the high level of judgment decisions of how the architect, the system, uh, what abstraction is do you use, how do you define interfaces that defines the difference between the really good software engineer versus, you know, a less experienced software engineer is not understanding and c plus a syntax.

Speaker 1:          00:15:51       Um, and I think in the same way, uh, today there are lots of ways for you to learn the technical tools of machine learning and deep learning. And you will learn that in this class. You know, you learn how the training and you're on that row if you learned the liters optimization, however rooms you, uh, understand deeply what the conference that is, whether a recurrent neural network, whereas when an Lstm is, you understand where the intention modelers, you, you learn all of these things in great detail in your work on pricing could be vision, national language processing, speech and so on. Um, but I think one other thing that is relatively unique to this class, um, uh, enter the, I guess the, the, the, the things you'll see, uh, on the deviant AI, Coursera websites as well as the things we'll do in class is trying to give you the practical no hole so that when you're building a machine learning system, you can be very efficient in, uh, deciding things like she would collect more data or not.

Speaker 1:          00:16:44       Right? And the answer is not always. Yes, I think, I think, um, with, I think that many of us tried to convey the message that having more data is good. Right? And that's actually true. More data pretty much never hurts. But I think the message of big data has also been overhyped and sometimes it's actually not worth your while to go and collect more data. Right? But, so when you're working on machine learning project and if you are either doing it by yourself or leading a team, your abilities and make a good judgment decision about she just spend another week collecting more data or she just spend another week searching for hyper parameters, are tuning parameters, your neural network, that's the type of decision that if you make it correctly, can easily make your team two x or three x or maybe 10 x more efficient. And so one thing we hope to do in this class is to more systematically imparts to you there's this type of knowledge.

Speaker 1:          00:17:37       Right? Um, and so I think, um, uh, even today, um, I actually, I actually visited lots of a machine learning teams around Silicon Valley. There are other were on the kind of see what they're doing. Um, uh, you know, recently I visited a company that had a team of 30 people, tried to build a learning algorithm and a team of about 30 people was working on learning. I have room for about three months, right? And, and they had not yet managed to get it to work. So they basically, you know, like, you know, not succeeded off to see months. Um, one of my colleagues, so the Datasets, oh, Ken, Ken, you're broadcasting.

Speaker 3:          00:18:17       Don't say anything back. All right. All right.

Speaker 1:          00:18:24       Um, so, uh, one of my colleagues, um, took the dataset home and spend one weekend

Speaker 3:          00:18:30       working on lesson three now. All right, cool.

Speaker 1:          00:18:39       Um, and, and, and one of my colleagues, uh, uh, working on this problem, he one long weekend, he rots on over a long weekend to see days, was able to build a machine learning system that outperform what this group was 30 people have been able to do after about three months. So what's that? That's like a, Oh, no, that's more than a tennis difference in speeds. Right. And, and the law of the differences between the great machines are any teams versus the less experienced ones is actually not just do you know how to implement, uh, uh, uh, is, is not just, you know, how to implement an LSTM right in, in, in tens of flow or carers or whatever. You have to know that, but it's actually other things as well. And I think, um, uh, Ken and I and the teaching team, I'm looking forward to trying to systematically and pots you a lot of this no hall, so that, uh, when this, hopefully someday with ya'll leading a team of machine learning engineer has a little deep diving engineer, is that you could help direct the teams fs more efficiently.

Speaker 1:          00:19:36       Um, and Oh, and actually if any racist, uh, uh, one of the things up in actually, how many of you have heard of machine learning, yearning, machine learning, [inaudible] urinate. Wow. Almost none of you. Okay. Interesting. Um, so this is a, if this is your first machine learning because this may be too advanced for you, but if you've had a little bit of other machine learning background, um, machine learning yearning has a book club and right. W W did, I've been dumping, working on, uh, is still in draft form. But, um, uh, if any of you want to be done, machine learning yearning is my attempt to try to turn, gather best principles for Tony Machines, learning from a black art into systematic engineering discipline. And so, uh, if you go to this websites, uh, uh, you know, this website we'll send you, actually I just finished the last, just finish the hope of draft last weekend.

Speaker 1:          00:20:29       Uh, and so email it allows students, if you want a copy, goes to the website and enter your email address and I'll make sure that, you know, when we send out the book, actually it might be later today. Not sure there won't, well then you'll get a copy of the book draft as well. I tend to write books and then just post them on the Internet for free so you could hear it. We just emailed him, yell out to people. So you can, you can, you can get it if you go to the websites. Um, I think this will, uh, and, and I think this class we talk a lot about law, the principles and machine learning yearning, but give you much more practice as well. Then they're just reading a book might, um, so messy. Okay. So, um, Shannon will give a greater overview of what we'll cover in this class.

Speaker 1:          00:21:17       But, uh, uh, one of the principles I've learned as well is that, you know, it. So I think, um, uh, some, you know, my background is a cofounder. Coursera was an educator for a long time, so I spent a long time really thinking a lot about education. And I think cs two 30 represents, you know, [inaudible] in our teaching teams, uh, really best attempt to deliver a great, uh, on campus deep learning course. Um, and so interesting. Um, um, and so the format of this class is what's called a flipped classroom class. And what that means is that, so, you know, and I think, uh, I've taught on Sdpd for a long time, right? For many, many years ago. And I found it, uh, even for classes, uh, like CST do nine or other standard courses, often students ended up, you know, watching videos at home. Uh, and, and I think with the flip classroom, what we realize was if many students are watching videos of these lectures at home anyway, why don't we spend a lot of effort to produce higher quality videos, a that you can watch then a more time efficient for you to watch at home.

Speaker 1:          00:22:31       Um, and so, uh, our team, uh, treated videos, deviant or AI created neon kind of the best videos. We knew how they treat it on deep learning, uh, that are now wholesale and Coursera. And so with, I actually think that it will be a quite time efficient for you to watch those videos. Um, do the online program exercises, do the online quizzes. And what that does is it preserves the class time, both the weekly sessions that we'll meet right here on Wednesdays, as well as a ta discussion sections on Fridays for much deeper interactions and for much deeper discussions. And so, um, the format of the class is that we asked you to, uh, you know, do the online contents, uh, treated by Divia wholesale, Coursera, and then in class, uh, both the meetings with Jeremy, I think Ken and I were split these sessions roughly 50, 50, as well as for the deeper small group discussion sessions you have with the tas that lets you spend much more time interacting with the tas interacting with and me and going deeper into the material.

Speaker 1:          00:23:35       Then just the, then, then the, then the, um, uh, then the, then the online contents, uh, by itself. And, uh, that will also give us more opportunities, give you, um, advanced material, uh, that goes beyond the west hosted online as well as, um, uh, uh, give you additional practice with these concepts. Right. Um, and so let's see. Yeah. And so, um, I was, uh, finish up with, uh, two more thoughts and now I'll hand it over to Ken on, I think, you know, uh, machine learning, deep learning, AI, whatever. It's changing a lot of industries, right? I, I think, you know, I think AI is the new electricity. Uh, my shares, the rise of electricity, uh, about a hundred years ago, starting at USDS, transform every industry, really the reservation, see transform agriculture because finally we had refrigeration, right? That transform agriculture, a transform healthcare, imagining going to a hospital, there's a day, there's no electricity.

Speaker 1:          00:24:38       How do you, how do you even do that? Right? Computers, mental advisors, have you been run? A healthcare system is transformed communications through Telecon, through the telegraph initially, but now so much a communications really needs electricity, but electricity transform every major industry. And I think machine learning and deep learning has reached a level of maturity where we see a surprisingly clear path for it to also transform pretty much every industry. And I hope that through this class, uh, after these next 10 weeks that all of you will be well qualified to go into these different industries and help transform them as well. And I think, you know, after this class, I hope that you'll be well qualified to like get a job as some of the big shiny tech companies that have a large AI teams. Uh, I think a lot of the most exciting work to be done today still is to go into the less shiny industries that do not yet have AI and machine learning yet.

Speaker 1:          00:25:37       And to take it to those areas actually underway. And I was chatting with the students, um, that works in cosmology. Who is commenting was that, you know, sorry, who was it? So at the back who was commenting their cosmology needs more machine learning and, and maybe he'll be the one to take a lot of the ideas are in deep learning into cosmology because I think even outside the shiny tech areas like, and, and maybe since I hope will play a role in the AI transmission of two large rough search, confused unlike done transforming Internet search companies. And I think that, but I think, and I think it's great that we have those great AI teams like Google grain by Dewey. I grew, uh, other large tech companies have great AI teams. I think that's wonderful. I think a lot of the important work to be done there.

Speaker 1:          00:26:17       Hope many of you will do research AI to healthcare, taking out the competition, biology ticket out to civil engineering to create in the coaching. I think all of this is worth doing just like electricity didn't have one killer APP is useful for a of things. And I think uh, many of you will go out after this course and execute many exciting projects both in tech companies and in other areas that, that cosmology right, or other areas that were not traditionally considered cs areas. Um, so, uh, just wrap up with uh, uh, uh, two last thoughts. Um, I think that uh, one of the things that excites me, it is theirs is I'm hoping, uh, you know, I don't want to share with you one of the lessons I learned, right? Uh, watching the rise of AI in multiple companies and spend a lot of time thinking about, you know, what is it that makes a great AI company?

Speaker 1:          00:27:16       And one of the lessons I learned was really a hearing Jeff beasel speak about what is it that makes for an internet company, right? And I think a lot of the lessons that we learn with the rise of the Internet will be useful. You know, Internet was maybe one of the last major technological ways of disruption and just as it has a great time to start working on the Internet, maybe 20 years ago, I think today is a great time to start working on AI or deep learning. And so it's sort of way to turn on the lights on this side as well or is, what do I do? I control that. Uh,

Speaker 3:          00:27:50       okay.

Speaker 1:          00:27:50       Oh Great. Thank you. Thanks again. Great. So I want to share with you one of the lessons I learned. Really spend a lot of times trying to understand the rise of the Internet because they'd be useful to many of you as you navigate the rise of machine learning AI in your upcoming careers as well, which is, um, one lessons I learned was you can take your favorite shopping mall and build the website for the shopping mall that does not turn your shopping mall.

Speaker 3:          00:28:24       Yeah.

Speaker 1:          00:28:25       And to Internet company. Right. So, you know, oh, like my wife like Stanford shopping center, uh, and I, and snappish [inaudible] has a website that even if you know, a great shopping mall sell stuff on the website, there's a huge difference between a shopping mall with a website compared to true internet company like an Amazon were war and whatever. So what's the difference? Um, about five, six, eight, six, six, seven years ago, I was chatting with the CEO of a very large American retailer. And, uh, at that time here and the CIO were saying to me, they were saying, look, Andrew, we have a website. We sell things on their website. Amazon has a website, Amazon sells things. And the website is the same thing, but of course it's not. And today this particular large American retailers, you know, future existence is actually a little bit in the question part of the part of you because of Amazon.

Speaker 1:          00:29:15       Um, so one of the lessons I learned, um, uh, uh, really, uh, the variances me, Jeff Besos is that what defines it into their company is not just where are you, have a website instead. It is, have you organized your team or your company to do the things that the Internet lets you do really well? For example, Internet teams, uh, engage in pervasive ab testing, right. We, we, we know that we could launch two of the website and just see which one works better. And so we learned much faster, whereas a traditional shopping, while you can't launch two shopping malls in two parallel universes and see which one works better. Yeah. So you just, it's just so much harder to do that. We tend to have short shipping times.

Speaker 3:          00:30:00       Yeah.

Speaker 1:          00:30:01       Right. You can shipping new product every day or every week and so you learn much faster. Whereas the traditional shopping mall May, I redesigned the shopping mall once per once every three months. Right. And we actually organize our teams differently. Um, we tend to push decision making,

Speaker 3:          00:30:22       yeah.

Speaker 1:          00:30:23       Down to the engineers or engineers and product managers because in the traditional shopping mall, you know, things kind of move slower and maybe the CEO says something and then everyone just does what the CEO says and that's fine. But in the Internet era, we learned that, um, the technology and it uses is so complicated that, uh, only the engineers and the product managers for those of you to know what that is, oh, are close enough to the technology, to the algorithms and the users to make good decisions. And so we tend to push the zoom making power and Internet companies down to the engineers. So engineers and product managers. And you have to do that in the Internet era because that's how you organize a company or organize a team to do the things the Internet lets you do really well. So I think that was the rise of the Internet. I think with the rise of the AI era or AI machine learning or deep learning, whether you want to call it, um, we're learning that if you have, you know, a traditional company plus a few neuronetworks

Speaker 1:          00:31:31       that does not by itself turn the company into an AI company. Right. And I think what we'll define the great AI teams of the future, um, uh, will be, do you know how to organize your own work and organize your teams work to do the things that modern, you know, machine learning and deep learning and other AI things lets you do really well. Um, and I think, um, having the items that Google and Baidu, I'm of the buyers, I think Google and Baidu, I great and the head of many other companies and thinking this through, but I think even the best companies in the world haven't completely figured out whether the principles by which to organize AI teams, but I think some of them will be that. Um, we tend to, um, uh, I think that AI teams tend to be very good as a strategic data acquisition.

Speaker 3:          00:32:27       Okay.

Speaker 1:          00:32:28       And so you'll see AI companies or AI teams even, even, uh, you know, do things that may not seem like it makes sense. Why do these companies have all these free products that don't make any money? Some of it is a car data that you can monetize through other ways, right? Uh, through advertising was who's doing the, about users. And so there are a lot of ag data acquisition strategies that as a surface level may not make sense but actually do make sense if you understand how this can be married with deep learning algorithms to create value elsewhere. Um, and I think that's a, uh, AI companies tend to um, organize data differently,

Speaker 1:          00:33:10       right? A AI teams tend to be very good at putting out data together. I think before the rise of deep learning, many companies have fragmented data warehouses where if you have a big company, if you have 50 different databases, know in 50 different divisions is actually very difficult for an engineer to look all this data and put it together, I had to train the learning of room to do something valuable. So the leading AI companies tend to have unified day there and warehouses. And I guess, and I know we have a large, a whole audience or SEBD or other home audience here. I said, if any of you work a lot of tech companies, you know, this is something that, that many companies are investing in today to lay the foundation for learning algorithms. Oh, we tend to be very good and smart and pervasive automation opportunities, which is very good at spotting opportunities where you could, instead of having people do a toss of a deep learning algorithm to a tall, so I have a different day, I often do a toss. Um, and we also have a

Speaker 1:          00:34:11       new job descriptions, which I don't have time to talk about. But just as with the rise of the Internet, we started creating a lot of new roles for engineers, right? I think actually once upon a time there where it was simple and there was just a software engineering title. Uh, but as technology got to got more complicated, we started to specialize. So that's why yeah. Was the Internet where front end, back end mobile, right? And now we have, uh, uh, yeah. And, and then with increasing the other girls, right? Qa Dev ops it into increased specialization of knowledge. Uh, and so with the rise of machine learning, we're starting the creation of new roles like machine learning, engineer, a research machine, learning research scientists. Uh, and, and our product managers in AI teams also behave differently than probably manages and Internet companies. And so one of the things we'll revisit a few times throughout this quarter is, and I don't mean to be too corporate, I know that many of you are, you know, some of the SFPD audience or online audience already working company.

Speaker 1:          00:35:11       Many of you when you graduate from Stanford will end up maybe stop, Hey, you own company or join an existing company. Uh, but I think that's solving a lot of these questions of how to organize your teams effective in the AI era. We'll help you do more valuable work. Um, and I think, uh, to, to, to make one more analogy, you know, I think that, uh, one of the things I hope I can and I will share with you throughout this quarter is, um, just as in the software engineering world, it took us a long time to figure out what is agile development, right? Or what are the pros and cons of, you know, waterfall model versus agile or how do you, uh, what, what is a strum process right? Or is code review it? Good idea. Seems a good idea to me, right? It's, but this, these practices, uh, after, after programming languages were created or invented or whatever, we still had to figure all these ways to help individuals and teams right.

Speaker 1:          00:36:08       Software effectively. And so if you worked in, you know, high performing corporate industrial AI teams using these software, injuring practices, everything, Code Review to agile to, to, to whatever you, you, you know, they're having a team work effectively. The right software is more than everyone knowing c plus plus in tasks, everyone doing python syntax. And I think in the machine learning world, we're still in the process of inventing these types of processes, whether it's the strong, what is the agile development, what's the equivalent of code review for developing machine learning algorithms. And I think, um, probably, uh, this class more than more than this class and machine there, any yearning, uh, more than any other of these walls I'm aware of right now. I think we'll try to systematically teach you these tools so that you don't just are able to derive a learning our river, um, and, and implemented learning algorithm, but that you're actually, you know, very effective in terms of how you go about building these systems.

Speaker 1:          00:37:08       Um, so last thing are the Fi, uh, uh, pass it to Ken is the other question that I've been us I guess several times this week now that, uh, just pm to have the answer is, uh, uh, so, uh, uh, there are multiple machine there, any courses going on at Stanford this quarter. So the other frequently asked question is, which of these courses should you take? So let me just address that preemptively before someone asks me, because I've been asked twice already, uh, in the other two classes of quarter. Um, so I think actually what's happened over the last several years of standard as the demand for machine learning education has, you know, been rising dramatically because, uh, I mean, you know, the majority of CSP CSPC Africans to Stanford, you know, are applying to do work in machine learning or applying it to, to do work in Ai. And I think all of you can kind of see that there's such a shortage of machine learning engineers, right?

Speaker 1:          00:38:07       And then there's a little bit of, and, and, and I think that shortage will continue for a long time. So the many people see that if you're calling an expert in machine learning, there'll be great opportunity is for you to do meaningful work on campus to take machine. They're only into con buyer or cosmology or Macallan Jane, or do great research on campus as well as graduate from Stanford and do very unique work. Uh, w when a wonder around silicon valley, I feel like there are so many ideas for great machine learning projects that exactly zero people seem to be working on because he's just on enough machines or any people in the world right now. So by learning these skills, you could, you have many opportunities to be the first one to do something very exciting and meaningful. Right? Oh, and, and, and um, you probably read in the newspapers about how much money have machine learning people make.

Speaker 1:          00:38:50       I'm actually much less is more, I actually find out, I hope a lot of you make a lot of money, but I actually proceed. They'll find out that, you know, as, as exciting. I think that, um, every time there's a major technological disruption, it gives us an opportunity to remake last parts of the world. And I hope that there's some of you go improve a hoka system, improve the educational system. Maybe you'll see if we can help preserve the smooth functioning of democracy around the world. I think that it really, your unique skills and deep learning and will give you opportunities to do that. I think hopefully very meaningful work. Um, but because of this massive, massive, uh, a rise in demand for machine learning education, um, there are, so for a long time, see cs two, three, nine machine learning was the core machine learning class at Stanford.

Speaker 1:          00:39:34       Um, and then, uh, see us two 30 is actually the newest, a new creation I think. Oh, and the other costs that were involved in that unit and I are involved in discourse or is a cs two 29 a. So, um, uh, so if China decides which of these classes to take, um, I think, I think that these classes are a little bit like Pokemon, right? You really should collect them all. Um, but, but, uh, but, but I think what we've been trying to design these classes to actually teach different things and not have too much overlap. Uh, uh, and, and so, um, there is, uh, so I have seen students take two courses at the same time and that's actually fine. There's not the, the, the, the view of all lap is fine that you actually learned different things. If you take any two of these classes at the same time, um, CST between nine is machine learning is the most mathematical of these classes.

Speaker 1:          00:40:28       We'd go much more systems. You now it goes much more into the mathematical derivations of the algorithms. Um, CSU 29 a is applying machine learning is much less mathematical but spends a bit more time on the practical aspects. Uh, is actually the easiest on round two machine learning as well as the least mathematical of these classes. See us through 30 is somewhere in between. This is a bit more, it's more math world than CSU doing it. Less mathematical does CSU 30, but where CSU 30, uh, focuses on is on deep learning, which is just one small subset of machine learning, but it is the hardest subset of machine learning. Whereas there are a lot of other machine learning algorithms from your PCA K-means recommender systems support vector machines that are also very useful. Did I use in my work quite frequently that we don't teach in CSU 30, but there's towards the cs two, three, nine, six two, two, three 90.

Speaker 1:          00:41:19       Um, where's Soso the unique things about cs two 30, is it focusing on deep learning? So I'll know if you want to have this deep learning on your resume. I guess maybe this is the easiest way to do it. I don't know. Again, it's not what I tend to optimize for a bit, but, uh, and I think 30, uh, goes to deeper as in their practical know how and how to apply these algorithms. Um, oh and so, and I want to set expectations accurate as well. Right? So, um, what, I don't want this, but you guys to complain it in a Coolterra that you know, there wasn't enough map because that's actually not the point. What has happened in the last decade is the amount of math you need to be a great machine learning person has actually decrease, I think. Uh, and I wanted to um, to less math and cs two 30, but spend more time teaching you the practical knowhow of how to actually apply these algorithms.

Speaker 1:          00:42:08       Right? So, um, yeah I think two, two then a is probably the easiest is cause that's the most technical cause this the most most hands on applied and you do a lot of the projects on different, different topics, right? And I think these courses are often the foundation or some subset of these are often the foundational courses as soon as hey, um, uh, because if you say learn deep learning some common sequence first students is the, you know, learn the foundations and machine learning or machine learning or deep learning at so you have the foundation of first before you go, which then often says yup to later go deeper into computer vision or national here's processing or robotics or the reinforcement learning. And so common sequencing, that common tactic that Stanford has take is to use these as the foundation. You see a bit of everything from quick division and natural language processing, speech recognition, Yo, we'll touch a little bit low on self driving cars are the, is the foundation to then decide do you want to go deeper into national actors processing or robotics or enforcement learning or computer vision or something else?

Speaker 1:          00:43:12       So this common sequencing of courses that students take. Okay. So, um, look forward to spending this quarter with you. Let me just check with the quick questions and then I'll hand it over to Ken. Yeah, go for it.

Speaker 4:          00:43:27       What's the third bullet and AI era?

Speaker 1:          00:43:30       Well that and the AI decision making by engineers and product managers. Really pushing decision making. I wrote this is you're making by engineers there, but really engineers and product managers. Oh, AI era. A pervasive pervasive automation.

Speaker 4:          00:43:50       Well you're talking about a high being the next like other tricity. Um, I was wondering, and I don't say that like we're like so far, like what are the most like the most meaningful success or of machine learning that you think have happened already?

Speaker 1:          00:44:11       So all of are using learning algorithm is probably dozens of times a day, maybe even hundreds of times a day without you knowing it, right? Every time you use a website changing does a learning algorithm that's improving the quality of sectors else. There's also plenty, however, trying to show you the most relevant ads and just helps those companies actually make all the money every time. It turns out that, um, uh, actually Google and Baidu has public sent that over 10% of searches on mobile are through voicage. Uh, and so I think it's great that you can now talk to your cell phone rather than typing on a tiny little keyboard. If you want to do a do a web search and mobile, uh, if you go to need a website like Amazon or Netflix or, uh, uh, uh, there are learning algorithms recommending more readily movies and more relevant products to you every time you use your credit card.

Speaker 1:          00:44:57       Uh, there's a learning algorithm I to probably almost all companies I'm aware of. There's learning. Everyone, I'm trying to figure out if it's you using your credit card or have as soon stolen. So they should, they should, you know, just allow the CF as a fraudulent transaction or not every time you open up your email. Uh, the only reason email is even usable is because of your spam filter, which is cause of learning algorithm that works much better now than, than before. Uh, I know, uh, I and yeah, so, so there's, uh, I think, uh, you know, one of the amazing things about AI and machine learning is I love it when it disappears in the background, right? You use your, you know, you use these algorithms are you boot up your map application and the fines are shorter's Ralphie the drive from here to there.

Speaker 1:          00:45:38       And there's a learning algorithm predicting what traffic will be like on highway one or one one offer now. But you don't even need to think that there was a learning algorithm and trying to figure out what traffic will be light one are in the future. See, it's really magical, right, that, you know, uh, that, that you could just use it. We can bill all of these wonderful products and systems that helps people, uh, but abstract away a lot of the details. So that's the present. And I think in the future, near future, uh, most of my phd students, most of my research group, he has work on machine learning for healthcare. I think that will have significant in rows. Uh, uh, you know, um, my, my, my team at landing AI has been lot of time with, with a lot of industry is for manufacturing, the agriculture. So all the things, uh, I'm excited about machine learning for education, uh, give people precisely you to help people recommended ProSites contents. There's fascinating research done here at Stanford, uh, by Tris peach and a few others on using, learning our rooms to give people feedback on coding homework assignments. So, so sorry, there's so many examples of hilarity learning. I could talk for quite some time. Yeah. One last question. I had that over again. Yeah, go ahead.

Speaker 1:          00:46:50       Um, let's see. So the, uh, so the format of the class is that, uh, you are watch, uh, videos, uh, created by deep learning AI and whole song Coursera. So you see me a lot there. Uh, but in addition, uh, Karen and I will be having lectures here in this classroom every Wednesday, uh, and that will be, you know, completely new material that is not online anywhere. Have you three now. Yeah, yeah. Uh, and, and then also the, I think the, the, the, the point, the point of the flip classroom thing really is some of the things is really more time efficient for you to just learn online. So there's the online content, but whether it does is it leaves this classroom time for us to not, you know, deliver the same lecture a year off the year. But to get Charlie to spend time to get to know you, have more time answering your questions, uh, and also give you more in costs practice on these things, right? So there's the Coursera Devonta our content, the lot, what we do in CSS 30 is to augment that, to give you a much deeper practice, more advanced examples, uh, uh, some more deeper map balco derivations and, and more practice. So you'd say you deepen your knowledge of that

Speaker 2:          00:47:58       and with that, then you hand it over to chat.

Speaker 1:          00:48:14       Yeah, I'm going to get back at him by making noise while he's talking. Okay.

Speaker 2:          00:48:26       Okay.

Speaker 5:          00:48:28       Thanks Andrew. Hi everyone. Uh, I'm Keon, we're excited to have you here today. Those of you who are in class, but also those of you who are, or CPD students. Uh, we wanted to take a little more time to explain a little bit about the course logistics, what this course is about, and also what it is to be a CS to 30 students in fall 2018. So the course online is structured into five chapters or sub courses, let's say, uh, which we will teach you first is what is in Europe. You need to know that after understanding what the neuron is, you're going to be layers with this new roads. You're then going to stuck these layers on top of each other to build a network that can be small or did, uh, this is the first course. Unfortunately, it's not enough to deploy a network.

Speaker 5:          00:49:21       Uh, just just building a neural network is not enough to get it to work. So in the second course, we're going to teach you the methods that are used to tune these network in order to improve their performances. This is the second part. Um, as Andrew mentioned, one thing we really, uh, we think a huge emphasis on incest two 30 is the industrial applications and how the industry works today. So the third course is going to help you understand how to strategize your project that you do to find the quarter, but also in general, how do a I teams work? You can have an algorithm, you have to identify why does the algorithm work, why does it not work and if it doesn't work, what are the parts that you should improve inside the algorithm? The two last courses of course forth and of course four and five are focusing on two fields that are defined by two types of algorithms.

Speaker 5:          00:50:15       First convolutional neural networks that have been proven to work very well on imaging or videos. And on the other hand sequence models that include also record your own networks. There's whore applied, the lots in natural language processing or speech recognition. So you're going to see all that. Uh, from the online perspective. Um, we use a specific notation in cs two 30. So when I will say c two m three, it refers to course to module three. So the third module of improving deep neural networks. Okay. And I'd like everyone to go on the website to 30 syllabus after the class to look at all the syllabus revived the quarter check when the midterm is and when the final poster presentation, um, the schedule is posted there. Um, so check it out and we're going to use the coarser applied form as you know. So on Coursera you will receive an invite on your Stanford email and you should have received it already for course. One. In order to access the platform from the platform, you will be able to watch videos, do quizzes, and do programming assignments. And every time we finish one of these courses, so c one has four modules. When you're at c one m four, you will receive a new invite to access CE two and so on. Okay. Insights. [inaudible] we're going to use [inaudible] as a class form for you to interact with the Tas and we, the instructors. Uh, you can post privately or publicly depending on the matter.

Speaker 5:          00:51:50       Okay. So let's see what it is to be a one week in the life of the CSC to 30 students. So we're going to do 10 times that over this, the fall quarter. So what is one module in a module you will watch about 10 videos on Coursera, which will be about one hour and a half a. You will do quizzes after watching the videos. This is going to take you about 20 minutes per module. And finally you will complete programming assignments, which are on Jupiter notebooks. You will get sales to test your code and also submit your code directly on the course of our platform. In one week of class in Stanford here we will have two modules. Usually on top of these two modules, you will come to lecture for one hour and a half, uh, in class lecture on an advanced topic that is not taught online.

Speaker 5:          00:52:42       And after that, uh, you will have ta sections on Fridays that are around one hour and it's a good chance for you to meet other students, uh, for your projects and also to interact with the tas directly. Um, finally, we have also a personalized monitorship this quarter where every one of you will meet 15 minutes per week with a ta in order to check in on your projects and gives you the next steps. So we put a huge emphasis on the project in this class and we want you, you will see it later to build two to the side of your teams by this Friday. In order to get started as soon as possible, next week you will have your first mentorship meeting with the TS. Okay. It's going to be fun. Um, assignments and quizzes that are part of modules or do you every Wednesday at 11:00 AM so 30 minutes before class so you can come to class with everything done and uh, understanding, uh, and do not follow the deadlines displayed on the Coursera Platform.

Speaker 5:          00:53:42       Follow the deadlines posted on the CS, two 30 websites. The reason the deadlines are different is because we want to allow you to have laid days and course was not being poor late days. So we, we put the deadlines later on of course, search to allow you to submit even if you, you want to use a late day. Does that make sense? Okay. So we're also using a kind of interactive, uh, this, this is going to start course too. We, we will use an interactive tool that is called Mentimeter, um, to checking attendance in class and also for you to answer some interactive questions. So he's going to start, uh, next, next week, sorry. Not Course to uh, regarding the grading formula. Uh, here it is. So you have a small part on attendance that is 2% of the final grade, 8% on quizzes, 25% on programming assignments and a big part on the midterm and on the final projects.

Speaker 5:          00:54:39       Um, so this is posted on the website if you want to check it. Uh, attendance is taken for in class lectures for, uh, 15 minutes, ca meetings and for the ta sections on Friday, you can have a bonus. And we've had students very active on, on Piazza that's answered questions to other students, which was great and they got a bonus. So I encourage you to do the same. Maybe we don't need tas and instructors anyway. Okay? So I wanted to take a little more time to go over some of the programming assignments that you're going to do this quarter. Um, so that you, you, you know where you're going in about three weeks from now, you're going to be able to translate these pictures here in the numbers that they correspond to in, in sign languages. So it's sign language, trust translation from images to the outputs, a signification, um, you're going to build a convolutional neural network, uh, and the first to logistic regression and then a convolutional neural network.

Speaker 5:          00:55:42       In order to solve this problem a little later, you're going to be, uh, a deep learning engineer in a house that is not too far from here called the happy house. So there's only one rule in this house and the rule is that no sad person should enter the house should avoid that. And because you're the only deep learning engineer that has the knowledge, you're given this task, which is don't let these sad people in, just let happy people and you're going to build the network that will run on a camera that is in front of the house and that is going to let people in or not. And unfortunately some people will not get in and other people will, will get in because they're happy and you will save to whup your house at the end of the assignment hopefully. Um, this is uh, uh, one of the applications of deep learning that I personally prefer. It's called, uh, object detection. You, you might have heard of it. So this is running real time and that that's what he's very pressing. You're going to work on a deep learning architecture called Yolo v two and Yolo Vitu is an object detection algorithm that runs real time and is able to, they take 9,000 objects as fast as that. So it's, it's really, really impressive. You have a few links here. If you want to check the paper already, but maybe you will need it some weeks to understand it. Okay.

Speaker 5:          00:57:12       Actually we have, uh, we can even run it directly on my computer. I think she's going to be fun. Oh yeah, we can run. It's so he did you see it's running live on this computer. And so you see that if I move, it's, we'll find out that I moved so I cannot escape. Yeah, here it is. Okay.

Speaker 2:          00:57:48       Yeah.

Speaker 5:          00:57:51       Okay. A few other projects. Uh, one, two weeks from now, you will build an optimal goalkeeper shoot prediction. So in soccer, you're a goalkeeper and you want to decide where you should shoot them all in order to make it land on one of your teammates. You're getting two signs. What's the exact line on the field? Which tabs that will keep our word to shoot two weeks from now about, um, in the, in the fourth course, a convolutional neural network, you're going to work on car detection. So this is a bigger image. Uh, this is exactly the programming assignments. So we're going to work on the autonomous driving application that is finding cars, finding stop signs, finding lights, finding pedestrians and all the objects that are related to road features. Okay, this is pretty cool and you will generate these images yourself. So this is a picture taken from a camera in the front of, uh, of a car and was, was generated by drive that Ai, um, you will have a face recognition system that is going to first do face verification.

Speaker 5:          00:58:58       Is this person, is this person the right person, but also face recognition. Who is this person, which is a little more complex. We're going to go over that together, both online and in lecture or generation. Some of you have heard of this. It's an algorithm called neural style transfer. And again, we usually put the, the papers, uh, at the bottom of the slides in case you want to check him yourself for your projects. Uh, but this is a problem where you give the contents image, which is the Golden Gate Bridge and the style image, which is an image that was painted usually by someone or an image from which you want to extract this style. This algorithm is going to generate a new image, is going to mix the contents of the first image with the style of the second image music generation, which is super fun. You're going to generate jazz music in the fifth course sequence models. You going in the same course also generate texts by giving a huge corpus written by Shakespeare a long time ago of poems. You're going to teach the algorithm to, to generate poems as if it was written by Shakespeare. So you can even write the first sentence is going to continue.

Speaker 5:          01:00:11       And what g Phi, you all have smartphones. And I guess your notes is that when you write a sentence on your smartphone, uh, each usually tells you what you should put next. And sometimes it's an Emoji. You going to do this part, you're going to implement the algorithm that takes an input sentence and tells you what's the Emoji that that should come after it. Machine translation is, uh, is one of the application that has been tremendously performing well with deep learning. You're going to implement not to a full machine translation from one language to another, but a similar task that is as exciting, which is uh, changing human readable dates to machine readable dates. So, you know, let's say you're, you're, you're, you're filling in a form and you're typing a date. The, the, the NTT that's, that gathers this data. We'll have a hard time convert all these dates into a specific format.

Speaker 5:          01:01:03       You're going to implement the algorithm that he's going to take all these different data in different formats and generate the right format translated to human from human readable to machine readable data. And finally trigger word detection that I also love. And, and some of you have have seen us build this algorithm, uh, a year ago, I believe, uh, which was which unison and Andrew and I have, I've worked on, um, trigger word detection is a problem of detecting a single word. So, you know, you, you, you probably have, uh, objects from big companies that detect the voice and activate themselves under a trigger word. You're going to build this algorithm for the trigger word activate. Yeah.

Speaker 5:          01:01:47       And many more projects that you will see. Now, these are the things that you will all build in this course. Every one of you will build it through programming assignments, but you also have to choose your own projects to work on throughout the course. And these are example of projects that CSU 30 students have, have built in the past, which have worked very well. One is coloring black and white pictures using a neural network into new color representation of these features. So it's pretty cool because we can now watch a movies that were, that were filmed in the 1930s or 1950s, or I dunno, when, uh, in color, which is super cool. Uh, predicting a price of an object from a picture. So this was a great project in the first iteration of sis to 30, where you give it a bike and the neural network guests is how much is the bike?

Speaker 5:          01:02:39       So if you want to sell stuff, you don't know how much it just give it, then you sell it at the price. Uh, the students had actually implemented an algorithm to see which features of the bike or related to the price. So it was super fun to see if it's the steering wheel or if it's the wheels or if it's the body of the bike that makes this bike expensive according to the algorithm. And many more. So last quarter specifically, we've had a lot of projects in physics and uh, and astrophysics and chemical engineering and mechanics, which was great. Uh, some examples are detecting earthquake procure. So signals with a sequence model predicting the atom energy based on the atomic structure of an atom. So you have, you have for instance, a softwares that run that are really computationally expensive that look at the atomic structure of an atom and we'll output the energy of this item.

Speaker 5:          01:03:35       This takes a long time. These students have tried to make it a three second problem by running on your own network to find the energy of the atom. So you have a bunch of problem across industries. So healthcare, cancer, parking, stone, Alzheimer detection. We've had a lot of these, we've had rain tomorrow. Segmentation. Segmentation is a problem of on an image classifier. Every Pixel tell me which speaks all correspond to the tumor for example. So we were really excited to see what you guys are going to build at the end of this quarter and that's why we want you to build your teams very quickly get started because the project is what you should be proud of at the end of the quarter. We hope that you guys, we've come at the poster session proud of your poster, proud of the final project that you sent us, and you can talk about it in the 10 x years or 20 next years, hopefully.

Speaker 5:          01:04:24       And I guess Andrew Can, can, can come from that. A CSU to nine students from the, the few past years have done projects that are amazing today and have been featured, uh, around the world as a research or, or, or industrial project. So to sum up in this course, you will build a wide range of applications. Uh, it's very applied. There was some math, but less than cs, two to tonight, more than six, two, two, nine, eight. Uh, and you have access to personalized mentorship thanks to the amazing ta team and the instructors. Um, and finally we'll have to build a 10 week long project. So now we get to the serious thing. What is, uh, what we are up to this week. So at the end of every lecture you'll have one slide that's going to remind you what have to do for next week. Uh, next Wednesday, 11:00 AM. So create your course there.

Speaker 5:          01:05:22       I accounts based on the invite that you receive. If you didn't receive any invite, send it as a private post on cards are, we will send it again, finish the two first modules of course one c one m one and c one and two. It corresponds to two quizzes and to programming assignments and around 20 videos. Okay. Which are sit here and for Friday it means two days from now by the end of the day, uh, find project he mates and uh, fill in the form to tell us who are your teammates is going to help us find your mentor. Um, finally there is a ta section also this Friday, no project mentorship. It would start next week. Um, but we, we will see you on Friday. I'm going to take a few questions. Should have about yes, yeah. These days what people said at the end of the stars.

Speaker 5:          01:06:16       So the ta sections, we're going have a large range of ta section on Friday. So there's going to meet basically every time you are going to be assigned to one of them. And if you want to move, you can send an email as a PR, a Pr Zappos privately to ask to be moved to another section. How big is the team? Usually it's from one to three students. Exceptionally. We would accept of four students if the project is challenging enough. Yeah. Yes. So, uh, it is possible to combine the project with other classes in, it's been done in the past. Uh, what we want is you to, to give a project and a poster that that is framed as cs two 31 seat to be frank and you discuss with us in order for us to validate if you can merge this project with another class because it requires to have deep yearning. Of course, you're not supposed to combine this project with something that doesn't have turning it off. Okay. One more question. Can we take quizzes so you can, you can retake the quizzes as much as you want. Then of course, Sarah, uh, we will consider the last submitted quiz for this class. Okay. So you can resubmit if you didn't get full way. Yeah. Okay. Thanks guys and see you on Friday.