WEBVTT

1
00:00:06.510 --> 00:00:11.310
Hello everyone.
Welcome to the second lecture for CST 30.
So as I,

2
00:00:11.311 --> 00:00:13.050
as I said earlier,
uh,

3
00:00:13.051 --> 00:00:18.051
you can go on menti.com from your smartphones or computers and entered these

4
00:00:18.751 --> 00:00:21.210
code 84 57 zero nine.

5
00:00:21.870 --> 00:00:25.980
We will use these tool for interactive questions during the lecture and we will

6
00:00:25.981 --> 00:00:30.900
also use it to track attendance.
Uh,
I,
I did at the end of the lecture,

7
00:00:30.901 --> 00:00:32.640
but uh,
if you have time to do it now

8
00:00:34.260 --> 00:00:37.590
let's start the lecture or you guys are doing that.

9
00:00:40.650 --> 00:00:45.430
Okay.
So today's lecture is going to be about deep yearning,

10
00:00:45.431 --> 00:00:45.870
intuition.

11
00:00:45.870 --> 00:00:50.870
And the goal is to give you a systematic way to think about projects.

12
00:00:51.030 --> 00:00:55.350
Everything related to deep learning.
It includes how to collect your data,

13
00:00:55.560 --> 00:00:58.470
how to label your data,
how to choose an architecture,

14
00:00:58.740 --> 00:01:02.190
but also how to design a proper loss function to optimize.

15
00:01:02.460 --> 00:01:06.030
So all of these decisions are decisions you are going to have to do during your

16
00:01:06.031 --> 00:01:06.810
projects.

17
00:01:06.810 --> 00:01:11.810
And we try to give you here an overview of this systematic way of ticking for

18
00:01:12.091 --> 00:01:17.091
different projects is going to be high level more than other lectures.

19
00:01:17.460 --> 00:01:20.010
But we hope it gives you a good start for your project.

20
00:01:20.400 --> 00:01:25.020
We start with the 10 minutes recap on what you've seen in the two first two in

21
00:01:25.021 --> 00:01:28.920
the first week,
uh,
about neural networks.
So as you know,

22
00:01:28.921 --> 00:01:31.740
you can think of a machine learning,

23
00:01:31.741 --> 00:01:35.730
deep learning in general as modeling a function that takes an input that can be

24
00:01:35.731 --> 00:01:39.300
an image,
a speech and natural language,

25
00:01:39.330 --> 00:01:41.640
or a CSV file.

26
00:01:41.970 --> 00:01:46.970
Give it to a box and get an output that can be classification easy to cats.

27
00:01:48.480 --> 00:01:49.313
Zero.

28
00:01:49.400 --> 00:01:53.790
Is there a cat on the CMH output one or is there no tat on this image?

29
00:01:54.060 --> 00:01:54.893
Outputs zero.

30
00:01:55.740 --> 00:01:59.700
And I think a good way to remember what is a model is to define it as

31
00:01:59.790 --> 00:02:04.790
architecture plus piraters architecture is the design that you choose.

32
00:02:06.210 --> 00:02:08.370
So logistic regression is the first one you've seen.

33
00:02:08.730 --> 00:02:11.280
You will see shallow neural networks,
deep neural networks.

34
00:02:11.281 --> 00:02:14.510
Then you will see convolutional neural networks and retro neural networks.

35
00:02:14.511 --> 00:02:19.080
So these are all types of architectures and you can choose to make them deeper

36
00:02:19.081 --> 00:02:22.680
or shallower parameters or the core parts.

37
00:02:22.740 --> 00:02:26.360
They're the numbers that makes your function.
Take these cats as inputs.

38
00:02:26.430 --> 00:02:29.520
And converted to announce boots.
So these are millions of numbers.

39
00:02:29.670 --> 00:02:33.570
And the goal of machine learning,
deep learning is to find all these numbers.

40
00:02:33.840 --> 00:02:36.840
So we're all trying hard to find numbers.

41
00:02:36.841 --> 00:02:39.000
Basically millions of numbers in matrices.

42
00:02:41.550 --> 00:02:43.850
If you give these cats and you forward propagated.

43
00:02:43.851 --> 00:02:46.110
So we propagated through the model to get an output.

44
00:02:47.220 --> 00:02:51.250
You will have to compare this output to the ground truth.
Uh,

45
00:02:51.450 --> 00:02:53.790
the function used to do so it's called the lost function.

46
00:02:53.880 --> 00:02:57.130
You've seen an example of a loss function this week that is the logistic loss

47
00:02:57.131 --> 00:03:01.810
function.
Uh,
we will see more or less functions,
uh,
later on.
Uh,

48
00:03:01.870 --> 00:03:02.411
computing.

49
00:03:02.411 --> 00:03:05.380
The gradient of these loss function is going to tell you how much should I move

50
00:03:05.381 --> 00:03:10.381
my perimeters in order to update in order in order to make the loss go down.

51
00:03:11.080 --> 00:03:14.590
So in order to make these function,
recognize cats better than before.

52
00:03:15.340 --> 00:03:16.001
You do that many,

53
00:03:16.001 --> 00:03:20.800
many times until you find the right parameters to plug in your architecture,

54
00:03:21.160 --> 00:03:23.770
you can then give your cats and get an output.

55
00:03:24.880 --> 00:03:28.360
What is very interesting and deep learning is that many things can change.

56
00:03:28.570 --> 00:03:32.410
You can change the inputs.
We've talked about natural language,
speech,
structured,

57
00:03:32.411 --> 00:03:35.380
unstructured data in general,
you can change the outputs.

58
00:03:35.860 --> 00:03:39.220
It can be a classification algorithm,
it can be a multi-class algorithm.

59
00:03:39.221 --> 00:03:42.730
I can ask you,
give me the breed of the cat.
Instead of asking you,

60
00:03:42.731 --> 00:03:46.180
give me just the cats,
which makes the problem more complicated.

61
00:03:46.760 --> 00:03:50.890
We can also be a regression problem.
I give you the cat,
I ask you,

62
00:03:50.891 --> 00:03:54.460
give me the age of the cat.
She's much more complicated again.

63
00:03:55.600 --> 00:04:00.370
Does that make sense?
Okay.
Another thing that can change the architecture.

64
00:04:00.400 --> 00:04:03.430
We talked about it earlier and finally the last function.

65
00:04:03.460 --> 00:04:04.990
I think that its function is something that,

66
00:04:04.991 --> 00:04:09.430
that people struggle with to understand what plus function to,
to choose,
uh,

67
00:04:09.490 --> 00:04:13.660
for a specific project.
And we're going to put a huge emphasis on that today.

68
00:04:14.770 --> 00:04:15.603
Okay.

69
00:04:16.420 --> 00:04:20.440
And of course in the architecture you can change the activation functions in

70
00:04:20.441 --> 00:04:21.400
this optimization look,

71
00:04:21.401 --> 00:04:25.990
you can choose a specific optimizers we're going to see in about three weeks,

72
00:04:26.020 --> 00:04:29.380
all the optimizers that can be Adam,
stochastic gradient descent,

73
00:04:29.381 --> 00:04:33.460
batch gradient descent,
rms,
prop and momentum.
And finally,

74
00:04:33.461 --> 00:04:36.220
all the hyper parameters.
What is the learning rate of this loop?

75
00:04:36.250 --> 00:04:38.410
What is the batch that I'm using for my optimization?

76
00:04:38.411 --> 00:04:39.610
We're going to see all that together,

77
00:04:39.611 --> 00:04:42.550
but there's a bunch of things that can change in this scheme.

78
00:04:43.990 --> 00:04:48.910
Any questions on that in general?
So far,

79
00:04:48.911 --> 00:04:50.350
so good.
Okay,

80
00:04:52.270 --> 00:04:55.390
so let's take the first architecture that we've seen together.

81
00:04:55.391 --> 00:04:57.400
Logistic Regression.
As you know,

82
00:04:57.401 --> 00:05:01.930
an image in computer science can be represented by a three d matrix.

83
00:05:02.440 --> 00:05:07.150
Each matrix,
we present a certain color,
RGB,
red,
green,
blue.

84
00:05:07.870 --> 00:05:11.680
We can take all these numbers from these three d metrics and put it in a vector.

85
00:05:11.770 --> 00:05:16.470
We flatten it in order to give it to our logistic regression.
We for propagated,

86
00:05:16.660 --> 00:05:21.160
we multiply it byW ,
which is our parameter and B,
which is our bias.

87
00:05:21.190 --> 00:05:23.050
Give it to a sigmoid function and get an output.

88
00:05:23.380 --> 00:05:25.210
If the network is trained properly,

89
00:05:25.211 --> 00:05:29.380
we should get a number that is more than 0.5 here to tell us that there is a cat

90
00:05:29.500 --> 00:05:33.970
in this summit.
So this is the basic scheme.
Now,

91
00:05:34.600 --> 00:05:38.200
my question for you is if I want to do the same thing,

92
00:05:38.830 --> 00:05:43.030
but uh,
I want to have a classifier that 10 classify several animals.

93
00:05:43.390 --> 00:05:45.260
So on the image there could be a giraffe,

94
00:05:45.280 --> 00:05:47.890
there could be an elephant or there could be a cat.

95
00:05:48.430 --> 00:05:50.770
How would you modify this architecture?

96
00:05:57.030 --> 00:05:57.863
Yes,

97
00:06:04.980 --> 00:06:05.813
<v 2>yes.</v>

98
00:06:05.840 --> 00:06:09.020
<v 0>So that's a good point.
We could add several units.
So several neurons,</v>

99
00:06:09.280 --> 00:06:13.300
one for each animal and we will call it multi logistic regression.

100
00:06:13.750 --> 00:06:18.310
So it could be something like that.
So we have a fully connection here.

101
00:06:18.490 --> 00:06:19.630
Before we were all,

102
00:06:19.690 --> 00:06:23.110
all the inputs were connected to this neuron and now we added two neurons and

103
00:06:23.111 --> 00:06:26.530
each neuron is going to be responsible for one animal.

104
00:06:26.590 --> 00:06:29.380
How do we know which neuron is responsible for which animal?

105
00:06:33.170 --> 00:06:35.870
Is the network going to figure it out on its own or do we have

106
00:06:35.870 --> 00:06:36.703
<v 1>to help it?</v>

107
00:06:43.630 --> 00:06:44.463
<v 2>Exactly.</v>

108
00:06:44.950 --> 00:06:48.790
<v 0>The label is important.
So what is going to tell your model?</v>

109
00:06:48.940 --> 00:06:51.700
This neuron should focus on cat dispersions,
refocused on elephant.

110
00:06:51.710 --> 00:06:54.730
Decent flips on Giraffe is the way you label your data.

111
00:06:55.300 --> 00:06:59.530
So how should we label these data?
Now if we were to do this specific task.

112
00:07:06.810 --> 00:07:08.260
<v 1>Any ideas?
Yeah.</v>

113
00:07:11.850 --> 00:07:12.683
<v 2>Okay.
So one HUD</v>

114
00:07:12.840 --> 00:07:17.400
<v 0>term means a vector with all Zeros and one one.
Any other ideas?</v>

115
00:07:19.040 --> 00:07:19.873
Hmm,

116
00:07:21.330 --> 00:07:23.610
<v 2>one,
two,
three.
So I assume you,</v>

117
00:07:23.611 --> 00:07:27.210
you say that each integer we correspond to a circle anymore.
Okay.

118
00:07:27.211 --> 00:07:28.110
Any other ideas?

119
00:07:35.640 --> 00:07:36.473
<v 0>Hmm,</v>

120
00:07:36.510 --> 00:07:38.210
<v 2>no loss of function.
What do you find?</v>

121
00:07:38.211 --> 00:07:41.270
The last hundred you want to put more weight on one animal.

122
00:07:41.570 --> 00:07:44.000
So you modified the loss function or what?
Exactly.

123
00:07:46.070 --> 00:07:50.570
It was more,
like
I said,
we didn't want her to come into it.

124
00:07:50.740 --> 00:07:51.573
So quick one,

125
00:07:52.000 --> 00:07:54.960
<v 0>Hudson coding.
I think there's a downside to do one hot encoding.</v>

126
00:07:54.990 --> 00:07:56.860
What is the downside of the one cuts and Courtney?

127
00:08:04.910 --> 00:08:09.100
<v 2>Yeah.
So you're saying that the data,
we have a lot of animals,
the detox,</v>

128
00:08:09.140 --> 00:08:12.200
the labels,
all new content.
Zero in one.
One.
So there's a huge imbalance.

129
00:08:12.940 --> 00:08:13.530
I don't think that's

130
00:08:13.530 --> 00:08:16.970
<v 0>it's,
you should because these neurons are independent from each other right now.</v>

131
00:08:17.420 --> 00:08:18.860
So yeah,

132
00:08:18.861 --> 00:08:22.610
it could run into an issue of a really a lot of animals this,

133
00:08:23.030 --> 00:08:26.420
but there is another problem with it.
The problem is that,

134
00:08:26.660 --> 00:08:30.770
do you think if you want,
if you won hearts and codes,
uh,
your labels,

135
00:08:31.070 --> 00:08:33.500
you would be able to detect an image with us,

136
00:08:33.501 --> 00:08:37.490
giraffe and an elephant on the image,
you will not be able to do so.

137
00:08:38.390 --> 00:08:41.450
You need the multi huts and coding.
So in this case,

138
00:08:41.480 --> 00:08:43.700
if there is a cat on the image,
I will use a one hot,

139
00:08:43.760 --> 00:08:46.460
I would say zero one zero as my label.

140
00:08:46.730 --> 00:08:50.450
But if I have a dog and a cat on the image,
I would say one one zero.

141
00:08:51.440 --> 00:08:51.870
<v 1>Okay?</v>

142
00:08:51.870 --> 00:08:52.500
<v 0>Okay.</v>

143
00:08:52.500 --> 00:08:56.550
The one hot encoding works very well when you have the constraint of having only

144
00:08:56.551 --> 00:08:57.930
one animal per image.

145
00:08:58.560 --> 00:09:01.830
And in this case you would not use an activation function called sigmoid.

146
00:09:01.860 --> 00:09:04.080
You would use another one,
which is

147
00:09:06.710 --> 00:09:10.290
soft Max.
The softmax function we're going to see together.

148
00:09:10.291 --> 00:09:13.950
And for those of you tonight,
you probably heard of it.
Okay?

149
00:09:14.250 --> 00:09:17.520
So what I wanted to explain here is the way you choose your labeling is very

150
00:09:17.521 --> 00:09:21.600
important and it's a decision you should make prior to start the project.

151
00:09:22.710 --> 00:09:25.040
Okay?
In terms of notation in the,

152
00:09:25.050 --> 00:09:29.520
in this class we're going to use the following a square brackets one with the

153
00:09:29.521 --> 00:09:33.030
note all the activations of the first layer.
So the square brackets would,

154
00:09:33.060 --> 00:09:38.060
would they know the layer and the lower squeak we they know the index of the

155
00:09:38.550 --> 00:09:40.260
neuron in delay.
Okay.

156
00:09:40.410 --> 00:09:43.620
And of course you can stack these neurone on top of each other to make the

157
00:09:44.040 --> 00:09:48.840
network more complex depending on the task you're solving.
Okay.

158
00:09:50.580 --> 00:09:55.140
Now the concept I wanted to introduce in this recap was the concept of encoding.

159
00:09:55.700 --> 00:09:59.850
Um,
you probably,
some of you have probably seen this image before.

160
00:10:00.480 --> 00:10:05.390
If you have a network that is not too shallow,
you would not,

161
00:10:05.400 --> 00:10:07.290
is that what the first year owns?

162
00:10:07.380 --> 00:10:10.590
See are very um,

163
00:10:10.800 --> 00:10:12.420
precise representation of the data.

164
00:10:12.421 --> 00:10:15.930
So there are pixel level representation of the data x three.

165
00:10:15.931 --> 00:10:19.860
I is probably one of the three channels of the treaty Matrix.

166
00:10:20.070 --> 00:10:20.970
Just one number.

167
00:10:21.390 --> 00:10:25.650
So what these neurons sees is going to be a pixel level representation of the

168
00:10:25.651 --> 00:10:30.570
image.
Okay.
What these neurons is the second layer,

169
00:10:30.630 --> 00:10:33.690
the one in the hidden layer is going to see the representation output.

170
00:10:33.720 --> 00:10:37.710
It by all the neurons in the first layer.
These are going to be more high level,

171
00:10:37.711 --> 00:10:40.590
more complex because the first year owns,
we'll see pixels.

172
00:10:40.591 --> 00:10:43.140
They're going to outputs a little more detailed information.

173
00:10:43.141 --> 00:10:45.990
Like I found an edge here,
I found an edge there.
And so on.

174
00:10:46.170 --> 00:10:47.340
Give it to the second layer.

175
00:10:47.580 --> 00:10:50.760
The secretary is going to see more complex inflammation is going to give it to

176
00:10:50.761 --> 00:10:51.594
the third layer,

177
00:10:51.630 --> 00:10:56.040
which is going to assemble some high level complex features.

178
00:10:56.520 --> 00:11:00.630
That could be eyes,
nose,
mouth,
depending on what network you've been training.

179
00:11:01.230 --> 00:11:05.740
So this is an extraction of what's happening in each layer,
uh,

180
00:11:05.750 --> 00:11:09.570
when the network was trained on a face recognition.
Yes.

181
00:11:16.650 --> 00:11:20.670
Yeah.
So I see you are fully connected network,
but that's true.

182
00:11:20.970 --> 00:11:25.910
These type of visuals are more a observed in convolutional neural networks

183
00:11:25.920 --> 00:11:29.970
because these are filters.
But this happens also in this type of network.

184
00:11:30.000 --> 00:11:33.750
It's just harder to visualize.
Okay.

185
00:11:33.751 --> 00:11:35.760
So this is what we call an encoding.

186
00:11:36.210 --> 00:11:40.920
It means if I extract the information from this layer,

187
00:11:41.130 --> 00:11:45.030
so all the numbers that are coming out of these edges,
I extract them.

188
00:11:45.150 --> 00:11:48.960
I will have a complex representation of my input data.

189
00:11:49.320 --> 00:11:52.080
If I extract the numbers that are at the end of the first layer,

190
00:11:52.140 --> 00:11:57.130
I will have a lower representation of my data.
That might be edges.
Okay.

191
00:11:57.310 --> 00:11:59.950
We're going to use these including a two,
five this lecture.

192
00:12:00.760 --> 00:12:01.780
Any questions on that?

193
00:12:06.010 --> 00:12:09.730
Okay,
so let's build intuition on concrete applications.

194
00:12:10.060 --> 00:12:11.510
We're going to start,
uh,
we,

195
00:12:11.511 --> 00:12:14.830
the short warm up we the day and night classification and then quickly moved to

196
00:12:14.831 --> 00:12:16.780
face verification and face recognition.

197
00:12:17.350 --> 00:12:20.920
And after that we'll do some art generation and finished with a trigger word

198
00:12:20.921 --> 00:12:25.000
detection.
If we have time,
we will talk about how to ship a model,

199
00:12:25.480 --> 00:12:30.240
which is shipping architecture plus parameters.
Okay.
We didn't,
I'm,

200
00:12:30.310 --> 00:12:30.500
he's,

201
00:12:30.500 --> 00:12:34.090
as I said on the architecture of the lost the training strategy to help you make

202
00:12:34.091 --> 00:12:38.110
decisions during your project.
So let's start with the first game.
Uh,

203
00:12:38.180 --> 00:12:43.180
were given an image and we have to build a network that tells us if the image is

204
00:12:44.140 --> 00:12:49.140
taken during the day labeled zero or was taken at night label one.

205
00:12:53.470 --> 00:12:56.800
So first question is what data said do we need to collect,

206
00:13:06.300 --> 00:13:10.180
<v 2>look at the images captured during the day and during the nights?</v>

207
00:13:11.380 --> 00:13:15.430
I agree.
So probably,
oh yeah.
Then he asked the question how many images

208
00:13:17.230 --> 00:13:18.063
that was wrong,

209
00:13:20.030 --> 00:13:23.210
<v 0>how many images?
Like how do you get this number?</v>

210
00:13:27.190 --> 00:13:30.460
<v 2>Can someone give me an estimate of how many images you need in order to solve</v>

211
00:13:30.461 --> 00:13:35.450
this problem and explain how you get
around those.

212
00:13:39.190 --> 00:13:42.340
So you're saying a number of similar to a number of parameters you have in the

213
00:13:42.341 --> 00:13:46.650
network.
So I think it's better to think of it the other way around the network

214
00:13:46.950 --> 00:13:50.100
<v 0>after.
So right now you don't know what network you will use.</v>

215
00:13:50.370 --> 00:13:54.750
So you cannot decide the number of data points based on your parameters later on

216
00:13:55.020 --> 00:13:57.180
based on how your network is flexible.

217
00:13:57.181 --> 00:14:00.540
You can add more data and that's where I'll be what,
two minutes.

218
00:14:00.930 --> 00:14:03.660
But at first you want to get,
you want to get to number?
Yeah,

219
00:14:05.050 --> 00:14:10.030
<v 2>just the pixels within an image,
more images than big soles within an image.</v>

220
00:14:10.670 --> 00:14:12.210
Uh,
I,

221
00:14:12.690 --> 00:14:15.880
I don't think that that's that that has anything to do with the pixels.

222
00:14:16.130 --> 00:14:17.470
You can have a very simple task.

223
00:14:17.471 --> 00:14:21.310
Like you have only images that are red and green and you want to classify

224
00:14:21.350 --> 00:14:24.670
reading green.
Doing Mitch can be giant.
You can have a lot of it.

225
00:14:24.710 --> 00:14:26.790
<v 0>Pixels isn't going to change the number of data points in it.</v>

226
00:14:32.490 --> 00:14:35.130
<v 2>Okay.
So you're talking about computation resource sources.</v>

227
00:14:35.220 --> 00:14:39.490
<v 0>So the more images we have,
probably the more computation resources we will need.</v>

228
00:14:39.540 --> 00:14:43.180
So to me,
yeah,
there's something like that.
I think in general,
uh,

229
00:14:43.350 --> 00:14:46.050
you want to try to engage the complexity of the task.

230
00:14:46.860 --> 00:14:50.880
So let's say we did a problem that was Catterick on mission detective.

231
00:14:50.881 --> 00:14:53.840
There was a cut on any major nuts in this problem.

232
00:14:53.841 --> 00:14:56.330
We remember that we 10,000 images,

233
00:14:56.660 --> 00:14:59.540
we managed to train a pretty good classifier.

234
00:15:00.110 --> 00:15:03.020
How do you compare this problem to the cats problem?

235
00:15:03.860 --> 00:15:08.760
You think it's easier or harder?
Easier.
Yeah,
I agree.

236
00:15:08.761 --> 00:15:11.730
That's probably easier.
So in terms of complexity,

237
00:15:11.731 --> 00:15:15.480
these tasks looks less complex than the Catholic commission task.

238
00:15:15.930 --> 00:15:18.780
So you would probably need less data.
That's a rule of thumb.

239
00:15:19.950 --> 00:15:23.910
The second rule of thumb and why I get to this image is what do we exactly want

240
00:15:23.911 --> 00:15:27.210
to do?
Do we want to classify pictures that were taken outside,

241
00:15:27.780 --> 00:15:29.250
which seems even easier?

242
00:15:29.490 --> 00:15:33.000
Or do we want also the network to classify complicated pictures?

243
00:15:33.090 --> 00:15:34.920
What do I mean by complicated pictures?

244
00:15:36.890 --> 00:15:37.723
<v 1>Yeah,</v>

245
00:15:39.790 --> 00:15:40.660
<v 0>inside your house.</v>

246
00:15:41.080 --> 00:15:44.830
So like let's say on a picture you have a window on the right side of the human

247
00:15:44.831 --> 00:15:47.530
will be able to say it's the day because they see the window,

248
00:15:48.010 --> 00:15:51.580
but for the network he's got to take a much longer to learn that much longer

249
00:15:51.581 --> 00:15:56.140
than four pictures taken upside.
What else?
What are other complicated?
Dawn?

250
00:15:58.930 --> 00:16:01.210
Dawn,
twilight.
Sunrise.
Sunset in general.

251
00:16:01.510 --> 00:16:04.860
It's complicated because you have to define it and you have to teach your

252
00:16:04.870 --> 00:16:08.590
network.
What does that mean?
Is it night or day?
Okay,

253
00:16:08.680 --> 00:16:11.590
so depending on what tasks you want to solve,

254
00:16:11.980 --> 00:16:15.460
it's going to tell you is you need more data or less data.
I think for this task,

255
00:16:15.461 --> 00:16:19.060
if you take outside teachers,
10,000 images is going to be enough,

256
00:16:19.810 --> 00:16:22.870
but if you want the network to detect indoor as well,

257
00:16:22.900 --> 00:16:27.490
you probably need 100,000 images or something and this is based on comparing

258
00:16:27.491 --> 00:16:30.190
with projects you did in the past so he's going to come with experience.

259
00:16:31.750 --> 00:16:35.530
Now as you know when you have a later set you need to split it between train

260
00:16:35.650 --> 00:16:37.060
validation and test sets.

261
00:16:37.240 --> 00:16:39.910
Some of you I've heard that we're going to see together even more.

262
00:16:40.360 --> 00:16:43.720
You need to train your network on a specific sets and test it on another one.

263
00:16:44.230 --> 00:16:46.720
How do you think you should split these 10,000 images?

264
00:16:51.310 --> 00:16:53.020
50 50 between training tests,

265
00:16:54.740 --> 00:16:59.740
80 20 I think we would go towards 80 20 because the test sets is made for an

266
00:17:01.881 --> 00:17:05.690
Eliza to analyze if your network is doing well on real world data or not.

267
00:17:06.050 --> 00:17:09.510
I think 2000 images is enough to get that sense probably.

268
00:17:09.800 --> 00:17:13.130
And you want to put complicated examples in this data set as well.

269
00:17:13.430 --> 00:17:16.380
So I would go towards 80 20 and the bigger the data set,

270
00:17:16.400 --> 00:17:19.760
the more I would put in the train set.
So if I have 1 million images,

271
00:17:20.060 --> 00:17:25.040
I would put even more like 98% maybe in the train set and 2% to test my model.

272
00:17:26.030 --> 00:17:29.960
Okay.
Now I wrote bias here.
What do I mean by bias?

273
00:17:34.970 --> 00:17:36.920
Yes,
you need to correct balance between classes.

274
00:17:36.921 --> 00:17:41.840
You don't want to give 9,000 dark images in 1000 day images.

275
00:17:41.841 --> 00:17:45.470
You want to balance between these two two teacher networks to recognize both

276
00:17:45.471 --> 00:17:49.740
classes.
Okay.
What should be the input?
Your network?

277
00:17:58.060 --> 00:17:58.510
<v 1>Yeah,</v>

278
00:17:58.510 --> 00:18:02.050
<v 0>so this is an example of a pixel image.
It's the Louvre Museum during the day.</v>

279
00:18:04.420 --> 00:18:09.370
Harder question,
what should be the resolution of this image and why do we care?

280
00:18:14.130 --> 00:18:14.963
Yeah,

281
00:18:20.340 --> 00:18:21.173
<v 1>that's great</v>

282
00:18:22.720 --> 00:18:27.720
<v 0>for a civilian students as well as low as you can in order to achieve good</v>

283
00:18:28.001 --> 00:18:28.834
results.

284
00:18:28.990 --> 00:18:32.560
Why do we want low resolution is because in terms of computation is going to be

285
00:18:32.561 --> 00:18:37.120
better.
You remember if I have a 32 by 32 image,

286
00:18:37.180 --> 00:18:41.830
how many pixels there are?
If it's color,
I have 32 times 32 times three.

287
00:18:42.760 --> 00:18:47.170
If I have 400 by 400 I have 400 by 400 by three it's a lot more.

288
00:18:47.830 --> 00:18:51.580
So I want to minimize the resolution in order to still be able to achieve good

289
00:18:51.581 --> 00:18:56.290
performance.
So what does it mean to still achieve good performance?

290
00:18:57.130 --> 00:18:58.150
How do I get this number?

291
00:19:06.640 --> 00:19:10.330
<v 2>Okay.
Similar resolution as you expect the algorithm in real life to work on.</v>

292
00:19:10.720 --> 00:19:11.553
Yeah,
probably.

293
00:19:11.800 --> 00:19:12.760
<v 0>I agree.
What else?</v>

294
00:19:13.390 --> 00:19:16.360
What other rule of thumb you use in order to choose this resolution?

295
00:19:23.720 --> 00:19:26.870
<v 2>Great idea.
Compared to human performance.
So what they do,</v>

296
00:19:26.871 --> 00:19:29.270
so there's one way to do it,
which is the brute force way.

297
00:19:29.271 --> 00:19:33.400
I would say we will train models on different resolutions and then compare their

298
00:19:33.401 --> 00:19:37.700
results.
Or you can be smart and use human performance as a comparison.

299
00:19:38.240 --> 00:19:42.530
So I would print this image or several images like this in different resolutions

300
00:19:42.560 --> 00:19:46.220
on paper and that would go see humans and say classify those,

301
00:19:46.280 --> 00:19:47.630
classify those and classify those.

302
00:19:47.690 --> 00:19:50.930
<v 0>And I would compare a human performance on all these three types of resolution</v>

303
00:19:51.800 --> 00:19:56.030
in order to decide what's the minimum resolution that I can use in order to get

304
00:19:56.031 --> 00:19:59.330
perfect human performance.
So by doing that,

305
00:20:01.040 --> 00:20:06.040
I got that 64 by 64 by three was enough resolution for a human to detect if an

306
00:20:06.801 --> 00:20:08.690
image is taken during the day or during the night.

307
00:20:09.200 --> 00:20:13.460
And this is a pretty small resolution imaging,
but it seems like a small,

308
00:20:13.490 --> 00:20:17.810
like an easy task.
If you have to find a breed of a chats,

309
00:20:18.110 --> 00:20:23.110
you probably need more because some cats are very look very alike and you need a

310
00:20:23.481 --> 00:20:26.480
high resolution to distinguish them.
And maybe training for the human as well.

311
00:20:27.950 --> 00:20:32.360
I normally three breeds of cats so I wouldn't be able to do it anyway.
Um,

312
00:20:32.720 --> 00:20:34.280
what should be the output of the model

313
00:20:38.170 --> 00:20:42.330
labels?
The y equals zero four day.
Why he called one four nights.
I agree.

314
00:20:42.660 --> 00:20:44.700
What should be the last activation of the network?

315
00:20:45.830 --> 00:20:46.640
<v 1>Okay.</v>

316
00:20:46.640 --> 00:20:47.473
<v 0>The last</v>

317
00:20:48.460 --> 00:20:49.850
<v 1>sigmoid,
we saw that Seymour,</v>

318
00:20:49.890 --> 00:20:52.290
it takes a number between plus and minus in Fijian bloods.

319
00:20:52.291 --> 00:20:55.990
50 puts it between zero and one.
So that we can interpret it as a problem.

320
00:20:57.430 --> 00:20:58.870
What architecture would you use?

321
00:21:03.470 --> 00:21:04.303
Yeah,

322
00:21:06.150 --> 00:21:07.570
<v 0>fully connected or convolutional.</v>

323
00:21:07.600 --> 00:21:11.020
I think later this quarter you will see that convolutional to perform well in

324
00:21:11.021 --> 00:21:13.030
imaging,
so we would directly use a convolutional,

325
00:21:13.180 --> 00:21:14.620
when I think of shallow network,

326
00:21:14.890 --> 00:21:17.140
fully connected to a convolution of would do the job pretty well.

327
00:21:17.170 --> 00:21:22.170
You don't need a deep network because you gauge the complexity of this task and

328
00:21:22.331 --> 00:21:23.920
what should be the loss function finally.

329
00:21:32.530 --> 00:21:33.363
Yeah.

330
00:21:37.190 --> 00:21:42.050
<v 2>Yeah.
It's also called the logistic loss.
That's the one you're talking about.</v>

331
00:21:42.950 --> 00:21:46.590
The way you get this number and you'd prove it in in cs two to nine we're,

332
00:21:46.591 --> 00:21:47.810
we're not doing it to prove it here,

333
00:21:48.110 --> 00:21:51.680
but basically you interpret your data in a probabilistic way

334
00:21:52.070 --> 00:21:56.030
<v 0>and you take the maximum likelihood estimation of the data,</v>

335
00:21:56.060 --> 00:21:58.900
which gives you this formula.
For those of you who did the math behind it,

336
00:21:59.300 --> 00:22:00.440
you can ask any office hours,

337
00:22:00.441 --> 00:22:04.280
teas are going to help you understand it more properly.
Okay,

338
00:22:04.340 --> 00:22:06.890
and of course this means that if y equals zero,

339
00:22:06.891 --> 00:22:10.100
we want why had the prediction to be close to zero,
if why you called one.

340
00:22:10.101 --> 00:22:13.580
We want white hide the prediction to be close to one.
Okay,

341
00:22:13.581 --> 00:22:17.900
so this was the warmer,
now we're going to delve into face verification.

342
00:22:18.190 --> 00:22:21.420
Any question on day night classification?
Yes,

343
00:22:39.830 --> 00:22:40.663
<v 1>that's the,</v>

344
00:22:48.970 --> 00:22:49.640
<v 0>so you're,</v>

345
00:22:49.640 --> 00:22:53.200
the question is about how you choose the size of the test set versus the train

346
00:22:53.201 --> 00:22:54.034
sets.

347
00:22:54.160 --> 00:22:59.050
In general you would first say how many images do I need or data points in order

348
00:22:59.051 --> 00:23:02.680
to gable to understand what my model do in the real world.

349
00:23:03.310 --> 00:23:06.390
These can depend on the task.
Like if I talk about,
if I,

350
00:23:06.400 --> 00:23:07.960
if I tell you about speech recognition,

351
00:23:08.410 --> 00:23:12.340
you want to figure out if your model is doing well for all accents in the world.

352
00:23:12.850 --> 00:23:15.550
So your test set might be very big and very distributed.

353
00:23:16.090 --> 00:23:20.080
In this case you might have a few examples that are doing the day few during the

354
00:23:20.081 --> 00:23:22.210
nights and a few,
I don't a sunset,

355
00:23:22.211 --> 00:23:25.300
sunrise and also indoor two of those is going to give you a number.

356
00:23:25.810 --> 00:23:30.160
So there was no good number.
There is like you have to gauge it.
Okay.

357
00:23:30.190 --> 00:23:31.023
One more question.

358
00:23:34.530 --> 00:23:37.980
<v 2>Yeah,
that's a good question.
So how do you choose the loss function?</v>

359
00:23:38.070 --> 00:23:38.990
We're going to see,

360
00:23:39.570 --> 00:23:43.060
<v 0>uh,
uh,
in the next slides how to choose loss functions.</v>

361
00:23:43.270 --> 00:23:47.090
But for these ones specifically,
you chose this one because it's,
it's,
it's a,

362
00:23:47.100 --> 00:23:49.610
it's a convex function for classification of plot problem,

363
00:23:50.090 --> 00:23:53.630
it's easier to optimize then other loss functions.
So there is approved but,

364
00:23:53.660 --> 00:23:55.670
but I will not go over it here.

365
00:23:57.290 --> 00:24:00.110
If you know the l one loss that copper's why too.

366
00:24:00.111 --> 00:24:03.500
I had this one is harder to optimize for a classification problem,

367
00:24:03.530 --> 00:24:07.340
we would use it for regression problems.
Okay.

368
00:24:07.790 --> 00:24:09.350
So our new game is,
uh,

369
00:24:09.720 --> 00:24:14.720
the school wants to use face verification to validate student Ids in facilities

370
00:24:15.530 --> 00:24:20.450
like the gym.
So they know when you entered the gym you swiped your Id and then,

371
00:24:20.650 --> 00:24:20.840
uh,

372
00:24:20.840 --> 00:24:25.220
I guess the person sees your face on the screen based on these ID and looks at

373
00:24:25.221 --> 00:24:28.050
your face in real and compares.
It's like,

374
00:24:28.790 --> 00:24:33.790
so now we want to put the camera and have you swiped and the camera is going to

375
00:24:34.281 --> 00:24:36.770
compare this image to the imaging,
the database.

376
00:24:37.400 --> 00:24:42.020
Does that make sense to let you in or not?
So what's what data said,

377
00:24:42.021 --> 00:24:45.020
do we need to solve this problem?
What should we collect?

378
00:24:52.360 --> 00:24:53.193
<v 1>Okay.</v>

379
00:24:53.370 --> 00:24:57.320
<v 0>Making between the ID and the image.
Yeah,</v>

380
00:24:57.650 --> 00:25:01.430
so probably schools have databases because when you enter the school,

381
00:25:01.431 --> 00:25:05.300
you submit your image and your,
sorry,
given a card,
an ID.

382
00:25:05.450 --> 00:25:08.540
So you'll have this mapping.
Okay.
What else do we need?

383
00:25:08.690 --> 00:25:11.810
So pictures of every student labeled with their names.
That's what you said.

384
00:25:12.140 --> 00:25:17.000
So this is a picture of where car is a picture when he was younger and that's

385
00:25:17.001 --> 00:25:18.860
the one he gave to the school when he arrived.

386
00:25:21.540 --> 00:25:23.280
What should be the input of our model?

387
00:25:26.940 --> 00:25:27.810
Is it this picture?

388
00:25:29.880 --> 00:25:30.713
<v 1>Hmm.</v>

389
00:25:31.610 --> 00:25:34.910
<v 0>More photos of him.
I'm asking just like the output of the model.</v>

390
00:25:35.640 --> 00:25:38.560
Like we probably need more photos of him as well.
But what's,

391
00:25:38.590 --> 00:25:40.550
what's going to be the image we give to the model?

392
00:25:44.260 --> 00:25:47.950
Exactly.
The person standing in front of the camera when entering the gym.

393
00:25:48.160 --> 00:25:52.570
So this is the entrance of the gym and a veterans trying to enter the gym.

394
00:25:53.690 --> 00:25:56.680
So it's him.
Okay.
What should be the resolution?

395
00:25:59.520 --> 00:26:01.310
Those of you who have done projects in imaging,

396
00:26:01.320 --> 00:26:02.670
what'd you think should be the resolution?

397
00:26:10.080 --> 00:26:14.130
Two 56 by two 56 and the other idea for precise?

398
00:26:14.230 --> 00:26:15.063
<v 1>Yeah,</v>

399
00:26:16.110 --> 00:26:20.760
<v 0>I think in general you will go over 400.
The 400 by 400.</v>

400
00:26:20.761 --> 00:26:21.594
What's the reason?

401
00:26:23.930 --> 00:26:28.760
Why do we need 64 four for the night and 404 phase verification?

402
00:26:31.970 --> 00:26:34.750
Yeah.
Yeah.
There's more details to the tech.

403
00:26:34.751 --> 00:26:39.280
So like distance between the eyes probably size of the nose,

404
00:26:39.281 --> 00:26:44.100
mouth,
uh,
general,
general features of the,
these are harder to

405
00:26:44.100 --> 00:26:47.520
<v 2>detect for 64 by 60,
40 minutes and you can test it.</v>

406
00:26:47.521 --> 00:26:51.990
You can go outside and show two pictures of people that look like each other and

407
00:26:51.991 --> 00:26:54.140
ask people can you differentiate those two person or not?

408
00:26:54.720 --> 00:26:58.470
And you'll see that with less than that,
sometimes it's people are struggling.

409
00:27:00.880 --> 00:27:02.580
Is color important?
That's a good question.

410
00:27:02.581 --> 00:27:04.680
We should have talked about it in day and night.
Actually.

411
00:27:04.681 --> 00:27:06.820
Is color important because if you remove the

412
00:27:06.880 --> 00:27:10.600
<v 0>color,
you basically divide by three the number of Pixels,
right?</v>

413
00:27:11.200 --> 00:27:14.950
So if we could do it without color,
we would do it without color.
In this case,

414
00:27:14.951 --> 00:27:17.480
color is going to be important because,
uh,

415
00:27:17.560 --> 00:27:22.260
probably you want your camera to work in different settings a day,

416
00:27:22.270 --> 00:27:24.760
night as well.
So the luminosity is different,

417
00:27:24.790 --> 00:27:28.870
the brightness and also we all have different colors and we need to all be

418
00:27:28.871 --> 00:27:32.770
detected compared teacher.
Yeah,
I might go summer in,

419
00:27:32.771 --> 00:27:36.920
in an island and come back,
uh,
you know,
full of color but uh,

420
00:27:37.030 --> 00:27:41.860
but I see on to be able to access the gym,
uh,
outputs.

421
00:27:42.400 --> 00:27:43.330
What should be the output?

422
00:27:52.250 --> 00:27:55.250
I think if you have unlimited computational power,

423
00:27:55.251 --> 00:27:56.540
you would take more resolution.

424
00:27:56.810 --> 00:27:59.180
But that's a trade off between computation and results.

425
00:28:00.800 --> 00:28:05.660
So output is going to be one if it's you and zero if it's not you,

426
00:28:05.661 --> 00:28:09.260
in which case they would not let you in.
Okay?

427
00:28:09.620 --> 00:28:14.360
Now the question is what architecture should we use to solve this problem?

428
00:28:14.361 --> 00:28:19.361
Now that we collected the data set of mapping between student ideas and images,

429
00:28:21.190 --> 00:28:23.560
<v 3>how do you know how many images?</v>

430
00:28:27.420 --> 00:28:28.253
<v 2>The question is,</v>

431
00:28:30.550 --> 00:28:34.060
how do you know how many images we need to train the network?
You don't know.

432
00:28:34.510 --> 00:28:37.870
<v 0>You can find an estimate.
It's going to depend on your architecture,</v>

433
00:28:38.140 --> 00:28:41.320
but in general,
the more complex the task,
the more data you would need.

434
00:28:41.710 --> 00:28:45.190
And we will see something called error analysis in about four weeks,

435
00:28:45.460 --> 00:28:49.540
which is once your network works,
you're going to give it a lot of examples.

436
00:28:49.960 --> 00:28:54.190
Detect which examples are misclassified by your network and you're going to add

437
00:28:54.191 --> 00:28:59.090
more of these in the training set.
So you're going to boost your dataset.
Okay.

438
00:28:59.460 --> 00:29:00.580
Talk to you about the architecture.

439
00:29:00.670 --> 00:29:03.790
If I ask you what's the easiest way to compare two images,

440
00:29:04.860 --> 00:29:09.280
what would you like these three images,
the database image and the input image,

441
00:29:11.060 --> 00:29:13.690
<v 2>sort of Hash Hash.
What do you mean?</v>

442
00:29:15.460 --> 00:29:20.430
Put runs,
standardized function on it and then they're okay taking him.

443
00:29:21.000 --> 00:29:23.970
Take this,
run it into a specific function,
take this,

444
00:29:23.971 --> 00:29:27.270
run it into a specific function and compared the two largest that's correct.

445
00:29:27.750 --> 00:29:28.583
That's a good idea.

446
00:29:28.860 --> 00:29:32.550
And the more basic one is just computer distance between the pixels.

447
00:29:33.150 --> 00:29:36.150
Just compute the distance between the pixels and you get if it's the same person

448
00:29:36.151 --> 00:29:39.600
or not.
And unfortunately it doesn't work and a few reasons are the background.

449
00:29:39.601 --> 00:29:42.310
Lighting can be different.
And so if I do this,

450
00:29:42.310 --> 00:29:44.230
<v 0>mine is this,
this pixel,</v>

451
00:29:44.231 --> 00:29:48.460
which is let's say dark is going to have a value of zero.
This pixel,

452
00:29:48.461 --> 00:29:52.990
which is why it is going to have a value of two 55.
The distance is gigantic,

453
00:29:53.080 --> 00:29:57.700
but it's still the same person.
He's a problem per can wear makeup.

454
00:29:57.830 --> 00:30:01.420
I can grow a beard,
can be younger on a picture,
the ID can be outdated.

455
00:30:01.750 --> 00:30:04.510
So it doesn't work.
To just compare these two pictures together,

456
00:30:04.750 --> 00:30:09.340
we need to find a function that we will apply this,
this,
these two images too,

457
00:30:09.370 --> 00:30:13.900
and will give us a more,
a better representation of the image.

458
00:30:15.430 --> 00:30:16.480
So that's what we're going to do.

459
00:30:16.481 --> 00:30:20.110
Now what we're going to do is that will encode information,

460
00:30:20.140 --> 00:30:24.190
use the encoding that we talked about of the picture in the vector.

461
00:30:24.580 --> 00:30:29.200
So we want a vector that would represent teachers like distance between eyes,

462
00:30:29.201 --> 00:30:33.860
nose,
mouth,
color,
or all these type of stuff,
hair,
uh,

463
00:30:34.090 --> 00:30:38.020
in a vector.
So this is a picture of [inaudible] home from the ID.

464
00:30:38.050 --> 00:30:42.310
We would run it to a network and we hopefully can find the good encoding of this

465
00:30:42.311 --> 00:30:46.750
network.
Then we will run the picture of Beth Hall at the facility,

466
00:30:46.930 --> 00:30:49.840
run it in the deep network,
get another vector,

467
00:30:50.200 --> 00:30:52.840
and hopefully if we train the network properly,

468
00:30:53.050 --> 00:30:54.700
these two vectors should be close to each other.

469
00:30:55.930 --> 00:31:00.930
Let's say we have a threshold that is 0.5 0.4 is the distance between these two.

470
00:31:01.300 --> 00:31:04.900
It's less than the threshold.
So I would say [inaudible] is the right person.

471
00:31:05.530 --> 00:31:08.530
It's you.
Does this scheme exchange may make sense.

472
00:31:12.670 --> 00:31:15.670
What does the one 28 minutes?
So the question is,

473
00:31:16.000 --> 00:31:18.850
can I say that the third entry corresponds to something specific?

474
00:31:19.390 --> 00:31:20.530
It's complicated to say,

475
00:31:20.830 --> 00:31:25.000
but depending on what networks you choose and the training process you choose,

476
00:31:25.030 --> 00:31:27.670
it will use your different network,
a different vector.

477
00:31:28.000 --> 00:31:29.230
So that's what we're going to talk about.

478
00:31:29.231 --> 00:31:33.970
Now the question is how do I know that these vector is good?
Like right now,

479
00:31:34.000 --> 00:31:35.560
if I take a random network,

480
00:31:35.770 --> 00:31:38.230
I give my image to it is going to output around the vector.

481
00:31:38.590 --> 00:31:41.080
This vector is not going to contain any useful information.

482
00:31:41.500 --> 00:31:46.150
I want to make sure that this information is useful and that's how I will design

483
00:31:46.151 --> 00:31:50.320
my loss function.
Okay,
so just to recap,

484
00:31:50.321 --> 00:31:53.140
we gather all student faces and coding in a database.

485
00:31:53.380 --> 00:31:57.550
Once we have this and given a new picture,
we come to the distance between,

486
00:31:57.820 --> 00:32:01.750
between the new picture and all the vectors in the database.
If we find a match,

487
00:32:01.840 --> 00:32:02.673
oh sorry.

488
00:32:02.830 --> 00:32:07.830
We compare this vector of the input image with the vector corresponding to the

489
00:32:08.980 --> 00:32:13.570
ID image.
If it's small,
we consider that this the same person.
Okay.

490
00:32:13.600 --> 00:32:17.080
Now talking about the loss and the training to figure out is this vector

491
00:32:17.500 --> 00:32:18.850
corresponds to something meaningful.

492
00:32:22.600 --> 00:32:26.860
First,
we need more data because we need our model to understand in general the

493
00:32:26.861 --> 00:32:31.360
features of the face and a university that has a thousand students.

494
00:32:31.750 --> 00:32:35.560
It's probably not going to be enough to have a thousand image in order to push

495
00:32:35.561 --> 00:32:39.320
them all to understand all the features of the face.
Instead we will go online,

496
00:32:39.380 --> 00:32:44.380
find open data sets with millions of teachers of faces and help the model learn

497
00:32:44.511 --> 00:32:47.030
from these faces to then use it inside the facility.

498
00:32:47.060 --> 00:32:48.020
There was a question in the back,

499
00:32:49.750 --> 00:32:52.870
<v 1>what do you like?
We did with the like the cat elephant giraffe.</v>

500
00:32:53.020 --> 00:32:56.350
But every student is a wine.
That's another option.
So

501
00:32:56.640 --> 00:33:00.360
<v 0>the question is why can you tell?
Can't you use the one hot encoding?</v>

502
00:33:00.570 --> 00:33:05.570
We couldn't be Lou classifier that's has an output neurons and corresponding to

503
00:33:06.721 --> 00:33:10.500
the number of students in the school and you take an image,
you,

504
00:33:10.501 --> 00:33:12.780
Ronnie to the network is going to tell you which student it is.

505
00:33:13.380 --> 00:33:16.830
What's the issue with that?
Every year student center to school,

506
00:33:17.340 --> 00:33:21.480
you will have to modify your network every year because you have more students

507
00:33:21.930 --> 00:33:26.040
and you need to hire output vector,
larger output vector.

508
00:33:26.080 --> 00:33:30.860
And we don't want to retrain all the time our networks.
Okay,
so what's what,

509
00:33:30.900 --> 00:33:33.510
what's we really want,
if we want to put it in words,

510
00:33:33.930 --> 00:33:37.110
is that uh oh,
there's a mistake here.

511
00:33:37.380 --> 00:33:41.670
What we really want is if I give you two pictures of the same person,

512
00:33:42.960 --> 00:33:45.630
I want a similar in quitting,
I want the vector to be similar.

513
00:33:46.320 --> 00:33:50.640
If I give you two pictures of different persons,
I want different encodings.

514
00:33:50.700 --> 00:33:55.080
I want the victor to be very different and we're going to rely on these two

515
00:33:55.081 --> 00:33:58.500
assumptions and these two thoughts in order to generate,
uh,

516
00:33:58.610 --> 00:34:03.570
our loss function by giving you triplets.
Triplets means three pictures,

517
00:34:03.600 --> 00:34:08.100
one that we call anchor,
that is the person a person,
one did,

518
00:34:08.101 --> 00:34:10.800
we call it positive.
That is the same person as the anchor,

519
00:34:10.890 --> 00:34:15.720
but a different picture of that person.
And the third one that we call negative,

520
00:34:16.080 --> 00:34:17.340
that is a picture of someone else.

521
00:34:17.970 --> 00:34:20.940
And now what we want to do is to minimize the encoding distance between the

522
00:34:20.941 --> 00:34:24.650
anchor and the positive and maximize including the sins between gang corals.

523
00:34:24.660 --> 00:34:28.920
In the end,
the negative,
does these two thoughts make sense?

524
00:34:29.940 --> 00:34:34.140
So now my question for you is what should be the loss function?

525
00:34:36.850 --> 00:34:37.683
<v 1>Yeah,</v>

526
00:34:38.080 --> 00:34:39.310
<v 0>what should be the loss function?</v>

527
00:34:39.311 --> 00:34:44.200
So please go and mentee and enter the code and their tree off.
Since here a,
B,

528
00:34:44.201 --> 00:34:45.034
and c,

529
00:34:45.460 --> 00:34:49.120
choose which of these you think should be the right loss function to use for

530
00:34:49.121 --> 00:34:49.954
these problems?

531
00:34:54.810 --> 00:34:59.020
Oh,
you have it on your phone as well,
like issue.
It's more on the screen,

532
00:34:59.021 --> 00:35:03.830
but you can see it on on,
it's got us,

533
00:35:10.240 --> 00:35:11.073
<v 1>it's better here</v>

534
00:35:17.040 --> 00:35:18.460
in the back.
That's too small.

535
00:35:24.670 --> 00:35:26.410
Eight four five seven zero nine

536
00:35:32.770 --> 00:35:33.720
can you see it on your phone?

537
00:35:54.200 --> 00:35:55.033
Yeah.

538
00:36:00.240 --> 00:36:01.073
Yes.

539
00:36:05.250 --> 00:36:10.170
<v 0>So by adjunct of a,
I mean and codings vector off the anchor,</v>

540
00:36:10.920 --> 00:36:11.780
my anchor fee,

541
00:36:11.781 --> 00:36:15.540
I mean the encoding vector of the positive image after you run them through the

542
00:36:15.541 --> 00:36:16.374
network.

543
00:36:41.260 --> 00:36:42.630
<v 1>Okay.
30 more seconds.</v>

544
00:36:52.440 --> 00:36:56.970
<v 0>Okay.
All right.
20 more seconds.</v>

545
00:37:03.310 --> 00:37:04.143
<v 1>Yeah.</v>

546
00:37:07.380 --> 00:37:08.730
<v 0>Okay.
Let's see what we have.</v>

547
00:37:12.800 --> 00:37:13.633
Okay.

548
00:37:15.970 --> 00:37:20.970
So two thirds of the people think that that it's the first uncertain a,

549
00:37:21.790 --> 00:37:23.380
so I read it for everyone.

550
00:37:23.710 --> 00:37:28.430
The last is equal to the l two distance between the encoding of a engine cording

551
00:37:28.450 --> 00:37:33.190
of t minus the Ltd stands between the encoding of a and the encoding of n.

552
00:37:34.480 --> 00:37:38.530
So someone who has uncertainties,
do you want to give a an explanation?

553
00:37:40.420 --> 00:37:41.253
Yes,

554
00:37:42.140 --> 00:37:47.030
<v 2>we are trying to minimize the first difference between the positive and you're</v>

555
00:37:47.031 --> 00:37:51.070
trying to maximize the of and the negative.
And then you subtract.

556
00:37:51.130 --> 00:37:53.060
So let's stop for a second.
Fuck.

557
00:37:53.070 --> 00:37:56.930
And blessed because a lot in cinema and the first one would be minimized.

558
00:37:58.070 --> 00:37:59.180
Yes,
that's correct.

559
00:37:59.820 --> 00:38:01.900
<v 0>So what you said,
I repeated it.
Just be the students.</v>

560
00:38:02.740 --> 00:38:07.180
We want to maximize the distance between the encoding of a and encoding of the

561
00:38:07.181 --> 00:38:07.900
negative.

562
00:38:07.900 --> 00:38:12.250
That's why we have a minus sign here because we wanted the last to go down and

563
00:38:12.251 --> 00:38:14.050
to go down,
we put a minus sign in,

564
00:38:14.051 --> 00:38:18.310
we maximize Easter and on your hand we want to minimize the other term because

565
00:38:18.311 --> 00:38:22.750
it's deployed.
Positive Story.
Okay.
So I agree.
We don't say,

566
00:38:23.800 --> 00:38:25.530
okay,
that was the first time you use these tool.

567
00:38:25.531 --> 00:38:30.190
It's going to be quitter next time.
Okay.
So we have uh,
we have,

568
00:38:30.191 --> 00:38:34.000
uh,
figured out what's the loss function should be.
And now think about it.

569
00:38:34.300 --> 00:38:35.950
Now that we designed loss function,

570
00:38:36.430 --> 00:38:39.390
we're able to use an optimization algorithm,

571
00:38:39.860 --> 00:38:43.210
run an image in the network,
sorry,
run,

572
00:38:43.240 --> 00:38:48.240
run three images into networks like that gets three outputs and coding of a

573
00:38:49.360 --> 00:38:52.780
encoding of tea and coding event.
Come to the loss,

574
00:38:53.170 --> 00:38:57.220
take the gradients of the loss and update department chairs in order to minimize

575
00:38:57.221 --> 00:38:58.054
the loss.

576
00:38:58.120 --> 00:39:02.560
Hopefully after doing that many times we would get an encoding.

577
00:39:02.561 --> 00:39:06.190
That's the presents features of the face cause him network.

578
00:39:06.250 --> 00:39:09.970
We'll have to figure out who are the same people who are different people.

579
00:39:10.870 --> 00:39:11.703
Does that make sense?

580
00:39:12.010 --> 00:39:15.550
These called the treatment of loss and I cheated a little bit in the,

581
00:39:15.551 --> 00:39:18.220
in the quiz.
I didn't write this alpha.

582
00:39:18.670 --> 00:39:21.970
The true loss function contains a small alpha.
You know why?

583
00:39:25.810 --> 00:39:26.643
<v 1>Okay.</v>

584
00:39:27.520 --> 00:39:28.353
<v 0>Yes.</v>

585
00:39:30.530 --> 00:39:34.220
<v 2>So do you don't have negative loss.
Yeah,
dead.
That's not exactly</v>

586
00:39:34.250 --> 00:39:35.083
<v 0>the role of the outside.</v>

587
00:39:35.090 --> 00:39:38.600
In order to not have negative lost with what you can do is to use a maximum of

588
00:39:38.601 --> 00:39:41.600
the loss and zero and train on the maximum of the loss.

589
00:39:41.601 --> 00:39:44.810
N Zero but there is another reason why we have this alpha.

590
00:39:45.940 --> 00:39:49.120
<v 2>Yes.
Essentially it's you have like different stitching,</v>

591
00:39:49.930 --> 00:39:52.150
false negatives and false positives like which one,

592
00:39:53.650 --> 00:39:56.760
which one do you prefer based on false negative and false negatives?
No,

593
00:39:56.870 --> 00:40:00.470
it's not about that.
So sometimes you have announced weight loss function too.

594
00:40:00.530 --> 00:40:04.170
<v 0>Puts a weight on some classes,
but this is an additional al fights,</v>

595
00:40:04.171 --> 00:40:07.510
not a multiplicative alpha.
So it has nothing to do with that.
Yeah.

596
00:40:10.100 --> 00:40:14.370
<v 2>We painted the guards.
Wait,
so you're talking about characterization?
Yes.</v>

597
00:40:14.450 --> 00:40:19.450
<v 0>We had weights in this formula next to the Alpha Alpha times the norm of the</v>

598
00:40:19.581 --> 00:40:20.030
weights.

599
00:40:20.030 --> 00:40:23.340
This would dare regularization but hear this term doesn't penalize weights,

600
00:40:24.900 --> 00:40:25.733
Constance.

601
00:40:28.510 --> 00:40:30.550
<v 2>It's not going to affect the ingredients.
It's not going to effect,</v>

602
00:40:30.580 --> 00:40:32.050
it's not going to affect the weights.

603
00:40:32.380 --> 00:40:37.380
But the reason we hung it here is because let's say the encoding function is,

604
00:40:37.720 --> 00:40:40.840
uh,
let's say you and Coleen function is just a function zero.

605
00:40:42.560 --> 00:40:45.800
<v 0>What we're going to have is that we're going to have encoding of a equals zero</v>

606
00:40:45.830 --> 00:40:48.620
minus zero,
zero minus zero.

607
00:40:49.910 --> 00:40:54.740
And so we will have basically a perfect loss of zero.
Uh,

608
00:40:55.970 --> 00:40:59.140
and we still didn't train or network.
We just learned the no.

609
00:40:59.750 --> 00:41:00.700
So these are five school,

610
00:41:00.710 --> 00:41:04.910
the margin and it pushes your network to learn something meaningful in order to,

611
00:41:05.110 --> 00:41:09.110
to,
to stay stabilize itself on,
on Zeros.
Okay.

612
00:41:14.320 --> 00:41:17.590
<v 2>But there's nothing changes.
Yeah.</v>

613
00:41:17.591 --> 00:41:19.720
So it also has to do with the initializations.

614
00:41:20.050 --> 00:41:22.270
But because we didn't talk about any civilization yet,

615
00:41:22.600 --> 00:41:27.370
we only saw zero initialization I think in consultation to get her another way

616
00:41:27.371 --> 00:41:31.250
to,
to avoid,
uh,
the networks to stabilize or to,

617
00:41:31.251 --> 00:41:34.460
to become stable and zero is to change the initialization scheme.

618
00:41:34.880 --> 00:41:38.180
And in two weeks we're going to see different industrialization schemes
together.

619
00:41:40.300 --> 00:41:41.550
Is it guaranteed?

620
00:41:42.390 --> 00:41:46.540
<v 1>Wait,
just wait.
It's going to do the robot patients</v>

621
00:41:48.610 --> 00:41:50.850
other like scaling.

622
00:41:51.010 --> 00:41:54.670
<v 2>So the question is how do we know that this network is going to be robust to</v>

623
00:41:54.671 --> 00:41:58.540
rotations of the image or scaling of the image or translation of the image?

624
00:41:59.140 --> 00:42:01.660
We know it's because in the data set we're going to give,

625
00:42:01.990 --> 00:42:05.770
let's say your picture and your picture scale and are we going to tell the

626
00:42:05.771 --> 00:42:07.060
network this is the same person.

627
00:42:07.540 --> 00:42:11.410
So their network will have to learn that the scale doesn't mean it's not the

628
00:42:11.411 --> 00:42:14.740
same person.
You have to learn this feature.
Okay.

629
00:42:14.770 --> 00:42:16.810
One more question and then we move on.
I'm fine.
Yeah.

630
00:42:17.080 --> 00:42:19.180
So why isn't it starting at zero problem?

631
00:42:19.181 --> 00:42:22.660
Can you just wait and Megan loss values.
Yeah.
So a good question.

632
00:42:23.190 --> 00:42:28.190
Why is he to call them to to to stay at to establish at zero is because it's

633
00:42:28.691 --> 00:42:29.910
common to keep them.

634
00:42:29.980 --> 00:42:33.480
The loss function is positive and in the paper that you can find its face.

635
00:42:33.500 --> 00:42:36.920
That paper they don't train exactly this last they trend the maximum of this

636
00:42:36.921 --> 00:42:37.754
loss.
N Zero.

637
00:42:38.460 --> 00:42:39.293
<v 1>Yeah.</v>

638
00:42:40.810 --> 00:42:43.390
<v 2>Okay,
so you train and you get the right function.</v>

639
00:42:43.960 --> 00:42:46.210
Now let's make the problem a little more complicated.

640
00:42:46.810 --> 00:42:50.410
What we did so far was face [inaudible].
We're going to do face recognition.

641
00:42:50.980 --> 00:42:53.230
What's the difference?
The difference is there is no more ID.

642
00:42:54.460 --> 00:42:58.410
So now you just have the camera in the facility,
you enter the camera,

643
00:42:58.430 --> 00:42:59.530
looks at you and finds you.

644
00:43:02.000 --> 00:43:03.650
How would you design this new network?

645
00:43:14.020 --> 00:43:14.271
Yes,

646
00:43:14.271 --> 00:43:19.271
in Dubai you got it in an element now of recognition as well because now for you

647
00:43:20.860 --> 00:43:23.370
sort of stand in front of it and you that every picture had a base.

648
00:43:23.610 --> 00:43:26.400
Now it needs to detect the face.
Okay,

649
00:43:26.401 --> 00:43:29.420
so you're saying maybe we need to add an element to the pipeline that is a

650
00:43:30.270 --> 00:43:33.690
detection limit.
That's true in general.
For face recognition,

651
00:43:34.470 --> 00:43:36.300
let's say you have a picture that is quite big.

652
00:43:36.330 --> 00:43:39.120
You want to use the first network that identifies the face,

653
00:43:39.150 --> 00:43:41.070
like finds it on the picture,
detects it,

654
00:43:41.280 --> 00:43:44.340
and then crop the face and give it to another network.
That's true.

655
00:43:44.880 --> 00:43:46.770
That could also be using verification as well.

656
00:43:50.430 --> 00:43:52.780
<v 1>Well,
it's in the old space.</v>

657
00:43:54.840 --> 00:43:56.300
<v 2>Wait,
so the difference,</v>

658
00:43:56.510 --> 00:44:00.720
maybe what you're saying is maybe we can use it or verification algorithm to be

659
00:44:00.730 --> 00:44:05.100
trained,
but instead of looking at one to one comparison,
we look at one,

660
00:44:05.101 --> 00:44:09.870
two n comparison,
so we have the picture as a whole.
The students in the database,

661
00:44:10.410 --> 00:44:15.240
what we can do is run all these database pictures in the model gets a vector

662
00:44:15.241 --> 00:44:18.170
that represents them,
right?
We'll get the vectors.

663
00:44:18.750 --> 00:44:22.620
Now you entered the facility,
we get your picture.

664
00:44:22.680 --> 00:44:23.820
We run it through the model.

665
00:44:23.850 --> 00:44:27.630
We get your vector and we can compare these vector to all the vectors in the

666
00:44:27.631 --> 00:44:31.830
database to identify you.
What's the of this?

667
00:44:35.830 --> 00:44:39.610
<v 0>It's at the number of students you have for every prediction to go over the</v>

668
00:44:39.611 --> 00:44:40.444
whole day database days.

669
00:44:41.620 --> 00:44:46.120
And a common network like model that you can use to do that is 10 years

670
00:44:46.121 --> 00:44:50.500
neighbors.
So of course,
if you have only one picture per students,

671
00:44:50.650 --> 00:44:52.090
it's not going to be very precise.

672
00:44:52.420 --> 00:44:56.200
But if you collect three pictures per student and you run a two nearest

673
00:44:56.201 --> 00:44:59.800
neighbors algorithm,
you would decide that if the two pictures are the same,

674
00:44:59.980 --> 00:45:03.460
it's likely that this person is the same as the two person on the picture.

675
00:45:04.880 --> 00:45:05.713
<v 1>Okay.</v>

676
00:45:07.280 --> 00:45:09.860
<v 0>Now let's make it a little more complicated.</v>

677
00:45:10.670 --> 00:45:14.250
You probably saw that on your,
on your phones.
Uh,

678
00:45:14.330 --> 00:45:19.130
sometimes you take a picture and it recognizes that it's your grandmother or

679
00:45:19.131 --> 00:45:22.580
your grandfather or your mother and father.
Uh,

680
00:45:22.790 --> 00:45:26.810
what's happening behind these that there is some clustering happening.

681
00:45:27.260 --> 00:45:32.260
It means we have a bunch of images and we want to cluster them together.

682
00:45:33.500 --> 00:45:37.000
So this is also another algorithm that you've seen [inaudible] nine eight,

683
00:45:37.001 --> 00:45:38.720
which is Kamins algorithm.

684
00:45:39.410 --> 00:45:43.160
And this is a clustering algorithm by taking all the vectors that we have in the

685
00:45:43.161 --> 00:45:47.840
database,
we can find,
uh,
let,
let's say,
sorry you haven't,
you have a phone,

686
00:45:47.930 --> 00:45:52.250
you have thousands of pictures of let's say 20 different people.

687
00:45:53.090 --> 00:45:56.720
What you want is to cluster all the teachers have the same person separately.

688
00:45:57.620 --> 00:46:01.190
What you will do is that you will encode all the pictures in vectors and then

689
00:46:01.191 --> 00:46:05.540
you will run a cloud clustering algorithm like Kamins in order to cluster those

690
00:46:05.750 --> 00:46:08.480
into groups.
These are the vectors that look like each other.

691
00:46:08.510 --> 00:46:11.060
These are the vectors that you've liked each other.
Okay.

692
00:46:11.300 --> 00:46:14.930
And then you can simply give folders to the users with all the pictures of your

693
00:46:14.931 --> 00:46:18.800
mom,
all the pictures of your dad.
And so how,

694
00:46:23.160 --> 00:46:23.530
<v 4>yeah,</v>

695
00:46:23.530 --> 00:46:28.450
<v 0>good question.
How would you define the cake?
So,
uh,
someone has an idea actually.</v>

696
00:46:37.150 --> 00:46:37.983
<v 4>Yeah.</v>

697
00:46:41.460 --> 00:46:43.270
So one way is to,

698
00:46:43.560 --> 00:46:45.600
<v 0>as you said,
to try different values,</v>

699
00:46:45.820 --> 00:46:49.950
train or clustering algorithm and look at a certain last few to find how small

700
00:46:49.951 --> 00:46:53.910
it is.
There's actually an algorithm called x means that is used x meals.

701
00:46:54.180 --> 00:46:57.210
You might search for that.
If you want to find,
uh,

702
00:46:57.330 --> 00:47:01.950
to find the k there was also a method called the elbow method or that you want

703
00:47:01.951 --> 00:47:03.870
to search for his way to figure out the cake.

704
00:47:06.480 --> 00:47:07.313
<v 1>Okay.</v>

705
00:47:07.920 --> 00:47:08.611
<v 0>And as you said,</v>

706
00:47:08.611 --> 00:47:11.910
maybe we need to detect the face first and then crop and give it to the

707
00:47:11.911 --> 00:47:14.120
algorithm.
One more question on face verification.

708
00:47:15.780 --> 00:47:17.420
<v 4>Do you also use the</v>

709
00:47:22.610 --> 00:47:25.330
louder,
you also need to,

710
00:47:31.850 --> 00:47:32.683
okay.

711
00:47:32.710 --> 00:47:37.430
<v 0>You trained for classification?
Um,</v>

712
00:47:38.270 --> 00:47:41.180
sorry,
I do.
I didn't understand.
So you mean could,

713
00:47:50.420 --> 00:47:54.380
<v 4>oh,
so where is the encoding coming from?
That's what you mean in in the network?</v>

714
00:47:54.490 --> 00:47:56.390
Yeah.
Okay.
Good question.

715
00:47:56.740 --> 00:47:59.920
<v 0>So you have a deep network and you want to decide where should you take the</v>

716
00:47:59.921 --> 00:48:04.900
encoding from.
In this case,
the more complex the task,
the deeper you would go.

717
00:48:05.110 --> 00:48:08.530
But for face verification and what you want and you know it as a human,

718
00:48:08.531 --> 00:48:12.610
you want to know features like a distance between the eyes,
nose and stuff.

719
00:48:12.790 --> 00:48:14.860
And so you have to go deeper.
You need,

720
00:48:14.861 --> 00:48:18.370
the first layer is to figure out the edges,
give the edges to the second layer.

721
00:48:18.400 --> 00:48:21.970
The second layer to figure out the nose,
the eyes,
give it to the third layer,

722
00:48:21.971 --> 00:48:24.220
the third layer to figure out the distances between the eyes,

723
00:48:24.221 --> 00:48:25.300
the distance in between the ears.

724
00:48:25.690 --> 00:48:29.260
So you would go deeper and get the encoding deeper because you know that you

725
00:48:29.261 --> 00:48:30.220
want high level features.

726
00:48:32.440 --> 00:48:33.273
<v 1>Okay?</v>

727
00:48:34.440 --> 00:48:39.210
<v 0>Our generation,
even a picture and making it look beautiful</v>

728
00:48:42.020 --> 00:48:45.050
as usual data.
What do we need?

729
00:48:49.150 --> 00:48:52.500
<v 4>It's a little complicated because we have to define what you did for this</v>

730
00:48:56.070 --> 00:48:58.610
data.
Some beautiful pictures.
I don't know.

731
00:48:58.611 --> 00:49:00.950
Maybe my concept of beautiful is different.
In Europe

732
00:49:06.080 --> 00:49:07.450
they turned a certain stylist,

733
00:49:08.120 --> 00:49:10.700
<v 0>so we might say that beautiful means paintings,</v>

734
00:49:10.800 --> 00:49:12.290
like paintings are usually beautiful.

735
00:49:12.500 --> 00:49:14.990
So you want to have a set kind of a state yet it's true.

736
00:49:16.070 --> 00:49:16.830
<v 1>Okay,</v>

737
00:49:16.830 --> 00:49:19.770
<v 0>so let's say we have any data that we want.</v>

738
00:49:20.880 --> 00:49:25.880
What we're going to do and the way we define this problem is let's take an image

739
00:49:26.011 --> 00:49:27.540
that we call the content image.

740
00:49:27.690 --> 00:49:31.080
And here again you have the loof museum and let's take an image that we call the

741
00:49:31.081 --> 00:49:35.250
style image.
And this is a painting that we find beautiful.

742
00:49:36.420 --> 00:49:41.420
What we want is to generate an image that looks like it's the content of the

743
00:49:43.171 --> 00:49:47.610
content image but painted by the painter of the style image.

744
00:49:48.360 --> 00:49:52.470
So this style image is occluded Monet and here we have the Louver painted by

745
00:49:52.471 --> 00:49:56.760
Claude Monet.
Even if he was dead when this pyramid was created.

746
00:49:58.470 --> 00:49:59.303
So that's our goal

747
00:50:00.960 --> 00:50:03.510
and this is what we would call our generation.

748
00:50:03.720 --> 00:50:07.860
There are other methods but this is one.
So how do we do that?

749
00:50:08.340 --> 00:50:12.270
What architecture is do we need and please try to use what you've seen in the

750
00:50:12.271 --> 00:50:13.710
past two applications together,

751
00:50:16.350 --> 00:50:19.740
what training scheme,
what applications,
what,
what architecture.

752
00:50:28.790 --> 00:50:30.070
<v 4>No one wants to try</v>

753
00:50:36.520 --> 00:50:37.353
this.

754
00:50:55.300 --> 00:50:56.133
We

755
00:50:58.360 --> 00:51:01.970
pick some images to a network

756
00:51:02.590 --> 00:51:06.010
<v 0>and then at work outputs,
yes or no,
one or zero</v>

757
00:51:09.310 --> 00:51:11.590
<v 4>generate.
We want to generate to any events yet</v>

758
00:51:15.990 --> 00:51:17.550
this

759
00:51:21.120 --> 00:51:23.390
side,
okay

760
00:51:24.460 --> 00:51:29.460
<v 0>you're proposing is we get an image that is the content image and we have a</v>

761
00:51:30.251 --> 00:51:34.450
network that is the style style network,
which was style.

762
00:51:34.451 --> 00:51:38.000
This image and we will get the content but stag version of the content,

763
00:51:45.150 --> 00:51:49.240
<v 4>certain feature of his and change your site according to what the network isn't</v>

764
00:51:49.241 --> 00:51:50.890
it.
You see it actually done.

765
00:51:51.190 --> 00:51:55.400
And this is one method that's not the one who would see today the should with

766
00:51:55.401 --> 00:51:56.234
this method.

767
00:51:56.490 --> 00:51:59.550
<v 0>Well,
the issue is that you have to train your network to learn.</v>

768
00:51:59.551 --> 00:52:02.910
One style network learns one style.
You give the content,

769
00:52:02.911 --> 00:52:05.640
it gives you the constant with the specific style of the model.

770
00:52:06.330 --> 00:52:10.590
What we want to do is to have no model that is restricted to a specific style.

771
00:52:11.580 --> 00:52:15.960
I want to be able to give a painting of Picasso and Guess This picture painted

772
00:52:15.961 --> 00:52:20.430
by Picasso.
So the difference here is that we're not,

773
00:52:20.550 --> 00:52:23.670
we're not going to learn perimeters of a network like we did for phase

774
00:52:23.671 --> 00:52:26.010
verification or four a day and night classification.

775
00:52:26.670 --> 00:52:28.140
We're going to learn an image.

776
00:52:29.070 --> 00:52:32.640
So you remember when we talked about backpropagation of the gradient of the

777
00:52:32.641 --> 00:52:34.320
parameters.
We're not going to do that.

778
00:52:34.710 --> 00:52:37.650
We're going to back propagate all the way back to the image.

779
00:52:38.940 --> 00:52:39.840
Let's see how it works.

780
00:52:40.380 --> 00:52:45.380
So first we have to understand what content means and what stylists to do that

781
00:52:46.111 --> 00:52:47.130
we're going to use encoding.

782
00:52:47.400 --> 00:52:50.850
We're going to to to to use the ideas that we talked about later.

783
00:52:51.300 --> 00:52:56.300
Giving the content image to a network that is very good will allow us to extract

784
00:52:56.730 --> 00:53:01.050
some information about the content of this image we specifically so together

785
00:53:01.110 --> 00:53:03.930
that earlier layers with the tech,
the edges,

786
00:53:04.680 --> 00:53:09.680
the edges are usually a good representation of the content of the image so I

787
00:53:10.081 --> 00:53:13.320
might have a very good network.
Give my contents image,

788
00:53:13.380 --> 00:53:15.660
extract the information from the first layer.

789
00:53:15.690 --> 00:53:17.790
This information is going to be the content of the image.

790
00:53:19.200 --> 00:53:20.940
Now the question is how do I get the style?

791
00:53:23.250 --> 00:53:27.090
I want to give my style image and find a way to extract this die.

792
00:53:28.290 --> 00:53:30.480
That's what we're going to learn later in this course.

793
00:53:30.570 --> 00:53:34.530
It's a technical Graham Matrix and the important thing to remember is that the

794
00:53:34.531 --> 00:53:36.750
style is non localized inflammation.

795
00:53:38.520 --> 00:53:43.470
If I show you the the pictures in the previous slide,
oh sorry.

796
00:53:44.610 --> 00:53:49.420
Here you see that CG generated picture old on this tiny image,

797
00:53:49.421 --> 00:53:54.150
there was a tree on the left side.
There is no tree on the generated image.

798
00:53:54.570 --> 00:53:56.430
It means when I extracted the style,

799
00:53:56.880 --> 00:53:59.280
I just extracted known localized inflammation.

800
00:53:59.310 --> 00:54:01.800
What's the technique that code when it has used to paint?

801
00:54:02.190 --> 00:54:04.880
I didn't want to extract these tree that was on the stock image.

802
00:54:05.790 --> 00:54:07.800
Don't want the content.
Okay,

803
00:54:08.340 --> 00:54:13.340
so we're going to take the network that understands images very well and they're

804
00:54:13.711 --> 00:54:18.420
coming online.
You can find image nets,
classified classification networks online.

805
00:54:18.690 --> 00:54:22.530
That's where trains to recognize more than thousand thousands of objects.

806
00:54:24.060 --> 00:54:28.110
This networks is going to understand basically anything you give it.

807
00:54:28.440 --> 00:54:32.220
If I give you the Louvre Museum,
it's going to find all the edges very easily.

808
00:54:32.460 --> 00:54:35.340
It's going to figure out that there is,
it's during the day,

809
00:54:35.341 --> 00:54:38.290
it's going to figure out their buildings on the sides and all the features of

810
00:54:38.300 --> 00:54:42.300
the DME because it was trained for months on thousands of classes,

811
00:54:43.110 --> 00:54:44.370
but I'd say we have this network,

812
00:54:44.520 --> 00:54:49.140
we give our contents image to it and we extract information from the first few

813
00:54:49.141 --> 00:54:51.090
layers.
This information,

814
00:54:51.120 --> 00:54:55.080
we call it content c content of the contents image.

815
00:54:56.490 --> 00:54:57.323
Does that make sense?

816
00:54:58.200 --> 00:55:03.120
Now I give the style image and I will use another method that is called the

817
00:55:03.120 --> 00:55:06.570
Grain Matrix to extract style style of the style image.

818
00:55:08.550 --> 00:55:13.170
Okay.
And now the question is what should be the loss function?

819
00:55:13.860 --> 00:55:15.000
So let's go and mentee.

820
00:55:29.900 --> 00:55:32.990
So same code as usual.
Just open it.

821
00:55:40.250 --> 00:55:42.740
Do you want me to repeat?
I can repeat.
Do Code if you want.

822
00:55:43.040 --> 00:55:47.780
Eight four five seven zero nine and these are the three proposals for the loss

823
00:55:47.781 --> 00:55:52.640
function.
So reminder content c means content of their contents.

824
00:55:52.641 --> 00:55:56.280
Image style,
Essman style of the style.
Image Style,

825
00:55:56.300 --> 00:55:59.060
g means style of the generated image.

826
00:55:59.420 --> 00:56:02.510
Content g means content of the generated image.

827
00:56:07.640 --> 00:56:08.473
Like a minute.

828
00:56:18.450 --> 00:56:19.283
Small.

829
00:56:19.440 --> 00:56:20.273
<v 1>Yeah.</v>

830
00:56:21.380 --> 00:56:22.213
<v 0>Oh,
new code</v>

831
00:56:25.250 --> 00:56:27.320
eight four five seven zero nine

832
00:56:58.680 --> 00:57:02.370
what?
So just repeating the question of why do we need to use image net?

833
00:57:02.700 --> 00:57:04.080
Because we,
we don't treat it.

834
00:57:04.081 --> 00:57:07.170
You need to classify an image and he's going to waste time.

835
00:57:07.750 --> 00:57:11.670
The reason we need Gmh Nancy's because image net understands our pictures.

836
00:57:12.240 --> 00:57:16.800
So you can give the contents image to a network that doesn't understand teachers

837
00:57:16.801 --> 00:57:19.620
very well.
You're not going to get the edge is very well.

838
00:57:20.850 --> 00:57:25.350
So you want a network that
you don't care about the classification outputs.

839
00:57:25.440 --> 00:57:29.580
You just cut the network in the middle,
extract the layers in the middle.
Okay.

840
00:57:29.581 --> 00:57:32.880
Let's see what the answers are according to you guys

841
00:57:35.470 --> 00:57:39.180
<v 1>giving style,
style of training.</v>

842
00:57:40.260 --> 00:57:42.750
<v 0>So yeah,
I repeat,
we are not training anything here.</v>

843
00:57:43.230 --> 00:57:46.740
We're getting a model that exists and we use this model.

844
00:57:47.500 --> 00:57:50.340
We're going to talk about your training yester.
Okay.

845
00:57:50.370 --> 00:57:54.390
Someone who has uncertain the second question and I will read it out loud.

846
00:57:54.960 --> 00:57:58.850
The loss is the l two difference between the style of the style image in the

847
00:57:58.851 --> 00:58:03.210
generated style plus the ultra distance between the generator,

848
00:58:03.240 --> 00:58:05.850
the generators content and the content is content.

849
00:58:09.570 --> 00:58:11.160
Yup.
We want to maximize,

850
00:58:11.400 --> 00:58:15.530
<v 1>oh
okay.</v>

851
00:58:17.630 --> 00:58:20.090
<v 0>So yeah,
we want to nice both terms here.</v>

852
00:58:20.990 --> 00:58:24.320
So we want the content of their contents image to look like the content of the

853
00:58:24.350 --> 00:58:27.380
generated image.
So we want to minimize the l to the says of this too.

854
00:58:27.710 --> 00:58:31.370
And the reason we use a plus is because we also want to minimize the difference

855
00:58:31.371 --> 00:58:33.560
of styles between degenerated in the style image.

856
00:58:34.100 --> 00:58:37.400
So you see we don't have any terms that say's style of the content,

857
00:58:37.401 --> 00:58:41.200
image minus style of the generated image is many ways.

858
00:58:41.780 --> 00:58:42.690
This is the last one.

859
00:58:44.560 --> 00:58:45.393
<v 1>Okay.</v>

860
00:58:51.820 --> 00:58:55.510
<v 0>Okay,
so just going over the architecture again.</v>

861
00:58:56.170 --> 00:59:00.160
So the loss function we're going to use will be the one we sold.

862
00:59:00.790 --> 00:59:05.080
And so one thing that I want to emphasize here is we're not training the
network.

863
00:59:05.320 --> 00:59:06.850
There's no parameter that we train.

864
00:59:07.090 --> 00:59:10.810
The parameters are indie may Jeanette's classification network,
we use them,

865
00:59:10.811 --> 00:59:13.840
we don't train them.
What we will train is the image.

866
00:59:14.620 --> 00:59:17.080
So you get an image and you start with white noise.

867
00:59:17.950 --> 00:59:20.770
You run this image through the classification network,

868
00:59:20.800 --> 00:59:23.300
but you don't care about the classification of this image.

869
00:59:23.690 --> 00:59:27.440
Image net is going to give a random class to this image.
Totally random.

870
00:59:29.270 --> 00:59:33.500
Instead you will extract content g and Sig.

871
00:59:34.940 --> 00:59:39.680
Okay?
So from this image you run it and you extract information from this network

872
00:59:39.681 --> 00:59:43.910
using the same techniques that you've used to extract contents c and stylists.

873
00:59:44.510 --> 00:59:46.930
So contents stay and stylist,
you'll have it,
you'll have it.

874
00:59:47.450 --> 00:59:51.500
You able to compute the loss function because now you have the four terms of the

875
00:59:51.501 --> 00:59:52.334
class function.

876
00:59:53.000 --> 00:59:56.810
You computed derivatives instead of stopping in the network,

877
00:59:57.050 --> 01:00:01.850
you go all the way back to the pixels of the image and you decide how much

878
01:00:01.851 --> 01:00:05.060
should I move the big soles in order to make this last go down.

879
01:00:05.930 --> 01:00:09.320
And you do that many times.
You had many times and the more you do that,

880
01:00:09.380 --> 01:00:12.800
the more this is going to look like the content of the content image and the

881
01:00:12.801 --> 01:00:15.290
style of the stylish.
Yeah.
One question,

882
01:00:17.440 --> 01:00:21.140
<v 2>style of images,
you need to do a new training like this.
Yeah,</v>

883
01:00:21.210 --> 01:00:25.590
so the downside of this effort is although it has the flexibility to work with

884
01:00:25.650 --> 01:00:29.340
any style,
any content,
every time you want to generate an image,

885
01:00:29.341 --> 01:00:30.840
you have to do this training loop.

886
01:00:31.290 --> 01:00:34.020
While the other network that you talked about doesn't need that because the

887
01:00:34.021 --> 01:00:38.180
model is trained to to convert to content to a style and just give it and goes

888
01:00:39.620 --> 01:00:42.410
trained.
And that broke on many kinds of look

889
01:00:45.530 --> 01:00:47.250
which network you talk about this network.

890
01:00:48.150 --> 01:00:52.020
So do we need to train these network on morning images?
Usually not.

891
01:00:52.440 --> 01:00:54.720
This network is trained on millions of images.

892
01:00:54.750 --> 01:00:58.960
It's basically seen everything you can imagine.
Yeah.

893
01:01:04.940 --> 01:01:08.370
What do you mean back propagate properly here?
You're not training the network,

894
01:01:09.150 --> 01:01:12.990
you're giving this image competing the backpropagation and going back to the

895
01:01:12.991 --> 01:01:15.570
image.
Only updating the image.
You don't update the network.

896
01:01:16.190 --> 01:01:20.340
So then where does the art,
it comes from content,

897
01:01:20.341 --> 01:01:25.110
CN style as it comes from the stylus.
So the loss function,

898
01:01:25.200 --> 01:01:28.090
you bait.
The baseline is you have content,
CN stylists,

899
01:01:28.110 --> 01:01:31.860
because you've chosen a content picture in a sight picture and now every,

900
01:01:31.861 --> 01:01:36.520
at every step you will find the new content g and strategy back,

901
01:01:36.540 --> 01:01:40.110
propagate updates,
give it again,
get the new content giants dig,

902
01:01:40.290 --> 01:01:41.520
update again and so on.

903
01:01:44.140 --> 01:01:47.190
No did the art never touches the just one time.

904
01:01:47.640 --> 01:01:50.000
The art image just touches one time.
Then your electric,

905
01:01:50.010 --> 01:01:53.760
you can you extract stylists and then that's all you don't use it again.
Okay.

906
01:01:53.761 --> 01:01:55.740
Let's do one more question yet here.

907
01:01:58.140 --> 01:02:00.510
The content or the style?
Good question.

908
01:02:00.720 --> 01:02:04.320
Why do you start with white nose instead of the content or the style?
Actually,

909
01:02:04.321 --> 01:02:06.360
do you think it's better to start with the content or this time?

910
01:02:08.670 --> 01:02:13.560
Probably the style.
I think probably the contents because uh,

911
01:02:13.620 --> 01:02:14.130
the,

912
01:02:14.130 --> 01:02:19.080
the edges at least look like the content is to help the network converged

913
01:02:19.260 --> 01:02:20.190
quicker.
Yeah,
that's true.

914
01:02:20.400 --> 01:02:23.710
You don't have to start with white noise in generally the baseline you started

915
01:02:23.720 --> 01:02:26.880
with white noise so that anything can happen is he'll give you the content to

916
01:02:26.881 --> 01:02:27.331
start with.

917
01:02:27.331 --> 01:02:31.110
He's going to have a bias towards the content but gives you train longer.

918
01:02:32.400 --> 01:02:36.630
Okay.
One more question and then we can run these style of his content copies.

919
01:02:38.270 --> 01:02:40.010
Like know what is style,
price,

920
01:02:41.070 --> 01:02:43.500
image and it doesn't understand what content and style,

921
01:02:43.830 --> 01:02:48.000
but you mentioned it finds the edges on the image and so you can give the

922
01:02:48.001 --> 01:02:51.540
contents image and extract the shoe first layers to get information about them.

923
01:02:52.140 --> 01:02:54.360
Because when it was trained on classification,

924
01:02:54.720 --> 01:02:58.110
it needed to find the ages to find that a dog is a dog.

925
01:02:58.170 --> 01:03:01.380
You first need to find the edges of the dog sweets.
It's trained to do so.

926
01:03:01.710 --> 01:03:05.700
And for the style,
it's complicated to understand the style,

927
01:03:05.730 --> 01:03:08.400
but the network science,
all the features on the image.

928
01:03:08.700 --> 01:03:11.820
And then we use the post processing techniques and is called the grant matrix.

929
01:03:11.880 --> 01:03:15.400
In order to extract what we called style,
it's basically a,

930
01:03:15.401 --> 01:03:18.000
a cross correlation of all the features of the network.

931
01:03:18.210 --> 01:03:22.080
We will learn it together later.
Okay,

932
01:03:22.180 --> 01:03:25.000
<v 0>let's move on to the next application because we don't have too much time.</v>

933
01:03:25.400 --> 01:03:29.230
So this is the one I prefer,
uh,
given a ten second node,
your speech,

934
01:03:29.231 --> 01:03:31.360
detect the word activate.
So you know,

935
01:03:31.361 --> 01:03:34.030
we talked about trigger word detection and there are many companies that have

936
01:03:34.031 --> 01:03:38.020
this wake word thing where you have a device at home and when you say you're

937
01:03:38.021 --> 01:03:39.670
searching a word you'd activates itself.

938
01:03:39.730 --> 01:03:43.180
So here's the same thing for the word activate.
What data do we need?

939
01:03:45.150 --> 01:03:45.983
<v 1>Okay,</v>

940
01:03:47.760 --> 01:03:49.050
<v 0>do we need a lot or no?</v>

941
01:03:51.050 --> 01:03:53.000
Probably a lot because there are many accents.

942
01:03:53.210 --> 01:03:57.740
And one thing that is counter intuitive is that if two humans,

943
01:03:57.770 --> 01:04:02.630
like let's say,
let's say to two women speak as a human,

944
01:04:02.631 --> 01:04:07.430
you would say this voices are are pretty similar,
right?

945
01:04:07.490 --> 01:04:08.660
You can detect the word.

946
01:04:09.760 --> 01:04:14.180
What did network sees is a list of numbers that are totally different from one

947
01:04:14.181 --> 01:04:17.030
person to another because the frequencies we're using,

948
01:04:17.031 --> 01:04:19.010
our voices are totally different from each other.

949
01:04:19.220 --> 01:04:21.050
So the numbers are very different.

950
01:04:21.051 --> 01:04:24.080
Although as a human we feel that it's very similar.

951
01:04:25.760 --> 01:04:28.700
So we need a lot of ten second video clips.

952
01:04:29.450 --> 01:04:31.940
Let's see what should be the distribution.

953
01:04:31.941 --> 01:04:34.490
It should contain as many accidents as you can,

954
01:04:34.550 --> 01:04:38.810
as many female male voices,
uh,
kid,

955
01:04:38.870 --> 01:04:43.190
adults,
uh,
and so on.
What should be the input of the network?

956
01:04:44.090 --> 01:04:46.830
It should be a ten second video clip that we can represent like that.

957
01:04:47.360 --> 01:04:51.500
The ten second video clip is going to contain some positive words in green.

958
01:04:52.220 --> 01:04:57.220
Positive word is activate and it's also going to contain negative words in pink,

959
01:04:58.310 --> 01:05:00.950
like kitchen lion,

960
01:05:01.370 --> 01:05:03.590
whatever words that are not activate.

961
01:05:04.430 --> 01:05:09.050
And we want only to detect the positive word.
What should be the sample rates?

962
01:05:10.100 --> 01:05:14.420
Again.
Same question you would test on humans,
uh,
you would,
you would,

963
01:05:14.421 --> 01:05:18.040
you would also talk to an expert in spatial cognition to know what's

964
01:05:18.040 --> 01:05:20.830
<v 5>the best sample rate to use for speech processing.</v>

965
01:05:21.940 --> 01:05:23.050
What should be the output?

966
01:05:24.210 --> 01:05:25.043
<v 1>Any ideas?</v>

967
01:05:34.620 --> 01:05:36.460
Okay,
ma'am?

968
01:05:38.260 --> 01:05:42.220
<v 5>Classification.
Yes.
No,
so zero one actually,
let's make your test.</v>

969
01:05:43.200 --> 01:05:48.200
Let's,
let's do a test.
So we have three [inaudible] speech here.
Speech,
one,

970
01:05:48.201 --> 01:05:52.240
speech to speech.
The three.
I don't know if we have the sound here.

971
01:05:52.241 --> 01:05:53.170
Do we have the sound?

972
01:05:58.030 --> 01:06:00.820
<v 1>Maybe we'll have it now.
Okay,
let's try it.</v>

973
01:06:11.330 --> 01:06:12.490
So this is labeled one.

974
01:06:15.650 --> 01:06:19.700
<v 5>Nobody speaks Italian in the,
in the,
in the room.
No.
Second one.</v>

975
01:06:31.740 --> 01:06:32.970
Okay.
What's the wake word?

976
01:06:36.370 --> 01:06:41.230
Has Anybody found?
What was the trigger word?
We need more?

977
01:06:43.300 --> 01:06:46.780
So,
you know what's funny is this is the right scheme to label.

978
01:06:47.060 --> 01:06:50.260
Like it's definitely possible,
but it seems that even for humans,

979
01:06:50.261 --> 01:06:54.100
this labeling scheme is super hard.
We're not able to find what's,

980
01:06:54.110 --> 01:06:57.520
what's happening.
Like I don't know,
even if I did this slide,

981
01:06:57.521 --> 01:07:01.840
I don't even remember.
No kidding.
Now let's try something else.

982
01:07:02.650 --> 01:07:03.483
Okay.

983
01:07:03.790 --> 01:07:08.790
So now we have a different labeling scheme that tells us also where the wake

984
01:07:08.801 --> 01:07:11.440
word is happening.
Let's hear it again

985
01:07:27.120 --> 01:07:30.730
<v 6>because it's an inclusive community within the shopping.</v>

986
01:07:32.960 --> 01:07:36.080
<v 5>Okay.
What's the trigger word for Angel?</v>

987
01:07:36.490 --> 01:07:40.970
For Mary Jo means afternoon in Italian.
Okay.

988
01:07:41.660 --> 01:07:46.660
So you see what I'm trying to illustrate is a comfort a human to the computer

989
01:07:47.780 --> 01:07:50.000
and you will get what's the right labeling scheme to use.

990
01:07:50.030 --> 01:07:54.320
And of course the labeling scheme here is going to be better for the model

991
01:07:54.620 --> 01:07:59.520
rather than the first one.
And we just proved it.
Uh,
the,
the,

992
01:07:59.550 --> 01:08:02.450
the important thing is to know that the first one would also work.

993
01:08:02.810 --> 01:08:04.370
We just need a ton of data.

994
01:08:04.460 --> 01:08:07.250
We need a lot more data to make the first labeling scheme work,

995
01:08:07.280 --> 01:08:10.070
then we need for the second one.
Does that make sense?

996
01:08:12.290 --> 01:08:15.600
So,
yeah,
we will use something like that.
You get,

997
01:08:16.460 --> 01:08:21.250
<v 2>it's the acquisition where it starts or when you have one.
Good question.</v>

998
01:08:21.400 --> 01:08:24.760
Actually,
this is not the best labeling scheme,
as you said.

999
01:08:24.980 --> 01:08:26.980
Should the one come before or after

1000
01:08:27.000 --> 01:08:31.440
<v 5>stir the word was said?
What'd you guys think before?</v>

1001
01:08:33.090 --> 01:08:34.200
<v 2>Yeah,
you will see,</v>

1002
01:08:34.550 --> 01:08:35.030
<v 5>uh,</v>

1003
01:08:35.030 --> 01:08:40.030
record your general networks are going basically to look at the data just as

1004
01:08:40.781 --> 01:08:43.360
human dude,
like temporarily from the beginning to the end.

1005
01:08:43.680 --> 01:08:46.810
And in this case you need to hear the word in order to detect it.

1006
01:08:47.020 --> 01:08:49.510
So we're going to put the one right after the word was said.

1007
01:08:50.250 --> 01:08:53.320
And another issue that we have with this is that there are too many zeros.

1008
01:08:53.410 --> 01:08:57.580
It's highly unbalanced.
So the network is pushed to always predict Zeros.

1009
01:08:57.970 --> 01:08:59.260
So what we do as a hack,

1010
01:08:59.800 --> 01:09:02.410
and there's a lot of hacks like that happening in papers,
if you read them,

1011
01:09:02.560 --> 01:09:06.980
we're going to add several ones after the word was say I would add 20 ones

1012
01:09:07.840 --> 01:09:11.140
basically.
Okay.
So this is our labeling scheme.

1013
01:09:11.141 --> 01:09:15.070
Now what should be the last activation of our network?

1014
01:09:23.430 --> 01:09:26.130
<v 2>Sigmoid function?
Yeah,
sigmoid.
But sequential</v>

1015
01:09:26.540 --> 01:09:29.930
<v 5>for every time step you would use a sigmoid throughout.</v>

1016
01:09:29.970 --> 01:09:32.810
Put Zero or one basic.
No worries.

1017
01:09:32.811 --> 01:09:35.510
You don't understand specifically what networks were using.

1018
01:09:35.511 --> 01:09:39.230
You're going to learn it in a few weeks.
So the architecture should,

1019
01:09:39.440 --> 01:09:41.660
should be like a recurrent neural network.

1020
01:09:41.661 --> 01:09:45.140
Probably a convolutional neural networks might work as well.

1021
01:09:45.320 --> 01:09:47.150
We'll see it later on in the course.

1022
01:09:47.480 --> 01:09:49.610
And the last function should be the same as before,

1023
01:09:49.611 --> 01:09:52.280
but we should make it sequential for every time step.

1024
01:09:52.281 --> 01:09:55.700
We should use the loss function like that and we should some them over all the

1025
01:09:55.701 --> 01:09:59.180
times.
That
sounds good.

1026
01:09:59.810 --> 01:10:04.710
So another insights on this project,
I'll take it after,
uh,

1027
01:10:05.240 --> 01:10:07.580
is what it was critical to the success of this project.

1028
01:10:07.610 --> 01:10:10.250
I think there are two things that are really critical when you,

1029
01:10:10.280 --> 01:10:11.570
when you build such a project.

1030
01:10:12.320 --> 01:10:17.030
The first one is to have a straight strategic data acquisition pipeline.

1031
01:10:18.530 --> 01:10:19.550
So let's talk more about that.

1032
01:10:19.670 --> 01:10:24.140
We said that our data should be ten second video clips that content positive and

1033
01:10:24.141 --> 01:10:26.450
negative words from many different access.

1034
01:10:28.300 --> 01:10:29.770
How would you collect this data?

1035
01:10:43.060 --> 01:10:43.893
<v 1>Yes.</v>

1036
01:10:48.570 --> 01:10:52.840
<v 2>You said you paid the host gives you 10 seconds of their voice comments then</v>

1037
01:10:52.900 --> 01:10:57.180
maybe,
but yeah,
I think you,
you,
you can take your phone,

1038
01:10:57.690 --> 01:10:58.430
go around

1039
01:10:58.430 --> 01:11:01.550
<v 5>this and that's actually how we did it.
We took our phones,</v>

1040
01:11:01.551 --> 01:11:04.490
we went around campus and we got some audio recordings.

1041
01:11:05.390 --> 01:11:09.890
So one way to do it is that to go and get ten second or the recordings from

1042
01:11:09.891 --> 01:11:13.620
different people with a large distribution of accents.
And then what did you do?

1043
01:11:13.621 --> 01:11:18.600
You label you labeled by hand.
That's one method.

1044
01:11:19.350 --> 01:11:23.930
Is it long or short?
Is it,
is it quick or no,
it's super slow yet.

1045
01:11:26.850 --> 01:11:30.270
Oh,
subtitles in movies.
Oh that's a good idea.
Actually.

1046
01:11:30.271 --> 01:11:33.780
You could like based on the licensing of the movie,

1047
01:11:36.540 --> 01:11:40.830
you could like take a Nogio from a movie and you did the subtitles and you were

1048
01:11:40.831 --> 01:11:44.070
looking for activate and every time the subject say activate,

1049
01:11:44.310 --> 01:11:47.610
you could label your data.
That's Super Fun.
That's super good actually.

1050
01:11:48.090 --> 01:11:52.780
You could label automatically using that.
Yeah,
so that's a good idea.

1051
01:11:52.810 --> 01:11:55.390
I think there's another way to do it that is closer to that,

1052
01:11:55.800 --> 01:11:58.390
which is we're going to collect three databases.

1053
01:11:59.020 --> 01:12:02.230
The first one is going to be the positive word database.

1054
01:12:02.260 --> 01:12:04.630
The second one is going to be the negative word database.

1055
01:12:04.930 --> 01:12:07.810
The third one is going to be the background though database.

1056
01:12:09.550 --> 01:12:12.550
So I think the ground 10 seconds,

1057
01:12:13.450 --> 01:12:17.680
I insert randomly from one,
two,
three negative words.

1058
01:12:18.100 --> 01:12:21.310
And I insert randomly from one,
two,
three positive words,

1059
01:12:21.580 --> 01:12:26.470
making sure it doesn't overlap with a negative words.
Okay.

1060
01:12:27.250 --> 01:12:29.050
What's the main advantage of this method?

1061
01:12:32.110 --> 01:12:34.030
Programmatic generation of samples?
Yeah,

1062
01:12:34.060 --> 01:12:37.270
program at some generation of samples and automated labeling.

1063
01:12:38.660 --> 01:12:41.230
I tend label,
I know where I inserted my positive words.

1064
01:12:42.540 --> 01:12:44.170
Can I just add ones where I inserted it?

1065
01:12:44.700 --> 01:12:48.940
I can generate millions of data examples like that just because I found the

1066
01:12:48.941 --> 01:12:53.650
right strategy to to create data.
You see the difference between the two methods,

1067
01:12:54.280 --> 01:12:58.540
the one where you have to go out and collect data and the one where you just go

1068
01:12:58.541 --> 01:13:01.840
out,
collect positive words,
negative words,

1069
01:13:01.870 --> 01:13:06.070
and then find background noise on youtube or wherever you have the right license

1070
01:13:06.071 --> 01:13:07.730
to use.
It's,

1071
01:13:07.900 --> 01:13:12.550
it's a big difference and this can make to make a company succeed compared to

1072
01:13:12.551 --> 01:13:17.140
another company,
it's very common.
So I would go on campus,

1073
01:13:17.570 --> 01:13:21.440
take one second audio clips of positive words,
put it into the database in green,

1074
01:13:21.980 --> 01:13:25.460
take one second.
Audio clips of negative words of the same people as well.

1075
01:13:25.520 --> 01:13:29.750
Put it in the pink database and get background noise from anywhere.

1076
01:13:29.751 --> 01:13:33.290
I can find it.
It's very cheap.
And then create these synthetic data,

1077
01:13:33.380 --> 01:13:38.140
label it automatic
and you know,
we'd like five positive words,

1078
01:13:38.141 --> 01:13:42.070
five negative words,
five backgrounds.
You can create a lot of data points.

1079
01:13:43.700 --> 01:13:44.533
<v 7>Okay.</v>

1080
01:13:44.860 --> 01:13:45.250
<v 5>Okay.</v>

1081
01:13:45.250 --> 01:13:48.520
So this is an important technique that you might want to think about in your

1082
01:13:48.521 --> 01:13:49.354
projects.

1083
01:13:50.260 --> 01:13:54.940
The second thing that is important for the success of such a project is the

1084
01:13:54.941 --> 01:13:58.150
architecture of search and hyper parameter to uni.
So all of you,

1085
01:13:58.151 --> 01:14:02.680
you will have complicated projects where you would be lost,

1086
01:14:02.760 --> 01:14:05.500
uh,
regarding Jean cur architecture to use.

1087
01:14:05.501 --> 01:14:09.510
At first it's a complicated process to find the architecture,
but you,

1088
01:14:09.550 --> 01:14:13.510
you should not give up.
And the first I would say is talk to the experts.

1089
01:14:13.660 --> 01:14:16.980
So let me tell you the story of this project.
Uh,

1090
01:14:18.310 --> 01:14:18.980
first I,

1091
01:14:18.980 --> 01:14:23.980
I started like looking at the literature and figuring out what network I could

1092
01:14:24.521 --> 01:14:28.030
use for this project.
And I ended up using that for,
for,
for the beginning part,

1093
01:14:28.510 --> 01:14:32.020
I use a four year transform to extract features from the speech who's familiar

1094
01:14:32.021 --> 01:14:34.000
with spectrum rams or four year transforms.

1095
01:14:35.110 --> 01:14:38.680
So for the others tinker about audio speech as a one d signal,

1096
01:14:39.070 --> 01:14:44.070
but everyone does signal can be decomposed in a sum of signs and Co signs with a

1097
01:14:44.651 --> 01:14:49.650
specific frequency and amplitude for each of these and so I can convert a one d

1098
01:14:49.651 --> 01:14:54.610
signal into a matrix for with with with basically

1099
01:14:59.090 --> 01:15:04.090
with basically one axis that is the frequency one axis.

1100
01:15:04.390 --> 01:15:09.010
That is the time going from going from zero to 10 seconds

1101
01:15:11.500 --> 01:15:16.390
and I will get the value of all the the amplitude of this frequency,

1102
01:15:16.480 --> 01:15:19.570
so maybe this one is a strong frequency is one is a strong frequency.

1103
01:15:19.760 --> 01:15:22.360
This one is a low one and so on for every time step.

1104
01:15:22.870 --> 01:15:25.210
This is a spectrogram of an audio speech.

1105
01:15:25.660 --> 01:15:27.250
You're going to learn a little bit more about that.

1106
01:15:27.251 --> 01:15:28.630
So after I got the Spectrogram,

1107
01:15:28.631 --> 01:15:31.540
which is better than the one the signal for the network,

1108
01:15:32.170 --> 01:15:36.340
I would use an LSTM which is a restaurant general network and add a sigmoid

1109
01:15:36.341 --> 01:15:41.341
layer after it to get probabilities between zero and one I will threshold them

1110
01:15:41.950 --> 01:15:46.660
everything.
We more than 0.5,
I would consider that it's a one,
everything less.

1111
01:15:46.661 --> 01:15:47.494
It's a zero.

1112
01:15:47.890 --> 01:15:52.630
I tried for a long time fitting this network on the data.
It didn't work,

1113
01:15:53.290 --> 01:15:57.140
but one day I was working on campus and I,
I,
I,

1114
01:15:57.310 --> 01:16:00.190
I found a friend that was an expert in spatial cognition.

1115
01:16:00.640 --> 01:16:04.570
He's worked a lot on all these problems and he exactly knew that this was not

1116
01:16:04.571 --> 01:16:06.880
going to work.
He could told me,
he could have told me.

1117
01:16:07.580 --> 01:16:11.230
So he told me there are several issues with this network.

1118
01:16:11.830 --> 01:16:16.210
The first one is you're hyper parameters in the fourier transform their wrong.

1119
01:16:16.720 --> 01:16:17.710
Go on my guitar.

1120
01:16:18.010 --> 01:16:21.100
You will find what hyper parameters are used for this four year transform.

1121
01:16:21.130 --> 01:16:24.880
You will find specifically what sampling rate,
what's window size,

1122
01:16:24.881 --> 01:16:27.730
what frequencies are used.
So that was better.

1123
01:16:28.480 --> 01:16:32.470
Then he said one issue is that your record neural network is too big.

1124
01:16:32.740 --> 01:16:37.000
It's super hard to train.
Instead,
you should reduce it.
So I've used,

1125
01:16:37.170 --> 01:16:41.040
so he told me to use the convolution to reduce the number of time steps of my

1126
01:16:41.041 --> 01:16:45.070
audio clip.
You will learn about all these layers later.
Uh,

1127
01:16:45.250 --> 01:16:46.450
and also use batch norm,

1128
01:16:46.630 --> 01:16:49.930
which is a specific type of layer that that makes the training easier.

1129
01:16:51.130 --> 01:16:55.180
And finally you get your sigmoid layer and you output zeros and ones,

1130
01:16:55.900 --> 01:17:00.900
but because the outputs time steps is smaller than the inputs,

1131
01:17:02.170 --> 01:17:05.230
you have to expand it.
So you need an expansion algorithm.

1132
01:17:05.231 --> 01:17:08.380
Just a script that expands every zero in two Zeros,

1133
01:17:08.440 --> 01:17:10.340
let's say in two ones and so on.

1134
01:17:11.240 --> 01:17:15.800
And now I get to another architecture that I managed to train within a day and

1135
01:17:15.801 --> 01:17:20.801
this was all because I was lucky enough to find the experts and gets advice from

1136
01:17:21.021 --> 01:17:21.854
this person.

1137
01:17:21.980 --> 01:17:25.970
So I think you will run into the same problems as I run into during your

1138
01:17:25.971 --> 01:17:26.780
projects.

1139
01:17:26.780 --> 01:17:30.770
The important thing is spend more time figuring out who is the expert and who

1140
01:17:30.771 --> 01:17:34.430
can tell you the answer rather than trying.
Yeah.
Trends and things.

1141
01:17:34.730 --> 01:17:39.200
I think this is uh,
an important thing to think about.
Okay.

1142
01:17:39.350 --> 01:17:43.670
So don't give up and also use their analysis,
which we're going to see later.

1143
01:17:44.760 --> 01:17:47.960
Uh,
we have two more minutes so I'm not going to go over this one.

1144
01:17:47.990 --> 01:17:49.680
I'm just going to talk about it quickly there.

1145
01:17:49.730 --> 01:17:54.020
Another way to solve wake word detection and the other way is to use the triplet

1146
01:17:54.021 --> 01:17:57.770
loss algorithm.
Instead of using anchor positive and negative faces,

1147
01:17:57.830 --> 01:18:02.030
you can use audio speech of one second.
Anchor is the word activate.

1148
01:18:03.410 --> 01:18:05.570
Positive is the word activates,

1149
01:18:05.571 --> 01:18:09.260
said differently and negative is another word.

1150
01:18:09.800 --> 01:18:11.330
You will train your network to encode,

1151
01:18:11.900 --> 01:18:16.900
activates in a certain vector and then compare the distance between vectors to

1152
01:18:16.941 --> 01:18:21.440
figure out this activate is present or not.
Okay.

1153
01:18:21.530 --> 01:18:25.640
We have about two more minutes,
so I'm going to,

1154
01:18:28.540 --> 01:18:32.280
my butt
is on me.

1155
01:18:33.360 --> 01:18:36.700
Uh,
so just to finish with two more slides,

1156
01:18:37.990 --> 01:18:39.670
now that you've seen some loss function,

1157
01:18:39.671 --> 01:18:44.671
I want to show you another one and I want you to tell me what application does

1158
01:18:45.251 --> 01:18:46.960
this beauty food loss correspond to

1159
01:18:49.090 --> 01:18:51.070
these one of the most beautiful loss I've seen him

1160
01:18:55.080 --> 01:18:57.760
<v 2>so someone can tell me what's the application,</v>

1161
01:18:57.761 --> 01:19:00.880
what problem are we trying to solve if we use this loss function?

1162
01:19:05.450 --> 01:19:06.283
<v 1>Okay.</v>

1163
01:19:07.920 --> 01:19:11.330
<v 2>Speech recognition.
No,
it's not the good,
good try.</v>

1164
01:19:13.530 --> 01:19:16.290
Regression.
That's true.
It's a regression problem,

1165
01:19:16.610 --> 01:19:18.240
but it's a specific regression problem.

1166
01:19:21.050 --> 01:19:25.610
Bounding box.
Good bounding boxes.
Object detection.
This is object detection,

1167
01:19:26.360 --> 01:19:28.280
so I put the paper here.
You can check it out,

1168
01:19:28.281 --> 01:19:29.720
but how do you know that it's objective

1169
01:19:29.720 --> 01:19:30.553
<v 5>detection?</v>

1170
01:19:33.270 --> 01:19:34.200
<v 2>Oh,
you've done it before.</v>

1171
01:19:38.470 --> 01:19:40.790
Okay,
so this is the last one.
She knows her network are called

1172
01:19:40.810 --> 01:19:45.800
<v 5>Yolo and the reason you can find out these bounding boxes is because if you look</v>

1173
01:19:45.801 --> 01:19:50.801
at the first year you would see that it's comparing x two two x predicted x two

1174
01:19:52.191 --> 01:19:56.660
through x predicted y to true why?
This is the center of a bounding box,
x,

1175
01:19:56.661 --> 01:19:59.720
y second term is w and h,

1176
01:19:59.930 --> 01:20:04.930
w and h stands for width and height of the bounding box and it's trying to

1177
01:20:05.061 --> 01:20:09.930
minimize the distance between the bounding box and the predicted bounding box.

1178
01:20:09.931 --> 01:20:14.670
Basically the third term has an ideal indicator function with objects.

1179
01:20:14.700 --> 01:20:18.720
It's saying if there is an object you should have a high probability of

1180
01:20:18.721 --> 01:20:23.550
objectness.
The fourth therm is saying that if there is no object,

1181
01:20:23.790 --> 01:20:26.040
you should have a lower probability of objectness.

1182
01:20:27.060 --> 01:20:30.900
And finally the final term is telling you you have to find a class that is in

1183
01:20:30.901 --> 01:20:34.440
this box.
Is it a chat?
Is the dog,
is it an elephant?
Is whatever.

1184
01:20:34.980 --> 01:20:39.570
So this is an object detection,
uh,
loss function.
Actually.
Do you know why?

1185
01:20:39.630 --> 01:20:41.160
Why you?
We have a square root here.

1186
01:20:45.380 --> 01:20:49.100
Hmm.
What was the TVT no products.

1187
01:20:51.490 --> 01:20:56.490
The reason we have the square roots is because you want to penalize more errors

1188
01:20:57.071 --> 01:20:59.860
on small bounding boxes rather than big bounding boxes.

1189
01:21:00.190 --> 01:21:03.430
So if I give you an image of a human like that,

1190
01:21:04.160 --> 01:21:08.380
indoor cats like this,
you can have,

1191
01:21:09.120 --> 01:21:13.390
so this box,
the one insight is the ground truth is a very tight box.

1192
01:21:13.840 --> 01:21:14.291
This one,

1193
01:21:14.291 --> 01:21:18.940
same and the box that are predicted or the predictions.

1194
01:21:19.000 --> 01:21:22.450
So these are the predictions and the other ones are the ground truth.

1195
01:21:23.260 --> 01:21:28.260
What is interesting is that a two pixel error on these cats is much more

1196
01:21:29.441 --> 01:21:33.040
important than a two pixel air on this human,
because the box is smaller.

1197
01:21:33.490 --> 01:21:38.490
So that's why you use a square root to penalize more the errors on small boxes

1198
01:21:39.250 --> 01:21:43.690
then on big boxes.
Okay.
And finally,
the final slide.
Okay,

1199
01:21:43.691 --> 01:21:48.530
let's go over the,
so just recalling what we have for next week,

1200
01:21:49.600 --> 01:21:52.540
you have two modules to complete for next Wednesday.
Uh,

1201
01:21:52.660 --> 01:21:56.620
which are [inaudible] with the following quiz and the following programming

1202
01:21:56.621 --> 01:22:00.580
assignments,
c one m four,
with one quiz and true programming assignments.

1203
01:22:00.581 --> 01:22:02.960
You're going to build your first deep neural network.

1204
01:22:03.540 --> 01:22:05.020
This is all going to be on the web.

1205
01:22:05.030 --> 01:22:08.350
It's already on the website and we'll publish just slides.
Now,
uh,

1206
01:22:08.650 --> 01:22:11.710
you have ta project mentorship that is mandatory,
this switch.

1207
01:22:11.980 --> 01:22:16.870
So ta Project mentorships are mandatory this week to start the week before the

1208
01:22:16.871 --> 01:22:20.380
project proposal.
The week before the project?
No,
after the price proposal,

1209
01:22:20.590 --> 01:22:25.090
after the project milestone and before the final project submission.
Okay.

1210
01:22:25.540 --> 01:22:26.680
And Fry ATS sections,

1211
01:22:26.681 --> 01:22:30.490
you're going to do some neural style transfer and our generation,
uh,

1212
01:22:30.540 --> 01:22:33.270
fill in the AWS forum.
I don't know if it's been done yet.

1213
01:22:33.280 --> 01:22:37.990
We were going to try to give you some credits for your projects with gps.

1214
01:22:39.040 --> 01:22:40.480
Okay.
Thanks guys.

