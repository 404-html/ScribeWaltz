1
00:00:00,240 --> 00:00:03,850
Sometimes people think that emotion,
uh,

2
00:00:03,930 --> 00:00:07,740
and art are sort of side shows,
the human intelligence,

3
00:00:08,220 --> 00:00:09,053
the real essence of intelligence.
It's thinking logically if that were 

4
00:00:11,641 --> 00:00:12,474
true computers already smarter than we 
are and because so much better at 

5
00:00:15,031 --> 00:00:17,850
logical thinking that we are.
Uh,

6
00:00:17,940 --> 00:00:18,773
it's actually things like being funny,
being sexy or expressing a loving 

7
00:00:23,761 --> 00:00:27,450
sentiment maybe in a poem or an a 
musical piece.

8
00:00:28,160 --> 00:00:28,993
That's the cutting edge of human 
intelligence has to do with the 

9
00:00:31,081 --> 00:00:35,250
hierarchy of the NEOCORTEX and at the 
low levels,

10
00:00:35,280 --> 00:00:36,113
uh,
things may seem cold and mechanical 

11
00:00:37,981 --> 00:00:42,981
cause where our neocortex can recognize 
very simple objects and make very simple

12
00:00:43,291 --> 00:00:44,124
decisions at a high level.
It's dealing with concepts like the 

13
00:00:48,661 --> 00:00:51,050
beauty of a poem by Emily Dickinson or 
the,

14
00:00:51,060 --> 00:00:52,830
or the ability to create a poem like 
that.

15
00:00:52,831 --> 00:00:56,610
And we can come back to creativity.
I believe it's an exercise in,

16
00:00:57,100 --> 00:00:58,110
in metaphors.

17
00:00:58,110 --> 00:01:01,560
And the NEOCORTEX is a metaphor machine.
That's what it's good at.

18
00:01:02,100 --> 00:01:02,933
That's why humans are creative.
But we have this very large hierarchy 

19
00:01:07,411 --> 00:01:12,180
where we have more and more abstract and
complex patterns.

20
00:01:12,490 --> 00:01:14,520
You know,
Bill's on patterns below it.

21
00:01:15,270 --> 00:01:19,420
And the difference between humans and 
say other primates is,

22
00:01:19,421 --> 00:01:22,830
so we have more of the Neocortex,
we have this big forehead,

23
00:01:22,950 --> 00:01:23,783
we could fit it in the frontal cortex 
and therefore have a higher number of 

24
00:01:27,390 --> 00:01:28,223
hierarchies of levels of the hierarchy.
And that was the enabling factor that 

25
00:01:32,220 --> 00:01:36,960
that permitted the evolution of language
and technology and art and science.

26
00:01:36,990 --> 00:01:37,823
We're going to create synthetic 
neocortex is based on the same 

27
00:01:41,131 --> 00:01:43,200
principles.
I'm actually working on that.

28
00:01:43,860 --> 00:01:44,693
Uh,
and we've had hierarchical systems like 

29
00:01:48,571 --> 00:01:49,404
that.
I helped pioneer a concept called 

30
00:01:51,841 --> 00:01:55,410
hierarchical hidden Markov models 
similar to what happens in the brain,

31
00:01:55,411 --> 00:01:57,660
but we only had a few levels.

32
00:01:58,520 --> 00:01:59,353
The brain has a very large number of 
levels and all the way from recognizing 

33
00:02:03,211 --> 00:02:05,490
edges of objects up to,
you know,

34
00:02:05,520 --> 00:02:06,353
she's beautiful or creating a beautiful 
painting or work of music or scientific 

35
00:02:11,131 --> 00:02:13,350
insight.
Um,

36
00:02:14,130 --> 00:02:16,830
we will create artificial neocortex,
it said,

37
00:02:16,831 --> 00:02:19,320
have a comparable number or a greater 
number.

38
00:02:19,820 --> 00:02:20,653
And,
and I think the principal application 

39
00:02:22,711 --> 00:02:25,530
will actually be to extend our own 
neocortex.

40
00:02:26,190 --> 00:02:30,660
We have 300 million pattern recognizers 
in the neocortex by my estimate.

41
00:02:31,260 --> 00:02:32,093
That hierarchy we build ourselves.
Each of these pattern recognizers 

42
00:02:35,251 --> 00:02:39,960
capable of connecting itself to other 
neocortex is to build this hierarchy.

43
00:02:39,961 --> 00:02:43,950
We build that hierarchy from the moment 
we're born or before that,

44
00:02:44,510 --> 00:02:46,320
uh,
we're constantly building it,

45
00:02:47,130 --> 00:02:50,910
but we run up against this limitation of
300 million.

46
00:02:51,770 --> 00:02:54,240
We'll be able to extend that and 
thinking the cloud,

47
00:02:54,780 --> 00:02:55,613
you know,
if you do anything interesting with 

48
00:02:56,401 --> 00:02:59,920
this,
do a search or language or,

49
00:03:00,450 --> 00:03:02,890
uh,
bring up a map or ask it a question.

50
00:03:02,890 --> 00:03:06,190
It doesn't take place in the box.
It goes out to the cloud.

51
00:03:06,700 --> 00:03:10,240
We're going to put these just really w,
uh,

52
00:03:10,330 --> 00:03:14,770
gateways a gateway to the cloud.
We're going to put gateways to the cloud

53
00:03:14,771 --> 00:03:17,950
in our brains and have more than 300 
million.

54
00:03:18,600 --> 00:03:19,433
Uh,
just like the cloud can give you a 

55
00:03:21,760 --> 00:03:23,380
thousand or a million computers for a 
10th of a second,

56
00:03:23,860 --> 00:03:28,630
you need another billion pattern.
Recognizers uh,

57
00:03:29,040 --> 00:03:29,873
uh,
you'll be able to access that in the 

58
00:03:31,241 --> 00:03:33,370
cloud.
That's where we're headed.

59
00:03:34,170 --> 00:03:36,490
And it will be more intelligent,
uh,

60
00:03:36,500 --> 00:03:39,100
enabled to actually think in a greater 
number of hierarchies.

61
00:03:39,101 --> 00:03:39,934
If you think that realized that the 
quantitative improvement from primates 

62
00:03:45,011 --> 00:03:49,720
to humans with a big forehead to allow 
larger Neocortex,

63
00:03:50,220 --> 00:03:52,630
uh,
was the enabling factor for language art

64
00:03:52,631 --> 00:03:55,180
and music and science.
Uh,

65
00:03:55,181 --> 00:03:59,320
what kind of qualitative leap can we 
make with another quantitative increase?

66
00:04:00,040 --> 00:04:02,140
And that's,
that's I think where we're headed.

67
00:04:04,960 --> 00:04:05,793
Okay.

