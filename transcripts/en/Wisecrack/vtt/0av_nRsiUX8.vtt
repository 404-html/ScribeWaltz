WEBVTT

1
00:00:02.070 --> 00:00:06.720
<v Speaker 1>A data science,</v>
<v Speaker 1>ai,</v>

2
00:00:06.990 --> 00:00:07.823
<v Speaker 1>machine learning,</v>
<v Speaker 1>or these are all things that are in the </v>

3
00:00:10.260 --> 00:00:11.093
<v Speaker 1>middle year right now.</v>
<v Speaker 1>I think if they fundamentally point at </v>

4
00:00:12.661 --> 00:00:13.494
<v Speaker 1>the same idea,</v>
<v Speaker 1>the same concept around my call it </v>

5
00:00:16.680 --> 00:00:17.513
<v Speaker 1>machine intelligence,</v>
<v Speaker 1>where it's about how do you use </v>

6
00:00:20.520 --> 00:00:23.760
<v Speaker 1>computers and the vast amount of data </v>
<v Speaker 1>that's out there,</v>

7
00:00:23.910 --> 00:00:24.743
<v Speaker 1>that kind of big data and then leverage </v>
<v Speaker 1>that to make more intelligent decisions </v>

8
00:00:28.860 --> 00:00:30.870
<v Speaker 1>as an organization.</v>
<v Speaker 1>Um,</v>

9
00:00:30.960 --> 00:00:33.180
<v Speaker 1>as a government,</v>
<v Speaker 1>as a nonprofit,</v>

10
00:00:33.510 --> 00:00:38.510
<v Speaker 1>this really comes from a few major </v>
<v Speaker 1>secular trends that are happening.</v>

11
00:00:39.360 --> 00:00:42.840
<v Speaker 1>One is the plummeting cost of </v>
<v Speaker 1>computation,</v>

12
00:00:43.280 --> 00:00:45.180
<v Speaker 1>uh,</v>
<v Speaker 1>and the plumbing costs of storage.</v>

13
00:00:45.390 --> 00:00:46.223
<v Speaker 1>So now we have the capacity to store </v>
<v Speaker 1>that data relatively cheaply and three </v>

14
00:00:50.800 --> 00:00:52.710
<v Speaker 1>other process that data relatively </v>
<v Speaker 1>cheaply.</v>

15
00:00:53.400 --> 00:00:54.233
<v Speaker 1>And then the other major trend is that </v>
<v Speaker 1>everyone's walking around with </v>

16
00:00:57.370 --> 00:01:00.360
<v Speaker 1>smartphones.</v>
<v Speaker 1>Everyone's interacting with the Internet</v>

17
00:01:00.361 --> 00:01:01.194
<v Speaker 1>for a large part portion of the day.</v>
<v Speaker 1>And so we're able to capture huge parts </v>

18
00:01:04.621 --> 00:01:05.454
<v Speaker 1>of the human experience and digitize </v>
<v Speaker 1>that information and store it in the </v>

19
00:01:08.641 --> 00:01:09.474
<v Speaker 1>cloud.</v>

20
00:01:09.720 --> 00:01:12.810
<v Speaker 1>So when we have all these connected </v>
<v Speaker 1>devices that are measuring us,</v>

21
00:01:13.390 --> 00:01:15.690
<v Speaker 1>we can actually understand a lot about </v>
<v Speaker 1>human behavior.</v>

22
00:01:16.110 --> 00:01:17.730
<v Speaker 1>And that's actually really,</v>
<v Speaker 1>really fascinating.</v>

23
00:01:18.190 --> 00:01:22.200
<v Speaker 1>Um,</v>
<v Speaker 1>and we're from that we're able to create</v>

24
00:01:22.320 --> 00:01:23.880
<v Speaker 1>products,</v>
<v Speaker 1>services,</v>

25
00:01:24.120 --> 00:01:24.953
<v Speaker 1>uh,</v>
<v Speaker 1>that are so much more rich and so much </v>

26
00:01:27.661 --> 00:01:31.260
<v Speaker 1>more personalized than we've been able </v>
<v Speaker 1>to do before.</v>

27
00:01:31.560 --> 00:01:35.820
<v Speaker 1>And so if you think about maybe even the</v>
<v Speaker 1>simplest example might be something like</v>

28
00:01:35.910 --> 00:01:37.050
<v Speaker 1>a Netflix,</v>
<v Speaker 1>right?</v>

29
00:01:37.051 --> 00:01:37.884
<v Speaker 1>With recommendation engine that's able </v>
<v Speaker 1>to serve up content in a very targeted </v>

30
00:01:42.541 --> 00:01:44.430
<v Speaker 1>way.</v>
<v Speaker 1>So that's they give you,</v>

31
00:01:44.490 --> 00:01:46.700
<v Speaker 1>they show you out of there,</v>
<v Speaker 1>you know,</v>

32
00:01:46.730 --> 00:01:47.563
<v Speaker 1>library of probably millions of possible</v>
<v Speaker 1>videos where you watch the five to 10 </v>

33
00:01:52.411 --> 00:01:54.420
<v Speaker 1>that you're most likely to want to </v>
<v Speaker 1>watch.</v>

34
00:01:54.421 --> 00:01:55.254
<v Speaker 1>And they can do this from what's called </v>
<v Speaker 1>a lookalike analysis where they will </v>

35
00:01:58.531 --> 00:01:59.364
<v Speaker 1>look at what other people who have </v>
<v Speaker 1>watched a similar set of videos as you </v>

36
00:02:04.861 --> 00:02:07.710
<v Speaker 1>have,</v>
<v Speaker 1>how have they've rated those videos,</v>

37
00:02:07.740 --> 00:02:08.573
<v Speaker 1>how much they've liked those videos,</v>
<v Speaker 1>and then see what other videos those </v>

38
00:02:11.341 --> 00:02:13.860
<v Speaker 1>people of light that you haven't yet </v>
<v Speaker 1>watched.</v>

39
00:02:14.340 --> 00:02:17.040
<v Speaker 1>And that's probably a good candidate for</v>
<v Speaker 1>a video that you should wash,</v>

40
00:02:17.550 --> 00:02:20.190
<v Speaker 1>right?</v>
<v Speaker 1>So that kind of look alike analysis.</v>

41
00:02:20.191 --> 00:02:21.024
<v Speaker 1>Or if you're a data scientist,</v>
<v Speaker 1>you'd probably call that a </v>

42
00:02:22.591 --> 00:02:23.424
<v Speaker 1>recommendation engine.</v>
<v Speaker 1>That's actually a very powerful </v>

43
00:02:26.041 --> 00:02:27.390
<v Speaker 1>technique,</v>
<v Speaker 1>uh,</v>

44
00:02:27.450 --> 00:02:28.283
<v Speaker 1>and it's sort of very fundamental to a </v>
<v Speaker 1>business that has tens of millions of </v>

45
00:02:32.520 --> 00:02:34.260
<v Speaker 1>videos and they know you're only going </v>
<v Speaker 1>to watch one tonight,</v>

46
00:02:34.750 --> 00:02:36.780
<v Speaker 1>right?</v>
<v Speaker 1>How do you pick out that one good video?</v>

47
00:02:36.781 --> 00:02:39.870
<v Speaker 1>So that's not just a huge search problem</v>
<v Speaker 1>is for a consumer,</v>

48
00:02:39.930 --> 00:02:43.080
<v Speaker 1>but it's actually a pleasurable </v>
<v Speaker 1>experience for them and that's,</v>

49
00:02:43.440 --> 00:02:46.020
<v Speaker 1>you know,</v>
<v Speaker 1>has implications beyond Netflix,</v>

50
00:02:46.021 --> 00:02:49.260
<v Speaker 1>right?</v>
<v Speaker 1>If you think about a company like Amazon</v>

51
00:02:49.590 --> 00:02:52.220
<v Speaker 1>that's incredibly important for them,</v>
<v Speaker 1>uh,</v>

52
00:02:52.440 --> 00:02:55.410
<v Speaker 1>they have billions of items on their </v>
<v Speaker 1>store.</v>

53
00:02:56.130 --> 00:02:56.963
<v Speaker 1>You need to be able to figure out what </v>
<v Speaker 1>to buy and so they can tell you the </v>

54
00:03:01.571 --> 00:03:02.404
<v Speaker 1>right item.</v>
<v Speaker 1>They can maybe get you to buy something </v>

55
00:03:04.300 --> 00:03:05.133
<v Speaker 1>that you otherwise would have purchased </v>
<v Speaker 1>and that's know has a direct impact on </v>

56
00:03:09.311 --> 00:03:10.144
<v Speaker 1>their bottom line.</v>

57
00:03:10.180 --> 00:03:11.710
<v Speaker 1>And it also makes consumers happier,</v>
<v Speaker 1>right?</v>

58
00:03:11.711 --> 00:03:12.544
<v Speaker 1>It helps you reduce the amount of time </v>
<v Speaker 1>you spend searching for products and </v>

59
00:03:15.341 --> 00:03:16.174
<v Speaker 1>services.</v>
<v Speaker 1>So I think these kind of data enabled </v>

60
00:03:18.970 --> 00:03:23.170
<v Speaker 1>services where companies can give you </v>
<v Speaker 1>what you want when you want it,</v>

61
00:03:23.500 --> 00:03:24.333
<v Speaker 1>that's becoming increasingly powerful </v>
<v Speaker 1>within the kind of consumer markets and </v>

62
00:03:31.031 --> 00:03:36.031
<v Speaker 1>it's becoming increasingly the standard.</v>
<v Speaker 1>So I think what we've seen is that for a</v>

63
00:03:36.311 --> 00:03:38.520
<v Speaker 1>lot of legacy enterprises,</v>
<v Speaker 1>um,</v>

64
00:03:39.160 --> 00:03:39.993
<v Speaker 1>that are not digital first,</v>
<v Speaker 1>that haven't been able to embrace data </v>

65
00:03:42.881 --> 00:03:45.490
<v Speaker 1>and data science,</v>
<v Speaker 1>there's a,</v>

66
00:03:45.940 --> 00:03:46.773
<v Speaker 1>almost a kind of an adversarial </v>
<v Speaker 1>relationship between the consumer and </v>

67
00:03:49.481 --> 00:03:52.990
<v Speaker 1>that product or service where you're </v>
<v Speaker 1>saying as a consumer,</v>

68
00:03:53.260 --> 00:03:54.093
<v Speaker 1>hey,</v>
<v Speaker 1>I have this great experience when I'm </v>

69
00:03:56.260 --> 00:04:00.010
<v Speaker 1>interacting with facebook or google or </v>
<v Speaker 1>Netflix,</v>

70
00:04:00.011 --> 00:04:03.640
<v Speaker 1>they seem to give me what I want.</v>
<v Speaker 1>Why can't you give me what I want?</v>

71
00:04:04.000 --> 00:04:07.570
<v Speaker 1>And when you experienced that,</v>
<v Speaker 1>right,</v>

72
00:04:08.200 --> 00:04:10.840
<v Speaker 1>there's a lot of fear on the part of </v>
<v Speaker 1>those companies,</v>

73
00:04:10.841 --> 00:04:15.841
<v Speaker 1>the legacy companies that their ability </v>
<v Speaker 1>to sort of maintain that market is going</v>

74
00:04:16.471 --> 00:04:17.304
<v Speaker 1>to rapidly evaporates and it's going to </v>
<v Speaker 1>be deteriorate rates at a really quick </v>

75
00:04:21.851 --> 00:04:24.700
<v Speaker 1>rate if any of these sort of digital </v>
<v Speaker 1>companies,</v>

76
00:04:24.960 --> 00:04:25.793
<v Speaker 1>uh,</v>
<v Speaker 1>enter that market because they </v>

77
00:04:26.951 --> 00:04:28.300
<v Speaker 1>understand how to leverage data.</v>

78
00:04:28.360 --> 00:04:31.070
<v Speaker 1>They understand how to use that,</v>
<v Speaker 1>uh,</v>

79
00:04:31.140 --> 00:04:34.540
<v Speaker 1>the information they have or consumers </v>
<v Speaker 1>to give consumers a fundamentally better</v>

80
00:04:34.750 --> 00:04:35.583
<v Speaker 1>product.</v>
<v Speaker 1>There's obviously a lot in the news </v>

81
00:04:38.021 --> 00:04:40.550
<v Speaker 1>about Cambridge Analytica,</v>
<v Speaker 1>um,</v>

82
00:04:40.960 --> 00:04:45.960
<v Speaker 1>facebook and how we societaly deal with </v>
<v Speaker 1>data and how we are,</v>

83
00:04:47.330 --> 00:04:49.750
<v Speaker 1>how we should deal with data.</v>
<v Speaker 1>Should there be regulation?</v>

84
00:04:49.751 --> 00:04:52.100
<v Speaker 1>Should we have more privacy protections?</v>
<v Speaker 1>Um,</v>

85
00:04:52.510 --> 00:04:55.510
<v Speaker 1>and I think these are really interesting</v>
<v Speaker 1>and valid questions.</v>

86
00:04:55.780 --> 00:04:56.613
<v Speaker 1>Uh,</v>
<v Speaker 1>we,</v>

87
00:04:56.680 --> 00:04:59.200
<v Speaker 1>we as a society should ask,</v>
<v Speaker 1>right?</v>

88
00:05:00.190 --> 00:05:01.023
<v Speaker 1>And it seems that's where entering a </v>
<v Speaker 1>period where there's certainly within </v>

89
00:05:04.811 --> 00:05:05.644
<v Speaker 1>Europe with the passenger Gdpr,</v>
<v Speaker 1>there is increasing reluctance to just </v>

90
00:05:08.951 --> 00:05:11.980
<v Speaker 1>say a facebook,</v>
<v Speaker 1>Google,</v>

91
00:05:12.070 --> 00:05:15.940
<v Speaker 1>you can have free reign over all of our </v>
<v Speaker 1>data in an unchecked way.</v>

92
00:05:16.210 --> 00:05:19.420
<v Speaker 1>And I think we'll see what happens as we</v>
<v Speaker 1>move forward,</v>

93
00:05:19.900 --> 00:05:20.733
<v Speaker 1>uh,</v>
<v Speaker 1>with a regulation and this kind of </v>

94
00:05:24.550 --> 00:05:25.870
<v Speaker 1>consumer protections.</v>

